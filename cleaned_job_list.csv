Title,Company,Location,Type of Positions,Job Description,Salary,Identified_Skills
"Staff Applied Scientist, Marketplace",ThredUp Inc.,CA,Full-time,"
About thredUP thredUP is transforming resale with technology and a mission to inspire a new generation of consumers to think secondhand first. By making it easy to buy and sell secondhand, thredUP has become one of the world's largest online resale platforms for apparel, shoes and accessories. Sellers love thredUP because we make it easy to clean out their closets and unlock value for themselves or for the charity of their choice while doing good for the planet. Buyers love shopping value, premium and luxury brands all in one place, at up to 90% off estimated retail price. Our proprietary operating platform is the foundation for our managed marketplace and consists of distributed processing infrastructure, proprietary software and systems and data science expertise. With thredUP's Resale-as-a-Service, some of the world's leading brands and retailers are leveraging our platform to deliver customizable, scalable resale experiences to their customers. thredUP has processed over 172 million unique secondhand items from 55,000 brands across 100 categories. By extending the life cycle of clothing, thredUP is changing the way consumers shop and ushering in a more sustainable future for the fashion industry.

 Job Description
 As thredUP leads the charge in sustainable fashion, we seek an Applied Scientist with a focus on pricing and marketplace optimization. Your role is to balance the equation between supply and demand, using your expertise in economics and data science to optimize our two-sided marketplace. This position calls for an analytical savant who is passionate about modeling complex systems and generating insights that drive strategic pricing and marketplace health.  How You Will Make an Impact:
 As an Applied Scientist, your work will be pivotal in creating an equilibrium that benefits both sellers and buyers, ensuring competitive pricing while maintaining healthy marketplace dynamics. By crafting and refining pricing algorithms, you will directly contribute to thredUP’s mission of inspiring a new generation to think secondhand first.

 In This Role You’ll Get To:

 Develop and implement dynamic pricing models to optimize marketplace liquidity and profitability.
 Conduct in-depth analysis of marketplace trends to inform pricing strategies and inventory selection.
 Utilize econometric methods to forecast market behaviors and identify revenue-maximizing opportunities.
 Collaborate with data science and engineering teams to integrate your models into our marketplace platform.
 Design and analyze A/B tests to understand the impact of pricing strategies on customer behavior and marketplace performance.
 Provide thought leadership on marketplace economics, influencing strategic decisions across the company.


 What we are looking for:

 M.S or Ph.D.degree in Economics, Statistics, Applied Mathematics, or a related field.
 3+ years of industry experience as Applied or Data Scientist or equivalent
 Experience applying machine learning techniques and statistical analysis to complex economic problems.
 Proficiency in data querying and manipulation with SQL, along with programming skills in Python.
 Experience with big data technologies
 Experience communicating complex concepts clearly to cross-functional teams.
 Experience with optimization modeling techniques (Linear Programming, Mixed Integer Programming) and advanced statistical modeling techniques


 Preferred but not required:

 6+ years of industry experience
 Familiarity with AWS
 Experience in marketplace dynamics or pricing strategy


 At thredUP, your base pay is one part of your total compensation package. This role pays between $190,000 and $230,000, and your actual base pay will depend on your skills, qualifications, experience, and location.  Many thredUP employees also have the opportunity to own shares of thredUP stock. thredUP employees are eligible for discretionary restricted stock unit awards, as well as a discount when purchasing thredUP stock if voluntarily participating in thredUP’s Employee Stock Purchase Plan. Subject to eligibility requirements, you’ll also receive other benefits: Comprehensive medical & dental coverage, vision, 401k, life and disability insurance.
 What We Offer:

 4-day work week, with Fridays off
 Hybrid work environment: 3 days in the office and 1 day remote each week
 Competitive salary (we leverage market data)
 Many thredUP employees also have the opportunity to own shares of thredUP stock and are eligible for discretionary restricted stock unit awards
 Employee stock purchase plan
 Flexible PTO (take the time you need) + 13 company holidays
 Paid Sabbatical after 3 years of full time employment
 Generous paid parental leave for new mothers and fathers
 Medical, dental, vision, 401k, life and disability insurance offered
 We live by our Core Values of Transparency, SpeakingUP, Thinking Big, Infinite Learning, Influencing Outcomes & Seeking the Truth
 TIME Magazine’s Most Influential Companies of 2023, WWD’s Most Influential ESG Leaders, TIME Magazine’s Best Inventions 2022, Shoptalk’s ATLIS Awards, Business Insider’s Retail Tech Power Players, Inc.’s Power Partner Awards, Lattice’s People Success Awards, Digiday's WorkLife 50 award
 RaaS - Inc. Magazine, 2022 Power Partner Awards
 Thrift the Look– TIME Magazine, The Best Inventions of 2022
 Winner of Lattice's “People Vision” - recognizing thredUP as a top place to work for our investment in professional development and our innovations in work-life integration


 We believe diversity, inclusion and belonging is key for our team
 At thredUP, our mission has been built on extending the lives of millions of unique clothing items. Much like our inventory, we are proud to have fostered a workplace that is one-of-a-kind. As a company focused on diversity, inclusion and belonging, we are committed to ensuring our employees are comfortable bringing their authentic selves to work every day. A unique perspective is critical to solving complex problems and inspiring a new generation to think secondhand first. Be you.

 If you are a candidate with a disability and have a reasonable accommodation request for the job application process, please email disabilitysupport@thredup.com the specific details of your disability related accommodation request. This email address is reserved for candidates with disabilities only. General application inquiries will not receive a response.
",190000,"['python', 'machine learning', 'aws', 'sql']"
Prompt Engineer for Generative AI (chatbot and image),Vicarious Talent Agency,WA,Full-time,"We are Vicarious, a talent agency that represents established and emerging creatives all across the world! We’re currently seeking Prompt Engineers of all levels for Generative AI projects with our awesome clients.
What you’ll be doing:

Working collaboratively with cross-functional teams to discuss product development, identify uses of AI tools, and figure out ways algorithms can make workflows more efficient
Drafting, refining, and testing text prompts to make sure they are yielding the desired outcome
Integrating AI chatbots, image generators, and coding platforms into the client’s workflows efficiently
Optimizing text prompts based on feedback from clients
Staying up to date with the latest developments in AI and machine learning

What we’d like to see from you:

Demonstrated use of a variety of AI frameworks
Experience in developing and deploying chatbot or conversational AI systems
In-depth knowledge of natural language processing techniques
Understanding of deep learning architectures and frameworks
Proficiency in computer vision and image generation techniques
Ability to work independently and collaboratively within a team, and implement feedback quickly
Excellent problem-solving and analytical abilities
Strong communication skills

We work with corporate and agency clients, and roles could be from a few hours on up to full-time permanent. Roles can be onsite, remote, or hybrid.
Compensation is based on experience, and we provide healthcare benefits. There’s an opportunity for a 401(k) after 6 months.
The team behind Vicarious has been enmeshed in the advertising, marketing, design & art industries for decades and we’d like to represent you when our clients need creative solutions.
​​​Please reply with your work samples and resume. Cheers!
Vicarious is an equal-opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.“Prompt Engineer for Generative AI (chatbot and image)”Responsibilities:
- Design, develop, and implement software solutions using Java and other programming languages.- Utilize AWS services to build scalable and reliable applications.- Perform data mining and analysis to extract insights and drive decision-making.- Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions.- Work on quantum engineering projects to develop cutting-edge technologies.- Develop VBA scripts for automation and process improvement.- Apply machine learning and AI techniques to solve complex problems.- Utilize programming languages such as R, SAS, and Python for statistical analysis and modeling.- Design and implement ETL processes to extract, transform, and load data.
Skills:
- Strong proficiency in Java programming language.- Experience with AWS services such as EC2, S3, Lambda, etc.- Knowledge of data mining techniques and tools.- Familiarity with quantum engineering principles and technologies.- Proficiency in VBA scripting for automation tasks.- Understanding of machine learning algorithms and frameworks.- Knowledge of programming languages such as R, SAS, or Python for statistical analysis.- Experience with ETL processes and tools.
We are looking for a skilled Engineer who is passionate about technology and has a strong background in software development. The ideal candidate will have experience with Java programming, AWS services, data mining, quantum engineering, VBA scripting, machine learning, AI, statistical analysis using R/SAS/Python, and ETL processes. If you are a problem solver with a strong attention to detail and the ability to work in a fast-paced environment, we would love to hear from you. Join our team and be part of exciting projects that push the boundaries of technology.
Job Type: Contract
Pay: $35.00 - $55.00 per hour
Expected hours: 15 – 40 per week
Benefits:

401(k)
Health insurance

Experience level:

1 year

Work Location: Hybrid remote in Seattle, WA 98122",70000,"['python', 'machine learning', 'deep learning', 'aws', 'etl']"
Data Systems Analyst/Architect,General Dynamics Information Technology,Remote,Full-time,"Clearance Level None Category Data Science Location Remote, Working from the USA 


Public Trust: MBI Full 5C (T3) 
Requisition Type: Regular 
Your Impact 
Own your opportunity to work alongside federal civilian agencies. Make an impact by providing services that help the government ensure the well being of U.S. citizens.
 Job Description

 GDIT is seeking a Data Systems Analyst/Architect to support the NIH Office of Management (OM) Administrative Systems Technology Officer (ASTO) in undertaking a multi-year effort to implement a large-scale data strategy and governance program. This initiative represents a foundational change in the data support model throughout the enterprise performance lifecycle (EPLC) of the numerous systems which provide decision support data to the multiple mission-critical areas of responsibility within the OM. This position is an internal and external customer-facing role that works directly with leadership, stakeholders, business management teams, and technical management teams to build relationships with stakeholders and exceed their expectations.

 You will serve as a liaison between the ASTO and NIH stakeholders to modernize business systems data architecture by implementing NIH’s Digital Strategy. Other responsibilities include, but are not limited to, support for project management activities, data integration requirements, system integration management, and administrative support.

 Work Visa sponsorship will not be provided for this role.  HOW A DATA SYSTEMS ANALYST/ARCHITECT WILL MAKE AN IMPACT

 Lever expertise in enterprise data architecture, management, and governance to lead projects and teams of internal and external stakeholders
 Gather and document system design requirements, coordinate interviews for data documentation and analysis. Document ‘as is’ state of system and projected future state, including performing intersystem data mapping as needed. Present findings to stakeholders, and document processes and lessons learned
 Lead the development of analytic systems approach and framework design in cooperation with internal partners
 Present future design scenarios with strengths and weaknesses of each option. Score design options based on ability to fulfill stakeholder requirements within the technical constraints of the deployment environment
 Ensure the final design fits the customer requirements and is a scalable, open model that can be handed off to the customer to perpetuate once initial implementation is completed


 WHAT YOU’LL NEED TO SUCCEED


 Education: MS (or equivalent experience);



Required Experience: Minimum of 8 years of experience planning and implementing IT solutions from diverse software platforms across large and diverse organizations
Required Technical Skills:


 Minimum of six years with modern database architectures, such as RDBMS, NoSQL, key value
 Good understanding of leading cloud platforms, including AWS, Azure, and Google
 Familiarity with data governance
 Minimum of four years of experience with data cataloging
 Minimum of four years of experience with Extract, Transform, Load (ETL) processes and tools
 Familiarity with Project Management Institute (PMI) project management tools, techniques, and documentation with the ability to prescribe those into adaptable and flexible project plans
 Experience with communications and customer engagement for enterprise-wide software platform applications
 Experience contributing to change management and project management plans on large-scale projects
 Excellent Business Case development capabilities to include risk identification and risk management


Security Clearance: Ability to acquire Level 5 Public Trust
Required Skills and Abilities:


 Ability to effectively communicate and the ability to lead discussions with strong facilitation skills
 Ability to exhibit professional diplomacy, while effectively relating to people at all organizational levels internally and externally
 Proficiency in the use and integration of Microsoft 365 applications; specifically, Outlook, Teams, Word, Excel, Planner, Lists, Forms, and PowerPoint
 Experience working on multiple projects at once, balancing priorities and multitasking


Preferred Skills:


 Minimum of two years of direct experience working with NIH or other federal agencies within HHS
 Experience determining requirements for artifacts and records required by the HHS Enterprise Performance Lifecycle framework
 Experience with IT Infrastructure Library (ITIL) processes for ITSM
 Agile, SAFe, or other certifications for ITSM delivery
 Understanding of Artificial Intelligence and Machine Learning technologies
 Literacy with and the ability to ensure compliance with Federal requirements for accounting, record-keeping, project management, security, and other regulatory requirements


Location: Remote

 GDIT IS YOUR PLACE:
  

401K with company match
Comprehensive health and wellness packages
Internal mobility team dedicated to helping you own your career
Professional growth opportunities including paid education and certifications
Cutting-edge technology you can learn from
Rest and recharge with paid vacation and holidays


 #GDITFedHealthJobs
 #GDITFedHealthJobs-NIH
 #GDITPriority

",104000,"['machine learning', 'aws', 'azure', 'nosql', 'etl']"
AIOps Principle Data Scientist,CVS Health,CT,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary We are seeking a highly skilled and experienced Principal Data Scientist to lead our AIOps initiatives. As the Principal Data Scientist, you will play a crucial role in developing and implementing advanced data science models and algorithms to optimize our operations and enhance overall stability, resiliency and performance.

 Responsibilities include:

 Strategy and Leadership: Execute a strategic vision for AIOps problem sets leveraging data science techniques. Provide leadership in aligning AIOps initiatives with organizational goals.
 Algorithm development: Design, develop and deploy advanced machine learning and statistical models to analyze and interpret complex datasets. Ensure the accuracy and efficiency of the algorithms for proactive incident detection, root cause analysis and performance optimization
 Collaboration: Work closely with cross-functional teams to integration AI/ML solutions into existing workflows. Collaborate with stakeholders to understand business requirements and translate them into actionable data science projects.
 Data Management: Oversee the collection, processing and analysis of large-scale datasets. Implement data quality assurance processes and ensure data integrity for accurate model training and predictions.
 Monitoring and feedback: Establish monitoring mechanisms to evaluate model performance and provide continuous feedback for model improvement.
 Stay current with industry trends, emerging technologies and best practices in AIOps and data science. Integrate new methodologies and technologies to enhance the effectiveness of our solutions.

 Required Qualifications

 Proven track record of leading successful data science initiatives
 7+ years of expertise in machine learning, statistical modeling and data analysis
 7+ years proficiency in programming languages such as Python or R.
 Strong communication skills with ability to convey complex technical concepts to non-technical stakeholders

 Preferred Qualifications

 Experience processing data from various sources and via big data platforms (such as GCP, AWS, etc.)
 Experience developing and deploying Generative AI solutions.
 Experience enhancing existing data pipelines by exploring unstructured data sources and engineering new features.
 Strong software engineering skills, including understanding of software design patterns and best practices

 Education
 Ph.D or equivalent experience in a relevant field such as computer science or data science.

 Pay Range
 The typical pay range for this role is:
 $140,000.00 - $280,000.00
  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company’s equity award program.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",140000,"['python', 'machine learning', 'aws', 'gcp']"
Sr. Data Scientist,Altak Group,Remote,Full-time,"Job Summary:
We are seeking an experienced Data Scientist with minimum of 7 years of experience in data science and a strong background in healthcare analytics. As a Data Scientist, you will play a pivotal role in analyzing and leveraging large datasets to drive insights and improve the healthcare systems and services provided, with a focus on cloud-based solutions.
Responsibilities:

Identify and assess valuable healthcare data sources, optimizing the collection processes to ensure data quality and reliability in the AWS cloud.
Conduct preprocessing of both structured and unstructured healthcare data, ensuring it is ready for analysis.
Utilize advanced analytical techniques to analyze extensive healthcare datasets, identifying trends, patterns, and insights.
Develop predictive models and machine-learning algorithms to enhance healthcare decision-making and outcomes in the AWS cloud environment.
Collaborate with other data scientists to combine models through ensemble modeling to further improve accuracy and insights.
Communicate findings and insights effectively to both technical and non-technical stakeholders using data visualization techniques.
Propose data-driven solutions and strategies to address complex challenges within the healthcare industry, leveraging AWS cloud services.
Collaborate closely with engineering and product development teams to implement data-driven solutions effectively in the AWS cloud.

Skills and Qualifications:

Proven track record as a Data Scientist with a minimum of 7 years of experience, preferably in the healthcare industry.
Strong expertise in data mining and analysis, particularly within healthcare settings.
Proficiency in machine learning techniques and operations research.
Proficiency in programming languages such as Python and SQL, with familiarity in Scala, Java, or C++ being advantageous.
Experience using business intelligence tools (e.g., Tableau) and big data frameworks (e.g., Hadoop) within the context of healthcare analytics.
Exceptional analytical and mathematical skills (e.g., statistics, algebra).
Adept problem-solving abilities and critical thinking skills.
Excellent communication and presentation skills, with the ability to convey complex findings to diverse audiences.
Familiarity with AWS services and tools relevant to data science, cloud computing, and healthcare analytics.

Job Types: Full-time, Contract
Pay: $68.00 - $72.00 per hour
Schedule:

8 hour shift
Monday to Friday

Application Question(s):

Work Authorization in USA

Experience:

Machine learning: 7 years (Required)
Python: 7 years (Required)
SQL: 7 years (Required)
AWS: 5 years (Preferred)

Work Location: Remote",136000,"['python', 'machine learning', 'tableau', 'aws', 'sql', 'hadoop']"
LTD Data Scientist - Returnship,INTEL,Remote,Full-time,"

Job Description
 Have you taken a career break and had your resume rejected because of your resume gap?
 Intel is offering 16-week paid returnships for experienced professionals ready to return to the workforce. If you have taken a break of at least one year for the following reason(s), we welcome you to apply:

 Starting or raising a family
 Military service/military spouse
 Community service/volunteer work
 Caring for a family member or self
 Teaching
 Underemployment (working in a position unrelated to your professional or academic career)

 At Intel we are excited to have a Return-to-Work program because we appreciate the skills individuals who are returning to work can offer. This program offers you a chance to revamp your skills, update your resume with new experience, and make connections with others transitioning back to the workforce.  This position is remote during the 16-week returnship program. The goal of this program is to hire individuals who were successful throughout the program duration. A full-time offer will be remote.  The COMPASS Smart Manufacturing team at Intel Logic Technology Development (LTD) is seeking a talented Data Scientist who is passionate about transforming data into smart manufacturing decisions. As a member of this team, you will have the opportunity to apply your skills in mathematics, statistics, machine learning, and programming to the forefront of Intel's semiconductor manufacturing and make a direct impact on how transistors are made for the world. Together, we will drive cutting-edge autonomous process control, advanced process analytics, and smart factory operations.  Job responsibilities will include but will not be limited to:

 Be a champion in developing advanced mathematical/statistical methodologies to analyze and extract insights from big manufacturing data.
 Explore and develop novel machine learning/deep learning and algorithm solutions in different data domains (e.g., time series, images, texts) for intelligent process control and monitoring.
 Create powerful engineering analytics tools/platform in close collaboration with software, data, and process engineers.

 The candidate should also exhibit the following behavioral traits:

 Be a risk-taking self-starter.
 Creatively solve complex problems and generate new solutions.
 Works independently and within a team and collaborates across group boundaries.
 Strong verbal and written communication skills.


 Qualifications
 You must possess the below minimum qualifications to be considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates. Requirements listed would be obtained through a combination of industry relevant job experience, internship experiences, and schoolwork/classes/research.  This position is not eligible for Intel immigration sponsorship.  Minimum Qualifications

 Candidates must have been out of the paid technical workforce for at least one year.
 PhD degree in Statistics, Mathematics, Data Science, Computer Science, Physics, Industrial Engineering, or a related field.
 4+ years experience with data analysis using mathematical and statistical approaches
 2+ years experience with Machine Learning or Deep Learning modeling
 2+ years experience programming in Python

 Preferred Qualifications

 Advanced programming skills in Python, R, and SQL.
 Coding experience with MATLAB, OpenCV, and C/C++.
 Proficiency in developing models using Machine Learning frameworks (e.g., Pytorch, TensorFlow, Keras).
 Familiarity with semiconductor manufacturing.

 Inside this Business Group
 As the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art - from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology Development and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore’s Law to bring smart, connected devices to every person on Earth.
 
 Posting Statement
 All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.
 
 Benefits
 We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here.
 
 Annual Salary Range for jobs which could be performed in US, Colorado, New York, Washington, California: $52,000.00-$200,000.00
 

Salary range dependent on a number of factors including location and experience

 Working Model
 This role is available as a fully home-based and generally would require you to attend Intel sites only occasionally based on business need. This role may also be available as our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. 
 In certain circumstances the work model may change to accommodate business needs.
 JobType 
Fully Remote
",52000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'sql']"
Sr Data Analyst - 2200310,Optum,MN,Full-time,"EMPLOYER: Optum Services, Inc. 


JOB TITLE: Sr Data Analyst 


LOCATION: 11000 Optum Circle, Eden Prairie, Minnesota, 55344 


DUTIES: Manage environmental spaces that the analytics and reporting team uses. Work with the technical team to ensure availability of VCores and Space to ensure multiple systems and configurations are up and running. Assist with managing requirements, developing requirements and coding. Ensure deployment of multiple analytic processes. Lead assignments and help to guide and mentor junior team members in cloud environment. Work directly with customers to understand the business problem. Acquire the correct client data, reference data, trend data. Responsible for the management and manipulation of mostly structured data, with a focus on building business intelligence tools. Conduct analysis to distinguish patterns and recognize trends, performing normalization operations and assuring data quality. Partner with stakeholders to understand data requirements and develop tools and models such as segmentation, dashboards, data visualizations, decision aids and business case analysis to support the organization. Telecommuting is available from anywhere in the U.S. 


REQUIREMENTS: Employer will accept a Master’s degree in Information Technology, Computer Science, Data Science, Business Analytics or related field and 1 year of experience in the job offered or in a Analytics-related occupation. 

Position requires 1 year of experience in the following: • Pyspark, Spark, Hive, Cloud. • Hadoop/Bigdata Platforms/Programming such as; Airflow, HDFS, SQL, MapReduce, Sqoop, Shell Scripting, Azure.• Operating Systems such as; Linux, Windows, UNIX. •HBase, Oracle •Development methods such as; IDE’s VS code, Jupiter Notebook. 


RATE OF PAY: $96,283- $145,500 

 Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) 

 UnitedHealth Group offers a full range of comprehensive benefits, including medical, dental and vision, as well as matching 401k and an employee stock purchase plan. 


Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. 

 UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment. 

 #LI-DNI",96283,"['azure', 'sql', 'airflow', 'hadoop', 'pyspark']"
"Senior Data Analyst, Data Analytics",Cardinal Health,Remote,Full-time,"
What Data Analytics brings to Cardinal Health
 The Data & Analytics Function oversees the analytics lifecycle in order to identify, analyze and present relevant insights that drive business decisions and anticipate opportunities to achieve a competitive advantage. This function manages analytic data platforms, the access, design and implementation of reporting/business intelligence solutions, and the application of advanced quantitative modeling.

 Data Analytics applies business process knowledge and data analytics to develop, recommend and communicate timely, accurate, relevant and actionable insights to support business decisions and objectives.

 Job Summary
 This role is critical for the success of supporting our sales organizations and delivering best in class services and insights related to our Go-to-Market process Cardinal Health customers. The Data Analyst will work across multiple classes of trade to deploy and evolve activities such as sales tracking, measuring sales force effectiveness, sales force compensation tracking, and building training to improve outcomes of the sales organization. Additionally, they will partner with other commercial teams to develop and implement methods that enhance account level profitability and reduce customer churn. In doing so, you will be required to develop a deep understanding of various metrics that are used to track and prioritize sales forces efforts to grow profitably.
  Responsibilities

 Deliver commercial insights via reporting to the business stakeholders and the sales teams.
 Interacts regularly with Sales to design, develop and deploy regional and territory analyses, sales performance reports and dashboards, and other sales enablement tools.
 Acquire, validate, standardize, enrich, protect and publish structured and unstructured data for use by the business.


 Qualifications

 BA, BS, or equivalent experience in related field preferred
 8 - 10 years of experience in commercial analytics or related field preferred
 Experience in building and managing complex, customer facing programs.
 Knowledge of Structured Query Language (SQL), Relational Database Core Concepts, and experience with one or more BI Tools (Tableau/Looker/Data Studio/Business Objects) preferred. 
Executive presence, customer engagement and presentation skills
 Knowledge of Health Systems and Pharma segment, preferred.
 Understanding of pharmaceutical distribution business preferred.
 Experience directly supporting large IDNs and/or Sales Org by automating dataflows, conducting analysis, and distilling big data into concise summaries focused on key insights used for decision making preferred.
 Ability to recognize evolving trends and offer guidance related to their potential impact and solutions for seizing the opportunities. Ability to travel 25% as needed. 
 
 What is expected of you and others at this level

 Applies advanced knowledge and understanding of concepts, principles, and technical capabilities to manage a wide variety of projects
 Participates in the development of policies and procedures to achieve specific goals
 Recommends new practices, processes, metrics, or models
 Works on or may lead complex projects of large scope
 Projects may have significant and long-term impact
 Provides solutions which may set precedent
 Independently determines method for completion of new projects
 Receives guidance on overall project objectives
 Acts as a mentor to less experienced colleagues


 Anticipated salary range: $102,000-$145,700
 Bonus eligible: Yes
 Benefits: Cardinal Health offers a wide variety of benefits and programs to support health and well-being.

 Medical, dental and vision coverage
 Paid time off plan
 Health savings account (HSA)
 401k savings plan
 Access to wages before pay day with myFlexPay
 Flexible spending accounts (FSAs)
 Short- and long-term disability coverage
 Work-Life resources
 Paid parental leave
 Healthy lifestyle programs


 #LI-Remote
 Candidates who are back-to-work, people with disabilities, without a college degree, and Veterans are encouraged to apply.
Cardinal Health supports an inclusive workplace that values diversity of thought, experience and background. We celebrate the power of our differences to create better solutions for our customers by ensuring employees can be their authentic selves each day. Cardinal Health is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, ancestry, age, physical or mental disability, sex, sexual orientation, gender identity/expression, pregnancy, veteran status, marital status, creed, status with regard to public assistance, genetic status or any other status protected by federal, state or local law.
",102000,"['tableau', 'sql']"
"Data Scientist, ML Platform",CVS Health,NY,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary
 This position lies within the Enterprise Data & Machine Learning team. EDML focuses on data and ML platform design and development aimed at improving the productivity and efficacy of thousands of fellow data scientists and engineers. This platform is used to make billions of predictions that are ultimately used to run the business, whether that involves conventional decision support or customer-facing nudges and interventions. Our work is ambitious and far reaching with the potential to become a new internal standard, an OSS project, or differentiating intellectual property.


Partners closely with data scientists throughout the organization to assist with the development and deployment of ML solutions.
Works directly with the ML Platform product team and ML engineering to inform the development of new features and the broader roadmap.
Implements MLOps design patterns that incorporate best practices.
Regularly tests new features to ensure user requirements and practitioner standards are being met.
Collaborates regularly with designers, product managers, and data scientists so that the voice of user is always heard.
Identifies of opportunities for the development of solutions related to the data science lifecycle.
Helps evangelize the application of AI & ML throughout the broader organization and industry.


 Required Qualifications


Intern or professional experience working as a data scientist or machine learning engineer.
3+ years of programming experience with Python, SQL, and Git in *ix environments.
1-3 years of experience developing predictive models or ML systems in a cloud environment (e.g., GCP, AWS, Azure).
Demonstrated interest in developing ML and data science products.
Demonstrated analytical and problem-solving skills.
Demonstrated ability to communicate technical ideas clearly and succinctly in written and verbal form.


 Preferred Qualifications


Experience building machine learning pipelines and deploying them in a cloud (e.g., GCP, AWS, or Azure) environment.
Thorough understanding of machine learning engineering principles such as distributed/parallel computing paradigms and advanced data structures.
Thorough understanding of experiment design and MLOps principles.
Familiarity with ML frameworks such as Scikit-learn, TensorFlow, and PyTorch.
Familiarity with distributed frameworks such as Ray, Dask, or Rapids.
Familiarity with Docker and Kubernetes.
Familiarity with SFE best practices (unit testing and CI/CD).
Familiarity with natural language processing, computer vision, generative AI, and foundation models.


 EducationBachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Economics, Physics, Engineering, or related discipline. Master’s degree or PhD preferred.
 
 Pay Range
 The typical pay range for this role is:
 $80,500.00 - $170,000.00
 
 This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",80500,"['tensorflow', 'pytorch', 'python', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'sql', 'git']"
AIOps Principle Data Scientist,CVS Health,CT,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary We are seeking a highly skilled and experienced Principal Data Scientist to lead our AIOps initiatives. As the Principal Data Scientist, you will play a crucial role in developing and implementing advanced data science models and algorithms to optimize our operations and enhance overall stability, resiliency and performance.

 Responsibilities include:

 Strategy and Leadership: Execute a strategic vision for AIOps problem sets leveraging data science techniques. Provide leadership in aligning AIOps initiatives with organizational goals.
 Algorithm development: Design, develop and deploy advanced machine learning and statistical models to analyze and interpret complex datasets. Ensure the accuracy and efficiency of the algorithms for proactive incident detection, root cause analysis and performance optimization
 Collaboration: Work closely with cross-functional teams to integration AI/ML solutions into existing workflows. Collaborate with stakeholders to understand business requirements and translate them into actionable data science projects.
 Data Management: Oversee the collection, processing and analysis of large-scale datasets. Implement data quality assurance processes and ensure data integrity for accurate model training and predictions.
 Monitoring and feedback: Establish monitoring mechanisms to evaluate model performance and provide continuous feedback for model improvement.
 Stay current with industry trends, emerging technologies and best practices in AIOps and data science. Integrate new methodologies and technologies to enhance the effectiveness of our solutions.

 Required Qualifications

 Proven track record of leading successful data science initiatives
 7+ years of expertise in machine learning, statistical modeling and data analysis
 7+ years proficiency in programming languages such as Python or R.
 Strong communication skills with ability to convey complex technical concepts to non-technical stakeholders

 Preferred Qualifications

 Experience processing data from various sources and via big data platforms (such as GCP, AWS, etc.)
 Experience developing and deploying Generative AI solutions.
 Experience enhancing existing data pipelines by exploring unstructured data sources and engineering new features.
 Strong software engineering skills, including understanding of software design patterns and best practices

 Education
 Ph.D or equivalent experience in a relevant field such as computer science or data science.

 Pay Range
 The typical pay range for this role is:
 $140,000.00 - $280,000.00
  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company’s equity award program.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",140000,"['python', 'machine learning', 'aws', 'gcp']"
Sr. Data Scientist,Altak Group,Remote,Full-time,"Job Summary:
We are seeking an experienced Data Scientist with minimum of 7 years of experience in data science and a strong background in healthcare analytics. As a Data Scientist, you will play a pivotal role in analyzing and leveraging large datasets to drive insights and improve the healthcare systems and services provided, with a focus on cloud-based solutions.
Responsibilities:

Identify and assess valuable healthcare data sources, optimizing the collection processes to ensure data quality and reliability in the AWS cloud.
Conduct preprocessing of both structured and unstructured healthcare data, ensuring it is ready for analysis.
Utilize advanced analytical techniques to analyze extensive healthcare datasets, identifying trends, patterns, and insights.
Develop predictive models and machine-learning algorithms to enhance healthcare decision-making and outcomes in the AWS cloud environment.
Collaborate with other data scientists to combine models through ensemble modeling to further improve accuracy and insights.
Communicate findings and insights effectively to both technical and non-technical stakeholders using data visualization techniques.
Propose data-driven solutions and strategies to address complex challenges within the healthcare industry, leveraging AWS cloud services.
Collaborate closely with engineering and product development teams to implement data-driven solutions effectively in the AWS cloud.

Skills and Qualifications:

Proven track record as a Data Scientist with a minimum of 7 years of experience, preferably in the healthcare industry.
Strong expertise in data mining and analysis, particularly within healthcare settings.
Proficiency in machine learning techniques and operations research.
Proficiency in programming languages such as Python and SQL, with familiarity in Scala, Java, or C++ being advantageous.
Experience using business intelligence tools (e.g., Tableau) and big data frameworks (e.g., Hadoop) within the context of healthcare analytics.
Exceptional analytical and mathematical skills (e.g., statistics, algebra).
Adept problem-solving abilities and critical thinking skills.
Excellent communication and presentation skills, with the ability to convey complex findings to diverse audiences.
Familiarity with AWS services and tools relevant to data science, cloud computing, and healthcare analytics.

Job Types: Full-time, Contract
Pay: $68.00 - $72.00 per hour
Schedule:

8 hour shift
Monday to Friday

Application Question(s):

Work Authorization in USA

Experience:

Machine learning: 7 years (Required)
Python: 7 years (Required)
SQL: 7 years (Required)
AWS: 5 years (Preferred)

Work Location: Remote",136000,"['python', 'machine learning', 'tableau', 'aws', 'sql', 'hadoop']"
"Senior Data Analyst, Data Analytics",Cardinal Health,Remote,Full-time,"
What Data Analytics brings to Cardinal Health
 The Data & Analytics Function oversees the analytics lifecycle in order to identify, analyze and present relevant insights that drive business decisions and anticipate opportunities to achieve a competitive advantage. This function manages analytic data platforms, the access, design and implementation of reporting/business intelligence solutions, and the application of advanced quantitative modeling.

 Data Analytics applies business process knowledge and data analytics to develop, recommend and communicate timely, accurate, relevant and actionable insights to support business decisions and objectives.

 Job Summary
 This role is critical for the success of supporting our sales organizations and delivering best in class services and insights related to our Go-to-Market process Cardinal Health customers. The Data Analyst will work across multiple classes of trade to deploy and evolve activities such as sales tracking, measuring sales force effectiveness, sales force compensation tracking, and building training to improve outcomes of the sales organization. Additionally, they will partner with other commercial teams to develop and implement methods that enhance account level profitability and reduce customer churn. In doing so, you will be required to develop a deep understanding of various metrics that are used to track and prioritize sales forces efforts to grow profitably.
  Responsibilities

 Deliver commercial insights via reporting to the business stakeholders and the sales teams.
 Interacts regularly with Sales to design, develop and deploy regional and territory analyses, sales performance reports and dashboards, and other sales enablement tools.
 Acquire, validate, standardize, enrich, protect and publish structured and unstructured data for use by the business.


 Qualifications

 BA, BS, or equivalent experience in related field preferred
 8 - 10 years of experience in commercial analytics or related field preferred
 Experience in building and managing complex, customer facing programs.
 Knowledge of Structured Query Language (SQL), Relational Database Core Concepts, and experience with one or more BI Tools (Tableau/Looker/Data Studio/Business Objects) preferred. 
Executive presence, customer engagement and presentation skills
 Knowledge of Health Systems and Pharma segment, preferred.
 Understanding of pharmaceutical distribution business preferred.
 Experience directly supporting large IDNs and/or Sales Org by automating dataflows, conducting analysis, and distilling big data into concise summaries focused on key insights used for decision making preferred.
 Ability to recognize evolving trends and offer guidance related to their potential impact and solutions for seizing the opportunities. Ability to travel 25% as needed. 
 
 What is expected of you and others at this level

 Applies advanced knowledge and understanding of concepts, principles, and technical capabilities to manage a wide variety of projects
 Participates in the development of policies and procedures to achieve specific goals
 Recommends new practices, processes, metrics, or models
 Works on or may lead complex projects of large scope
 Projects may have significant and long-term impact
 Provides solutions which may set precedent
 Independently determines method for completion of new projects
 Receives guidance on overall project objectives
 Acts as a mentor to less experienced colleagues


 Anticipated salary range: $102,000-$145,700
 Bonus eligible: Yes
 Benefits: Cardinal Health offers a wide variety of benefits and programs to support health and well-being.

 Medical, dental and vision coverage
 Paid time off plan
 Health savings account (HSA)
 401k savings plan
 Access to wages before pay day with myFlexPay
 Flexible spending accounts (FSAs)
 Short- and long-term disability coverage
 Work-Life resources
 Paid parental leave
 Healthy lifestyle programs


 #LI-Remote
 Candidates who are back-to-work, people with disabilities, without a college degree, and Veterans are encouraged to apply.
Cardinal Health supports an inclusive workplace that values diversity of thought, experience and background. We celebrate the power of our differences to create better solutions for our customers by ensuring employees can be their authentic selves each day. Cardinal Health is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, ancestry, age, physical or mental disability, sex, sexual orientation, gender identity/expression, pregnancy, veteran status, marital status, creed, status with regard to public assistance, genetic status or any other status protected by federal, state or local law.
",102000,"['tableau', 'sql']"
"Data Science, Lead Associate",Peraton,MD,Full-time,"
Peraton Overview
 Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.
 
Responsibilities

 Peraton is hiring a Data Scientist to join our Cyber Mission business unit in Fort Meade, Maryland. As a Data Scientist on our team, you will support one of the largest enterprise-wide engineering contracts within the Intelligence Community. This is a full-time position requiring 1880 hours of support per year; and work is performed at a customer location. As a Data Scientist on our team you will provide support and related services to help simplify, automate, and hasten data movement across the mission platform. The successful individual will perform end-to-end systems engineering for data flows from the perspective of data modeling, data mapping, and support to implementers and mission customers. This position requires strong software and systems engineering expertise across the full life cycle of data and limited need for high-level direction. Key activities include: 
 

Framing, defining, and bounding Enterprise level data needs and concerns into broad actionable initiatives with clearly identifiable downstream tasking 
Recommending new automation strategies and maturing current automation efforts 
Performing high-level data requirements analysis to support the application of data standards across the enterprise. 
Operating within, and coordinating across, teams that employ varying development methodologies (Agile, Scrum, and Kanban). 
Possessing an instinctive aptitude to leverage information and knowledge sharing networks and navigating conflict in a way that fosters constructive outcomes. 

 The selected candidate will demonstrate the aptitude to learn and grow in the following areas. Experience in one or more of these areas will greatly increase the probability of success.
 



Hands on data wrangling: Extract Transform Load (or ETL), Databases, DBA, shell scripting 
Hands on experience with Data Serializations (AVRO/protobuf/YAML/XML/JSON) 
Problem framing, pattern recognition, AI/ML exposure 
SIGINT understanding 
Facility with data query DSLs (e.g. SQL) 


Qualifications


 Bachelor's degree Computer Science, Mathematics, or related discipline plus six years of experience in Mathematics/Statistics, Computer Science, and analysis of data syntax and semantics; High School Diploma or GED plus seven years of experience in Mathematics/Statistics, Computer Science, and analysis of data syntax and semantic; a Master's degree from an accredited college or university in Computer Science, Mathematics, or related discipline and three years of experience; or a or PhD degree from an accredited college or university in Computer Science, Mathematics, or related discipline. 
Position requires TS/SCI clearance with polygraph. 

 Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information. 
 
 Peraton is an Equal Opportunity/Affirmative Action Employer. We consider applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status, or membership in any other group protected by federal, state, or local law. 
 

Target Salary Range

 $112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors.
 

SCA / Union / Intern Rate or Range


EEO
 An Equal Opportunity Employer including Disability/Veteran.
 

Our Values


Benefits
 At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.
 

 Paid Time-Off and Holidays
 Retirement
 Life & Disability Insurance
 Career Development
 Tuition Assistance and Student Loan Financing
 Paid Parental Leave
 Additional Benefits
 Medical, Dental, & Vision Care

",112000,"['etl', 'sql']"
"Senior Data Scientist, 5+ Years of Experience",Snapchat,CA,Full-time,"


   Snap Inc.
   is a camera company. We believe that reinventing the camera represents our greatest opportunity to improve the way people live and communicate. Our products empower people to express themselves, live in the moment, learn about the world, and have fun together.
 


   The Product team uses creativity, insights, and operational excellence to steer our product vision across Snap Inc. This team of designers, scientists, and product managers work in a highly collaborative environment to build the products and experiences that bring our community together in new and special ways.
 


   We’re looking for a Sr. Data Scientist to join Snap Inc!
 


   What you’ll do:
 



     Apply your expertise in quantitative analysis, data mining, and statistical modeling to deliver impactful, objective, and actionable data insights that enable informed business and product decisions
   


     Drive informed and timely decision-making that improves and optimizes the way our products are created, completed, and adopted'
   


     Collaborate with product managers, engineers, product marketers, and designers
   


     Think creatively, proactively, and futuristically to identify and size up new opportunities within Snap's long term roadmap for data-scientific contributions
   


     Conduct machine learning or statistical analyses, and build pragmatic, scalable, and statistically thorough solutions to deliver actionable insights, accurate predictions, and effective optimizations
   


     Communicate best practices in quantitative analysis and develop cross-functional partnerships
   



   Knowledge, Skills & Abilities:
 



     Expertise using data modeling skills to identify key product trends and new product opportunities
   


     Ability to design implement, and track core metrics to analyze the performance of our products
   


     Ability to create visuals, dashboards, and reports to effectively communicate your insights
   


     Experience collaborating with engineers, product managers, and other cross-functional teams
   


     Ability to initiate and drive projects to completion with minimal guidance
   


     An understanding of Snapchat with great product sense and product understanding
   


     Ability to communicate sophisticated quantitative analysis in a clear, precise, and actionable manner
   



   Minimum Qualifications:
 



     BS/BA degree in statistics, mathematics, economics, computer science or equivalent years of experience
   


     5+ years of experience in quantitative analysis & data science or a related field
   


     5+ years of experience using SQL or similar big data querying languages
   


     5+ years of experience with programming language, such as Python or R
   


     5+ years of experience with applied statistical techniques, such as inferential methods, causal methods, A/B testing, or statistical modeling techniques
   



   Preferred Qualifications:
 



     Advanced degree in applied mathematics, statistics, actuarial science, economics or related field
   


     Experience in a product-focused role at a social media and/or mobile technology company
   


     Experience using machine learning and statistical analysis for building data-driven product solutions or performing methodological research.
   



   ""Default Together"" Policy at Snap: At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office at least 80% of the time (an average of 4 days per week).
 

   If you are not based in the same location(s) listed for this role and are open to relocation, we encourage you to apply to take advantage of our generous relocation policy.
 


   At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at accommodations-ext@snap.com.
 



    Our Benefits
  : Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid maternity & paternity leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!
 


   Compensation
 

   In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These pay zones may be modified in the future.
 



    Zone A (CA, WA, NYC)
  :
  The base salary range for this position is $205,000-$295,000 annually.
 


 Zone B
  :
  The base salary range for this position is $195,000-$280,000 annually.
 


    Zone C
  :
  The base salary range for this position is $174,000-$251,000 annually.
 

   This position is eligible for equity in the form of RSUs.
 

",174000,"['python', 'machine learning', 'sql']"
Software Engineering - Data Structures,JPMorgan Chase & Co,NJ,Full-time,"
JOB DESCRIPTION
 We have an opportunity to impact your career and provide an adventure where you can push the limits of what's possible.
 As a Lead Software Engineer at JPMorgan Chase within the Corporate Sector Liquidity Team, you are an integral part of an agile team that works to enhance, build, and deliver trusted market-leading technology products in a secure, stable, and scalable way. As a core technical contributor, you are responsible for conducting critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.
 Job responsibilities

Works in a fast-paced environment and helps build APIs, Calculators, on new cutting edge cloud and big data technologies such as AWS EMR, EC2, Scala Spark, Scala, Snowflake
Executes standard software solutions, design, development, and technical troubleshooting
Writes secure and high-quality code using the syntax of at least one programming language with limited guidance
Designs, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications
Applies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation
Applies technical troubleshooting to break down solutions and solve technical problems of basic complexity
Gathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development
Learns and applies system processes, methodologies, and skills for the development of secure, stable code and systems
Adds to team culture of diversity, equity, inclusion, and respect

 Required qualifications, capabilities, and skills

Formal training or certification on software engineering concepts and 5+ years of applied experience
Hands-on practical experience in Java, Scala and/or Python, system design, application development, testing, and operational stability
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages 
Experience across the whole Software Development Life Cycle
Exposure to agile methodologies such as CI/CD, Applicant Resiliency, and Security
Emerging knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.
Knowledge of Unix shell and SQL as well as NoSQL DBs is required.
In-depth knowledge of the financial services industry and their IT systems
Practical cloud native experience

 Preferred qualifications, capabilities, and skills

Knowledge of Spark and Scala
Familiarity with modern front-end technologies
Exposure to cloud technologies (AWS EMR, EC2, Snowflake)

ABOUT US


   JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management. 
  

We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)


We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.


JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans








ABOUT THE TEAM

 Our Corporate Technology team relies on smart, driven people like you to develop applications and provide tech support for all our corporate functions across our network. Your efforts will touch lives all over the financial spectrum and across all our divisions: Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal, and within the Corporate Administrative Office. You’ll be part of a team specifically built to meet and exceed our evolving technology needs, as well as our technology controls agenda.
",128250,"['python', 'machine learning', 'aws', 'nosql', 'sql']"
Data Scientist,Genworth,VA,Full-time,"
At Genworth, we empower families to navigate the aging journey with confidence. We are compassionate, experienced allies for those navigating care with guidance, products, and services that meet families where they are. Further, we are the spouses, children, siblings, friends, and neighbors of those that need care—and we bring those experiences with us to work in serving our millions of policyholders each day.

 We apply that same compassion and empathy as we work with each other and our local communities. Genworth values all perspectives, characteristics, and experiences so that employees can bring their full, authentic selves to work to help each other and our company succeed. We celebrate our diversity and understand that being intentional about inclusion is the only way to create a sense of belonging for all associates. We also invest in the vitality of our local communities through grants from the Genworth Foundation, event sponsorships, and employee volunteerism.

 Our four values guide our strategy, our decisions, and our interactions:

 Make it human. We care about the people that make up our customers, colleagues, and communities.
 Make it about others. We do what’s best for our customers and collaborate to drive progress.
 Make it happen. We work with intention toward a common purpose and forge ways forward together.
 Make it better. We create fulfilling purpose-driven careers by learning from the world and each other.


 POSITION TITLE
 Data Scientist

 POSITION LOCATION
 Richmond, VA (hybrid)
 Remote US (Eastern or Central Time Zones)

 This position is available to Virginia residents as Richmond, Virginia in-office applicants with a hybrid work schedule or remote applicants residing in states/locations under Eastern or Central Standard Time: Alabama, Arkansas, Connecticut, Delaware, Florida, Georgia, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Nebraska, New Hampshire, New Jersey, New York, North Carolina, North Dakota, Ohio, Oklahoma, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Virginia, Washington DC, Vermont, West Virginia or Wisconsin.

 YOUR ROLE
 Do you find energy and excitement in leveraging critical thinking and data to drive solutions to complex, unstructured problems? Do you have a self-starting attitude constantly driving improvements without direction? Are you naturally curious always looking for new information and relationships? Do you enjoy driving strategy and results using creative problem solving and data?  We are revolutionizing the analytics space in the Long-Term Care (LTC) Insurance industry via innovative technology, intuitive design, and creative thought leadership. We have repeatedly shown the value of the analytics team and continue to invest in our team.  Using the latest analytic tools and processes, we’re able to analyze our data to provide strategic insight leading to transformational change. To carry us even further, we are seeking a Data Scientist/Analyst to join our expanding, problem-solving team, supporting our Data Insights team. You will harness the power of data to enhance analytic insights and predictive capabilities related to our customers and processes in support of critical initiatives that will transform the landscape of Long-Term Care Insurance.

 What you will be doing

 Develop knowledge and experience of complex datasets
 Directly support various areas across the business by leveraging data, advanced analytical skills, and critical thinking to produce actionable insights and usable tools/models
 Uncover data trends and insights, telling a data story to inform strategies and recommend custom approaches/techniques in Long-Term Care market
 Analyze data using exploratory analysis and statistics to generate results and insights
 Leverage strong programming skills to explore, examine and interpret large data sets in various forms
 Communicate progress, insights and analytic findings via oral and written methods
 Build repeatable tools and models in the form of reports, dashboards, cost/benefit analysis, machine-learning model, etc.


 What you bring

 Bachelor's degree in an analytical or technical discipline
 At least 3 years of analyst experience in a dynamic environment, with data science expertise obtained through progressive analytical work experience OR a master’s degree with relevant data science course work
 Expertise in Excel
 Hands on Intermediate to advanced SQL/SAS or other programming language ability 
Experience with data visualization tool (e.g, Spotfire, Tableau, Business Power Intelligence or Business Objects)
 Critical thinker with the ability to leverage quantitative and qualitative data to support business strategy and execution
 Results-oriented with the ability to demonstrate a sense of urgency and accountability for your work
 Self-motivated with a drive for results and strong verbal/written communications skills 


Nice to have

 Life/LTC Insurance product and claims process knowledge
 Database/ETL experience
 Subject matter expertise in advanced analytical and modeling data capabilities utilizing Python and/or R
 Experience with big data technologies (e.g., Hadoop, Spark, Hive, Databricks, AWS/Azure and etc)


 Employee Benefits & Well-Being
 Genworth employees make a difference in people’s lives every day. We’re committed to making a difference in our employees’ lives.

 Competitive Compensation & Total Rewards Incentives
 Comprehensive Healthcare Coverage
 Multiple 401(k) Savings Plan Options
 Auto Enrollment in Employer-Directed Retirement Account Feature (100% employer-funded!)
 Generous Paid Time Off – Including 12 Paid Holidays, Volunteer Time Off and Paid Family Leave
 Disability, Life, and Long Term Care Insurance
 Tuition Reimbursement, Student Loan Repayment and Training & Certification Support
 Wellness support including gym membership reimbursement and Employee Assistance Program resources (work/life support, financial & legal management)
 Caregiver and Mental Health Support Services


 For the State of New York:
 The base salary pay range for this role starts at a minimum rate of $90,000 up to the maximum of $171,000. In addition to your base salary, you will also be eligible to participate in an incentive plan. The incentive plan is based on performance and the target earning opportunity is 7% of your base compensation. The final determination on base pay for this position will be based on multiple factors at the time of this job posting including but not limited to geographic location, experience, and qualifications to ensure pay equity within the organization.

",90000,"['python', 'tableau', 'aws', 'azure', 'etl', 'sql', 'hadoop']"
"Sr. Risk Adjustment Data Analyst, Medicare Advantage",UCLA Health,CA,Full-time,"

Description
 Take on a key role within an award-winning health system. Help improve patient experiences and operational efficiency as part of a world-class healthcare team. Take your career in an exciting new direction. You can do all this and more at UCLA Health. As an important member of our Medicare Advantage team, you will be responsible for leading the manipulation of large amounts of data and the development of dashboards in conjunction with our analytics team. You will also analyze large amounts of data to help identify opportunities for the development of new programs and interventions. Salary Range: $78,800 - $175,000 Annually


 Qualifications
 We’re seeking a self-motivated, flexible, goal-driven, service-oriented individual with: • Bachelor’s Degree in Business Administration, Economics, Health Care, Information Systems, Statistics, or other related field is required. Master’s Degree in related field preferred. Relevant combination of education and experience may be considered in lieu of degree. • Certification or progress toward certification is highly desired • Five or more years of analytics experience in healthcare, insurance or a related area • Proficiency with Visio; Visual Basic for automation in Excel, PowerPoint; SQL/server system tools; creation of file structures; Visual Analytics tools (Tableau) and Microsoft PowerBI • Expertise with SAS (Base, Macro, Graph, Email) a plus • Advanced knowledge of Excel (including pivot tables) • In-depth understanding of Medicare Advantage (HCC model); statistically (V24 and V28) and chronic condition category levels • Strong communication, analytical, and problem-solving skills • Expertise with statistical software tools • Knowledge of R, Python, and SAS (including certification) is a plus • Actuarial or finance experience preferred • This position is hybrid and can be located anywhere in the US; must be able to work Pacific Standard Time hours UCLA Health is a world-renowned health system with four award-winning hospitals and more than 260 community clinics throughout Southern California. We’re also home to the world-class medical research and clinical education capabilities of the David Geffen School of Medicine. Through the efforts of our outstanding people, we have become Los Angeles’ trusted provider of exceptional, compassionate patient care. If you’re looking to experience greater challenge and fulfillment in your career, you can at UCLA Health.

",78800,"['python', 'tableau', 'sql']"
Senior Principal Data Scientist (Melbourne FL),Northrop Grumman,FL,Full-time,"
Requisition ID: R10138069

 Category: Research and Sciences
 Location: Melbourne, Florida, United States of America
 Citizenship required: United States Citizenship
 Clearance Type: Secret
 Telecommute: No- Teleworking not available for this position
 Shift: Any (United States of America)
 Travel Required: Yes, 10% of the Time
 Positions Available: 1


   At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
 

 Are you motivated to work in an environment that will challenge you, force you to continuously innovate, and work on solutions that make a difference for your customers?

 Northrop Grumman Aerospace Systems relies on our team to provide the insights needed to drive performance across a broad range of strategic activities.

 We are looking for a passionate Senior Principal Data Scientist in Melbourne Florida to design and develop automated, end-to-end, ETL pipelines, Artificial Intelligence/Machine Learning (AI/ML) solutions, and Data Analytics/Visualization solutions from disparate data sources.

 You will share in the ownership of the technical vision and direction for advanced analytics systems that change the way we see and use data. We are looking for people who are self-motivated, hardworking, and have demonstrated the ability to find innovative solutions to complex technical problems.

 Job Responsibilities:

 Design, develop, and maintain a scalable Extract, Transform, and Load (ETL) pipelines.
 Enable storing, searching, processing, and securing of extremely large structured or unstructured data sets.
 Data preparation/cleaning, integration, and automation from heterogeneous sources
 Ensure data integrity and system availability
 Identify, evaluate, and recommend core technologies and strategies
 Monitor and optimize system performance
 Decomposition of user requirements into logical functions/components


 Basic Qualifications for Sr. Principal Data Scientist:

 Bachelor’s degree in STEM with 9 years of related experience; Masters degree in STEM with 7 years of related experience. PhD with 4 years of related experience.
 Understanding of elastic data storage and archive storage lifecycle management
 Experience with Data Science practices for prescriptive, predictive, diagnostic, descriptive, and cognitive analytics through automation, storage elasticity, and on-demand self service provisioning of all data types and lifecycles.
 Experience with Tableau development or similar data application development.
 Experience with SQL (structure query language) and relational databases.
 Experience with graphic design background, creating user interfaces, and user focused dashboards.
 Excellent communication skills and customer facing experience.
 Proven ability to learn and master new technologies and techniques.
 US Citizenship with the ability to obtain/maintain an active DoD Secret Clearance.
 Must be able to obtain Program Access (PAR) within a reasonable amount of time


 Preferred Qualifications:

 Master’s degree in STEM with 7 years of related experience.
 5+ years of experience working with ETL techniques and frameworks.


 Expert in Python, SQL, and data visualization tools.


 Development experience utilizing Hadoop, Spark, PowerShell, and automation scripts.
 Familiarity with Data Virtualization and Data Cataloging tools (e.g. Denodo, Collibra).
 Experience with NoSQL Databases (e.g., MongoDB, Neo4J, etc.)


 CompTIA Security+ Certification.
 Current DOD Top Secret clearance.




 Salary Range: $123,400 - $185,000
  


   Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
 

 Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.


",123400,"['python', 'machine learning', 'tableau', 'nosql', 'etl', 'sql', 'hadoop']"
Principal Statistician - Remote,Mayo Clinic,MN,Full-time,"

Why Mayo Clinic


 Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans – to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You’ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.
 


Responsibilities

 Candidate has deep expertise in applying statistical, programming and related methods such as machine learning and scientific expertise to the design, implementation, analysis, interpretation, and reporting of research, clinical and administrative studies. Has deep knowledge of healthcare data types, topics, and scientific challenges and approaches. The Principal Statistician must possess expert-level knowledge of statistics in medicine, and be able to identify and apply various analytical approaches as they relate to these fields.
 Work with data engineers, data scientists, informaticians and clinicians at Mayo, and partner with outside companies to design and execute complex statistical analysis that can be used to improve patient care both at Mayo and at healthcare institutions around the world. Candidates will present findings to various enterprise departments/divisions. May have direct and indirect reports.
 The position will be responsible for the following essential functions:

Provides deep, data-driven insights for complex business problems through an array of advanced statistical methods
Develops predictive and prescriptive models to address complex problems, discover insights, and identify opportunities using machine learning, statistical techniques, and data mining.
Makes presentations on assigned projects or proposals both internally and externally
Serves as a subject matter expert in model validation techniques and practices
Functions independently and initiates judgment in handling delegated responsibilities.
Experience leading technical/quantitative teams.
Develops and executes on experimental design approaches to validate findings or test hypotheses.
Leads and directs the interpretation of statistical analysis and writing reports.



Qualifications


PhD degree in Mathematics, Statistics, Biostatistics or equivalent.
Alternatively, a Masters' degree in same fields with at least 10 years of relevant experience.
Five years of experience as a statistician or equivalent required.
Experience in statistical analysis or programming software such as SAS, R or python.
Expertise in the use of statistical computing and data management packages.
Ability to prioritize, organize, and delegate various tasks on multiple, concurrent projects.
Contributes to organizational initiatives in administration, education, or software development.
Demonstrated success in project management.
Demonstrates initiative in administration and education (e.g., seminars or training).
A commitment to customer service with an attitude of owning the experience of each customer is required.

The successful candidate will need to have both technical and business background/experience along with strong leadership skills. Good written and oral communication skills are required. Deep expertise in the application of statistical methods in healthcare. Demonstrated initiative in software development, and technical reports. Demonstrated application of several problem-solving methodologies, planning techniques, continuous improvement methods, project management methods, and analytical tools and methodologies (e.g. machine learning, statistical packages, modeling, etc.) required. Incumbent must have ability to independently manage a varied workload of projects with multiple priorities and stay current on healthcare trends and enterprise changes. Excellent interpersonal skills to include presentation, negotiation, persuasion, and written communications skills are required. Exceptional time management is required. In addition, requires excellent analytical skills, consulting skills, ability to identify and recommend solutions, advanced computer application skills and a commitment to customer service. Experience with data modeling and date exploration tools.
 Exemption Status

 Exempt
 

Compensation Detail

 $138,236 - $200,408 / year
 

Benefits Eligible

 Yes
 

Schedule

 Full Time
 

Hours/Pay Period

 80
 

Schedule Details

 Monday - Friday, Normal Business Hours 100% Remote. This position may work remotely from any location within the US. 20%+ travel may be required This vacancy is not eligible for sponsorship/ we will not sponsor or transfer visas for this position. 
 

Weekend Schedule

 Not Applicable
 

International Assignment

 No
 

Site Description


  Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.
  




Affirmative Action and Equal Opportunity Employer


 As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.
   




Recruiter

 Julie Melton
",138236,"['python', 'machine learning']"
Staff AI and Radar Software Engineer,Northrop Grumman,MD,Full-time,"
Requisition ID: R10137637

 Category: Engineering
 Location: Linthicum, Maryland, United States of America
 Citizenship required: United States Citizenship
 Clearance Type: SAP
 Telecommute: No- Teleworking not available for this position
 Shift: 1st Shift (United States of America)
 Travel Required: Yes, 10% of the Time
 Relocation Assistance: Relocation assistance may be available
 Positions Available: 1


   At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
 

 As an integral part of our part of Northrop Grumman's AI Engineering and Radar ATR group in Mission Systems Engineering focused on the increasingly important technology areas of automatic target recognition, sensor fusion, advanced exploitation, cognitive mission management, and sensor resource management.
 This position requires up to 100% on-site work in the Linthicum/Baltimore, Maryland campus and the ability to pass an enhanced security review

 Roles & Responsibilities:

 Lead and participate in multi-disciplinary, collaborative teams and contribute to the advancement of novel artificial intelligence and machine learning capabilities for today’s warfighter
 Define, Develop, and deliver mathematical & statistical modeling and algorithm development to tackle the challenges of prediction, optimization, and classification.
 Apply machine learning algorithms to large sets of structured and unstructured data to solve a broad range of advanced exploitation problems that include applications in pattern recognition, target detection, tracking, and decision systems.
 Collaborate with cross-functional teams to deploy machine learning algorithms to both prototype and production systems. For example, today, there is often a significant gap between prototype systems (supported by server-farm trained neural networks) and the production systems that we deploy to, which often consist of less processing power than a typical smart phone. Bridging this gap will be a significant component of this role.
 Design, develop and analyze signal and image processing algorithms for exploitation of sensor data
 Works closely with the customer community, including the warfighter, to understand program intent, system capabilities, and output requirements
 May design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better reliability, precision, accuracy, and speed to meet performance requirements
 Additional tasks include defining software and system interfaces, system integration and testing, and field support of experiments and demonstrations including flight tests
 Work products include written reports, presentations, and project proposals. Occasional travel for meetings and flight test exercises will be required

 Basic Qualifications:

 Bachelor’s degree with 14 years of experience, a Master’s degree with 12 years of experience or a PhD with 9 years of experience in Electrical Engineering, Computer Engineering, Computer Science, or related technical fields; an additional 4 years of experience may be considered in lieu of a degree 
US citizenship required
 Top secret/SAP/SCI clearance required prior to access
 Expertise in remote sensing, including active radar imaging.
 Basic knowledge of red force threat systems.
 Experience with formulating innovative solutions to algorithm development, initiating and fostering client relationships, and executing projects in compliance with cost, schedule, and technical requirements.
 Experience in developing rapid prototype solutions from concept to design, implementation, initial testing, and integration.
 Experience with presenting and speaking at customer demonstrations, symposia, and conferences.
 The demonstrated ability to perform innovative, applied research, and to develop sophisticated algorithms under computational or other resource constraints.
 Experience with conventional software engineering principles, including code maintenance, coding standards, and version control.
 Demonstrated experience with algorithm implementations in MATLAB and software development in C, C++, Python, and/or Objective C
 Demonstrated experience with open-source computer vision and machine learning libraries (e.g., OpenCV, TensorFlow, and Caffe), Unix/Linux operating systems, and multi-threaded/parallel computing.


 This position is contingent upon the successful transfer of a Top secret/SAP/SCI clearance required prior to starting
 As a full-time employee of Northrop Grumman Mission Systems, you are eligible for our robust benefits package including:

 Medical, Dental & Vision coverage
 401k
 Educational Assistance
 Life Insurance
 Employee Assistance Programs & Work/Life Solutions
 Paid Time Off
 Health & Wellness Resources
 Employee Discounts


 Link to Benefits: https://totalrewards.northropgrumman.com/
 This positions standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off.



 Salary Range: $185,900 - $278,900
  


   Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
 

 Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.


",185900,"['tensorflow', 'python', 'machine learning']"
"Sr. Director, Data Science and Machine Learning",Centerfield,CA,Full-time,"

Hi, We're Centerfield. 


  Super-powered customer acquisition. Centerfield delivers outcome-based digital marketing solutions and personalized omnichannel experiences for the world’s leading brands. Powered by our proprietary Dugout platform, Centerfield acquires customers at scale for leading residential service, insurance, e-commerce and B2B brands. Centerfield’s digital experiences and digital brands, such as Business.com and BroadbandNow.com, reach more than 150 million in-market shoppers annually. Centerfield is headquartered in Silicon Beach and proud to be recognized as a Best Place to Work in Los Angeles.
 


 The Opportunity...


   Centerfield Media, a leading Los Angeles-based online advertising agency, is looking for a talented Sr. Director of data to join us in building innovative advertising technology. We are looking for a highly motivated, web-focused, Leader with experience with the full data life cycle. You will help design the data science programs, persona, machine learning models, and architecture to support Generative AI. You will build a team of data scientists, machine learning engineers, and Architects. You must have practical experience working with large data sets preferably in website lead generation & search engine marketing, SaaS, or cloud computing domains.
 
How You'll Contribute...

 Need to own problems from end to end so that you can best collect, extract, and clean the data.
 Ability to lead projects individually and deliver them on time.
 Experience with Realtime streaming implementation and architecture is a bonus.
 Experience building reports and data visualization with any BI tools like Tableau, Power BI, etc.
 Build high-performance, responsive teams of data scientists, and analysts that can gather and synthesize data quickly and accurately. Help to implement maintenance strategy for all datasets.
 Support an organizational effort toward better understanding user needs and pain points and propose roles that data science can play to further this goal.
 Support data-informed decision-making, throughout the Product Org and broader company. Be a thought leader and evangelist to drive adoption and knowledge at all levels of the organization.
 Develop an investment strategy to define, grow, and maintain an exemplary data science organization.
 Constantly look for strategic ways to expand the charter of the Data Science team beyond causal inference, starting with Ranking Data Science, and Market-Place Dynamics
 Determine how to leverage data science, machine learning, and other analytical techniques to offer actionable insights both internally & externally.

 What We're Looking For...

 Deep technical background with an MS or PhD in mathematics, statistics, computer science, or a related field
 10+ Years working in a Data Engineer, BI Engineer, or Data Warehousing Engineer role.
 Google Cloud Platform (Google cloud bucket, Google cloud fusion, Google Big Query, Google Analytics)
 6+ Years leading teams to conduct research, in-depth analysis, and automation efforts.
 5+ Years building repour and developing relationships with key stakeholders. Delivering against critical expectations for multiple priorities.
 5+ Years Building models and various ML tooling.

 Life at Centerfield...

 This is a hybrid position, and employees are expected to come into our Playa Vista, CA office every Tuesday, Wednesday & Thursday
 Competitive salary + bi-annual bonus
 Unlimited PTO – take a break when you need it!
 Industry-leading medical, dental, and vision plans + generous parental leave
 401(k) company match plan – fully vested on day 1
 Outside patio overlooking Playa Vista + cabanas, firepits & working grills
 Monthly happy hours, catered lunches + daily food trucks
 Award-winning culture & unprecedented team spirit (featured in LA Business Journal & Built In LA)
 Fully stocked kitchens with snacks & drinks
 Breakroom supplied with games, couches, workout equipment + weekly in-office exercise classes hosted by professional instructors (yoga, kickboxing & circuit training)
 Free onsite gym + locker rooms
 Paid charity and volunteer days (local mentor programs, adopt a pet, beach cleanup, etc.)
 Monthly team outings (ball games, casino night, hikes, etc.)
 Career growth – we enjoy promoting from within!


   #LI-Hybrid
 

 To learn more, visit us 
Here
. 


  Interviews will take place after resumes have been screened for minimum requirements. Please note that this position is not restricted solely to the responsibilities listed above and that the job scope and responsibilities are subject to change.
 


 For more information about our collection, use, and disclosure of your personal information in connection with our evaluating your candidacy, please visit our Privacy Policy at https://www.centerfield.com/privacy-policy/.
 



 Centerfield Media is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected under federal, state or local law.

",125000,"['machine learning', 'tableau']"
Artificial Intelligence Engineer,KLA,CA,Full-time,"
 Base Pay Range: $142,000.00 - $241,400.00 Annually 
 Primary Location: USA-CA-Milpitas-KLA 
 KLA’s total rewards package for employees may also include participation in performance incentive programs and eligibility for additional benefits identified below. Interns are eligible for some of the benefits identified below. Our pay ranges are determined by role, level, and location. The range displayed above reflects the minimum and maximum pay for this position in the primary location identified in this posting. Actual pay depends on several factors, including location, job-related skills, experience, and relevant education level or training. If applicable, your recruiter can share more about the specific pay range for your preferred location during the hiring process. 
 
Company Overview KLA is a global leader in diversified electronics for the semiconductor manufacturing ecosystem. Virtually every electronic device in the world is produced using our technologies. No laptop, smartphone, wearable device, voice-controlled gadget, flexible screen, VR device or smart car would have made it into your hands without us. KLA invents systems and solutions for the manufacturing of wafers and reticles, integrated circuits, packaging, printed circuit boards and flat panel displays. The innovative ideas and devices that are advancing humanity all begin with inspiration, research and development. KLA focuses more than average on innovation and we invest 15% of sales back into R&D. Our expert teams of physicists, engineers, data scientists and problem-solvers work together with the world’s leading technology providers to accelerate the delivery of tomorrow’s electronic devices. Life here is exciting and our teams thrive on tackling really hard problems. There is never a dull moment with us. 
 
Group/Division With over 40 years of semiconductor process control experience, chipmakers around the globe rely on KLA to ensure that their fabs ramp next-generation devices to volume production quickly and cost-effectively. Enabling the movement towards advanced chip design, KLA's Global Products Group (GPG), which is responsible for creating all of KLA’s metrology and inspection products, is looking for the best and the brightest research scientist, software engineers, application development engineers, and senior product technology process engineers. The LS-SWIFT Division of KLA’s Global Products Group provides patterned wafer inspection systems for high-volume semiconductor manufacturing. Its mission is to deliver market-leading cost of ownership in defect detection for a broad range of applications in the production of semiconductors. Customers from the foundry, logic, memory, automotive, MEMS, advanced packaging and other markets rely upon high-sample wafer inspection information generated by LS-SWIFT products. LS (Laser Scanning) systems enable cost-effective patterned wafer defect detection for the industry’s most sophisticated process technologies deployed in leading-edge foundry, logic, DRAM, and NAND fabs. SWIFT (Simultaneous Wafer Inspection at Fast Throughput) systems deliver all-wafer-surface (frontside, backside, and edge) macro inspection that is critical for automotive IC, MEMS, and advanced packaging processes as well as foundry/logic and memory fabs. LS-SWIFT operates from a global footprint that includes the US, Singapore, India and Germany, and serves a worldwide customer base across Asia, Europe and North America. 
 
Job Description/Preferred Qualifications 
KLA is seeking a motivated, experienced algorithm engineer to join our algorithms team within our LS-SWIFT in Milpitas, CA, USA. In this position, you will bring industry experience and/or academic background to research and develop new Image Processing algorithms for KLA’s innovative inspection products. You will bring forward and help drive creative ideas, provide technical expertise, and support other team members, collaborators, and customers. 
 Qualifications 

1-7 years of work experience required in development in Image Processing (spectral/spatial filtering techniques, model-based methods and inverse problems, etc.) 
Experience prototyping Algorithms using MATLAB or Python, and implementing algorithms in C++ software under Linux is highly preferred 
Full stack hands-on experience with data and backend infrastructure and front-end and user interface for algorithms 
Familiarity with any of the following is a plus: Linear and Nonlinear Optimization techniques, CUDA/GPU Programming frameworks (e.g., TensorFlow), and Data Analysis and Visualization tools 
Great teammate with excellent written and verbal communication skills. 


Minimum Qualifications Doctorate (Academic) Degree and related work experience of 3 years; Master's Level Degree and related work experience of 6 years; Bachelor's Level Degree and related work experience of 8 years 
 
The company offers a total rewards package that is competitive and comprehensive including but not limited to the following: medical, dental, vision, life, and other voluntary benefits, 401(K) including company matching, employee stock purchase program (ESPP), student debt assistance, tuition reimbursement program, development and career growth opportunities and programs, financial planning benefits, wellness benefits including an employee assistance program (EAP), paid time off and paid company holidays, and family care and bonding leave. 

KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com to request accommodation.

",142000,"['tensorflow', 'python']"
Full Stack Data Engineer,IBM,DC,Full-time,"

Introduction
 As an Application Developer, you will lead IBM into the future by translating system requirements into the design and development of customized systems in an agile environment. The success of IBM is in your hands as you transform vital business needs into code and drive innovation. Your work will power IBM and its clients globally, collaborating and integrating code into enterprise systems. You will have access to the latest education, tools and technology, and a limitless career path with the world’s technology leader. Come to IBM and make a global impact!
  

Your Role and Responsibilities
 Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes.
 Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region’s best places to work multiple times, Octo is an employer of choice!
 

You…
 As a Full Stack Data Engineer with Octo, you will add to our dynamic team supporting highly visible federal contracts and company initiatives. The right candidate will have hands on experience working at all tiers of an application and supporting multiple information retrieval systems to building data driven products. You will be passionate about discovering hidden secrets in piles of data and have an engineering mindset to build new products or improve existing ones based on that insight.
 
Us…
 We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client’s missions.
 
The Program Mission…
 This program will support the General Services Administration’s Information Technology mission to provide development and operational support of new and existing legacy mission-enabling applications. The team is leveraging data to improve user experience of our platform, some of the things you will be working include:

Improve product recommendations for an eCommerce site
Improve search relevance through analysis of existing searching patterns, adjusting synonyms and identifying gaps in performance
Improve algorithms that detect duplicate / similar products and services
Write algorithms to leverage clickstream data to create a more personalized user experience
Leverage NLP to perform entity extraction of information from unstructured data


Education: Bachelor’s Degree or equivalent experience in Computer Science/Engineering or related field.
 Location: Remote
 Clearance: Ability to obtain and maintain a Public Trust Clearance 


Required Technical and Professional Expertise


 ~10 years of overall experience in technology. Government consulting experience desired but not required
 Natural curiosity about data, ability to iterate through difficult and ambiguous problems
 Must be very fluent in writing clean, testable, well-structured Python code and unit tests
 Should have at least intermediate proficiency with Java
 Should have at least a few years of production experience with:
    
 Flask or Django
 Sci-kit learn
 Numpy
 Pandas

 5+ years working with SQL to extract / transform data
 5+ years working with Elasticsearch or Solr
 5+ years working with Linux and writing Shell scripts
 5+ years supporting python services on Linux servers
 5+ years building and operating REST APIs
 Experience working in SRE / DevOps style environment
 Work on sprint teams using agile, rapid development in environment using Continuous Integration and deployment techniques.
 Work independently and efficiently in high-paced environment.
 Excellent communication and writing skills
 Clearance: Ability to obtain and maintain a Public Trust Clearance


 Preferred Technical and Professional Expertise
 Intermediate proficiency in Perl

Previous experience with any of the following technologies:




 Redis
 Gunicorn
 Kubernetes
 SybaseDB
 Angular

 


Ansible
 Apache Kafka
 Apache Spark / Hadoop
 JBOSS



 Nginx
 Apache webserver
 NLP / Entity Extraction

 




Experience with building and deploying AI/ML models including neural networks
 Experience with CI/CD tools such as Jenkins, Artifactory, DataDog, and CI/CD pipelines
 Familiarity with government security frameworks like FISMA
 Agile development methodology experience (SAFe, LESS, Extreme, etc.).





 About Business Unit
 IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.
 



 Your Life @ IBM
 In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.
   Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.
 Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.
 Are you ready to be an IBMer?



 About IBM
 IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.
  
 Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. 
  
 At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.
 



 Location Statement
 IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:
  


Healthcare benefits including medical & prescription drug coverage, dental, vision, and mental health & well being
 - Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short & long- term disability coverage, and opportunities for performance based salary incentive programs
  

Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law
Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals
Diverse and inclusive employee resource groups, giving & volunteer opportunities, and discounts on retail products, services & experiences

 The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year. 
  
 We consider qualified applicants with criminal histories, consistent with applicable law.
  
 IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.
 



 Being You @ IBM
 IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
 
",98000,"['python', 'numpy', 'pandas', 'sql', 'kafka', 'hadoop', 'apache spark']"
"Lead Director, Data Science - Retail Pharmacy",CVS Health,MA,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary
 CVS Health is looking for an experienced analytics leader to direct and mentor a diverse and talented Retail Pharmacy Data Science team. In this role, you'll drive the future analytics direction of retail pharmacy as part of the Analytics & Behavior Change (A&BC) team. A&BC is an organization working to solve some of the most challenging problems at the intersection of technology and healthcare. A&BC leverages advanced analytics, machine learning, modeling, and a hypothesis-driven approach to quickly transform data into actionable, customer-centric insights to drive growth, improve health outcomes and access to health care across all of our businesses in CVS Health.

 This role will be responsible for leading and developing a Retail Pharmacy Data Science team focused on driving value through programs that optimize the patient experience and business value. You will leverage advanced analytics to identify business opportunities, develop and measure pilot programs, evaluate scenarios and optimize adherence outreach.

 KEY RESPONSIBILITIES

 Lead a team of analytic professionals in driving business value through data science solutions
 Collaborate with stakeholders across the organization, including executives, clinicians, technology professionals, and business analysts, to understand business strategy and provide data-driven solutions
 Develop advanced algorithms and statistical predictive models to evaluate scenarios, predict outcomes, and generate strategic insights that enable program optimization.
 Continually evolve and ensure delivery against an analytics roadmap aligned with business partners
 Provide thought leadership and guidance in the development of analytic solutions and business insights for stakeholders
 Interpret and present statistical results in a way that improves understanding and influences business action with a wide range of audiences
 Demonstrate a commitment to diversity, equity, and inclusion through continuous development, modeling inclusive behaviors, and proactively managing bias


 Required Qualifications

 10 + years total business experience
 5+ years of business experience leading analytic projects and initiatives with track record of business impact
 5+ years of people management experience with a track record of leading highly effective and engaged teams
 Bachelors’ degree in quantitative field
 Experience with statistical concepts and advanced analytic techniques, such machine learning models (e.g., linear regression, tree-based non-linear, time series, random forests, natural language processing), generative AI, clustering and segmentation, customer lifetime value, A/B testing, etc.
 Experience with analytic and modeling tools and software, like Python, R, SAS, SQL, etc.

 Preferred Qualifications

 Advanced degree in quantitative field
 Excellent analytical and problem-solving skills
 Strong oral and written communication skills
 Ability to handle multiple, complex projects in a deadline-driven environment
 High levels of self-motivation and attention to detail
 Experience working in healthcare industry

 Education
 Bachelors’ degree in quantitative field

 Pay Range
 The typical pay range for this role is:
 $140,000.00 - $280,000.00
  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company’s equity award program.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",140000,"['python', 'machine learning', 'sql']"
Principal/Senior Principal AI and Radar Software Engineer,Northrop Grumman,MD,Full-time,"
Requisition ID: R10137640

 Category: Engineering
 Location: Linthicum, Maryland, United States of America
 Citizenship required: United States Citizenship
 Clearance Type: Secret
 Telecommute: No- Teleworking not available for this position
 Shift: 1st Shift (United States of America)
 Travel Required: Yes, 10% of the Time
 Relocation Assistance: Relocation assistance may be available
 Positions Available: 6


   At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
 

 As an integral part of our part of Northrop Grumman's AI Engineering and Radar ATR group in Mission Systems Engineering focused on the increasingly important technology areas of automatic target recognition, sensor fusion, advanced exploitation, cognitive mission management, and sensor resource management.
 This position requires up to 100% on-site work in the Linthicum/Baltimore, Maryland campus and the ability to pass an enhanced security review

 This requisition may be filled as a Principal or Senior Principal AI and radar Software Engineer 
Roles and Responsibilities: 

Defines, develops, and delivers novel mathematical and statistical modeling and algorithm development to tackle the challenges of prediction, optimization, and classification.
 Applies machine learning algorithms to large sets of structured and unstructured data to solve a broad range of problems that include applications in pattern recognition, target detection and tracking, machine learning and decision systems, and robotic systems. Prototypes advanced artificial intelligence techniques to stretch the capability of autonomous systems research and development programs.
 Designs, develops, documents, tests and debugs applications software and systems that contain logical and mathematical solutions.
 Collaborates with cross-functional team to deploy machine learning algorithms to prototype testing and production.
 Ensures software standards are met. May use system-of-systems and multi-agent approaches to architect and design AI software systems.
 Works with the customer community, including the warfighter, to understand program intent, system capabilities, and output requirements. May design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better reliability, precision, accuracy, and speed to meet performance requirements.
 Lead and participate in multi-disciplinary, collaborative teams and contribute to the advancement of novel artificial intelligence and machine learning capabilities for today’s warfighter
 Define, Develop, and deliver mathematical & statistical modeling and algorithm development to tackle the challenges of prediction, optimization, and classification
 Apply machine learning algorithms to large sets of structured and unstructured data to solve a broad range of advanced exploitation problems that include applications in pattern recognition, target detection, tracking, and decision systems.
 Collaborate with cross-functional teams to deploy machine learning algorithms to both prototype and production systems. For example, today, there is often a significant gap between prototype systems (supported by server-farm trained neural networks) and the production systems that we deploy to, which often consist of less processing power than a typical smart phone. Bridging this gap will be a significant component of this role.
 Design, develop and analyze signal and image processing algorithms for exploitation of sensor data.
 Works closely with the customer community, including the warfighter, to understand program intent, system capabilities, and output requirements.
 Works closely with the customer community, including the warfighter, to understand program intent, system capabilities, and output requirements
 May design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better reliability, precision, accuracy
 Additional tasks include defining software and system interfaces, system integration and testing, and field support of experiments and demonstrations including flight tests

 Basic Qualifications for Principal :

 BS with 5+, MS with 3+, or Ph.D. with 0 years of experience in Electrical Engineering, Computer Science, Applied Physics, Applied Mathematics, or related technical fields; an additional 4 years of experience may be considered in lieu of a degree 
U.S Citizenship required
 Active DOD secret clearance required prior to start
 Experience in remote sensing, including active radar imaging.
 Experience in developing rapid prototype solutions from concept to design, implementation, initial testing, and integration.
 Experience with presenting and speaking at customer demonstrations, symposia, and conferences.
 Experience with conventional software engineering principles, including code maintenance, coding standards, and version control.
 Experience with algorithm implementations in MATLAB and software development in C, C++, Python, and/or Objective C.
 Demonstrated experience with open-source computer vision and machine learning libraries (e.g., OpenCV, TensorFlow, and Caffe), Unix/Linux operating systems, and multi-threaded/parallel computing.


 Preferred Qualifications:

 Experience with formulating innovative solutions to algorithm development, initiating and fostering client relationships, and executing projects in compliance with cost, schedule, and technical requirements.
 The demonstrated ability to perform innovative, applied research, and to develop sophisticated algorithms under computational or other resource constraints.
 Experience with presenting and speaking at customer demonstrations, symposia, and conferences.
 Possession of or ability to obtain TS/SAP/SCI clearance.


 Basic Qualifications for Senior Principal:

 BS with 9+, MS with 7+, or Ph.D. with 4+ years of experience in Electrical Engineering, Computer Science, Applied Physics, Applied Mathematics, or related technical fields; an additional 4 years of experience may be considered in lieu of a degree 
U.S Citizenship required
 Active DOD secret clearance required prior to start
 Experience in remote sensing, including active radar imaging.
 Experience in developing rapid prototype solutions from concept to design, implementation, initial testing, and integration.
 Experience with presenting and speaking at customer demonstrations, symposia, and conferences.
 Experience with conventional software engineering principles, including code maintenance, coding standards, and version control.
 Demonstrated experience with algorithm implementations in MATLAB and software development in C, C++, Python, and/or Objective C.
 Demonstrated experience with open-source computer vision and machine learning libraries (e.g., OpenCV, TensorFlow, and Caffe), Unix/Linux operating systems, and multi-threaded/parallel computing

 Preferred Qualifications:

 Basic knowledge of red force threat systems.
 Experience with formulating innovative solutions to algorithm development, initiating and fostering client relationships, and executing projects in compliance with cost, schedule, and technical requirements.
 The demonstrated ability to perform innovative, applied research, and to develop sophisticated algorithms under computational or other resource constraints.
 Possession of or ability to obtain TS/SAP/SCI clearance.

 This position is contingent upon the transfer an activeDOD secret clearance prior to starting
 As a full-time employee of Northrop Grumman Mission Systems, you are eligible for our robust benefits package including:

 Medical, Dental & Vision coverage
 401k
 Educational Assistance
 Life Insurance
 Employee Assistance Programs & Work/Life Solutions
 Paid Time Off
 Health & Wellness Resources
 Employee Discounts


 Link to Benefits: https://totalrewards.northropgrumman.com/

 This positions standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off.




 Salary Range: $120,900 - $181,300
  

 Salary Range 2: $149,800 - $224,800
  


   Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
 

 Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.


",120900,"['tensorflow', 'python', 'machine learning']"
Data Scientist,Kaizen Analytix,Remote,Full-time,"
Data Scientist
 Responsibilities: 

Participate in core delivery teams of Kaizen and non-Kaizen (clients, third parties) resources that possess business, technology, and data science skill sets
 Manage multiple work streams from acquisition and planning through successful delivery
 Solve business problems through excellent decision-making and innovative, strategic ideas
 Implement solutions in either client or Kaizen environments

Job Requirements:
Education and Experience: 

PhD in Operations Research, Econometrics, or other applied mathematical discipline OR Master's in Operations Research, Econometrics, or other applied mathematical discipline with at least 1 years of relevant professional experience OR
 Master's degree in Operations Research, Data Science, Business Analytics, Industrial Engineering, Econometrics, Computer Science, or other applied mathematical discipline, with at least 2 years of relevant professional experience 
Expertise in two or more of the following areas: math programming, probability, statistics, forecasting, machine learning, artificial intelligence, or other heuristics 
Strong background in implementing linear programming and mixed integer programming-based solutions
 Expert programmer in two or more of the following: R, SAS, C++, CPLEX, GLPK, Gurobi, MATLAB, Java, SQL, Tableau, Alteryx, PERL, Hadoop, C#
 Excellent written, verbal, and presentation skills
 Ability to travel as dictated by business needs
 , C++, CPLEX, GLPK, Gurobi, MATLAB, Java, SQL, Tableau, Alteryx, PERL, Hadoop, C# 
Excellent written, verbal, and presentation skills 
Ability to travel as dictated by business needs

",120000,"['machine learning', 'tableau', 'sql', 'hadoop']"
"Senior Data Scientist, Pricing",Airbnb,CA,Full-time,"

Airbnb was born in 2007 when two Hosts welcomed three guests to their San Francisco home, and has since grown to over 4 million Hosts who have welcomed more than 1 billion guest arrivals in almost every country across the globe. Every day, Hosts offer unique stays and experiences that make it possible for guests to connect with communities in a more authentic way.

 The Community You Will Join: 
You will join a collaborative team of data scientists, analysts, engineers, product managers and designers who build pricing products for Airbnb hosts. Your core team will consist of data scientists within the Marketplace organization, who develop models, foundational tools, and insights to improve the Airbnb marketplace for guests and hosts.
 The Difference You Will Make:
 You will develop methods to measure the impact of pricing feature launches, both experimental and observational (using causal methods). Your most impactful work will involve (1) designing experimental and observational measurement plans, (2) measuring the impact of new pricing features, and (3) successfully surfacing insights with a strong and coherent data narrative to cross-functional partners, thus driving decision making for future pricing innovation.
 A Typical Day:

Developing a strong relationship with cross-functional partners in Product, Engineering and Analytics.
Writing software (Python, SQL, R) to model, simulate and measure the impact of new pricing features.
Creatively diving into data to understand the differential effects of pricing feature launches and turning that understanding into clear insights.
Communicating learnings and insights to leaders and partners in a simple and lucid way

Your Expertise:

5+ years of experience with BS/masters degree, 2+ years of experience with PhD.
Experience with experimentation and causal observational analysis.
Strong coding skills in SQL and either Python or R.
Ability to autonomously set a roadmap for business impact.
Strong oral and written communication skills - an ability to communicate complex technical concepts to a non-technical audience.
Work authorization (if applicable)
Travel requirements (if applicable) 

Preferred unique skill-sets (eg: experience with certain technologies, systems or platforms, specific cross-functional expertise)
 

Your Location:
 This position is US - Remote Eligible. The role may include occasional work at an Airbnb office or attendance at offsites, as agreed to with your manager. While the position is Remote Eligible, you must live in a state where Airbnb, Inc. has a registered entity. Click here for the up-to-date list of excluded states. This list is continuously evolving, so please check back with us if the state you live in is on the exclusion list. If your position is employed by another Airbnb entity, your recruiter will inform you what states you are eligible to work from.
 Our Commitment To Inclusion & Belonging:
 Airbnb is committed to working with the broadest talent pool possible. We believe diverse ideas foster innovation and engagement, and allow us to attract creatively-led people, and to develop the best products, services and solutions. All qualified individuals are encouraged to apply.
 We strive to also provide a disability inclusive application and interview process. If you are a candidate with a disability and require reasonable accommodation in order to submit an application, please contact us at: reasonableaccommodations@airbnb.com. Please include your full name, the role you're applying for and the accommodation necessary to assist you with the recruiting process.
 We ask that you only reach out to us if you are a candidate whose disability prevents you from being able to complete our online application.


 How We'll Take Care of You:
 Our job titles may span more than one career level. The actual base pay is dependent upon many factors, such as: training, transferable skills, work experience, business needs and market demands. The base pay range is subject to change and may be modified in the future. This role may also be eligible for bonus, equity, benefits, and Employee Travel Credits.

 Pay Range

    $165,000—$208,500 USD
  

",165000,"['python', 'sql']"
Data Scientist (-),DCI Solutions,MD,Full-time,"JLS Job Requirement for:
Data Scientist
Location: Bethesda, MD
Job Description:
Serves as a Data Scientist for Big Data/Predictive Analytics program
Supports national security objectives:

Analyze data from a variety of sources

Design, build and optimize a Data Science platform focused on:

Small research and development projects
Analyzing a variety of big data
National Security, Cybersecurity, Business Intel, Social Media, Human Behavior, etc.
Exploratory analysis
Quantitative methods
Interface application design
Customization for customer’s requirements

Work both independently and within a team of professionals to:

Develop and enrich findings
Brief Senior Leaders and conferences
Contribute to publications

Identify novel sources of data across a range of fields to:

Improve the performance of predictive algorithms
Encourage user adoption of high-end data analytics platforms

Qualifications:
BS in quantitative or analytical field

Computer Science, Mathematics, Physics, Economics, Engineering, Statistics, etc

4+ years of directly relevant experience in data science
Proficient in scripting language such as R or Python
Experience conducting research in data analytics or big data
Requirement decomposition of software and data for optimized/cost-effective solutions
Familiar with containers/orchestration (Docker and Kubernetes)
Familiar with git, dvc, mlflow, and other version control technologies
Familiar with open source, PAI, forensic media, MASINT, cybersecurity, etc.
Experience with databases (SQL, NoSQL, Elasticsearch)
Experience with graphs and related technology such as neo4j
Clearance: TS/SCI
Job Type: Full-time
Salary: $170,000-$220,000
Job Type: Full-time
Pay: $170,000.00 - $220,000.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Professional development assistance
Relocation assistance
Retirement plan
Tuition reimbursement
Vision insurance

Schedule:

Monday to Friday

Supplemental pay types:

Commission pay
Signing bonus

Education:

Bachelor's (Preferred)

Experience:

data science: 4 years (Preferred)
R and python: 4 years (Preferred)
Docker and Kubernetes: 2 years (Preferred)
SQL, NoSQL, and/or Elasticsearch: 2 years (Preferred)

Security clearance:

Top Secret (Required)

Work Location: In person",170000,"['python', 'docker', 'nosql', 'sql', 'git']"
Senior Principal Data Scientist (Melbourne FL),Northrop Grumman,FL,Full-time,"
Requisition ID: R10138069

 Category: Research and Sciences
 Location: Melbourne, Florida, United States of America
 Citizenship required: United States Citizenship
 Clearance Type: Secret
 Telecommute: No- Teleworking not available for this position
 Shift: Any (United States of America)
 Travel Required: Yes, 10% of the Time
 Positions Available: 1


   At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
 

 Are you motivated to work in an environment that will challenge you, force you to continuously innovate, and work on solutions that make a difference for your customers?

 Northrop Grumman Aerospace Systems relies on our team to provide the insights needed to drive performance across a broad range of strategic activities.

 We are looking for a passionate Senior Principal Data Scientist in Melbourne Florida to design and develop automated, end-to-end, ETL pipelines, Artificial Intelligence/Machine Learning (AI/ML) solutions, and Data Analytics/Visualization solutions from disparate data sources.

 You will share in the ownership of the technical vision and direction for advanced analytics systems that change the way we see and use data. We are looking for people who are self-motivated, hardworking, and have demonstrated the ability to find innovative solutions to complex technical problems.

 Job Responsibilities:

 Design, develop, and maintain a scalable Extract, Transform, and Load (ETL) pipelines.
 Enable storing, searching, processing, and securing of extremely large structured or unstructured data sets.
 Data preparation/cleaning, integration, and automation from heterogeneous sources
 Ensure data integrity and system availability
 Identify, evaluate, and recommend core technologies and strategies
 Monitor and optimize system performance
 Decomposition of user requirements into logical functions/components


 Basic Qualifications for Sr. Principal Data Scientist:

 Bachelor’s degree in STEM with 9 years of related experience; Masters degree in STEM with 7 years of related experience. PhD with 4 years of related experience.
 Understanding of elastic data storage and archive storage lifecycle management
 Experience with Data Science practices for prescriptive, predictive, diagnostic, descriptive, and cognitive analytics through automation, storage elasticity, and on-demand self service provisioning of all data types and lifecycles.
 Experience with Tableau development or similar data application development.
 Experience with SQL (structure query language) and relational databases.
 Experience with graphic design background, creating user interfaces, and user focused dashboards.
 Excellent communication skills and customer facing experience.
 Proven ability to learn and master new technologies and techniques.
 US Citizenship with the ability to obtain/maintain an active DoD Secret Clearance.
 Must be able to obtain Program Access (PAR) within a reasonable amount of time


 Preferred Qualifications:

 Master’s degree in STEM with 7 years of related experience.
 5+ years of experience working with ETL techniques and frameworks.


 Expert in Python, SQL, and data visualization tools.


 Development experience utilizing Hadoop, Spark, PowerShell, and automation scripts.
 Familiarity with Data Virtualization and Data Cataloging tools (e.g. Denodo, Collibra).
 Experience with NoSQL Databases (e.g., MongoDB, Neo4J, etc.)


 CompTIA Security+ Certification.
 Current DOD Top Secret clearance.




 Salary Range: $123,400 - $185,000
  


   Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
 

 Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.


",123400,"['python', 'machine learning', 'tableau', 'nosql', 'etl', 'sql', 'hadoop']"
"Data Science, Lead Associate",Peraton,MD,Full-time,"
Peraton Overview
 Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.
 
Responsibilities

 Peraton is hiring a Data Scientist to join our Cyber Mission business unit in Fort Meade, Maryland. As a Data Scientist on our team, you will support one of the largest enterprise-wide engineering contracts within the Intelligence Community. This is a full-time position requiring 1880 hours of support per year; and work is performed at a customer location. As a Data Scientist on our team you will provide support and related services to help simplify, automate, and hasten data movement across the mission platform. The successful individual will perform end-to-end systems engineering for data flows from the perspective of data modeling, data mapping, and support to implementers and mission customers. This position requires strong software and systems engineering expertise across the full life cycle of data and limited need for high-level direction. Key activities include: 
 

Framing, defining, and bounding Enterprise level data needs and concerns into broad actionable initiatives with clearly identifiable downstream tasking 
Recommending new automation strategies and maturing current automation efforts 
Performing high-level data requirements analysis to support the application of data standards across the enterprise. 
Operating within, and coordinating across, teams that employ varying development methodologies (Agile, Scrum, and Kanban). 
Possessing an instinctive aptitude to leverage information and knowledge sharing networks and navigating conflict in a way that fosters constructive outcomes. 

 The selected candidate will demonstrate the aptitude to learn and grow in the following areas. Experience in one or more of these areas will greatly increase the probability of success.
 



Hands on data wrangling: Extract Transform Load (or ETL), Databases, DBA, shell scripting 
Hands on experience with Data Serializations (AVRO/protobuf/YAML/XML/JSON) 
Problem framing, pattern recognition, AI/ML exposure 
SIGINT understanding 
Facility with data query DSLs (e.g. SQL) 


Qualifications


 Bachelor's degree Computer Science, Mathematics, or related discipline plus six years of experience in Mathematics/Statistics, Computer Science, and analysis of data syntax and semantics; High School Diploma or GED plus seven years of experience in Mathematics/Statistics, Computer Science, and analysis of data syntax and semantic; a Master's degree from an accredited college or university in Computer Science, Mathematics, or related discipline and three years of experience; or a or PhD degree from an accredited college or university in Computer Science, Mathematics, or related discipline. 
Position requires TS/SCI clearance with polygraph. 

 Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information. 
 
 Peraton is an Equal Opportunity/Affirmative Action Employer. We consider applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status, or membership in any other group protected by federal, state, or local law. 
 

Target Salary Range

 $112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors.
 

SCA / Union / Intern Rate or Range


EEO
 An Equal Opportunity Employer including Disability/Veteran.
 

Our Values


Benefits
 At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.
 

 Paid Time-Off and Holidays
 Retirement
 Life & Disability Insurance
 Career Development
 Tuition Assistance and Student Loan Financing
 Paid Parental Leave
 Additional Benefits
 Medical, Dental, & Vision Care

",112000,"['etl', 'sql']"
Staff AI and Radar Software Engineer,Northrop Grumman,MD,Full-time,"
Requisition ID: R10137637

 Category: Engineering
 Location: Linthicum, Maryland, United States of America
 Citizenship required: United States Citizenship
 Clearance Type: SAP
 Telecommute: No- Teleworking not available for this position
 Shift: 1st Shift (United States of America)
 Travel Required: Yes, 10% of the Time
 Relocation Assistance: Relocation assistance may be available
 Positions Available: 1


   At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
 

 As an integral part of our part of Northrop Grumman's AI Engineering and Radar ATR group in Mission Systems Engineering focused on the increasingly important technology areas of automatic target recognition, sensor fusion, advanced exploitation, cognitive mission management, and sensor resource management.
 This position requires up to 100% on-site work in the Linthicum/Baltimore, Maryland campus and the ability to pass an enhanced security review

 Roles & Responsibilities:

 Lead and participate in multi-disciplinary, collaborative teams and contribute to the advancement of novel artificial intelligence and machine learning capabilities for today’s warfighter
 Define, Develop, and deliver mathematical & statistical modeling and algorithm development to tackle the challenges of prediction, optimization, and classification.
 Apply machine learning algorithms to large sets of structured and unstructured data to solve a broad range of advanced exploitation problems that include applications in pattern recognition, target detection, tracking, and decision systems.
 Collaborate with cross-functional teams to deploy machine learning algorithms to both prototype and production systems. For example, today, there is often a significant gap between prototype systems (supported by server-farm trained neural networks) and the production systems that we deploy to, which often consist of less processing power than a typical smart phone. Bridging this gap will be a significant component of this role.
 Design, develop and analyze signal and image processing algorithms for exploitation of sensor data
 Works closely with the customer community, including the warfighter, to understand program intent, system capabilities, and output requirements
 May design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better reliability, precision, accuracy, and speed to meet performance requirements
 Additional tasks include defining software and system interfaces, system integration and testing, and field support of experiments and demonstrations including flight tests
 Work products include written reports, presentations, and project proposals. Occasional travel for meetings and flight test exercises will be required

 Basic Qualifications:

 Bachelor’s degree with 14 years of experience, a Master’s degree with 12 years of experience or a PhD with 9 years of experience in Electrical Engineering, Computer Engineering, Computer Science, or related technical fields; an additional 4 years of experience may be considered in lieu of a degree 
US citizenship required
 Top secret/SAP/SCI clearance required prior to access
 Expertise in remote sensing, including active radar imaging.
 Basic knowledge of red force threat systems.
 Experience with formulating innovative solutions to algorithm development, initiating and fostering client relationships, and executing projects in compliance with cost, schedule, and technical requirements.
 Experience in developing rapid prototype solutions from concept to design, implementation, initial testing, and integration.
 Experience with presenting and speaking at customer demonstrations, symposia, and conferences.
 The demonstrated ability to perform innovative, applied research, and to develop sophisticated algorithms under computational or other resource constraints.
 Experience with conventional software engineering principles, including code maintenance, coding standards, and version control.
 Demonstrated experience with algorithm implementations in MATLAB and software development in C, C++, Python, and/or Objective C
 Demonstrated experience with open-source computer vision and machine learning libraries (e.g., OpenCV, TensorFlow, and Caffe), Unix/Linux operating systems, and multi-threaded/parallel computing.


 This position is contingent upon the successful transfer of a Top secret/SAP/SCI clearance required prior to starting
 As a full-time employee of Northrop Grumman Mission Systems, you are eligible for our robust benefits package including:

 Medical, Dental & Vision coverage
 401k
 Educational Assistance
 Life Insurance
 Employee Assistance Programs & Work/Life Solutions
 Paid Time Off
 Health & Wellness Resources
 Employee Discounts


 Link to Benefits: https://totalrewards.northropgrumman.com/
 This positions standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off.



 Salary Range: $185,900 - $278,900
  


   Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
 

 Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.


",185900,"['tensorflow', 'python', 'machine learning']"
Artificial Intelligence Engineer,KLA,CA,Full-time,"
 Base Pay Range: $142,000.00 - $241,400.00 Annually 
 Primary Location: USA-CA-Milpitas-KLA 
 KLA’s total rewards package for employees may also include participation in performance incentive programs and eligibility for additional benefits identified below. Interns are eligible for some of the benefits identified below. Our pay ranges are determined by role, level, and location. The range displayed above reflects the minimum and maximum pay for this position in the primary location identified in this posting. Actual pay depends on several factors, including location, job-related skills, experience, and relevant education level or training. If applicable, your recruiter can share more about the specific pay range for your preferred location during the hiring process. 
 
Company Overview KLA is a global leader in diversified electronics for the semiconductor manufacturing ecosystem. Virtually every electronic device in the world is produced using our technologies. No laptop, smartphone, wearable device, voice-controlled gadget, flexible screen, VR device or smart car would have made it into your hands without us. KLA invents systems and solutions for the manufacturing of wafers and reticles, integrated circuits, packaging, printed circuit boards and flat panel displays. The innovative ideas and devices that are advancing humanity all begin with inspiration, research and development. KLA focuses more than average on innovation and we invest 15% of sales back into R&D. Our expert teams of physicists, engineers, data scientists and problem-solvers work together with the world’s leading technology providers to accelerate the delivery of tomorrow’s electronic devices. Life here is exciting and our teams thrive on tackling really hard problems. There is never a dull moment with us. 
 
Group/Division With over 40 years of semiconductor process control experience, chipmakers around the globe rely on KLA to ensure that their fabs ramp next-generation devices to volume production quickly and cost-effectively. Enabling the movement towards advanced chip design, KLA's Global Products Group (GPG), which is responsible for creating all of KLA’s metrology and inspection products, is looking for the best and the brightest research scientist, software engineers, application development engineers, and senior product technology process engineers. The LS-SWIFT Division of KLA’s Global Products Group provides patterned wafer inspection systems for high-volume semiconductor manufacturing. Its mission is to deliver market-leading cost of ownership in defect detection for a broad range of applications in the production of semiconductors. Customers from the foundry, logic, memory, automotive, MEMS, advanced packaging and other markets rely upon high-sample wafer inspection information generated by LS-SWIFT products. LS (Laser Scanning) systems enable cost-effective patterned wafer defect detection for the industry’s most sophisticated process technologies deployed in leading-edge foundry, logic, DRAM, and NAND fabs. SWIFT (Simultaneous Wafer Inspection at Fast Throughput) systems deliver all-wafer-surface (frontside, backside, and edge) macro inspection that is critical for automotive IC, MEMS, and advanced packaging processes as well as foundry/logic and memory fabs. LS-SWIFT operates from a global footprint that includes the US, Singapore, India and Germany, and serves a worldwide customer base across Asia, Europe and North America. 
 
Job Description/Preferred Qualifications 
KLA is seeking a motivated, experienced algorithm engineer to join our algorithms team within our LS-SWIFT in Milpitas, CA, USA. In this position, you will bring industry experience and/or academic background to research and develop new Image Processing algorithms for KLA’s innovative inspection products. You will bring forward and help drive creative ideas, provide technical expertise, and support other team members, collaborators, and customers. 
 Qualifications 

1-7 years of work experience required in development in Image Processing (spectral/spatial filtering techniques, model-based methods and inverse problems, etc.) 
Experience prototyping Algorithms using MATLAB or Python, and implementing algorithms in C++ software under Linux is highly preferred 
Full stack hands-on experience with data and backend infrastructure and front-end and user interface for algorithms 
Familiarity with any of the following is a plus: Linear and Nonlinear Optimization techniques, CUDA/GPU Programming frameworks (e.g., TensorFlow), and Data Analysis and Visualization tools 
Great teammate with excellent written and verbal communication skills. 


Minimum Qualifications Doctorate (Academic) Degree and related work experience of 3 years; Master's Level Degree and related work experience of 6 years; Bachelor's Level Degree and related work experience of 8 years 
 
The company offers a total rewards package that is competitive and comprehensive including but not limited to the following: medical, dental, vision, life, and other voluntary benefits, 401(K) including company matching, employee stock purchase program (ESPP), student debt assistance, tuition reimbursement program, development and career growth opportunities and programs, financial planning benefits, wellness benefits including an employee assistance program (EAP), paid time off and paid company holidays, and family care and bonding leave. 

KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com to request accommodation.

",142000,"['tensorflow', 'python']"
AI and Radar Software Engineer,Northrop Grumman,MD,Full-time,"
Requisition ID: R10137644

 Category: Engineering
 Location: Linthicum, Maryland, United States of America
 Citizenship required: United States Citizenship
 Clearance Type: Secret
 Telecommute: No- Teleworking not available for this position
 Shift: 1st Shift (United States of America)
 Travel Required: Yes, 10% of the Time
 Relocation Assistance: Relocation assistance may be available
 Positions Available: 3


   At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
 

 As an integral part of our part of Northrop Grumman's AI Engineering and Radar ATR group in Mission Systems Engineering focused on the increasingly important technology areas of automatic target recognition, sensor fusion, advanced exploitation, cognitive mission management, and sensor resource management.
 This position requires up to 100% on-site work in the Linthicum/Baltimore, Maryland campus and the ability to pass an enhanced security review
 Roles and Responsibilities: 

Defines, develops, and delivers novel mathematical and statistical modeling and algorithm development to tackle the challenges of prediction, optimization, and classification.
 Applies machine learning algorithms to large sets of structured and unstructured data to solve a broad range of problems that include applications in pattern recognition, target detection and tracking, machine learning and decision systems, and robotic systems. Prototypes advanced artificial intelligence techniques to stretch the capability of autonomous systems research and development programs.
 Designs, develops, documents, tests and debugs applications software and systems that contain logical and mathematical solutions.
 Collaborates with cross-functional team to deploy machine learning algorithms to prototype testing and production. Ensures software standards are met. May use system-of-systems and multi-agent approaches to architect and design AI software systems.
 Works with the customer community, including the warfighter, to understand program intent, system capabilities, and output requirements. May design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better reliability, precision, accuracy, and speed to meet performance requirements.

 Basic Qualifications

 Bachelor’s degree with 2+ years of experience, Masters’s degree and no experience, in Electrical Engineering, Computer Science, Applied Physics, Applied Mathematics, or related technical fields. an additional 4 years of experience may be considered in lieu of a degree
 US citizenship required
 Ability to obtain/ Maintain DOD secret clearance prior to access
 Experience with conventional software engineering principles, including code maintenance, coding standards, and version control.
 Experience with software development in C, C++, Python, and/or Objective C.
 Demonstrated experience with open-source computer vision and machine learning libraries (e.g., OpenCV, TensorFlow, and Caffe), Unix/Linux operating systems, and multi-threaded/parallel computing.

 Preferred Qualifications

 Experience in remote sensing, including active radar imaging.
 Experience in developing rapid prototype solutions from concept to design, implementation, initial testing, and integration.
 Experience with presenting and speaking at customer demonstrations, symposia, and conferences.
 Experience with formulating innovative solutions to algorithm development, initiating and fostering client relationships, and executing projects in compliance with cost, schedule, and technical requirements.
 The demonstrated ability to perform innovative, applied research, and to develop sophisticated algorithms under computational or other resource constraints.
 Possession of or ability to obtain a Secret clearance.

 This position is contingent upon the ability to obtain/maintain DOD secret clearance prior to starting
 As a full-time employee of Northrop Grumman Mission Systems, you are eligible for our robust benefits package including:

Medical, Dental & Vision coverage
401k
Educational Assistance
Life Insurance
Employee Assistance Programs & Work/Life Solutions
Paid Time Off
Health & Wellness Resources
Employee Discounts

 Link to Benefits: https://totalrewards.northropgrumman.com/
 This positions standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off.



 Salary Range: $98,200 - $147,200
  


   Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
 

 Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.


",98200,"['tensorflow', 'python', 'machine learning']"
"Senior Manager, Data Science",CVS Health,NY,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary
 This is a hands-on senior manager role – expected to be able to manage 2-3 junior data scientists while also serving as
 a technical leader and driving forward independent contribution.

 As a senior manager, you will:

Direct activities of data scientists, providing guidance, mentorship, and performance management

 to drive excellence in data science projects and deliverables.

Define data science strategies, methodologies, and best practices to solve complex healthcare

 challenges and drive innovation.

Counsel the team in data exploration, analysis, and modeling techniques to derive actionable

 insights and inform healthcare decision-making processes.

Direct activities of data science projects, including resource allocation, budget management, and

 timeline adherence, ensuring successful project execution.

Advise senior leadership and stakeholders on data-driven strategies and solutions, providing

 insights and recommendations based on data analysis.

Collaborate with multiple departments, including clinicians, data engineers, marketing, etc. to

 define project objectives, scope, and deliverables.

Manage team performance through regular, timely feedback as well as the formal performance

 review process to ensure delivery of exceptional services and engagement, motivation, and team
 development.

Deliver a culture of learning and growth within the data science team, fostering collaboration,

 knowledge sharing, and professional development opportunities.  Required Qualifications

8+ years of data analytics experience
5+ years of experience in technical programming fundamentals in either SQL, Python or

 comparable software

2+ years supervisory/leadership experience


 Preferred Qualifications

Demonstrates strong ability to communicate technical concepts and implications to business

 partners

Adept at problem solving and decision-making skills
Adept at execution + delivery; anticipates and prevents problems and roadblocks before they

 occur

Attention to detail and consistent delivery of high-quality work
Experience with using cloud-based tools (Google, AWS, Azure) for analytics and model

 development

Healthcare sector experience preferred
Experience with deploying models and maintaining models in production using ML Ops workflow


 Education
 Bachelors; Masters or PhD Preferred
 
 Pay Range
 The typical pay range for this role is:
 $132,250.00 - $260,000.00
  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company’s equity award program.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",132250,"['python', 'aws', 'azure', 'sql']"
Senior Concept Development Analyst (NLP),Cotiviti,Remote,Full-time,"
 Overview: 
  As a Senior NLP Concept Development Analyst (CDA), you will play a pivotal role in advancing the identification, creation, implementation, and seamless integration of groundbreaking Natural Language Processing (NLP) concepts. Building upon your extensive experience and expertise in the industry, clinical domain, and technical acumen, you will drive the evolution of our NLP application. You will create new and enhance existing NLP rules supporting the CCV NLP Program. This role serves both government and commercial payers. Responsibilities: 
 
Collaborates with CCV NLP Program leads to identify new and existing rule development opportunities. 
Utilizes current NLP solution infrastructure to write and revise NLP 
Develops NLP systems according to business requirements. 
Spearheads the exploration, generation, and execution of NLP concepts across various healthcare provider settings by leveraging in-depth insights into healthcare billing and coding practices, clinical insights, and regulatory knowledge.
 Leads the effort to identify NLP coding and clinical logic development opportunities. 
Maintains an enterprise vision for the group; understands challenges, complexities, and possibilities of expanding logic to other business units.
 Has significant knowledge of the current and potential uses of AI, Machine Learning (ML), and NLP technologies for clinical information analysis and processing.
 Utilizes strong working relationships across the organization to leverage development of improved processes in the Concept Development (CD) team and to support their completion and adaptation in the organization.
 Provides support for all levels of auditor claims, particularly those of a complex nature. 
Provides guidance and support to other team members regarding verification of claims validation and policy guidance.
 Uses analytical skills to identify concept effectiveness and potential areas for refinement. Advanced level of proficiency using audit tools to evaluate, document, and validate new claims and concept effectiveness.
 Qualifications: 
 
Bachelor’s degree in Health Informatics, Biomedical Informatics, HIM, nursing, or related field; or 5 years of related experience.
 Minimum of 5 years of related experience in healthcare and informatics.
 Proven claim integrity expertise within Hospital, SNF, IRF, or Physician Billing.
 Experience with most healthcare coding systems (SNOMED, CPT4, HCPCS, DRG, ICD-10 and ICD-10, Home Health, SNF, Modifiers, Revenue Codes, etc.)
 Excellent verbal and written communication skills.
 Effective mentorship and training skills.
 Strong analytical and investigative skills.
 Proficiency with Excel including pivot tables and formulas required. 
Proficiency in manipulating data within Tableau preferred.
 Ability to work independently, recognize and quickly shift priorities, and document progress required.
 Prior auditing or consulting experience desirable in either a provider or payer environment.


 Job Demands:


 The role can work at home anywhere in the continental United States
 Able to use computer keyboard for extended periods of time
 After hours and/or weekend work may be required where necessary for major deliverables /deadlines.


   Base compensation ranges from $100,000 to $130,000. Specific offers are determined by various factors, such as experience, education, skills, certifications, and other business needs. This role is eligible for discretionary bonus consideration.
 


 Cotiviti offers team members a competitive benefits package to address a wide range of personal and family needs, including medical, dental, vision, disability, and life insurance coverage, 401(k) savings plans, paid family leave, 9 paid holidays per year, and 17-27 days of Paid Time Off (PTO) per year, depending on specific level and length of service with Cotiviti. For information about our benefits package, please refer to our Careers page.
 


 #LI-JB1
 

   #LI-Remote
 

   #senior
 
",100000,"['machine learning', 'tableau']"
"Sr. Director, Data Science and Machine Learning",Centerfield,CA,Full-time,"

Hi, We're Centerfield. 


  Super-powered customer acquisition. Centerfield delivers outcome-based digital marketing solutions and personalized omnichannel experiences for the world’s leading brands. Powered by our proprietary Dugout platform, Centerfield acquires customers at scale for leading residential service, insurance, e-commerce and B2B brands. Centerfield’s digital experiences and digital brands, such as Business.com and BroadbandNow.com, reach more than 150 million in-market shoppers annually. Centerfield is headquartered in Silicon Beach and proud to be recognized as a Best Place to Work in Los Angeles.
 


 The Opportunity...


   Centerfield Media, a leading Los Angeles-based online advertising agency, is looking for a talented Sr. Director of data to join us in building innovative advertising technology. We are looking for a highly motivated, web-focused, Leader with experience with the full data life cycle. You will help design the data science programs, persona, machine learning models, and architecture to support Generative AI. You will build a team of data scientists, machine learning engineers, and Architects. You must have practical experience working with large data sets preferably in website lead generation & search engine marketing, SaaS, or cloud computing domains.
 
How You'll Contribute...

 Need to own problems from end to end so that you can best collect, extract, and clean the data.
 Ability to lead projects individually and deliver them on time.
 Experience with Realtime streaming implementation and architecture is a bonus.
 Experience building reports and data visualization with any BI tools like Tableau, Power BI, etc.
 Build high-performance, responsive teams of data scientists, and analysts that can gather and synthesize data quickly and accurately. Help to implement maintenance strategy for all datasets.
 Support an organizational effort toward better understanding user needs and pain points and propose roles that data science can play to further this goal.
 Support data-informed decision-making, throughout the Product Org and broader company. Be a thought leader and evangelist to drive adoption and knowledge at all levels of the organization.
 Develop an investment strategy to define, grow, and maintain an exemplary data science organization.
 Constantly look for strategic ways to expand the charter of the Data Science team beyond causal inference, starting with Ranking Data Science, and Market-Place Dynamics
 Determine how to leverage data science, machine learning, and other analytical techniques to offer actionable insights both internally & externally.

 What We're Looking For...

 Deep technical background with an MS or PhD in mathematics, statistics, computer science, or a related field
 10+ Years working in a Data Engineer, BI Engineer, or Data Warehousing Engineer role.
 Google Cloud Platform (Google cloud bucket, Google cloud fusion, Google Big Query, Google Analytics)
 6+ Years leading teams to conduct research, in-depth analysis, and automation efforts.
 5+ Years building repour and developing relationships with key stakeholders. Delivering against critical expectations for multiple priorities.
 5+ Years Building models and various ML tooling.

 Life at Centerfield...

 This is a hybrid position, and employees are expected to come into our Playa Vista, CA office every Tuesday, Wednesday & Thursday
 Competitive salary + bi-annual bonus
 Unlimited PTO – take a break when you need it!
 Industry-leading medical, dental, and vision plans + generous parental leave
 401(k) company match plan – fully vested on day 1
 Outside patio overlooking Playa Vista + cabanas, firepits & working grills
 Monthly happy hours, catered lunches + daily food trucks
 Award-winning culture & unprecedented team spirit (featured in LA Business Journal & Built In LA)
 Fully stocked kitchens with snacks & drinks
 Breakroom supplied with games, couches, workout equipment + weekly in-office exercise classes hosted by professional instructors (yoga, kickboxing & circuit training)
 Free onsite gym + locker rooms
 Paid charity and volunteer days (local mentor programs, adopt a pet, beach cleanup, etc.)
 Monthly team outings (ball games, casino night, hikes, etc.)
 Career growth – we enjoy promoting from within!


   #LI-Hybrid
 

 To learn more, visit us 
Here
. 


  Interviews will take place after resumes have been screened for minimum requirements. Please note that this position is not restricted solely to the responsibilities listed above and that the job scope and responsibilities are subject to change.
 


 For more information about our collection, use, and disclosure of your personal information in connection with our evaluating your candidacy, please visit our Privacy Policy at https://www.centerfield.com/privacy-policy/.
 



 Centerfield Media is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected under federal, state or local law.

",125000,"['machine learning', 'tableau']"
"Lead Director, Data Science - Retail Pharmacy",CVS Health,MA,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary
 CVS Health is looking for an experienced analytics leader to direct and mentor a diverse and talented Retail Pharmacy Data Science team. In this role, you'll drive the future analytics direction of retail pharmacy as part of the Analytics & Behavior Change (A&BC) team. A&BC is an organization working to solve some of the most challenging problems at the intersection of technology and healthcare. A&BC leverages advanced analytics, machine learning, modeling, and a hypothesis-driven approach to quickly transform data into actionable, customer-centric insights to drive growth, improve health outcomes and access to health care across all of our businesses in CVS Health.

 This role will be responsible for leading and developing a Retail Pharmacy Data Science team focused on driving value through programs that optimize the patient experience and business value. You will leverage advanced analytics to identify business opportunities, develop and measure pilot programs, evaluate scenarios and optimize adherence outreach.

 KEY RESPONSIBILITIES

 Lead a team of analytic professionals in driving business value through data science solutions
 Collaborate with stakeholders across the organization, including executives, clinicians, technology professionals, and business analysts, to understand business strategy and provide data-driven solutions
 Develop advanced algorithms and statistical predictive models to evaluate scenarios, predict outcomes, and generate strategic insights that enable program optimization.
 Continually evolve and ensure delivery against an analytics roadmap aligned with business partners
 Provide thought leadership and guidance in the development of analytic solutions and business insights for stakeholders
 Interpret and present statistical results in a way that improves understanding and influences business action with a wide range of audiences
 Demonstrate a commitment to diversity, equity, and inclusion through continuous development, modeling inclusive behaviors, and proactively managing bias


 Required Qualifications

 10 + years total business experience
 5+ years of business experience leading analytic projects and initiatives with track record of business impact
 5+ years of people management experience with a track record of leading highly effective and engaged teams
 Bachelors’ degree in quantitative field
 Experience with statistical concepts and advanced analytic techniques, such machine learning models (e.g., linear regression, tree-based non-linear, time series, random forests, natural language processing), generative AI, clustering and segmentation, customer lifetime value, A/B testing, etc.
 Experience with analytic and modeling tools and software, like Python, R, SAS, SQL, etc.

 Preferred Qualifications

 Advanced degree in quantitative field
 Excellent analytical and problem-solving skills
 Strong oral and written communication skills
 Ability to handle multiple, complex projects in a deadline-driven environment
 High levels of self-motivation and attention to detail
 Experience working in healthcare industry

 Education
 Bachelors’ degree in quantitative field

 Pay Range
 The typical pay range for this role is:
 $140,000.00 - $280,000.00
  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company’s equity award program.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",140000,"['python', 'machine learning', 'sql']"
Consulting AI and Radar Software Engineer,Northrop Grumman,MD,Full-time,"
Requisition ID: R10136654

 Category: Engineering
 Location: Linthicum, Maryland, United States of America
 Citizenship required: United States Citizenship
 Clearance Type: SAP
 Telecommute: No- Teleworking not available for this position
 Shift: 1st Shift (United States of America)
 Travel Required: Yes, 25% of the Time
 Relocation Assistance: Relocation assistance may be available
 Positions Available: 1


   At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
 

 As an integral part of our part of Northrop Grumman's AI Engineering and Radar ATR group in Mission Systems Engineering focused on the increasingly important technology areas of automatic target recognition, sensor fusion, advanced exploitation, cognitive mission management, and sensor resource management.
 This position requires up to 100% on-site work in the Linthicum/Baltimore, Maryland campus and the ability to pass an enhanced security review
 Roles and Responsibilities: 

Lead and participate in multi-disciplinary, collaborative teams and contribute to the advancement of novel artificial intelligence and machine learning capabilities for today’s warfighter
 Define, Develop, and deliver mathematical & statistical modeling and algorithm development to tackle the challenges of prediction, optimization, and classification
 Apply machine learning algorithms to large sets of structured and unstructured data to solve a broad range of advanced exploitation problems that include applications in pattern recognition, target detection, tracking, and decision systems
 Collaborate with cross-functional teams to deploy machine learning algorithms to both prototype and production systems. For example, today, there is often a significant gap between prototype systems (supported by server-farm trained neural networks) and the production systems that we deploy to, which often consist of less processing power than a typical smart phone. Bridging this gap will be a significant component of this role.
 Design, develop and analyze signal and image processing algorithms for exploitation of sensor data.
 Works closely with the customer community, including the warfighter, to understand program intent, system capabilities, and output requirements
 May design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better reliability, precision, accuracy, and speed to meet performance requirements
 May design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better reliability, precision, accuracy, and speed to meet performance requirements.
 Additional tasks include defining software and system interfaces, system integration and testing, and field support of experiments and demonstrations including flight tests
 Work products include written reports, presentations, and project proposals. Occasional travel for meetings and flight test exercises will be required.

 Basic Qualifications:

 Bachelor’s degree with 20 years of experience, a Master’s degree with 18 years of experience or a PhD with 15 years of experience in Electrical Engineering, Computer Engineering, Computer Science, Applied Physics, Applied Mathematics, or related technical fields; an additional 4 years of experience may be considered in lieu of a degree
 U.S Citizenship required
 Active Top Secret/ SAP/SCI clearance required prior to access
 Proven expertise in remote sensing, including active radar imaging
 Strong working knowledge of red force threat systems
 Proven experience with formulating innovative solutions to algorithm development, initiating and fostering client relationships, and executing projects in compliance with cost, schedule, and technical requirements.
 Proven experience in developing rapid prototype solutions from concept to design, implementation, initial testing, and integration.
 Proven experience with presenting and speaking at customer demonstrations, symposia, and conferences.
 The demonstrated ability to perform innovative, applied research, and to develop sophisticated algorithms under computational or other resource constraints.
 Proven experience with conventional software engineering principles, including code maintenance, coding standards, and version control.
 Proven experience with algorithm implementations in MATLAB and software development in C, C++, Python, and/or Objective C.
 Proven experience with open-source computer vision and machine learning libraries (e.g., OpenCV, TensorFlow, and Caffe), Unix/Linux operating systems, and multi-threaded/parallel computing.

 This position is contingent upon the successful transfer of an active DoD Secret Clearance and the ability to obtain Special Program Access (SAP) prior to starting
 As a full-time employee of Northrop Grumman Mission Systems, you are eligible for our robust benefits package including:

 Medical, Dental & Vision coverage
 401k
 Educational Assistance
 Life Insurance
 Employee Assistance Programs & Work/Life Solutions
 Paid Time Off
 Health & Wellness Resources
 Employee Discounts


 Link to Benefits: https://totalrewards.northropgrumman.com/

 This positions standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off.



 Salary Range: $229,400 - $344,000
  


   Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
 

 Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.


",229400,"['tensorflow', 'python', 'machine learning']"
Data Scientist,Kaizen Analytix,Remote,Full-time,"
Data Scientist
 Responsibilities: 

Participate in core delivery teams of Kaizen and non-Kaizen (clients, third parties) resources that possess business, technology, and data science skill sets
 Manage multiple work streams from acquisition and planning through successful delivery
 Solve business problems through excellent decision-making and innovative, strategic ideas
 Implement solutions in either client or Kaizen environments

Job Requirements:
Education and Experience: 

PhD in Operations Research, Econometrics, or other applied mathematical discipline OR Master's in Operations Research, Econometrics, or other applied mathematical discipline with at least 1 years of relevant professional experience OR
 Master's degree in Operations Research, Data Science, Business Analytics, Industrial Engineering, Econometrics, Computer Science, or other applied mathematical discipline, with at least 2 years of relevant professional experience 
Expertise in two or more of the following areas: math programming, probability, statistics, forecasting, machine learning, artificial intelligence, or other heuristics 
Strong background in implementing linear programming and mixed integer programming-based solutions
 Expert programmer in two or more of the following: R, SAS, C++, CPLEX, GLPK, Gurobi, MATLAB, Java, SQL, Tableau, Alteryx, PERL, Hadoop, C#
 Excellent written, verbal, and presentation skills
 Ability to travel as dictated by business needs
 , C++, CPLEX, GLPK, Gurobi, MATLAB, Java, SQL, Tableau, Alteryx, PERL, Hadoop, C# 
Excellent written, verbal, and presentation skills 
Ability to travel as dictated by business needs

",120000,"['machine learning', 'tableau', 'sql', 'hadoop']"
"Senior Data Scientist, Pricing",Airbnb,CA,Full-time,"

Airbnb was born in 2007 when two Hosts welcomed three guests to their San Francisco home, and has since grown to over 4 million Hosts who have welcomed more than 1 billion guest arrivals in almost every country across the globe. Every day, Hosts offer unique stays and experiences that make it possible for guests to connect with communities in a more authentic way.

 The Community You Will Join: 
You will join a collaborative team of data scientists, analysts, engineers, product managers and designers who build pricing products for Airbnb hosts. Your core team will consist of data scientists within the Marketplace organization, who develop models, foundational tools, and insights to improve the Airbnb marketplace for guests and hosts.
 The Difference You Will Make:
 You will develop methods to measure the impact of pricing feature launches, both experimental and observational (using causal methods). Your most impactful work will involve (1) designing experimental and observational measurement plans, (2) measuring the impact of new pricing features, and (3) successfully surfacing insights with a strong and coherent data narrative to cross-functional partners, thus driving decision making for future pricing innovation.
 A Typical Day:

Developing a strong relationship with cross-functional partners in Product, Engineering and Analytics.
Writing software (Python, SQL, R) to model, simulate and measure the impact of new pricing features.
Creatively diving into data to understand the differential effects of pricing feature launches and turning that understanding into clear insights.
Communicating learnings and insights to leaders and partners in a simple and lucid way

Your Expertise:

5+ years of experience with BS/masters degree, 2+ years of experience with PhD.
Experience with experimentation and causal observational analysis.
Strong coding skills in SQL and either Python or R.
Ability to autonomously set a roadmap for business impact.
Strong oral and written communication skills - an ability to communicate complex technical concepts to a non-technical audience.
Work authorization (if applicable)
Travel requirements (if applicable) 

Preferred unique skill-sets (eg: experience with certain technologies, systems or platforms, specific cross-functional expertise)
 

Your Location:
 This position is US - Remote Eligible. The role may include occasional work at an Airbnb office or attendance at offsites, as agreed to with your manager. While the position is Remote Eligible, you must live in a state where Airbnb, Inc. has a registered entity. Click here for the up-to-date list of excluded states. This list is continuously evolving, so please check back with us if the state you live in is on the exclusion list. If your position is employed by another Airbnb entity, your recruiter will inform you what states you are eligible to work from.
 Our Commitment To Inclusion & Belonging:
 Airbnb is committed to working with the broadest talent pool possible. We believe diverse ideas foster innovation and engagement, and allow us to attract creatively-led people, and to develop the best products, services and solutions. All qualified individuals are encouraged to apply.
 We strive to also provide a disability inclusive application and interview process. If you are a candidate with a disability and require reasonable accommodation in order to submit an application, please contact us at: reasonableaccommodations@airbnb.com. Please include your full name, the role you're applying for and the accommodation necessary to assist you with the recruiting process.
 We ask that you only reach out to us if you are a candidate whose disability prevents you from being able to complete our online application.


 How We'll Take Care of You:
 Our job titles may span more than one career level. The actual base pay is dependent upon many factors, such as: training, transferable skills, work experience, business needs and market demands. The base pay range is subject to change and may be modified in the future. This role may also be eligible for bonus, equity, benefits, and Employee Travel Credits.

 Pay Range

    $165,000—$208,500 USD
  

",165000,"['python', 'sql']"
Data Scientist (-),DCI Solutions,MD,Full-time,"JLS Job Requirement for:
Data Scientist
Location: Bethesda, MD
Job Description:
Serves as a Data Scientist for Big Data/Predictive Analytics program
Supports national security objectives:

Analyze data from a variety of sources

Design, build and optimize a Data Science platform focused on:

Small research and development projects
Analyzing a variety of big data
National Security, Cybersecurity, Business Intel, Social Media, Human Behavior, etc.
Exploratory analysis
Quantitative methods
Interface application design
Customization for customer’s requirements

Work both independently and within a team of professionals to:

Develop and enrich findings
Brief Senior Leaders and conferences
Contribute to publications

Identify novel sources of data across a range of fields to:

Improve the performance of predictive algorithms
Encourage user adoption of high-end data analytics platforms

Qualifications:
BS in quantitative or analytical field

Computer Science, Mathematics, Physics, Economics, Engineering, Statistics, etc

4+ years of directly relevant experience in data science
Proficient in scripting language such as R or Python
Experience conducting research in data analytics or big data
Requirement decomposition of software and data for optimized/cost-effective solutions
Familiar with containers/orchestration (Docker and Kubernetes)
Familiar with git, dvc, mlflow, and other version control technologies
Familiar with open source, PAI, forensic media, MASINT, cybersecurity, etc.
Experience with databases (SQL, NoSQL, Elasticsearch)
Experience with graphs and related technology such as neo4j
Clearance: TS/SCI
Job Type: Full-time
Salary: $170,000-$220,000
Job Type: Full-time
Pay: $170,000.00 - $220,000.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Professional development assistance
Relocation assistance
Retirement plan
Tuition reimbursement
Vision insurance

Schedule:

Monday to Friday

Supplemental pay types:

Commission pay
Signing bonus

Education:

Bachelor's (Preferred)

Experience:

data science: 4 years (Preferred)
R and python: 4 years (Preferred)
Docker and Kubernetes: 2 years (Preferred)
SQL, NoSQL, and/or Elasticsearch: 2 years (Preferred)

Security clearance:

Top Secret (Required)

Work Location: In person",170000,"['python', 'docker', 'nosql', 'sql', 'git']"
Data Scientist (-),DCI Solutions,MD,Full-time,"JLS Job Requirement for:
Data Scientist
Location: Bethesda, MD
Job Description:
Serves as a Data Scientist for Big Data/Predictive Analytics program
Supports national security objectives:

Analyze data from a variety of sources

Design, build and optimize a Data Science platform focused on:

Small research and development projects
Analyzing a variety of big data
National Security, Cybersecurity, Business Intel, Social Media, Human Behavior, etc.
Exploratory analysis
Quantitative methods
Interface application design
Customization for customer’s requirements

Work both independently and within a team of professionals to:

Develop and enrich findings
Brief Senior Leaders and conferences
Contribute to publications

Identify novel sources of data across a range of fields to:

Improve the performance of predictive algorithms
Encourage user adoption of high-end data analytics platforms

Qualifications:
BS in quantitative or analytical field

Computer Science, Mathematics, Physics, Economics, Engineering, Statistics, etc

4+ years of directly relevant experience in data science
Proficient in scripting language such as R or Python
Experience conducting research in data analytics or big data
Requirement decomposition of software and data for optimized/cost-effective solutions
Familiar with containers/orchestration (Docker and Kubernetes)
Familiar with git, dvc, mlflow, and other version control technologies
Familiar with open source, PAI, forensic media, MASINT, cybersecurity, etc.
Experience with databases (SQL, NoSQL, Elasticsearch)
Experience with graphs and related technology such as neo4j
Clearance: TS/SCI
Job Type: Full-time
Salary: $170,000-$220,000
Job Type: Full-time
Pay: $170,000.00 - $220,000.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Professional development assistance
Relocation assistance
Retirement plan
Tuition reimbursement
Vision insurance

Schedule:

Monday to Friday

Supplemental pay types:

Commission pay
Signing bonus

Education:

Bachelor's (Preferred)

Experience:

data science: 4 years (Preferred)
R and python: 4 years (Preferred)
Docker and Kubernetes: 2 years (Preferred)
SQL, NoSQL, and/or Elasticsearch: 2 years (Preferred)

Security clearance:

Top Secret (Required)

Work Location: In person",170000,"['python', 'docker', 'nosql', 'sql', 'git']"
Principal AI/ML Engineer,Provoke,TX,Full-time,"
Who we are:
 Join the dynamic team at Provoke, where we're not just about meeting expectations but exceeding them. We're looking for innovative professionals who are passionate about driving exceptional outcomes for our customers. At Provoke, you'll be empowered to challenge the status quo and encouraged to think differently, leveraging a growth mindset to deliver tangible results. Here, professional growth isn't just a concept—it's a reality, fueled by continuous learning and a supportive, forward-thinking environment. If you're ready to make a significant impact and grow alongside a team of like-minded individuals, Provoke is your destination.

 What we do:
 We build bespoke software using modern technologies and are on a mission to help our clients flourish with smart solutions to solve their business needs.

 The Provoke Experience:
 We are committed to building high performing teams and offer tangible rewards to ensure that effort is recognized. We are remote-first but understand the need for connection so provide a forum for this time consistently and purposefully. We are dedicated to providing an enriching environment and learning opportunities for our employees to grow within and fast track their careers. We are focused on diversity – diversity in race, gender, orientation and experience.

 Position Overview:
 We are looking for a seasoned Principal AI/ML Engineer to lead our AI/ML initiatives. In addition to providing technical expertise and leadership in the development of intelligent solutions, the ideal candidate will have a proven track record in generative modeling and the ability to lead and mentor a team of talented engineers.

 Responsibilities:

 Technical Leadership:

Provide technical leadership in the design and implementation of AI/ML solutions, with a specific focus on Generative AI.
Lead and guide the development team in solving complex AI/ML challenges, including generative modeling.

Generative AI Expertise:

Design and implement state-of-the-art generative models for tasks such as image synthesis, text generation, and data augmentation.
Stay abreast of the latest advancements in Generative AI to integrate cutting-edge technologies into our solutions.

Project Management:

Collaborate with project managers to define project objectives, scope, and deliverables.
Take ownership of project timelines, ensuring successful delivery within specified deadlines.

Team Collaboration:

Foster a collaborative and innovative team culture within the AI/ML engineering team.
Mentor and coach team members, promoting professional growth and development.

Algorithm Development:

Develop and implement robust machine learning algorithms, with a particular emphasis on generative models.
Ensure that generative models align with business objectives and client requirements.

Model Deployment:

Lead the deployment of both generative and traditional machine learning models into production, ensuring scalability and reliability.
Collaborate with DevOps and infrastructure teams for seamless integration.

Client Interaction:

Work closely with clients to understand their AI/ML requirements, with a specific emphasis on Generative AI, and provide strategic guidance.
Act as a technical liaison between the development team and clients, ensuring clear communication and understanding of project goals.



 Qualifications:

Bachelor's or Master's degree in Computer Science, Data Science, or a related field.
Proven experience as a Senior or Principal AI/ML Engineer, with a focus on Generative AI, in a consulting or similar environment.
Strong proficiency in machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn, with a specialization in generative modeling libraries.
Expertise in developing and deploying both generative and traditional machine learning models at scale.
Excellent leadership and communication skills.
Demonstrated ability to manage multiple AI/ML projects, including generative modeling projects, simultaneously.
Familiarity with cloud-based AI/ML services (e.g., AWS SageMaker, Azure ML).



 Benefits and Perks:

Health/dental/vision insurance
401k
Long-term/short term disability and AD&D
Reimbursed cell phone plan
Give you your birthday off
Provide you with an environment where high performance is not only recognized but rewarded.
If you are looking for international opportunities, we have them!

",180000,"['tensorflow', 'pytorch', 'machine learning', 'aws', 'azure']"
Staff Machine Learning Engineer - Personalization,"DoorDash, Inc.",CA,Full-time,"
About the Team
 Come help us build the world's most reliable on-demand, logistics engine for last-mile retail delivery! We're looking for an experienced machine learning engineer to help us develop modern growth and personalization models that power DoorDash's growing retail and grocery business.
 About the Role
 We’re looking for a passionate Applied Machine Learning expert to join our team. As a Staff Machine Learning Engineer, you’ll be conceptualizing, designing, implementing, and validating algorithmic improvements to the growth and personalization experiences at the heart of our fast-growing grocery and retail delivery business. You will use our robust data and machine learning infrastructure to implement new ML solutions to make the consumer search experience more relevant, seamless, and delightful across grocery, convenience, and many other retail categories. You will demonstrate a strong command of production level machine learning, experience with solving end-user problems, and collaborate well with multi-disciplinary teams.
 You will report into the engineering manager on our Personalization team. We expect this role to be hybrid with some time in-office and some time remote (#LI-Hybrid).
 You’re excited about this opportunity because you will…

Develop production machine learning solutions to build a world class personalized shopping experience for a diverse and expanding retail space
Partner with engineering and product leaders to help shape the product roadmap applying ML
Mentor junior team members, and lead cross functional pods to create collective impact

You can find out more on our ML blog here
 We’re excited about you because you have…

8+ years of industry experience developing machine learning models with business impact, and shipping ML solutions to production.
Expertise in applied ML for Causal Inference and Recommendation Systems - both classical and deep learning based. Additional familiarity with explore/exploit/MAB algorithms, LLMs!
Machine learning background in Python; experience with PyTorch or TensorFlow preferred.
Familiarity with Kotlin/Scala
Ability to communicate technical details to nontechnical stakeholders
M.S., or PhD. in Statistics, Computer Science, Math, Operations Research, Physics, Economics, or other quantitative fields
You keep the mission in mind, take ideas and help them grow using data and rigorous testing, show evidence of progress and then double down
Desire for impact with a growth-minded and collaborative mindset

About DoorDash
 At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.   DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.
 Our Commitment to Diversity and Inclusion
 We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.
 Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.
 Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.
 If you need any accommodations, please inform your recruiting contact upon initial connection.
 Compensation
 The location-specific base salary range for this position is listed below. Compensation in other geographies may vary.
 Actual compensation within the pay range will be decided based on factors including, but not limited to, skills, prior relevant experience, and specific work location. For roles that are available to be filled remotely, base salary is localized according to employee work location. Please discuss your intended work location with your recruiter for more information.
 DoorDash cares about you and your overall well-being, and that’s why we offer a comprehensive benefits package, for full-time employees, that includes healthcare benefits, a 401(k) plan including an employer match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid time off, paid parental leave, and several paid holidays, among others.
 In addition to base salary, the compensation package for this role also includes opportunities for equity grants.



     California Pay Range:
   

     $176,000—$238,000 USD
   



     New York Pay Range:
   

     $176,000—$238,000 USD
   



     Washington Pay Range:
   

     $176,000—$238,000 USD
   


",176000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Staff Machine Learning Engineer - Personalization,"DoorDash, Inc.",CA,Full-time,"
About the Team
 Come help us build the world's most reliable on-demand, logistics engine for last-mile retail delivery! We're looking for an experienced machine learning engineer to help us develop modern growth and personalization models that power DoorDash's growing retail and grocery business.
 About the Role
 We’re looking for a passionate Applied Machine Learning expert to join our team. As a Staff Machine Learning Engineer, you’ll be conceptualizing, designing, implementing, and validating algorithmic improvements to the growth and personalization experiences at the heart of our fast-growing grocery and retail delivery business. You will use our robust data and machine learning infrastructure to implement new ML solutions to make the consumer search experience more relevant, seamless, and delightful across grocery, convenience, and many other retail categories. You will demonstrate a strong command of production level machine learning, experience with solving end-user problems, and collaborate well with multi-disciplinary teams.
 You will report into the engineering manager on our Personalization team. We expect this role to be hybrid with some time in-office and some time remote (#LI-Hybrid).
 You’re excited about this opportunity because you will…

Develop production machine learning solutions to build a world class personalized shopping experience for a diverse and expanding retail space
Partner with engineering and product leaders to help shape the product roadmap applying ML
Mentor junior team members, and lead cross functional pods to create collective impact

You can find out more on our ML blog here
 We’re excited about you because you have…

8+ years of industry experience developing machine learning models with business impact, and shipping ML solutions to production.
Expertise in applied ML for Causal Inference and Recommendation Systems - both classical and deep learning based. Additional familiarity with explore/exploit/MAB algorithms, LLMs!
Machine learning background in Python; experience with PyTorch or TensorFlow preferred.
Familiarity with Kotlin/Scala
Ability to communicate technical details to nontechnical stakeholders
M.S., or PhD. in Statistics, Computer Science, Math, Operations Research, Physics, Economics, or other quantitative fields
You keep the mission in mind, take ideas and help them grow using data and rigorous testing, show evidence of progress and then double down
Desire for impact with a growth-minded and collaborative mindset

About DoorDash
 At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.   DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.
 Our Commitment to Diversity and Inclusion
 We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.
 Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.
 Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.
 If you need any accommodations, please inform your recruiting contact upon initial connection.
 Compensation
 The location-specific base salary range for this position is listed below. Compensation in other geographies may vary.
 Actual compensation within the pay range will be decided based on factors including, but not limited to, skills, prior relevant experience, and specific work location. For roles that are available to be filled remotely, base salary is localized according to employee work location. Please discuss your intended work location with your recruiter for more information.
 DoorDash cares about you and your overall well-being, and that’s why we offer a comprehensive benefits package, for full-time employees, that includes healthcare benefits, a 401(k) plan including an employer match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid time off, paid parental leave, and several paid holidays, among others.
 In addition to base salary, the compensation package for this role also includes opportunities for equity grants.



     California Pay Range:
   

     $176,000—$238,000 USD
   



     New York Pay Range:
   

     $176,000—$238,000 USD
   



     Washington Pay Range:
   

     $176,000—$238,000 USD
   


",176000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Staff Machine Learning Engineer - Personalization,"DoorDash, Inc.",CA,Full-time,"
About the Team
 Come help us build the world's most reliable on-demand, logistics engine for last-mile retail delivery! We're looking for an experienced machine learning engineer to help us develop modern growth and personalization models that power DoorDash's growing retail and grocery business.
 About the Role
 We’re looking for a passionate Applied Machine Learning expert to join our team. As a Staff Machine Learning Engineer, you’ll be conceptualizing, designing, implementing, and validating algorithmic improvements to the growth and personalization experiences at the heart of our fast-growing grocery and retail delivery business. You will use our robust data and machine learning infrastructure to implement new ML solutions to make the consumer search experience more relevant, seamless, and delightful across grocery, convenience, and many other retail categories. You will demonstrate a strong command of production level machine learning, experience with solving end-user problems, and collaborate well with multi-disciplinary teams.
 You will report into the engineering manager on our Personalization team. We expect this role to be hybrid with some time in-office and some time remote (#LI-Hybrid).
 You’re excited about this opportunity because you will…

Develop production machine learning solutions to build a world class personalized shopping experience for a diverse and expanding retail space
Partner with engineering and product leaders to help shape the product roadmap applying ML
Mentor junior team members, and lead cross functional pods to create collective impact

You can find out more on our ML blog here
 We’re excited about you because you have…

8+ years of industry experience developing machine learning models with business impact, and shipping ML solutions to production.
Expertise in applied ML for Causal Inference and Recommendation Systems - both classical and deep learning based. Additional familiarity with explore/exploit/MAB algorithms, LLMs!
Machine learning background in Python; experience with PyTorch or TensorFlow preferred.
Familiarity with Kotlin/Scala
Ability to communicate technical details to nontechnical stakeholders
M.S., or PhD. in Statistics, Computer Science, Math, Operations Research, Physics, Economics, or other quantitative fields
You keep the mission in mind, take ideas and help them grow using data and rigorous testing, show evidence of progress and then double down
Desire for impact with a growth-minded and collaborative mindset

About DoorDash
 At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.   DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.
 Our Commitment to Diversity and Inclusion
 We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.
 Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.
 Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.
 If you need any accommodations, please inform your recruiting contact upon initial connection.
 Compensation
 The location-specific base salary range for this position is listed below. Compensation in other geographies may vary.
 Actual compensation within the pay range will be decided based on factors including, but not limited to, skills, prior relevant experience, and specific work location. For roles that are available to be filled remotely, base salary is localized according to employee work location. Please discuss your intended work location with your recruiter for more information.
 DoorDash cares about you and your overall well-being, and that’s why we offer a comprehensive benefits package, for full-time employees, that includes healthcare benefits, a 401(k) plan including an employer match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid time off, paid parental leave, and several paid holidays, among others.
 In addition to base salary, the compensation package for this role also includes opportunities for equity grants.



     California Pay Range:
   

     $176,000—$238,000 USD
   



     New York Pay Range:
   

     $176,000—$238,000 USD
   



     Washington Pay Range:
   

     $176,000—$238,000 USD
   


",176000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Staff Machine Learning Engineer - Personalization,"DoorDash, Inc.",WA,Full-time,"
About the Team
 Come help us build the world's most reliable on-demand, logistics engine for last-mile retail delivery! We're looking for an experienced machine learning engineer to help us develop modern growth and personalization models that power DoorDash's growing retail and grocery business.
 About the Role
 We’re looking for a passionate Applied Machine Learning expert to join our team. As a Staff Machine Learning Engineer, you’ll be conceptualizing, designing, implementing, and validating algorithmic improvements to the growth and personalization experiences at the heart of our fast-growing grocery and retail delivery business. You will use our robust data and machine learning infrastructure to implement new ML solutions to make the consumer search experience more relevant, seamless, and delightful across grocery, convenience, and many other retail categories. You will demonstrate a strong command of production level machine learning, experience with solving end-user problems, and collaborate well with multi-disciplinary teams.
 You will report into the engineering manager on our Personalization team. We expect this role to be hybrid with some time in-office and some time remote (#LI-Hybrid).
 You’re excited about this opportunity because you will…

Develop production machine learning solutions to build a world class personalized shopping experience for a diverse and expanding retail space
Partner with engineering and product leaders to help shape the product roadmap applying ML
Mentor junior team members, and lead cross functional pods to create collective impact

You can find out more on our ML blog here
 We’re excited about you because you have…

8+ years of industry experience developing machine learning models with business impact, and shipping ML solutions to production.
Expertise in applied ML for Causal Inference and Recommendation Systems - both classical and deep learning based. Additional familiarity with explore/exploit/MAB algorithms, LLMs!
Machine learning background in Python; experience with PyTorch or TensorFlow preferred.
Familiarity with Kotlin/Scala
Ability to communicate technical details to nontechnical stakeholders
M.S., or PhD. in Statistics, Computer Science, Math, Operations Research, Physics, Economics, or other quantitative fields
You keep the mission in mind, take ideas and help them grow using data and rigorous testing, show evidence of progress and then double down
Desire for impact with a growth-minded and collaborative mindset

About DoorDash
 At DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.   DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees’ happiness, healthiness, and overall well-being by providing comprehensive benefits and perks including premium healthcare, wellness expense reimbursement, paid parental leave and more.
 Our Commitment to Diversity and Inclusion
 We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.
 Statement of Non-Discrimination: In keeping with our beliefs and goals, no employee or applicant will face discrimination or harassment based on: race, color, ancestry, national origin, religion, age, gender, marital/domestic partner status, sexual orientation, gender identity or expression, disability status, or veteran status. Above and beyond discrimination and harassment based on “protected categories,” we also strive to prevent other subtler forms of inappropriate behavior (i.e., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at DoorDash. We value a diverse workforce – people who identify as women, non-binary or gender non-conforming, LGBTQIA+, American Indian or Native Alaskan, Black or African American, Hispanic or Latinx, Native Hawaiian or Other Pacific Islander, differently-abled, caretakers and parents, and veterans are strongly encouraged to apply. Thank you to the Level Playing Field Institute for this statement of non-discrimination.
 Pursuant to the San Francisco Fair Chance Ordinance, Los Angeles Fair Chance Initiative for Hiring Ordinance, and any other state or local hiring regulations, we will consider for employment any qualified applicant, including those with arrest and conviction records, in a manner consistent with the applicable regulation.
 If you need any accommodations, please inform your recruiting contact upon initial connection.
 Compensation
 The location-specific base salary range for this position is listed below. Compensation in other geographies may vary.
 Actual compensation within the pay range will be decided based on factors including, but not limited to, skills, prior relevant experience, and specific work location. For roles that are available to be filled remotely, base salary is localized according to employee work location. Please discuss your intended work location with your recruiter for more information.
 DoorDash cares about you and your overall well-being, and that’s why we offer a comprehensive benefits package, for full-time employees, that includes healthcare benefits, a 401(k) plan including an employer match, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, paid time off, paid parental leave, and several paid holidays, among others.
 In addition to base salary, the compensation package for this role also includes opportunities for equity grants.



     California Pay Range:
   

     $176,000—$238,000 USD
   



     New York Pay Range:
   

     $176,000—$238,000 USD
   



     Washington Pay Range:
   

     $176,000—$238,000 USD
   


",176000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Senior Data Scientist,Pluto TV,NY,Full-time,"Overview & Responsibilities 
The primary responsibility of the Senior Data Scientist is to apply experimentation, machine learning and visualization techniques to drive insights and help power data-driven decision making across all departments and levels of Pluto TV. For this senior-level individual contributor Data Scientist, it is anticipated that they would independently contribute meaningful analysis and drive complex Data Science-based full life cycle projects to completion. 
In this role, the incumbent must be able to extract data, model and optimize production algorithms across our platforms, and to query and manipulate data on an ad-hoc basis by using SQL, Python or R. 
Additionally, the Data Scientist must be flexible to quickly learn open source and big-data technologies such as Spark and the AWS/GCP ecosystems. 
Set up and measure nontrivial experiments and apply causal analysis methods. 
Take advantage of machine learning techniques sought at researching and implementing live cross-platform blueprints, model user behavior, and optimize marketing & programming initiatives. 
Design advanced data-visualization dashboards and presentations which facilitate distinctive views into our product and operations. 


Basic qualifications:
 Undergraduate degree (STEM strongly preferred) 
2+ years working with data science toolkits in R, Python or Matlab (a combination of industry and academic experience might acceptable) 
Tried experience with unstructured data projects, preferably in the Media / Entertainment / Streaming industry 
Strong understanding of statistical and machine learning methodologies (experimentation, regression analysis, clustering, classification) 
Analytical, meticulous, and results-focused 
Experience writing SQL queries on structured and unstructured data sets 
Lucid communication skills with the ability to summarize complex results into digestible analysis 
Additional Qualifications 
Experience working with big-data technology on Linux-based systems 
Graduate STEM degree or higher in a quantitative or technical field such as Computer Science, Data Science, Statistics, Applied Mathematics or Economics, Combinatorics, etc. 
#LI-FV 38394 
#LI-REMOTE 

 Join the Paramount Streaming Talent Community ! Get the inside scoop on life at Paramount Streaming and about career opportunities. 

 Pluto TV, a Paramount Global company, is the leading free streaming television service in America, delivering 250+ live and original channels and thousands of on-demand movies in partnership with major TV networks, movie studios, publishers, and digital media companies. Pluto TV is available on all mobile, web and connected TV streaming devices and millions of viewers tune in each month to watch premium news, TV shows, movies, sports, lifestyle, and trending digital series. Headquartered in West Hollywood, Pluto TV has offices in New York, Silicon Valley, Chicago and Berlin. 

 ADDITIONAL INFORMATION 


Hiring Salary Range: $124,000.00 - 170,500.00. 

 The hiring salary range for this position applies to New York City, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible. 

 https://www.paramount.com/careers/benefits 

 Paramount is an equal opportunity employer (EOE) including disability/vet. 

 At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. 

 If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",124000,"['python', 'machine learning', 'aws', 'gcp', 'sql']"
Senior Data Scientist - 2199648,Optum,MN,Full-time,"
Senior Data Scientist - 2199648
 EMPLOYER: Optum Services, Inc.  JOB TITLE: Senior Data Scientist
 LOCATION: 11000 Optum Circle. Eden Prairie, MN 55344
 DUTIES: Identify business problems or management objectives that can be addressed through data analysis. Duties include: apply knowledge of statistics, machine learning, programming, data modeling, and advanced mathematics to recognize patterns; identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement; design, develop, and evaluate models and advanced algorithms that lead to optimal value extraction from the data; work with analytics and statistical software to perform analysis and interpret data; work with vast amounts of data from multiple sources to provide predictive analytics to the enterprise; anticipate customer needs and proactively develop solutions to meet them; serve as a key resource on complex and/or critical issues; solve complex problems and develop innovative solutions; review work performed by others and provide recommendations for improvement; forecast and plan resource requirements; and provide explanations and information to associates on the most complex issues. Telecommuting is available from anywhere in the U.S.

 REQUIREMENTS: Master’s degree in Computer Science, Engineering, Mathematics, Statistics, Public Health, Health Services Research, Economics, or a related field and two years of experience in the job offered or related computer occupation.
 Experience must include:

analyzing health insurance claims;
transactions data such as Insurance verification, Coding, billing, and payment data of healthcare claims;
clinical data such as analyzing health records, claims data, clinical quality metrics and surveys.
program or employer data such as analyze emerging business data; and
analytics and statistical software such as SQL, R, Python, or Hadoop.

 RATE OF PAY: $101,400 - $147,032/year
 Please apply via careers.uhg.com and search for job #2199648
 Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm)
 UnitedHealth Group offers a full range of comprehensive benefits, including medical, dental and vision, as well as matching 401k and an employee stock purchase plan.
 Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.
 UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.


#LI-DNI
",101400,"['python', 'machine learning', 'sql', 'hadoop']"
Senior Data Scientist,Pluto TV,NY,Full-time,"Overview & Responsibilities 
The primary responsibility of the Senior Data Scientist is to apply experimentation, machine learning and visualization techniques to drive insights and help power data-driven decision making across all departments and levels of Pluto TV. For this senior-level individual contributor Data Scientist, it is anticipated that they would independently contribute meaningful analysis and drive complex Data Science-based full life cycle projects to completion. 
In this role, the incumbent must be able to extract data, model and optimize production algorithms across our platforms, and to query and manipulate data on an ad-hoc basis by using SQL, Python or R. 
Additionally, the Data Scientist must be flexible to quickly learn open source and big-data technologies such as Spark and the AWS/GCP ecosystems. 
Set up and measure nontrivial experiments and apply causal analysis methods. 
Take advantage of machine learning techniques sought at researching and implementing live cross-platform blueprints, model user behavior, and optimize marketing & programming initiatives. 
Design advanced data-visualization dashboards and presentations which facilitate distinctive views into our product and operations. 


Basic qualifications:
 Undergraduate degree (STEM strongly preferred) 
2+ years working with data science toolkits in R, Python or Matlab (a combination of industry and academic experience might acceptable) 
Tried experience with unstructured data projects, preferably in the Media / Entertainment / Streaming industry 
Strong understanding of statistical and machine learning methodologies (experimentation, regression analysis, clustering, classification) 
Analytical, meticulous, and results-focused 
Experience writing SQL queries on structured and unstructured data sets 
Lucid communication skills with the ability to summarize complex results into digestible analysis 
Additional Qualifications 
Experience working with big-data technology on Linux-based systems 
Graduate STEM degree or higher in a quantitative or technical field such as Computer Science, Data Science, Statistics, Applied Mathematics or Economics, Combinatorics, etc. 
#LI-FV 38394 
#LI-REMOTE 

 Join the Paramount Streaming Talent Community ! Get the inside scoop on life at Paramount Streaming and about career opportunities. 

 Pluto TV, a Paramount Global company, is the leading free streaming television service in America, delivering 250+ live and original channels and thousands of on-demand movies in partnership with major TV networks, movie studios, publishers, and digital media companies. Pluto TV is available on all mobile, web and connected TV streaming devices and millions of viewers tune in each month to watch premium news, TV shows, movies, sports, lifestyle, and trending digital series. Headquartered in West Hollywood, Pluto TV has offices in New York, Silicon Valley, Chicago and Berlin. 

 ADDITIONAL INFORMATION 


Hiring Salary Range: $124,000.00 - 170,500.00. 

 The hiring salary range for this position applies to New York City, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible. 

 https://www.paramount.com/careers/benefits 

 Paramount is an equal opportunity employer (EOE) including disability/vet. 

 At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. 

 If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",124000,"['python', 'machine learning', 'aws', 'gcp', 'sql']"
Astrophysicist (Artificial Intelligence),US Smithsonian Institution,MA,Full-time,"

Duties



Formulate and execute independent, original scientific research that focuses on the development and application of machine learning and other AI methods to astronomy, astrophysical phenomena, and cosmology that aligns with the strategic interests of SAO. Performs analysis that is creative, definitive, and thorough.


Prepare peer-reviewed publications describing research results, techniques, and interpretations for publication in peer-reviewed scientific or technical journals, and presentation at scientific or technical meetings and conferences, and within the CfA.


Propose for extramural contract and grant support for research in specific areas of astronomy, astrophysics or related fields, including but not limited to, machine learning and other AI methods, data science, and/or data analytics, typically applied to the analysis and interpretation of very large datasets.


Serve in a leadership role in the development of major new scientific initiatives for SAO relevant to the successful candidate’s expertise and skills.


Engage in education activities to train the next generation of scientists in astronomy and astrophysics by leading a research team that is diverse and inclusive, and providing mentorship and supervision.


Engage in outreach activities to share AI research and AI-based astronomical discoveries with the broader public through traditional and non-traditional media.





Requirements
Conditions of Employment

U.S. citizenship is required.
Electronic funds transfer/direct deposit is required for salary payment
National and international travel may be required
Males born after 12/31/59 must be registered with Selective Service.
Pre- and post-appointment background investigation
May be required to serve a one-year probationary period.

For information on qualification requirements, see Qualification Standards Handbook for General Schedule Positions viewable on the web at http://www.opm.gov/qualifications/standards/group-stds/gs-prof.asp 

Qualifications

Minimum Education Requirements:  A) Degree in one or a combination of astronomy, physics, mathematics, space science or electronics, including course work in differential and integral calculus and 12 semester hours in astronomy or physics; OR  B) A combination of education and experience equivalent to A above including at least 30 semester hours of courses equivalent to a major in any combination of astronomy, space science, physics, mathematics, and electronics with required course work as shown in A above.   Specialized Experience: One year of directly related experience (Federal or other) equivalent to GS-13. Specialized experience would include activities such as formulating and conducting leading independent and original astrophysical research related to machine learning and other Artificial Intelligence methods related to astronomy, presenting the results of research through peer-reviewed publications, conferences, and engagingin education activities to train the next generation of scientists in astronomy and astrophysics, etc.
 Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.
 Part-time and/or unpaid experience related to this position will be considered to determine the total number of years and months of experience. Be sure to note the number of paid or unpaid hours worked each week.
 There is no education substitution for this position.
 Qualifications must be met by the closing date of the announcement.
 Special Instructions for Foreign Education: If you are qualifying by education and/or you have education completed in a foreign college/university described above, it is your responsibility to provide transcripts and proof of U.S. accreditation for foreign study. For instructions on where to fax these documents, see the ""Required Documents"" section of this announcement.
 Important Note:
 The review of your resume will determine your final rating and should provide sufficient information regarding how your education and experience relate to this position, including the major duties and qualifications criteria listed.



Additional information



The Smithsonian embraces diversity and equal employment opportunity (www.si.edu/oeema).
 Recruitment Incentive: Recruitment incentive(s) may be authorized for this position. However, approval for incentives are contingent upon various availability. If authorized, certain incentives will require the incumbent to sign a service agreement to remain in the Federal government for a certain time period.  Note: This statement does not imply nor guarantee an incentive will be offered and paid.






Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.

Your application will be evaluated first for the basic education and specialized requirements. Applicants that meet the basic qualifications will be evaluated further against the following criteria:

Exceptional initiative and scholarly ability necessary to formulate, conduct and present results of programs of advanced scientific research in machine learning and other AI methods related to astronomy.
Advanced skill in preparing scientific results for publication in peer-reviewed scientific or technical journals and for presentation at professional conferences that apply machine learning and other AI methods to astronomical phenomena.
Advanced skill in proposing for extramural contract and grant support for research into specific areas of astronomy, astrophysics, or related fields.
Broad experience in the development of major new scientific initiatives relevant to the person’s expertise and skills.
Proven experience in developing the careers of students and early career researchers, including mentoring and supervision.
Proven ability to engage the general public in scientific results and discoveries through traditional and non-traditional media.



 Applicants who meet or exceed minimum qualifications will be assigned to one of three category groups based on job-related criteria:
 Best Category - Meets the minimum qualification requirements and excels in most of the job related competencies above.
 Better Category - Meets the minimum qualification requirements and satisfies most of the job related competencies above.
 Good Category - Meets the minimum qualification requirements, but does not satisfy most of the job related competencies above to a substantive degree.
 This category rating process does not add veterans' preference points or apply the ""rule of three"", but protects the rights of veterans by placing them ahead of non-preference eligibles within each category. A selecting official may make selections from the highest quality category (Best Category) provided no preference eligible in that category is passed over to select a non-preference eligible in that category unless the requirements of 5 U.S.C. 3317(b) or 3318(b) are satisfied. Preference eligibles who meet minimum qualification requirements and who have a compensable service-connected disability of at least 10 percent must be listed in the highest quality category, except when the position being filled is scientific or professional at the GS-9 grade level or higher. Applicants who have not submitted a resume in the USAjobs system and/or have not answered all of the vacancy questions will not be considered for this position.
 Important Note:
 Your resume and supporting documentation will be compared to your responses to the occupational questionnaire or other assessment tool for consistency. If a determination is made that you have rated yourself higher than is supported by your resume, you will be assigned a rating commensurate to your described experience. Your resume should provide sufficient information regarding how your education and experience relate to this position, including the major duties and qualifications criteria listed.


You may 
preview questions
 for this vacancy.





Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.

Your application package must include the following documents:

CV and Bibliography
school transcripts
proof of U.S. accreditation for foreign study, if applicable.
statement of previous research (3 pages max)
research vision, plan and objections (5 pages max)
diversity statement (3 pages max)
names/contact info for 4 references



If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating. 


How to Apply


Click on the ""Apply Online"" button on the upper right side of the page.  Please Note: 

You must apply for this position online through the 'Apply Online' button and submit required supplemental documents (if they are relevant to you).
You may submit required documents by uploading them online during the application process;  OR You may manually fax required documents. Faxes are received by an automated system, not a physical fax machine. Documents that are faxed as part of the application process must be sent with the system generated cover sheet by the closing date. Documents faxed without the system generated coversheet are not retrievable and cannot be considered as part of the application package.
The complete application package, including any required documents, is due in the Smithsonian Office of Human Resources on the closing date of the announcement by 11:59 PM Eastern Time.
If you are unable to apply online, paper applications may be accepted with prior approval of the Contact Person listed below.




Agency contact information
Judy Gallagher 


Phone
617-495-7374 
Fax
617-495-7263
Email
jgallagher@si.edu 


Address


SMITHSONIAN

Human Resources

60 Garden Street Cambridge, MA 02138 

Mail Stop 17 

Cambridge, Massachusetts 02138

United States 




Next steps

You will receive an automated email acknowledgment that your application has been received. This may take several hours. We often receive a large number of applications for a job. We review each application carefully, and this process may take a few weeks. As we go through each round of review, we will send you an email to date you on your status. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents


Your application package must include the following documents:

CV and Bibliography
school transcripts
proof of U.S. accreditation for foreign study, if applicable.
statement of previous research (3 pages max)
research vision, plan and objections (5 pages max)
diversity statement (3 pages max)
names/contact info for 4 references



If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.






 Help 
 This job is open to




Individuals with disabilities




Federal employees - Competitive service
Current or former competitive service federal employees.




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.




Special authorities
Individuals eligible under a special authority not listed above, but defined in the federal hiring regulations.




Veterans




Clarification from the agency
This position is open to all qualified U.S. Citizens or U.S. Nationals.

",130929,['machine learning']
Mid-Level Data Scientist,BOEING,WA,Full-time,"

At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.
 Boeing Defense, Space & Security (BDS) is seeking a Mid-Level Data Scientist to join our team located in Multiple Locations.

 This position can be located in the following cities: Seattle, WA; Arlington, VA; Denver, CO; Long Beach, CA; Miami, FL; New York, NY; North Charleston, SC; Plano, TX; Saint Louis, MO; San Francisco, CA.

 Boeing is the world's largest aerospace company and leading manufacturer of commercial jetliners, defense, space and security systems, and service provider of aftermarket support

 We are looking for an accomplished Mid-Level Data Scientist – Machine Learning Expert to support our Boeing Data Analytics organization. The organizational scope supports all Boeing enterprise functions and programs as well as corporate initiatives.

 At Boeing, we are already making a difference across the industry using the latest and state of the art artificial intelligence and machine learning techniques to deliver best in class product experience to our commercial and government customers. We are expanding and growing in all areas in the frontiers of the aerospace industry. We already have some of the best minds and talent in this field, and we’re looking for someone with applied experience in Artificial Intelligence and Machine Learning (including Natural Language Processing, Reinforcement Learning, Deep Learning, Conversational A.I, and Computer Vision) to join our team.

 Our data scientists work closely everyday with product managers, researchers, industrial and manufacturing engineers and software engineers to solve complex problems and create next generation solutions for our internal and external customers. The team works in tandem on some of the hardest problems at the intersection of technology and business. We bring new ideas to making future commercial and military airplanes, creating future space and autonomous systems, and making our operations world class. We also partner and collaborate with multiple universities and research institutions worldwide to keep abreast of advancements in the field.

 You must have a passion for continuous learning, teaching and collaborating. You should have well-reasoned opinions on technical matters but recognize other ideas and opinions. Paramount to success in this role is the ability to define, build and deploy artificial intelligence and machine learning solutions. Additionally, working directly with customers and business leaders to scope problems, clearly communicate results, and address any concerns in terms that can be understood by non-technical community of stakeholders.

 Position Responsibilities:

 Develop end-to-end artificial intelligence and machine learning solutions including data processing, feature & model development and production deployment with agility and scale.
 Lead and mentor small teams of data scientists in the design, development, and implementation of complex and challenging efforts in advanced analytics and machine learning.
 Partner with the enterprise business functions and collaborate across multiple teams including analytics, product management, and operations to solve problems and identify trends and opportunities.
 Have passion about working with large and complex unstructured and structured data sets.
 Lead and contribute to design, algorithm, and code reviews.
 Able to self-direct and succeed with minimal guidance.
 Strong communication and interpersonal skills. You should be able to work across functions and effectively present, recommend and communicate a position by demonstrating its value and tradeoffs.


 This position is hybrid. The selected candidate will be required to perform some work onsite at one of the listed location options. This is at the hiring team’s discretion and could potentially change in the future.

 The position must meet Export Control compliance requirements, therefore a “US Person” as defined by 22 C.F.R. § 120.15 is required. “US Person” includes US Citizen, lawful permanent resident, refugee, or asylee.

 Basic Qualifications (Required Skills/Experience):


 3+ years of experience using Python or R (Python Preferred)
 1+ year of experience working in the field of Artificial Intelligence including Machine Learning
 1+ year of experience in SQL


 Preferred Qualifications (Desired Skills/Experience):


 A technical Bachelor's degree with 4+ years of relevant work experience, or MS/MA degree with 4+ years of relevant work experience, or a relevant PhD degree. A relevant degree is defined as one in a quantitative field such as computer science, statistics, mathematics, operations research, bioinformatics, economics, computational biology, physics or chemistry. (Masters or PhD Degree preferred.)
 Experience leading small teams of technical experts in the development of advanced analytics, machine learning, or software solutions.
 Experience and expertise building and implementing state-of-the-art computer vision models and pipelines.
 Experience and expertise building and implementing state-of-the-art graph neural networks and pipelines.
 Experience and expertise building and implementing state-of-the-art natural language processing models and pipelines
 5+ years of work experience or relevant coursework with machine learning related open-source libraries including, but not limited to: Pandas, SciKit-Learn, TensorFlow, PyTorch, Theano, etc. Python experience preferred.
 2+ years of work experience or relevant coursework training machine learning models in a cloud computing environment such as: AWS, Google Cloud Platform, Microsoft Azure, etc.


 Typical Education & Experience:
 Education/experience typically 5 or more years' related work experience or relevant military experience. Advanced degree (e.g. Bachelor, Master, etc.) preferred, but not required.

 Relocation:
 This position offers relocation based on candidate eligibility. Note: Basic relocation will be offered for eligible internal candidates.

 Drug Free Workplace:
 Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

 Travel:
 This position requires up to 10% travel.

 Shift:
 This position is for 1st shift

 At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.

 The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.

 The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.

 Pay is based upon candidate experience and qualifications, as well as market and business considerations.

 Summary pay range: USD 113,900 – 164,450
 Export Control Requirements: U.S. Government Export Control Status: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.
 

Export Control Details: US based job, US Person required
  Equal Opportunity Employer:
 Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.
",113900,"['tensorflow', 'pytorch', 'python', 'pandas', 'machine learning', 'deep learning', 'aws', 'azure', 'sql']"
"Lead Data Analyst/Senior Data Analyst, Tiktok Ads - USDS",TikTok,NY,Full-time,"Responsibilities 
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo. 

 Why Join Us 
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. 
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. 
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. 
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. 
Join us. 

 About USDS 
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data. 

 U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more. 

 In order to enhance collaboration and cross-functional partnerships, among other things, at this time, our organization follows a hybrid work schedule that requires employees to work in the office 3 days a week, or as directed by their manager/department. We regularly review our hybrid work model, and the specific requirements may change at any time. 

 About the team 
We are a team of passionate Data Analysts, Data Scientists, and Operations who safeguard TikTok's US user data and join forces with cross-functional teams to derive actionable insights from US user data to maximize monetization results while still giving users a pleasant experience in our app. 

 We are looking for data analysts to join the efforts driving monetization, 


Apply expertise in data analysis and visualization to see beyond the numbers and understand how our users interact with our ads products.
Deliver data support for both short term and long term business development plans from strategic scope and execution aspects with in-depths analysis.
Work closely with key cross functional teams such as product managers, data science, and engineers to solve business problems.
Build/maintain reports, dashboards, and metrics to monitor the performance of business products.
This is an individual contributor role, but will be expected to manage projects.
 Qualifications 


Bachelor's degree with a background in Math, Economics, Computer Science, Statistics, or other quantitative fields;
5 years experience of Data Analytics.
Expert experience pulling large and complex data using SQL and writing data pipelines.
Experience with a data visualization tool (e.g. Tableau);
 Prefer to Have 


Experience doing quantitative analysis;
Development experience in at least one scripting language (PHP, Python, Perl, etc.);
Excellent verbal and written English communication skills;
Experience with large data sets and distributed computing (Hive/Hadoop) a plus
 TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. 

 TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at usds.accommodations@tiktok.com. 
Job Information 
The base salary range for this position in the selected city is $123626 - $220611 annually. 

 ​ 

 Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units. 

 ​ 

 Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: 

 ​ 

 We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. 

 ​ 


Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. 

 ​ 

 We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",123626,"['python', 'tableau', 'sql', 'hadoop']"
Applied Scientist,TikTok,NY,Full-time,"Responsibilities 
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. 

 Why Join Us 
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. 
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. 
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. 
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. 

 About the team 
This team is responsible for both supporting AI researchers with annotated data and developing its own LLM/ML tools for optimizing the labeling and model evaluation processes. We seek highly driven, highly motivated individuals desire to work hands-on with this cutting-edge technology."" Could you please change it to ""This team is responsible for both supporting AI researchers with annotated data and developing LLM/AIGC applications that would benefit internal and external users 

 Responsibilities 


Develop and fine-tune LLM applications for various tasks, such as text generation, summarization, translation, and more.
Build machine learning models and deploy your models into production; work closely with software engineers to assist in productionizing your ML models.
Stay up-to-date with the latest advancements in AI, machine learning, and generative models. Apply this cutting-edge knowledge to enhance existing models and methodologies.
 Qualifications 


MS/PhD (PhD preferred) degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. PhD with 0-3 years of experience. Master with 2-5 years of experience and previous research experiences.
Deep knowledge or past working experience in Large Language Models (LLM), model Fine Tuning methods (instruct tuning, SFT, RLHF, etc.) and Reinforced Learning (RL).
Additional experience in latent-diffusion models and Computer Vision (CV) is preferred.
Proficient in Python and familiar with machine learning frameworks like TensorFlow and PyTorch.
Experience in developing end-to-end AI solutions, from ideation to deployment.
Strong problem-solving skills and a passion for innovation.
 TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. 

 TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com 
Job Information 
The base salary range for this position in the selected city is $144000 - $312000 annually. 

 ​ 

 Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units. 

 ​ 

 Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: 

 ​ 

 We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. 

 ​ 


Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. 

 ​ 

 We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",144000,"['tensorflow', 'pytorch', 'python', 'machine learning']"
Lead Data Scientist,Opinion Dynamics Corporation,MA,Full-time,"
Opinion Dynamics is growing and is seeking a new team member to join our Data Analytics team. In this role, you will provide analytical leadership and technical innovation backed by extensive knowledge of and experience in the clean energy space. Our ideal candidate will bring a strong quantitative skillset at the cross-section of data science, statistics, and econometrics combined with the ability to effectively navigate the dynamic and collaborative environment of a consulting firm. You will have demonstrated applied experience performing advanced analytics of interval energy consumption and equipment telematics data streams in support of load impact, forecasting, and disaggregation studies of clean energy interventions, including energy efficiency, demand response, electric vehicles, and other distributed energy resources (DERs).
 As a member of the Data Analytics team, you will lead the analytic design process and oversee the effective execution of a portfolio of analytically complex and computationally intensive projects. You will work in collaboration with our in-house Data Management, Engineering, and other teams to ensure that analytical solutions are supported and enhanced by sound data management and building science practices. While your primary function on projects will be defining analytic design process and oversight of the work, this is a hands-on role, and you are someone who jumps into the details of analyses to guide staff and provide the necessary oversight and support to ensure high-quality, accurate work products. As a methodological expert in the organization, you will participate in client-facing conversations, contribute to proposals and business development efforts, and effectively translate concepts between technical and non-technical audiences.


 Required Qualifications

Advanced degree in economics, statistics, data science, quantitative social science, political science, or related field and 8+ years of relevant experience. A bachelor’s degree with sufficient applied professional experience will be considered.
At least 4+ years in the clean energy space, ideally conducting advanced analyses leveraging load and other data streams in the context of research and consulting environment.
Expertise with advanced statistical approaches and evaluation and measurement practices and standards, specifically as applied to flexible load, time-varying rates, managed charging, decarbonization, energy efficiency, and grid resiliency programs and interventions.
Demonstrated experience conducting advanced statistical analyses with large volumes of interval load data.
Passionate about cultivating analytical innovation; comfortable tackling complex statistical problems through new and unexplored methods and data streams.
Passionate about mentoring and training junior staff.
Critical thinker who is curious, comfortable with complexity, a strong communicator, and has a strong consulting mindset.
Excited to serve in a hands-on role to ensure 1) the choice of rigorous and appropriate methodological solutions, 2) the successful execution of analytical tasks within agreed-upon timelines and budgets, and 3) the production of client-ready analytic outputs.
Advanced programmer in R or Python.
Skilled in data visualization and data management practices.

Additional Desired Qualifications

Knowledge of DER data streams (e.g., solar generation, battery charge/discharge, vehicle and device telematics)
Experience conducting DER valuation studies and analyses
Experience with rate design
Experience with integrated research planning studies
Skilled in big data analytics and corresponding tools and practices
Knowledge of machine learning and data science approaches and methodologies
Experience with version control software (e.g. Git) and collaborative code development



 Salary Range: $135K – 160K. Salary is negotiable depending on experience.



ABOUT OPINION DYNAMICS
 Opinion Dynamics advances knowledge to address emerging energy and social issues through sound and insightful research. Our inter-disciplinary team of consultants develops actionable and insightful research to support an array of clients, including electric and gas utilities, regulators, and stakeholders. Our research supports planning, assessment, and optimizing energy efficiency, demand response, and renewable energy programs. Our team uses a customized approach leveraging innovative methodologies to answer our client’s questions. Our company fosters innovative thought, collegiality, and growth opportunities for our employees.
 Opinion Dynamics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
 Opinion Dynamics is also committed to fostering a more diverse workforce. BIPOC, women, members of the LGBTQIA+ community, veterans, and individuals with disabilities are encouraged to apply.


",135000,"['python', 'machine learning', 'git']"
"Software Engineer, Machine Learning",Packback Inc,Remote,Full-time,"
Packback is looking for a Software Engineer to support our mission to awaken and fuel the lifelong curiosity in every student. As a software engineer at Packback, you will be building features that empower students and professors to have a better learning experience.

 Packback’s A.I.-powered platform is used by educators in K-12 and higher education to help their students fall in love with the subject matter, drive personalized learning, and most importantly, quantify and improve student critical thinking skills.
 Key job duties include communicating well, providing thoughtful feedback to teammates, pairing, actively improving our team knowledge-base, and of course, writing code. You’ll be improving our Python APIs that power Packback’s AI, supporting the integration of machine learning models in our web application, and incrementally improving our infrastructure and CI/CD pipeline.
 Why You Should Work at Packback
 Reach - Our platform, Packback Questions, is used by more than 10 thousand educators and 1.5 million students, who collectively author more than 10 million posts a year. You will be a part of building a platform that has a huge impact on inspiring curiosity in students.
 Training - We offer opportunities for learning and mentorship. We value people who like to wear many hats. You can get involved with the front end, back end, infrastructure and data functions.
 Ownership - Packback is a rapidly growing company. You will have responsibility for bringing innovative features to market while working closely with the product team.
 Want to learn more about engineering at Packback? Check out our docs repo on Github.
 Requirements
 We’re looking for somebody who is excited to work on our backend, infrastructure, and data science codebases. To succeed, you should have solid experience in backend engineering within a modern web application (We use Django and focus on NLP, but care mainly that you are a great developer).
 Additionally, we’re looking for:

A strong grasp on Python fundamentals, experience writing both functional and object oriented code with an emphasis on performance
 Demonstrated experience doing backend web development using a modern web framework such as Django (or some other equivalent MVC framework)
 Extensive experience writing thorough unit and integration tests in Python
 3+ years of software engineering experience, especially with web-based products. However, transferable experience is more important than years of experience.

It's great if you have

Strong SQL skills
 Experience building, validating, and deploying machine learning models in a production environment (NLP experience is a bonus)
 Experience working on highly scalable cloud infrastructures
 Comfort with Linux/UNIX systems


Comfort with Infrastructure as Code tools such as Terraform


 Startup or small company experience

 Our commitment to diversity
 Working in the Education Technology space, it is an ethical necessity for us to build a diverse and inclusive team in order to better consider the needs of our audience’s wide range of backgrounds and educational experiences. We provide regular training on topics of diversity, equity, and inclusion to all employees.
 Employees of color are invited to participate in a mentorship program with members of our executive team to build career skills and to help with career progression.
 We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
 Perks of working at Packback
 A culture that you can be proud to build: We work hard at building an inclusive culture of curiosity and continuous learning at Packback. In any role at Packback, being a good steward of our values and using them to inform decisions and communication can make an enormous impact on the business.
 Work-life balance: Packback offers an unlimited vacation policy. Team members are encouraged to take time off for volunteer opportunities. Our engineering team is fully remote, and provides flexibility and support for working wherever makes the most sense for you.
 Competitive Salary and Benefits: The salary range for this position is $85k-150k annually + bonus. We set clear expectations for professional growth and offer an annual learning and development stipend.
 Benefits
 Health & Wellness

Medical Insurance
 Dental Insurance
 Vision Insurance
 401(k) with a 50% employer match
 Stock options
 Disability Insurance
 Life Insurance
 Commuter Benefits
 Generous Parental Leave up to 12 weeks
 Family Medical Leave
 Unlimited Time Off

Additional Perks:

Access to premium membership to One Medical
 Calm subscription
 Monthly Dashpass subscription by DoorDash

",85000,"['python', 'machine learning', 'sql']"
Senior Data Analyst,Remitly,WA,Full-time,"

  Job Description:
 

   Remitly is on a mission to transform the lives of immigrants and their families by providing the most trusted financial products and services on the planet. Since 2011, we have been tirelessly delivering on our promises to immigrants sending their hard earned money home. Today, we are reimagining international payments at scale and building new products to create deeper relationships with our customers and their loved ones across the globe. Join over 2,700 employees across 10 offices who are growing their careers while having a positive impact on people globally.
 


   Remitly is registered as a Money Services Business in the U.S., Canada, EU, United Kingdom, Singapore and Australia. Each of these jurisdictions require, among other items, that Remitly maintain a comprehensive Risk and Compliance Program.
 


   About the Role:
 

   As the Senior Data Analyst, Complaints and Errors you will report to the Analytics Director, Customer Success. Your time will be spent working with structured and unstructured data, building analytical frameworks to detect the poorest customer experiences, and performing root cause analyses. You will collaborate with programme and product managers to prevent poor experiences and minimise their impact when they occur. Your work will directly influence customer experiences, and improve Remitly's regulatory compliance stance globally.
 


   You Will:
 

 Focus on the small number of customers who have the poorest experiences
 Effectively communicate metrics, analyses, commentary, and recommendations to multiple levels of stakeholders including regular exposure to senior leadership
 Simultaneously and independently manage multiple projects while ensuring deadlines are met and the desired business impact is achieved
 Use appropriate statistical tools and techniques to address ambiguous problems; identifying complaints and errors, classifying root cause, and modeling impact
 Partner with Compliance Officers to support regulatory reporting related to complaints and errors



   You Have:
 

 Degree in Statistics, Mathematics, Computer Science, Operations Research, Engineering, Economics, or related fields.
 An obsession with customer experiences
 Minimum of 6 years of relevant experience in an analytics role
 Minimum of 2 years experience classification modeling
 Experience modelling complicated scenarios with data then estimating their relative size and impact
 Experience in SQL, statistical modeling platforms (Python, R), data modeling
 Experience with regulatory reporting and natural language processing are beneficial but not required



   Our Benefits
 



     Flexible paid time off
   


     Health, dental, and vision benefits + 401k plan with company matching
   


     Company contributions to your HSA plan, if you choose one
   


     Employee Stock Purchase Plan (ESPP) available for eligible employees
   


     Continuing education and corridor travel benefits
   



   Remitly is an Equal Opportunity Employer. Equal employment opportunity has been, and will continue to be, a fundamental principle at Remitly. We are committed to nondiscrimination across our global organization and in all of our business operations. Employment is determined based upon personal capabilities and qualifications without discrimination on the basis of race, creed, color, religion, sex, gender identification and expression, marital status, military status or status as an honorably discharge/veteran, pregnancy (including a woman's potential to get pregnant, pregnancy-related conditions, and childbearing), sexual orientation, age (40 and over), national origin, ancestry, citizenship or immigration status, physical, mental, or sensory disability (including the use of a trained dog guide or service animal), HIV/AIDS or hepatitis C status, genetic information, status as an actual or perceived victim of domestic violence, sexual assault, or stalking, or any other protected class as established by law.
 


   Remitly is an E-Verify Employer
 


   Compensation Details. The starting base salary range for this position is typically $120,000 - $150,000. In the U.S., Remitly employees are shareholders in our Company and equity is part of our total compensation plan. Your recruiter can share more information about medical benefits offered, as well as other financial benefits and total compensation components offered with this role.
 

   Your recruiter can share more information about medical benefits offered, as well as other financial benefits and total compensation components offered with this role.
 


   Remitly is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
 
",120000,"['python', 'sql']"
Principal Data Scientist,Microsoft,WA,Full-time,"

  Microsoft Silicon, Cloud Hardware, and Infrastructure Engineering (SCHIE) is the team behind Microsoft’s expanding Cloud Infrastructure and responsible for powering Microsoft’s “Intelligent Cloud” mission. SCHIE delivers the core infrastructure and foundational technologies for Microsoft's over 200 online businesses including Bing, MSN, Office 365, Xbox Live, Teams, OneDrive and the Microsoft Azure platform globally with our server and data center infrastructure, security and compliance, operations, globalization, and manageability solutions. Our focus is on smart growth, high efficiency, and delivering a trusted experience to customers and partners worldwide and we are looking for a passionate,
   Principal Data Scientist to help achieve that mission.
 


 The Cloud Hardware Analytics & Tools (CHAT) Team within SCHIE develops advanced analytical and tooling solutions to support and improve the quality of Microsoft Azure. We collect and analyze data across the full Azure stack, HW & SW components, Silicon development processes, and much more. CHAT Data Science, a branch of CHAT, provides data science support, machine learning and artificial intelligence solutions, and advanced visualizations to cloud engineering and management partners. The Principal Data Scientist will lead end-to-end development of Artificial Intelligence/Machine Learning (AI/ML) solutions. This high-impact role combines data engineering with data science, and will have direct contributions to Azure-level projects, including working with highly visible platforms through data-driven approaches. This role closely collaborates with Data Scientists, Business Intelligence (BI) and Data Engineers, Software Engineers, Program Managers, and HW Engineering teams.
 

 Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.
 Responsibilities

 Analyze large-scale Azure data to address critical business problems
 Work on new data engineering solutions to extract, transform, load (ETL) massive datasets at near real-time
 Work on complex, mission-critical solutions that involve multiple Azure Services
 Design and develop production-level code for data science
 Design and develop new machine learning solutions end-to-end
 Work in collaborative environment

 Qualifications

 Required/Minimum Qualifications


 Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 10+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
   
 OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 7+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
 OR Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
 OR equivalent experience.

 7+ years developing data-driven analytics and solutions using a programming language such as Python, R, C#, C++, Java, Go.
 7+ years developing and deploying enterprise-scale end-to-end machine learning solutions, including developing novel modeling approaches / architectures, or fine-tuning models (such as LLMs) for specific business used-cases.
 7+ years developing enterprise-scale data engineering solutions, leveraging big data technologies such as Spark, Azure Synapse, Databricks.


 Other Requirements



 Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter.
 


 Preferred
 Qualifications


 Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 12+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
   
 OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 10+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
 OR Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND
 8+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results)
 OR equivalent experience.

 5+ years experience developing ML solutions within Microsoft Azure, or 7+ years experience with another cloud provider such as GCP, AWS.
 10+ years developing and deploying enterprise-scale end-to-end machine learning solutions.
 7+ years experience acting as technical project lead, and expertise in data engineering, machine learning, MLOps, and / or related advanced data-driven analytics.
 3+ years experience developing ML solutions within a cloud environment, such as Microsoft Azure, GCP, AWS.


   Data Science IC5 - The typical base pay range for this role across the U.S. is USD $133,600 - $256,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $173,200 - $282,200 per year.
  
 Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay
 

 Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
",133600,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'etl']"
Technology Enabled Analyst,Booz Allen Hamilton,DC,Full-time,"


Job Description










         Location: 
        

         Washington,DC,US 
        



         Remote Work: 
        

         No 
        



         Job Number: 
        

         R0185031
        


















         Technology Enabled Analyst
          Key Role:
 Identify the customer's data source requirements and applying data reconnaissance techniques. Build analytical workflows and methodologies using these data sources and create or implement new or existing tools and capabilities. Combine information from multiple sources to help your client understand their mission environment more effectively. Grow your expertise, develop new skills, and your methodologies with the intelligence community. Provide the right information at the right time to support the critical needs of our customers.

 Basic Qualifications:

 3+ years of experience with programming in Python, R, or JavaScript
 Experience with providing intelligence support to DoD and Inter-Agency partners
 Experience with intelligence systems, domains, and analytical tools
 Experience with developing high-quality deliverables tailored to clients, including tactical and strategic levels
 Ability to manage, clean, condition, and manipulate large data sets for visualization
 Ability to collaborate and innovate to solve problems
 Ability to travel up to 10% of the time CONUS and OCONUS to accommodate client needs, when necessary
 TS/SCI clearance
 HS diploma or GED

  Additional Qualifications:

 Experience with Attack the Network Tool Suite and other community tools
 Experience with JupyterHub or Jupyter Notebook
 Experience as a data scientist or data analyst using data science tools and practices
 Experience with SQL, REGEX, or API Requests
 Experience with ArcGIS Online or GEOINT tools
 Experience with using open-source research tools to support intelligence requirements
 Experience with providing intelligence support to the special operations community
 Knowledge of Machine Learning and Artificial Intelligence concepts or principles
 Possession of excellent verbal and written communication skills
 Bachelor's degree


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",58400,"['python', 'machine learning', 'sql']"
Senior Data Analyst - People Analytics - Workday Reporting,kraken,Remote,Full-time,"


Location

     United States - Remote
   


 Type

     Full time
   


 Department


      People
    
 People Operations



 Compensation


 Estimated Base Salary $79K – $116K • Offers Equity • Offers Bonus




      This is the target annual salary range for this role. This range is not inclusive of other additional compensation elements, such as our Bonus program, Equity program, Wellness allowance, and other benefits [US Only] (including medical, dental, vision and 401(k)).
    


      The compensation range provided is influenced by various factors and represents the initial target range. Our salary offerings are dynamic and we strive to ensure that our base salary and total compensation package aligns and recognizes the top talent we aim to attract and retain. The compensation package of the successful candidate is based on various factors such as their skillset, experience, and job scope.
    





 





 Building the Future of Crypto

 Our Krakenites are a world-class team with crypto conviction, united by our desire to discover and unlock the potential of crypto and blockchain technology.

 What makes us different? 
Kraken is a mission-focused company rooted in crypto values. As a Krakenite, you’ll join us on our mission to accelerate the global adoption of crypto, so that everyone can achieve financial freedom and inclusion. For over a decade, Kraken’s focus on our mission and crypto ethos has attracted many of the most talented crypto experts in the world.

 Before you apply, please read the Kraken Culture page to learn more about our internal culture, values, and mission. 

As a fully remote company, we have Krakenites in 60+ countries who speak over 50 languages. Krakenites are industry pioneers who develop premium crypto products for experienced traders, institutions, and newcomers to the space. Kraken is committed to industry-leading security, crypto education, and world-class client support through our products like Kraken Pro, Kraken NFT, and Kraken Futures.

 Become a Krakenite and build the future of crypto!
 Proof of Work

 The Team
 The People Analytics team plays an essential part in the Krakenite Experience (KX) function by empowering stakeholders across the business to make informed, data-driven people decisions. We support various projects and programs including talent acquisition, onboarding, training and development, the listening strategy, org design, performance appraisal, exit, and more.
 As a Senior Data Analyst, you will play a pivotal role by ensuring that we have necessary data and insights at our fingertips. You will be responsible for collecting, cleaning, and analyzing people data to identify trends and patterns. You will use your findings to develop recommendations and build solutions that foster a world-class Krakenite experience.

 The Opportunity



        Collect, clean, and analyze people data to identify key trends and patterns
      


        Develop and implement reports and dashboards to communicate findings to stakeholders
      


        Leverage Workday to complete ad hoc data request within the stated SLA
      


        Support the listening strategy with survey design, dashboard deployment, and analysis
      


        Partner with KX teams to support people strategies and initiatives
      


        Conduct research and recommend actionable solutions with data and insight
      


        Provide guidance on measuring impact with projects and initiatives developed within KX
      


        Remain in compliance with data privacy policies, regulations, and best practices
      

 Skills you should HODL



        4+ years of experience in People Analytics or similar role
      


        Proficiency with Workday (querying, report writing, dashboarding, etc.)
      


        The ability to clearly communicate complex results to technical and non-technical audiences alike
      


        Experience developing and implementing solutions from ideation to deployment
      


        The versatility and willingness to learn new technologies on the job
      


        Comfortable managing ambiguous tasks and balancing simultaneous projects
      

 Nice to haves



        Experience with Ashby, Tableau, Qualtrics, or other BI tools and HR technologies is a strong plus
      


        Python or R programming skills are a plus
      


        BA/BS or MA/MS degree with a quantitative focus (e.g., Industrial and Organizational Psychology, Mathematics, Statistics, etc.) is a plus
      

 Location Tagging: #US #LI-Remote #LI-DA1
 Kraken is powered by people from around the world and we celebrate all Krakenites for their diverse talents, backgrounds, contributions and unique perspectives. We hire strictly based on merit, meaning we seek out the candidates with the right abilities, knowledge, and skills considered the most suitable for the job. We encourage you to apply for roles where you don't fully meet the listed requirements, especially if you're passionate or knowledgable about crypto!

 As an equal opportunity employer, we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.




",79000,"['python', 'tableau']"
Health Data Scientist,Booz Allen Hamilton,MD,Full-time,"


Job Description










         Location: 
        

         Bethesda,MD,US 
        



         Remote Work: 
        

         Yes 
        



         Job Number: 
        

         R0185011
        


















         Health Data Scientist
          The Opportunity:
 As a health data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a health data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors—from fraud detection to cancer research to national intelligence—we need you to help find the answers in the data.

 On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide teammates and lead the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used.

 Work with us as we use data science for good.

 Join us. The world can’t wait.

 You Have:

 3+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining
 3+ years of experience with statistical and general-purpose programming languages for data analysis, including Python or R
 3+ years of experience with analyzing structured and unstructured data sources
 Experience with developing predictive data models, quantitative analyses, and visualization of targeted data sources
 Experience with advanced AI and ML techniques, including deep learning and generative models
 Ability to obtain a security clearance
 Bachelor’s degree


 Nice If You Have:

 Experience with leading the development of solutions to complex programs
 Experience in the development of algorithms leveraging R, Python, SQL, or NoSQL
 Experience with conducting large scale data analyses in Cloud-based environments, including AWS, GCP, or Azure
 Experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL
 Experience with visualization packages, including Plotly, Seaborn, or ggplot2
 Ability to work independently and manage the work of others
 Ability to communicate complex concepts clearly and concisely
 Ability to write white papers and scientific and technical manuscripts for publication
 Master's degree in Data Science, Applied Statistics, or Quantitative Life and Health Sciences


 Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.  Create Your Career:
 Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",58400,"['python', 'machine learning', 'deep learning', 'aws', 'azure', 'gcp', 'mysql', 'nosql', 'sql', 'kafka', 'hadoop']"
Senior Data Scientist - 2199648,Optum,MN,Full-time,"
Senior Data Scientist - 2199648
 EMPLOYER: Optum Services, Inc.  JOB TITLE: Senior Data Scientist
 LOCATION: 11000 Optum Circle. Eden Prairie, MN 55344
 DUTIES: Identify business problems or management objectives that can be addressed through data analysis. Duties include: apply knowledge of statistics, machine learning, programming, data modeling, and advanced mathematics to recognize patterns; identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement; design, develop, and evaluate models and advanced algorithms that lead to optimal value extraction from the data; work with analytics and statistical software to perform analysis and interpret data; work with vast amounts of data from multiple sources to provide predictive analytics to the enterprise; anticipate customer needs and proactively develop solutions to meet them; serve as a key resource on complex and/or critical issues; solve complex problems and develop innovative solutions; review work performed by others and provide recommendations for improvement; forecast and plan resource requirements; and provide explanations and information to associates on the most complex issues. Telecommuting is available from anywhere in the U.S.

 REQUIREMENTS: Master’s degree in Computer Science, Engineering, Mathematics, Statistics, Public Health, Health Services Research, Economics, or a related field and two years of experience in the job offered or related computer occupation.
 Experience must include:

analyzing health insurance claims;
transactions data such as Insurance verification, Coding, billing, and payment data of healthcare claims;
clinical data such as analyzing health records, claims data, clinical quality metrics and surveys.
program or employer data such as analyze emerging business data; and
analytics and statistical software such as SQL, R, Python, or Hadoop.

 RATE OF PAY: $101,400 - $147,032/year
 Please apply via careers.uhg.com and search for job #2199648
 Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm)
 UnitedHealth Group offers a full range of comprehensive benefits, including medical, dental and vision, as well as matching 401k and an employee stock purchase plan.
 Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.
 UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.


#LI-DNI
",101400,"['python', 'machine learning', 'sql', 'hadoop']"
Data Scientist Consultant (Remote),DataKind,NY,Full-time,"
DataKind is looking for a Data Scientist Consultant (Remote)!
Objective
 Nonprofit organization DataKind is requesting proposals from junior and mid-level data scientists.
 Context
 DataKind is a global nonprofit dedicated to harnessing the power of data science and artificial intelligence (AI) in the service of humanity. DataKind matches skilled volunteers from academia and industry with visionary changemakers, collaboratively designing innovative solutions to tough social challenges.
 People are at the center of our process: DataKind follows human-centered design principles that focus on questions such as ""why?"", ""for whom?"" and ""should we?"" before we get going on the ""what?"". We'll continue our work until all people and all communities can use digital technology for the outcomes they want to see, with an emphasis on including those who have historically been excluded from the technology sector or will be impacted by the intervention.
 Engagement Description
 DataKind's success ultimately comes down to the quality, timeliness, and effectiveness of our volunteer data science projects. Our Data Scientist Consultant will support a portfolio of internal and volunteer-led projects using cutting-edge technology to help high-performing organizations nation-wide make an even greater impact. In this highly visible and high impact role, you'll assist teams with any challenges they might face in building sustainable solutions.
 The Data Scientist Consultant will report to the Head of Data Science and will work closely with other staff and pro bono data scientists.
 This is a remote consultant role for an estimated 40 hours/week from mid December through end of May 2024 with a possibility of an extension. Due to the collaborative nature of the role, we require that the majority of working hours each day fall between 8am and 6pm Eastern Standard Time.
 What You'll Do
 The Data Scientist Consultant will be responsible for the following in addition to any other projects assigned by their manager:

Help manage data science and business intelligence products hosted by DataKind
Advance data science solutions beyond prototype phase
Carry out feasibility studies and exploratory analyses for proposed projects and areas of opportunity
Provide data science support for the portfolio of volunteer data science projects at DataKind
Advance internal analytics reporting and automation capabilities

The consultant should be willing to work a flexible schedule to meet on some nights or weekends with volunteer teams or to help run DataKind events.
 Qualifications

At least 3 years of work experience, preferably including experience in a nonprofit or start-up context.
Fluency in data science technology stack including R/Python, SQL, Postgres, AWS, and related technologies.
Deep experience in machine learning/AI with confidence in applying, tuning and evaluating a wide variety of AI algorithms, from logistic regression and random forests to deep learning.
Comfort and skill in communicating highly technical information to semi- and non-technical audiences.
Proven track record of successfully managing full lifecycle tech/AI projects.
Experience managing technical teams and deliverables in the volunteer, non-profit or tech spaces (or perhaps all three.)
Ability to motivate people to collaborate towards a shared goal, to keep them engaged throughout the process, and to intervene as needed to make sure balls don't get dropped.
Demonstrated customer service orientation that will allow you to represent DataKind well to our volunteers and partners alike.

Compensation
 $75 - $115/hour
 Based on the candidate's level of experience.
 Proposal
 By 12pm ET on Friday, December 1, 2023, interested parties are requested to provide the following:

A resume describing relevant professional experience
A cover letter that includes a short description of why you are interested in the position and outlines how your qualifications align with the role
If possible, a relevant work sample that demonstrates your ability to break down complex concepts in a compelling, approachable way. This could be any medium - github profile, thesis, blog post, etc. - and could have redacted information as needed.
Two references (name, phone number, and email address) from similar work, including a brief description of each project scope

Selection
 Strong proposals will be contacted for further discussion. These will be selected based on relevance of past experience and alignment with DataKind's goals and budget.
 DataKind is an Equal Opportunity Employer
 DataKind is an equal opportunity employer and strongly encourages candidates from underrepresented groups in tech to apply. DataKind does not discriminate on the basis of race, color, gender, disability, religion, national origin, age, sexual orientation, genetic information, pregnancy, or any other protected category.
 Applicants must be currently authorized to work in the United States.
",150000,"['python', 'machine learning', 'deep learning', 'aws', 'sql']"
Senior Data Scientist,Pluto TV,NY,Full-time,"Overview & Responsibilities 
The primary responsibility of the Senior Data Scientist is to apply experimentation, machine learning and visualization techniques to drive insights and help power data-driven decision making across all departments and levels of Pluto TV. For this senior-level individual contributor Data Scientist, it is anticipated that they would independently contribute meaningful analysis and drive complex Data Science-based full life cycle projects to completion. 
In this role, the incumbent must be able to extract data, model and optimize production algorithms across our platforms, and to query and manipulate data on an ad-hoc basis by using SQL, Python or R. 
Additionally, the Data Scientist must be flexible to quickly learn open source and big-data technologies such as Spark and the AWS/GCP ecosystems. 
Set up and measure nontrivial experiments and apply causal analysis methods. 
Take advantage of machine learning techniques sought at researching and implementing live cross-platform blueprints, model user behavior, and optimize marketing & programming initiatives. 
Design advanced data-visualization dashboards and presentations which facilitate distinctive views into our product and operations. 


Basic qualifications:
 Undergraduate degree (STEM strongly preferred) 
2+ years working with data science toolkits in R, Python or Matlab (a combination of industry and academic experience might acceptable) 
Tried experience with unstructured data projects, preferably in the Media / Entertainment / Streaming industry 
Strong understanding of statistical and machine learning methodologies (experimentation, regression analysis, clustering, classification) 
Analytical, meticulous, and results-focused 
Experience writing SQL queries on structured and unstructured data sets 
Lucid communication skills with the ability to summarize complex results into digestible analysis 
Additional Qualifications 
Experience working with big-data technology on Linux-based systems 
Graduate STEM degree or higher in a quantitative or technical field such as Computer Science, Data Science, Statistics, Applied Mathematics or Economics, Combinatorics, etc. 
#LI-FV 38394 
#LI-REMOTE 

 Join the Paramount Streaming Talent Community ! Get the inside scoop on life at Paramount Streaming and about career opportunities. 

 Pluto TV, a Paramount Global company, is the leading free streaming television service in America, delivering 250+ live and original channels and thousands of on-demand movies in partnership with major TV networks, movie studios, publishers, and digital media companies. Pluto TV is available on all mobile, web and connected TV streaming devices and millions of viewers tune in each month to watch premium news, TV shows, movies, sports, lifestyle, and trending digital series. Headquartered in West Hollywood, Pluto TV has offices in New York, Silicon Valley, Chicago and Berlin. 

 ADDITIONAL INFORMATION 


Hiring Salary Range: $124,000.00 - 170,500.00. 

 The hiring salary range for this position applies to New York City, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible. 

 https://www.paramount.com/careers/benefits 

 Paramount is an equal opportunity employer (EOE) including disability/vet. 

 At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. 

 If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",124000,"['python', 'machine learning', 'aws', 'gcp', 'sql']"
Astrophysicist (Artificial Intelligence),US Smithsonian Institution,MA,Full-time,"

Duties



Formulate and execute independent, original scientific research that focuses on the development and application of machine learning and other AI methods to astronomy, astrophysical phenomena, and cosmology that aligns with the strategic interests of SAO. Performs analysis that is creative, definitive, and thorough.


Prepare peer-reviewed publications describing research results, techniques, and interpretations for publication in peer-reviewed scientific or technical journals, and presentation at scientific or technical meetings and conferences, and within the CfA.


Propose for extramural contract and grant support for research in specific areas of astronomy, astrophysics or related fields, including but not limited to, machine learning and other AI methods, data science, and/or data analytics, typically applied to the analysis and interpretation of very large datasets.


Serve in a leadership role in the development of major new scientific initiatives for SAO relevant to the successful candidate’s expertise and skills.


Engage in education activities to train the next generation of scientists in astronomy and astrophysics by leading a research team that is diverse and inclusive, and providing mentorship and supervision.


Engage in outreach activities to share AI research and AI-based astronomical discoveries with the broader public through traditional and non-traditional media.





Requirements
Conditions of Employment

U.S. citizenship is required.
Electronic funds transfer/direct deposit is required for salary payment
National and international travel may be required
Males born after 12/31/59 must be registered with Selective Service.
Pre- and post-appointment background investigation
May be required to serve a one-year probationary period.

For information on qualification requirements, see Qualification Standards Handbook for General Schedule Positions viewable on the web at http://www.opm.gov/qualifications/standards/group-stds/gs-prof.asp 

Qualifications

Minimum Education Requirements:  A) Degree in one or a combination of astronomy, physics, mathematics, space science or electronics, including course work in differential and integral calculus and 12 semester hours in astronomy or physics; OR  B) A combination of education and experience equivalent to A above including at least 30 semester hours of courses equivalent to a major in any combination of astronomy, space science, physics, mathematics, and electronics with required course work as shown in A above.   Specialized Experience: One year of directly related experience (Federal or other) equivalent to GS-13. Specialized experience would include activities such as formulating and conducting leading independent and original astrophysical research related to machine learning and other Artificial Intelligence methods related to astronomy, presenting the results of research through peer-reviewed publications, conferences, and engagingin education activities to train the next generation of scientists in astronomy and astrophysics, etc.
 Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.
 Part-time and/or unpaid experience related to this position will be considered to determine the total number of years and months of experience. Be sure to note the number of paid or unpaid hours worked each week.
 There is no education substitution for this position.
 Qualifications must be met by the closing date of the announcement.
 Special Instructions for Foreign Education: If you are qualifying by education and/or you have education completed in a foreign college/university described above, it is your responsibility to provide transcripts and proof of U.S. accreditation for foreign study. For instructions on where to fax these documents, see the ""Required Documents"" section of this announcement.
 Important Note:
 The review of your resume will determine your final rating and should provide sufficient information regarding how your education and experience relate to this position, including the major duties and qualifications criteria listed.



Additional information



The Smithsonian embraces diversity and equal employment opportunity (www.si.edu/oeema).
 Recruitment Incentive: Recruitment incentive(s) may be authorized for this position. However, approval for incentives are contingent upon various availability. If authorized, certain incentives will require the incumbent to sign a service agreement to remain in the Federal government for a certain time period.  Note: This statement does not imply nor guarantee an incentive will be offered and paid.






Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.

Your application will be evaluated first for the basic education and specialized requirements. Applicants that meet the basic qualifications will be evaluated further against the following criteria:

Exceptional initiative and scholarly ability necessary to formulate, conduct and present results of programs of advanced scientific research in machine learning and other AI methods related to astronomy.
Advanced skill in preparing scientific results for publication in peer-reviewed scientific or technical journals and for presentation at professional conferences that apply machine learning and other AI methods to astronomical phenomena.
Advanced skill in proposing for extramural contract and grant support for research into specific areas of astronomy, astrophysics, or related fields.
Broad experience in the development of major new scientific initiatives relevant to the person’s expertise and skills.
Proven experience in developing the careers of students and early career researchers, including mentoring and supervision.
Proven ability to engage the general public in scientific results and discoveries through traditional and non-traditional media.



 Applicants who meet or exceed minimum qualifications will be assigned to one of three category groups based on job-related criteria:
 Best Category - Meets the minimum qualification requirements and excels in most of the job related competencies above.
 Better Category - Meets the minimum qualification requirements and satisfies most of the job related competencies above.
 Good Category - Meets the minimum qualification requirements, but does not satisfy most of the job related competencies above to a substantive degree.
 This category rating process does not add veterans' preference points or apply the ""rule of three"", but protects the rights of veterans by placing them ahead of non-preference eligibles within each category. A selecting official may make selections from the highest quality category (Best Category) provided no preference eligible in that category is passed over to select a non-preference eligible in that category unless the requirements of 5 U.S.C. 3317(b) or 3318(b) are satisfied. Preference eligibles who meet minimum qualification requirements and who have a compensable service-connected disability of at least 10 percent must be listed in the highest quality category, except when the position being filled is scientific or professional at the GS-9 grade level or higher. Applicants who have not submitted a resume in the USAjobs system and/or have not answered all of the vacancy questions will not be considered for this position.
 Important Note:
 Your resume and supporting documentation will be compared to your responses to the occupational questionnaire or other assessment tool for consistency. If a determination is made that you have rated yourself higher than is supported by your resume, you will be assigned a rating commensurate to your described experience. Your resume should provide sufficient information regarding how your education and experience relate to this position, including the major duties and qualifications criteria listed.


You may 
preview questions
 for this vacancy.





Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.

Your application package must include the following documents:

CV and Bibliography
school transcripts
proof of U.S. accreditation for foreign study, if applicable.
statement of previous research (3 pages max)
research vision, plan and objections (5 pages max)
diversity statement (3 pages max)
names/contact info for 4 references



If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating. 


How to Apply


Click on the ""Apply Online"" button on the upper right side of the page.  Please Note: 

You must apply for this position online through the 'Apply Online' button and submit required supplemental documents (if they are relevant to you).
You may submit required documents by uploading them online during the application process;  OR You may manually fax required documents. Faxes are received by an automated system, not a physical fax machine. Documents that are faxed as part of the application process must be sent with the system generated cover sheet by the closing date. Documents faxed without the system generated coversheet are not retrievable and cannot be considered as part of the application package.
The complete application package, including any required documents, is due in the Smithsonian Office of Human Resources on the closing date of the announcement by 11:59 PM Eastern Time.
If you are unable to apply online, paper applications may be accepted with prior approval of the Contact Person listed below.




Agency contact information
Judy Gallagher 


Phone
617-495-7374 
Fax
617-495-7263
Email
jgallagher@si.edu 


Address


SMITHSONIAN

Human Resources

60 Garden Street Cambridge, MA 02138 

Mail Stop 17 

Cambridge, Massachusetts 02138

United States 




Next steps

You will receive an automated email acknowledgment that your application has been received. This may take several hours. We often receive a large number of applications for a job. We review each application carefully, and this process may take a few weeks. As we go through each round of review, we will send you an email to date you on your status. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents


Your application package must include the following documents:

CV and Bibliography
school transcripts
proof of U.S. accreditation for foreign study, if applicable.
statement of previous research (3 pages max)
research vision, plan and objections (5 pages max)
diversity statement (3 pages max)
names/contact info for 4 references



If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.






 Help 
 This job is open to




Individuals with disabilities




Federal employees - Competitive service
Current or former competitive service federal employees.




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.




Special authorities
Individuals eligible under a special authority not listed above, but defined in the federal hiring regulations.




Veterans




Clarification from the agency
This position is open to all qualified U.S. Citizens or U.S. Nationals.

",130929,['machine learning']
Mid-Level Data Scientist,BOEING,WA,Full-time,"

At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.
 Boeing Defense, Space & Security (BDS) is seeking a Mid-Level Data Scientist to join our team located in Multiple Locations.

 This position can be located in the following cities: Seattle, WA; Arlington, VA; Denver, CO; Long Beach, CA; Miami, FL; New York, NY; North Charleston, SC; Plano, TX; Saint Louis, MO; San Francisco, CA.

 Boeing is the world's largest aerospace company and leading manufacturer of commercial jetliners, defense, space and security systems, and service provider of aftermarket support

 We are looking for an accomplished Mid-Level Data Scientist – Machine Learning Expert to support our Boeing Data Analytics organization. The organizational scope supports all Boeing enterprise functions and programs as well as corporate initiatives.

 At Boeing, we are already making a difference across the industry using the latest and state of the art artificial intelligence and machine learning techniques to deliver best in class product experience to our commercial and government customers. We are expanding and growing in all areas in the frontiers of the aerospace industry. We already have some of the best minds and talent in this field, and we’re looking for someone with applied experience in Artificial Intelligence and Machine Learning (including Natural Language Processing, Reinforcement Learning, Deep Learning, Conversational A.I, and Computer Vision) to join our team.

 Our data scientists work closely everyday with product managers, researchers, industrial and manufacturing engineers and software engineers to solve complex problems and create next generation solutions for our internal and external customers. The team works in tandem on some of the hardest problems at the intersection of technology and business. We bring new ideas to making future commercial and military airplanes, creating future space and autonomous systems, and making our operations world class. We also partner and collaborate with multiple universities and research institutions worldwide to keep abreast of advancements in the field.

 You must have a passion for continuous learning, teaching and collaborating. You should have well-reasoned opinions on technical matters but recognize other ideas and opinions. Paramount to success in this role is the ability to define, build and deploy artificial intelligence and machine learning solutions. Additionally, working directly with customers and business leaders to scope problems, clearly communicate results, and address any concerns in terms that can be understood by non-technical community of stakeholders.

 Position Responsibilities:

 Develop end-to-end artificial intelligence and machine learning solutions including data processing, feature & model development and production deployment with agility and scale.
 Lead and mentor small teams of data scientists in the design, development, and implementation of complex and challenging efforts in advanced analytics and machine learning.
 Partner with the enterprise business functions and collaborate across multiple teams including analytics, product management, and operations to solve problems and identify trends and opportunities.
 Have passion about working with large and complex unstructured and structured data sets.
 Lead and contribute to design, algorithm, and code reviews.
 Able to self-direct and succeed with minimal guidance.
 Strong communication and interpersonal skills. You should be able to work across functions and effectively present, recommend and communicate a position by demonstrating its value and tradeoffs.


 This position is hybrid. The selected candidate will be required to perform some work onsite at one of the listed location options. This is at the hiring team’s discretion and could potentially change in the future.

 The position must meet Export Control compliance requirements, therefore a “US Person” as defined by 22 C.F.R. § 120.15 is required. “US Person” includes US Citizen, lawful permanent resident, refugee, or asylee.

 Basic Qualifications (Required Skills/Experience):


 3+ years of experience using Python or R (Python Preferred)
 1+ year of experience working in the field of Artificial Intelligence including Machine Learning
 1+ year of experience in SQL


 Preferred Qualifications (Desired Skills/Experience):


 A technical Bachelor's degree with 4+ years of relevant work experience, or MS/MA degree with 4+ years of relevant work experience, or a relevant PhD degree. A relevant degree is defined as one in a quantitative field such as computer science, statistics, mathematics, operations research, bioinformatics, economics, computational biology, physics or chemistry. (Masters or PhD Degree preferred.)
 Experience leading small teams of technical experts in the development of advanced analytics, machine learning, or software solutions.
 Experience and expertise building and implementing state-of-the-art computer vision models and pipelines.
 Experience and expertise building and implementing state-of-the-art graph neural networks and pipelines.
 Experience and expertise building and implementing state-of-the-art natural language processing models and pipelines
 5+ years of work experience or relevant coursework with machine learning related open-source libraries including, but not limited to: Pandas, SciKit-Learn, TensorFlow, PyTorch, Theano, etc. Python experience preferred.
 2+ years of work experience or relevant coursework training machine learning models in a cloud computing environment such as: AWS, Google Cloud Platform, Microsoft Azure, etc.


 Typical Education & Experience:
 Education/experience typically 5 or more years' related work experience or relevant military experience. Advanced degree (e.g. Bachelor, Master, etc.) preferred, but not required.

 Relocation:
 This position offers relocation based on candidate eligibility. Note: Basic relocation will be offered for eligible internal candidates.

 Drug Free Workplace:
 Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies.

 Travel:
 This position requires up to 10% travel.

 Shift:
 This position is for 1st shift

 At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.

 The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.

 The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.

 Pay is based upon candidate experience and qualifications, as well as market and business considerations.

 Summary pay range: USD 113,900 – 164,450
 Export Control Requirements: U.S. Government Export Control Status: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.
 

Export Control Details: US based job, US Person required
  Equal Opportunity Employer:
 Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.
",113900,"['tensorflow', 'pytorch', 'python', 'pandas', 'machine learning', 'deep learning', 'aws', 'azure', 'sql']"
Applied Scientist,TikTok,NY,Full-time,"Responsibilities 
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. 

 Why Join Us 
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. 
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. 
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. 
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. 

 About the team 
This team is responsible for both supporting AI researchers with annotated data and developing its own LLM/ML tools for optimizing the labeling and model evaluation processes. We seek highly driven, highly motivated individuals desire to work hands-on with this cutting-edge technology."" Could you please change it to ""This team is responsible for both supporting AI researchers with annotated data and developing LLM/AIGC applications that would benefit internal and external users 

 Responsibilities 


Develop and fine-tune LLM applications for various tasks, such as text generation, summarization, translation, and more.
Build machine learning models and deploy your models into production; work closely with software engineers to assist in productionizing your ML models.
Stay up-to-date with the latest advancements in AI, machine learning, and generative models. Apply this cutting-edge knowledge to enhance existing models and methodologies.
 Qualifications 


MS/PhD (PhD preferred) degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field. PhD with 0-3 years of experience. Master with 2-5 years of experience and previous research experiences.
Deep knowledge or past working experience in Large Language Models (LLM), model Fine Tuning methods (instruct tuning, SFT, RLHF, etc.) and Reinforced Learning (RL).
Additional experience in latent-diffusion models and Computer Vision (CV) is preferred.
Proficient in Python and familiar with machine learning frameworks like TensorFlow and PyTorch.
Experience in developing end-to-end AI solutions, from ideation to deployment.
Strong problem-solving skills and a passion for innovation.
 TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. 

 TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com 
Job Information 
The base salary range for this position in the selected city is $144000 - $312000 annually. 

 ​ 

 Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units. 

 ​ 

 Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: 

 ​ 

 We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. 

 ​ 


Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. 

 ​ 

 We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",144000,"['tensorflow', 'pytorch', 'python', 'machine learning']"
Lead Data Scientist,Opinion Dynamics Corporation,MA,Full-time,"
Opinion Dynamics is growing and is seeking a new team member to join our Data Analytics team. In this role, you will provide analytical leadership and technical innovation backed by extensive knowledge of and experience in the clean energy space. Our ideal candidate will bring a strong quantitative skillset at the cross-section of data science, statistics, and econometrics combined with the ability to effectively navigate the dynamic and collaborative environment of a consulting firm. You will have demonstrated applied experience performing advanced analytics of interval energy consumption and equipment telematics data streams in support of load impact, forecasting, and disaggregation studies of clean energy interventions, including energy efficiency, demand response, electric vehicles, and other distributed energy resources (DERs).
 As a member of the Data Analytics team, you will lead the analytic design process and oversee the effective execution of a portfolio of analytically complex and computationally intensive projects. You will work in collaboration with our in-house Data Management, Engineering, and other teams to ensure that analytical solutions are supported and enhanced by sound data management and building science practices. While your primary function on projects will be defining analytic design process and oversight of the work, this is a hands-on role, and you are someone who jumps into the details of analyses to guide staff and provide the necessary oversight and support to ensure high-quality, accurate work products. As a methodological expert in the organization, you will participate in client-facing conversations, contribute to proposals and business development efforts, and effectively translate concepts between technical and non-technical audiences.


 Required Qualifications

Advanced degree in economics, statistics, data science, quantitative social science, political science, or related field and 8+ years of relevant experience. A bachelor’s degree with sufficient applied professional experience will be considered.
At least 4+ years in the clean energy space, ideally conducting advanced analyses leveraging load and other data streams in the context of research and consulting environment.
Expertise with advanced statistical approaches and evaluation and measurement practices and standards, specifically as applied to flexible load, time-varying rates, managed charging, decarbonization, energy efficiency, and grid resiliency programs and interventions.
Demonstrated experience conducting advanced statistical analyses with large volumes of interval load data.
Passionate about cultivating analytical innovation; comfortable tackling complex statistical problems through new and unexplored methods and data streams.
Passionate about mentoring and training junior staff.
Critical thinker who is curious, comfortable with complexity, a strong communicator, and has a strong consulting mindset.
Excited to serve in a hands-on role to ensure 1) the choice of rigorous and appropriate methodological solutions, 2) the successful execution of analytical tasks within agreed-upon timelines and budgets, and 3) the production of client-ready analytic outputs.
Advanced programmer in R or Python.
Skilled in data visualization and data management practices.

Additional Desired Qualifications

Knowledge of DER data streams (e.g., solar generation, battery charge/discharge, vehicle and device telematics)
Experience conducting DER valuation studies and analyses
Experience with rate design
Experience with integrated research planning studies
Skilled in big data analytics and corresponding tools and practices
Knowledge of machine learning and data science approaches and methodologies
Experience with version control software (e.g. Git) and collaborative code development



 Salary Range: $135K – 160K. Salary is negotiable depending on experience.



ABOUT OPINION DYNAMICS
 Opinion Dynamics advances knowledge to address emerging energy and social issues through sound and insightful research. Our inter-disciplinary team of consultants develops actionable and insightful research to support an array of clients, including electric and gas utilities, regulators, and stakeholders. Our research supports planning, assessment, and optimizing energy efficiency, demand response, and renewable energy programs. Our team uses a customized approach leveraging innovative methodologies to answer our client’s questions. Our company fosters innovative thought, collegiality, and growth opportunities for our employees.
 Opinion Dynamics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
 Opinion Dynamics is also committed to fostering a more diverse workforce. BIPOC, women, members of the LGBTQIA+ community, veterans, and individuals with disabilities are encouraged to apply.


",135000,"['python', 'machine learning', 'git']"
Behavioral Health Data Scientist (Human Services Data Scientist),King County,WA,Full-time,"


Summary






The Department of Community and Human Services values diverse perspectives and life experiences. The Department encourages people of all backgrounds to apply, including Black, Indigenous, and People of Color, immigrants, refugees, women, LGBTQ, people with disabilities, veterans, and those with lived experiences.



 King County's Department of Community and Human Services (DCHS) provides equitable opportunities for people to be healthy, happy, and connected to community.
   

 Are you a skilled data scientist with a commitment to social justice and utilization-focused performance measurement? Do you enjoy working collaboratively with partners to facilitate data-informed decision making? Are you interested in putting your skills to work to make a difference in your community? If so, King County's Department of Community and Human Services (DCHS) is looking for you!



 DCHS has a tremendous opportunity for a behavioral health data scientist to partner with one of the Country’s largest human services departments in advancing a cutting-edge collaborative model supporting behavioral health and recovery or pro-equity, community-driven programming to support people in King County! This position is centrally located within the Performance Measurement and Evaluation (PME) unit of the DCHS Director's Office but will help support the Behavioral Health and Recovery Division (BHRD). PME is composed of a team of dedicated data scientists and program evaluators who work with partners within and outside of DCHS to provide insights for data-informed program and policy decisions and test innovative approaches to tackle a variety of system, policy, and service delivery challenges.
   


 This position will support BHRD’s crisis and commitment services, including programs or services designed to provide intervention, outreach, or prevention all along the crisis continuum. You will be working with a team of extremely talented data scientists and evaluators to develop performance measures and dashboards, to conduct advanced quantitative analyses and to prepare reports that can inform business operations and improve King County’s behavioral health delivery system for the benefit of its clients.
   


 This Term-Limited Temporary position is anticipated to end 18 months after the start date. If filled by a King County employee who has passed their initial probation, the TLT will be as a Special Duty Assignment (SDA).



 WHO MAY APPLY: This position is open to all qualified candidates that meet the minimum qualifications. Interviews for this selection process will take place on or around December 18, 2023, with the possibility of second round technical interviews happening on or around January 2, 2024.
   


 REQUIRED MATERIALS: Candidates who wish to be considered for this position must submit an online King County application and respond to the supplemental questions. Your application may be rejected as incomplete if you do not include the requested and relevant information in the online application and supplemental questionnaire. Applications and/or supplemental questionnaires that state, “see my resume” are considered incomplete and will not be considered to be competitive.
   


 Additional Job Information:



 WORK SCHEDULE/CONDITIONS: This is a Special Duty Assignment (SDA), or Term-Limited Temporary (TLT) position anticipated to end 18 months after the start date but subject to change dependent on operational need. This position is exempt from the provisions of the Fair Labor Standards Act and is not eligible for overtime. Typical hours are Monday - Friday 8am - 5pm. This position is represented by PROTEC17.
   


 MISSION CRITICAL POSITION STATUS: This position has been designated non-mission critical. Unless otherwise directed by the County Executive, department director or agency head, all employees, regardless of designation, are expected to report to work or request leave during an emergency or inclement weather. For more detailed information, please visit HR Policy County Operations During Emergency Situations and the King County Guidelines for Workforce Management in an Emergency.
   


 TELEWORKING REQUIREMENT: The work associated with this position will be performed through a combination of teleworking complemented with onsite work and meetings as needed. Employees will have access to shared workspaces at various King County facilities. Employees must reside in Washington state and within a reasonable distance to their King County worksite to respond to workplace reporting requirements.
   

 Employees will be provided with a County issued laptop and must maintain a workspace with an internet connection (access may be supplemented in some situations) where they can reliably perform work and remain available and responsive during scheduled work hours. Please note that when an employee conducts work that is likely to bring them in contact with another individual, safety precautions are required, including the wearing of masks in some situations. King County is doing its part to reduce the spread of COVID-19 and remains committed to reducing our carbon footprint.
    
 King County has a robust collection of tools and resources to support working remotely. The individual selected for this opportunity will be joining an innovative and progressive team that is redefining how we work as we transition to the department's hybrid environment.
   


 RECRUITER: Susan Churchill, susan.churchill@kingcounty.gov
   



Job Duties




Develop Performance Measures and Dashboards


 Lead work with internal and external partners to design, create, and maintain production of key performance indicators, reports, dashboards, and trend analyses to improve performance of King County’s behavioral health crisis systems.
 Work with stakeholders to identify data needs to support initiatives, improve quality, monitor performance, and assess impacts.
 Extract, clean and transform data from large administrative datasets to make usable in production of performance measures, dashboards, and reports.
 Perform queries in structured query language (SQL) to extract data from large, complex administrative databases, especially within SQL Server.
 Serve as a subject matter expert in the technical specifications for key performance metrics, as well as understanding the complexities of various crisis programs and how they are reflected in administrative data.
 Develop standardized and streamlined processes using R and Git for producing several performance metrics on Tableau dashboards that can be used across BHRD bodies of work.
 Perform complex data analyses, analyze trends, and construct key performance measures to improve King County’s behavioral health system for the benefit of its clients.


Summarize Findings and Make Meaning of Complex Data


 Drive towards the application of a racial equity and social justice lens across a wide variety of projects and work products.
 Work independently to manipulate, analyze, and interpret data using appropriate statistical methods and data manipulation tools.
 Develop interactive dashboards, charts, reports, and presentations that visually represent key findings for non-technical audiences and communicate results in a way that is actionable.
 Conduct written and verbal presentations that share insights and recommendations with audiences of varying levels of technical sophistication.
 Develop tools to streamline key performance indicators and automation techniques to highlight actual performance change and identify any data system changes or data quality issues.
 As needed, participate in team, work group, division, and department meetings.
 Respond to other data requests and perform other related duties as assigned.




Experience, Qualifications, Knowledge, Skills




Demonstrated relevant work experience (typically 5 years), or an equivalent combination of education and work experience in finance, social sciences, statistics, public health, behavioral health, or a related field with course work in research methods and statistics and/or equivalent education and experience.
 Knowledge of equity and social justice principles and practices; lived experience with and/or understanding of the effect of place-, race- and policy & systems inequities on communities and populations.
 Extensive expertise working with large SQL databases and writing queries using structured query language (SQL).
 Skills with data management, analysis, and visualization tools, such as SQL, R, Excel, SAS, Python, and Tableau.
 Demonstrated experience conducting statistical analyses and preparing dashboards, reports, and presentations for non-technical audiences.
 Ability to develop a strong understanding of the key business processes, financial drivers and programmatic features reflected in the administrative data.
 Experience working with medical or behavioral health claims or encounter data.
 Experience extracting, matching, cleaning, managing, and validating data.
 Superb attention to detail.
 Strong analytical thinking skills.
 Strong oral and written communication skills, including the ability to communicate well with diverse groups including division leaders and executive leadership internally and externally.
 Strong problem solving and interpersonal skills, including the ability to work independently and maintain collaborative relationships as part of a team.
 Experience successfully managing complex projects, in detail, and meeting deadlines.


 DESIRED EXPERIENCE, QUALIFICATIONS, KNOWLEDGE, SKILLS


 Expert skills in SQL and R, including developing tools and packages.
 Experience working with version control systems, preferably Git/GitHub.
 Knowledge of advanced analytics and sophisticated statistical modelling techniques to identify trends, patterns, and relationships in healthcare data.
 Understanding of health and behavioral health measurement and management processes, indicators, and tools.




Supplemental Information



Forbes named King County as one of Washington State's best employers.
 Together, with leadership and our employees, we're changing the way government delivers service and winning national recognition as a model of excellence. Are you ready to make a difference? Come join the team dedicated to serving one of the nation's best places to live, work and play.
 Guided by our ""True North"", we are making King County a welcoming community where every person can thrive. We value diversity, inclusion and belonging in our workplace and workforce. To reach this goal we are committed to workforce equity. Equitable recruiting, support, and retention is how we will obtain the highest quality workforce in our region; a workforce that shares and will help advance our guiding principles - we are one team; we solve problems; we focus on the customer; we drive for results; we are racially just; we respect all people; we lead the way; and we are responsible stewards. We encourage people of all backgrounds and identities to apply, including Native American and people of color, immigrants, refugees, women, LGBTQ+, people living with disabilities, and veterans.
 King County is an Equal Employment Opportunity (EEO) Employer
 No person is unlawfully excluded from employment opportunities based on race, color, religion, national origin, sex (including gender identity, sexual orientation and pregnancy), age, genetic information, disability, veteran status, or other protected class. Our EEO policy applies to all employment actions, including but not limited to recruitment, hiring, selection for training, promotion, transfer, demotion, layoff, termination, rates of pay or other forms of compensation.
 To Apply
 If you are interested in pursuing this position, please follow the application instructions carefully. If you need this announcement in an alternate language or format, would like to request accommodation or assistance in the application or assessment process or if you have questions please contact the recruiter listed on this job announcement.



",106309,"['python', 'tableau', 'sql', 'git']"
"Lead Data Analyst/Senior Data Analyst, Tiktok Ads - USDS",TikTok,NY,Full-time,"Responsibilities 
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo. 

 Why Join Us 
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. 
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. 
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. 
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. 
Join us. 

 About USDS 
At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data. 

 U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more. 

 In order to enhance collaboration and cross-functional partnerships, among other things, at this time, our organization follows a hybrid work schedule that requires employees to work in the office 3 days a week, or as directed by their manager/department. We regularly review our hybrid work model, and the specific requirements may change at any time. 

 About the team 
We are a team of passionate Data Analysts, Data Scientists, and Operations who safeguard TikTok's US user data and join forces with cross-functional teams to derive actionable insights from US user data to maximize monetization results while still giving users a pleasant experience in our app. 

 We are looking for data analysts to join the efforts driving monetization, 


Apply expertise in data analysis and visualization to see beyond the numbers and understand how our users interact with our ads products.
Deliver data support for both short term and long term business development plans from strategic scope and execution aspects with in-depths analysis.
Work closely with key cross functional teams such as product managers, data science, and engineers to solve business problems.
Build/maintain reports, dashboards, and metrics to monitor the performance of business products.
This is an individual contributor role, but will be expected to manage projects.
 Qualifications 


Bachelor's degree with a background in Math, Economics, Computer Science, Statistics, or other quantitative fields;
5 years experience of Data Analytics.
Expert experience pulling large and complex data using SQL and writing data pipelines.
Experience with a data visualization tool (e.g. Tableau);
 Prefer to Have 


Experience doing quantitative analysis;
Development experience in at least one scripting language (PHP, Python, Perl, etc.);
Excellent verbal and written English communication skills;
Experience with large data sets and distributed computing (Hive/Hadoop) a plus
 TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. 

 TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at usds.accommodations@tiktok.com. 
Job Information 
The base salary range for this position in the selected city is $123626 - $220611 annually. 

 ​ 

 Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units. 

 ​ 

 Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: 

 ​ 

 We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. 

 ​ 


Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. 

 ​ 

 We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.",123626,"['python', 'tableau', 'sql', 'hadoop']"
Senior Data Analyst,Remitly,WA,Full-time,"

  Job Description:
 

   Remitly is on a mission to transform the lives of immigrants and their families by providing the most trusted financial products and services on the planet. Since 2011, we have been tirelessly delivering on our promises to immigrants sending their hard earned money home. Today, we are reimagining international payments at scale and building new products to create deeper relationships with our customers and their loved ones across the globe. Join over 2,700 employees across 10 offices who are growing their careers while having a positive impact on people globally.
 


   Remitly is registered as a Money Services Business in the U.S., Canada, EU, United Kingdom, Singapore and Australia. Each of these jurisdictions require, among other items, that Remitly maintain a comprehensive Risk and Compliance Program.
 


   About the Role:
 

   As the Senior Data Analyst, Complaints and Errors you will report to the Analytics Director, Customer Success. Your time will be spent working with structured and unstructured data, building analytical frameworks to detect the poorest customer experiences, and performing root cause analyses. You will collaborate with programme and product managers to prevent poor experiences and minimise their impact when they occur. Your work will directly influence customer experiences, and improve Remitly's regulatory compliance stance globally.
 


   You Will:
 

 Focus on the small number of customers who have the poorest experiences
 Effectively communicate metrics, analyses, commentary, and recommendations to multiple levels of stakeholders including regular exposure to senior leadership
 Simultaneously and independently manage multiple projects while ensuring deadlines are met and the desired business impact is achieved
 Use appropriate statistical tools and techniques to address ambiguous problems; identifying complaints and errors, classifying root cause, and modeling impact
 Partner with Compliance Officers to support regulatory reporting related to complaints and errors



   You Have:
 

 Degree in Statistics, Mathematics, Computer Science, Operations Research, Engineering, Economics, or related fields.
 An obsession with customer experiences
 Minimum of 6 years of relevant experience in an analytics role
 Minimum of 2 years experience classification modeling
 Experience modelling complicated scenarios with data then estimating their relative size and impact
 Experience in SQL, statistical modeling platforms (Python, R), data modeling
 Experience with regulatory reporting and natural language processing are beneficial but not required



   Our Benefits
 



     Flexible paid time off
   


     Health, dental, and vision benefits + 401k plan with company matching
   


     Company contributions to your HSA plan, if you choose one
   


     Employee Stock Purchase Plan (ESPP) available for eligible employees
   


     Continuing education and corridor travel benefits
   



   Remitly is an Equal Opportunity Employer. Equal employment opportunity has been, and will continue to be, a fundamental principle at Remitly. We are committed to nondiscrimination across our global organization and in all of our business operations. Employment is determined based upon personal capabilities and qualifications without discrimination on the basis of race, creed, color, religion, sex, gender identification and expression, marital status, military status or status as an honorably discharge/veteran, pregnancy (including a woman's potential to get pregnant, pregnancy-related conditions, and childbearing), sexual orientation, age (40 and over), national origin, ancestry, citizenship or immigration status, physical, mental, or sensory disability (including the use of a trained dog guide or service animal), HIV/AIDS or hepatitis C status, genetic information, status as an actual or perceived victim of domestic violence, sexual assault, or stalking, or any other protected class as established by law.
 


   Remitly is an E-Verify Employer
 


   Compensation Details. The starting base salary range for this position is typically $120,000 - $150,000. In the U.S., Remitly employees are shareholders in our Company and equity is part of our total compensation plan. Your recruiter can share more information about medical benefits offered, as well as other financial benefits and total compensation components offered with this role.
 

   Your recruiter can share more information about medical benefits offered, as well as other financial benefits and total compensation components offered with this role.
 


   Remitly is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
 
",120000,"['python', 'sql']"
DIRECTOR OF ARTIFICIAL INTELLIGENCE ENABLEMENT,Intero Digital,Remote,Full-time,"Job Title: Director of Artificial Intelligence Enablement
Job Type: Full-Time
Reports To: Operations Team
Location: United States, Remote, M-F, Mountain Time
Restriction: This opportunity is for candidates residing in the United States
Compensation: $100,000 to $150,000 Annually + Benefits
Summary:
As the Director of Artificial Intelligence (AI) Enablement, you’ll play a pivotal role in integrating AI technologies across our agency's operations and services. By collaborating with Presidents, VPs, and Managers, you'll spearhead the implementation and development of AI initiatives to optimize our current processes, enhance client performance, and ensure Intero Digital stays at the forefront of digital marketing innovation.
Key Responsibilities:
AI Strategy & Implementation:

Develop and implement a strategic AI roadmap in collaboration with senior leadership.
Lead the integration of AI and machine learning technologies to optimize digital marketing campaigns, analytics, and other core agency operations.
Manage AI projects ensuring timely delivery and measurable ROI.

Collaboration & Consultation:

Work closely with Presidents and other Managers to identify opportunities for AI application.
Engage with internal and external stakeholders to foster understanding and adoption of AI initiatives.

Technical Leadership

Stay updated on the latest advancements in AI, machine learning and related technologies.
Mentor and provide technical guidance to teams on AI-enabled solutions.

Development & Prototyping:

Hands-on development and prototyping of AI solutions, ensuring they meet the agency’s needs.
Evaluate, and if necessary, code and integrate third-party solutions, APIs, and platforms.

Performance Monitoring:

Establish metrics and monitor the effectiveness of AI initiatives, ensuring continuous improvement.

Compliance & Best Practices:

Ensure compliance with data privacy regulations and best practices.
Promote a culture of excellence, data-driven discussions, and a passion for AI.

Qualifications

Bachelor’s degree or equivalent
Experience in AI, machine learning, or a related field, with a track record of implementing AI solutions.
Familiarity with Chat GPT, and openness to building agents or GPTs.
Experience with AI-related APIs and frameworks.
Exceptional analytical, communication, and project management skills.
Ability to work independently, manage multiple projects simultaneously, and meet deadlines.
Ability to work remotely and collaborate with a geographically dispersed team.

Why Join Us?

Be a part of a culture of innovation and continuous learning.
Collaborate with a team of skilled professionals in the digital marketing and AI.
Flexible work arrangements with the ability to work remotely.
Competitive salary with potential for performance-based bonuses.

Application Process:

Interested candidates are encouraged to send their resume along with a cover letter explaining why they are the ideal candidate for this position to careers@interodigital.com
Deadline for applications: December 1, 2023

Job Type: Full-time
Pay: $100,000.00 - $150,000.00 per year
Work Location: Remote",100000,['machine learning']
Data Analyst Mid to Senior,Progressive,OH,Full-time,"

Data Analyst Mid to Senior


 Job Number
:
218922





 Join Forbes’ 2023 Best Employer for Diversity! 
As a mid or senior level data analyst on the Internal Audit & Advisory (A&A) Governance and Risk Data team, you'll have the opportunity to work closely with leadership and members of the entire department. You'll be responsible for contributing to existing reports and providing analysis on various audit initiatives, including support of departmental data measures. Additionally, you’ll be responsible for supporting our auditors in overseeing operational measures including labor analytics and the establishment and maintenance of key performance indicators (KPIs). You'll also provide guidance and support on the recently implemented new audit software, AuditBoard, as well as other tools used by the team.
 This will be a hybrid role, with preference for candidates residing within the area of Cleveland, OH. Will also consider candidates within the area of Carmel, IN or St. Petersburg, FL.


Must-have qualifications




     Bachelor's degree or higher in a quantitative field of study and a minimum of one year analytical work experience
     


     Instead of a quantitative degree, a bachelor's degree or higher and a minimum of three years of analytical work experience
     


     Instead of a degree, a minimum of four years of analytical work experience
     


Preferred skills

Proficiency in SQL and Tableau is preferred but open to experience with SAS and PowerBI
Demonstrated skills in Excel – including the ability to create, manipulate and formulate spreadsheets – including v-lookup, tables, VBA, macros, charts and graphing
Ability to learn quickly and work in an adaptive, fast-paced environment with a focus on detail orientation 
Proven aptitude for communicating insights and creating visualizations
Ability to prepare reports and conduct presentations to leadership and employee groups



Compensation

$56,300-$90,800/year depending on position level and experience
Gainshare bonus up to 24-30% of your eligible earnings based on company performance



Benefits

401(k) with dollar-for-dollar company match up to 6%
Medical, dental & vision, including free preventative care
Wellness & mental health programs
Health care flexible spending accounts, health savings accounts, & life insurance
Paid time off
Paid & unpaid sick leave where applicable, as well as short & long-term disability
Parental & family leave; military leave & pay
Diverse, inclusive & welcoming culture with Employee Resource Groups
Career development & tuition assistance

Energage recognizes Progressive as a 2023 Top Workplace for: Innovation, Purposes & Values, Work-Life Flexibility, Compensation & Benefits, and Leadership.
 Equal Opportunity Employer
 Sponsorship for work authorization for foreign national candidates is not available for this position.
 For ideas about how you might be able to protect yourself from job scams, visit our scam-awareness page at https://www.progressive.com/careers/how-we-hire/faq/job-scams/
 #LI-Remote






 Job
: Business Analysis
 



 Primary Location
: United States-Ohio-Cleveland
 



 Other Locations
: United States-Indiana-Carmel, United States-Florida-St Petersburg
 



 Schedule
: Full-time
 



 Employee Status
: Regular
 



 Work From Home
: No
 
",56300,"['tableau', 'sql']"
Machine Learning Engineer (Entry Level),"SRC, Inc.",NY,Full-time,"


SRC, Inc. is seeking an entry level engineer to work in the machine learning (ML) and artificial intelligence (AI) domains for our Syracuse, NY or Rome, NY office. The rapid advancement of deep learning continues to enable new and innovative applications, solutions, and capabilities for our products, including ground and airborne radar systems, electronic warfare (EW) systems, optical sensors, and more. The selected candidate will have the opportunity to design, develop, and field solutions using deep learning and other machine learning models on state-of-the-art hardware to solve a variety of challenges of national significance.

 What You'll Do

Applying machine learning models, tools, and techniques to imagery, video, signals, and other data products
Work with a team in the development of machine learning solutions for our customers
Performing data collections and running simulations to create, curate, and label machine learning datasets
Developing and delivering visualizations, demonstrations, and presentations for customers
Travel to technical conferences and various test sites in the United States
Remain current on state-of-the-art ML techniques and technologies

What You'll Bring

Bachelor's degree in computer science, electrical engineering, computer engineering, math, or physics. Other degrees may be considered if the candidate possesses a strong machine learning background.
Experience applying ML/AI to Department of Defense (DoD) and/or Intelligence Community (IC) problem domains, including radar, optical or infrared imagery, and electronic warfare systems.
Coursework in computer vision, machine learning, or neural networks
Technical proficiency in MATLAB, Python, and common deep learning frameworks (e.g., Tensorflow, PyTorch).
Excellent written and verbal communication and presentation skills.

Ways to Stand Out – Preferred Requirements:

Experience designing and developing ML/AI solutions for deployment on embedded platforms.
Familiar with signal processing algorithms, techniques, and related technologies
Technical proficiency in C++ for edge deployment

What Sets SRC, Inc. Apart? SRC, Inc. is a not-for-profit research and development company that combines information, science, technology to deliver innovative, advanced defense solutions and products that are redefining possible®. Our commitment is to our employees, our customers, and our communities, not the bottom line. We are committed to ensuring an inclusive and equitable workplace for all our employees. When you join our team, you’ll collaborate with more than 1,300 engineers, scientists and professionals — with 20 percent of those employees having served in the military — helping to keep America and its allies safe and strong.
 Total compensation for this role is market competitive. The anticipated salary range for this position based out of Syracuse, NY is estimated at $69,000 to $87,000 annually. The actual salary will vary based on applicant’s experience, skills, and abilities, geographic location as well as other business and organizational needs. SRC offers competitive benefit options, for more details please visit our website.



Equal Opportunity
Individuals seeking employment are considered without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, status as a protected veteran, or disability. You are being given the opportunity to provide the following information in order to help us comply with federal and state Equal Employment Opportunity/Affirmative Action record keeping, reporting, and other legal requirements.
Learn more about SRC:
  About Us Employee Benefits Diversity, Equity & Inclusion Awards & Recognition Security Clearance




Location Syracuse, New York 
Employment Type Full-Time Salaried 
Experience Required 0+ Years 
Education Required Bachelors Degree 
Security Clearance Requirement Must meet eligibility requirements 
Travel % 25


",69000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Data Science Director,Jellyfish,NY,Full-time,"
 Company Description
  Come and join our team at Jellyfish. We’ve got an exciting opportunity for a Data Science Director to support our growing Data Science practice on our NYC team.
 We’re passionate about giving talent a platform to perform, where everyone can shape and grow their own career in the way that works for them.
 At Jellyfish, our people are our biggest asset. The experiences and unique insights each individual brings to Jellyfish are what create the culture we are so proud of, and this culture is seen at every one of our offices around the globe as we continue to build one of the world's fastest-growing teams of digital experts.
 We work with some of the biggest brands on the planet, and as Google’s key global partner, we provide the right technology, strategy, and training while fostering strong relationships.
 Our four values:

 Be Positive: do you attempt to see the best in everyday situations and use challenges as learning experiences?
 Be the Solution: do you enjoy finding unique solutions with a problem-solving team?
 Be Accountable: do you believe in taking ownership of your work and want to work with a team that empowers each other to achieve their best?
 Be Passionate: do you enjoy what you do and want to work with a team that encourages your growth?

 If you answered yes to the above and want to be part of our dynamic team, we’d love for you to join us on our journey as One Jellyfish.



 Job Description
  About the role
 As the Data Science Director at Jellyfish, you'll be an integral part of our dynamic Data team consisting of talented data analysts and data scientists, and your role will involve overseeing our data analytics products and projects. Additionally, you will lead and nurture a growing team of Data Scientists, all with the goal of providing exceptional service to our diverse client base.
 This role has three primary objectives:

 Drive Our Vision: You will provide thought leadership in the data science and marketing science space, ensuring that Jellyfish maintains its position as an industry leader.
 Client-Centric Solutions: Create and execute data-driven strategies that empower our clients to extract greater insights and achieve superior performance. This involves close collaboration with technical teams, account managers, product teams, client teams, and other stakeholders.
 Global Impact: Design, build, and deliver solutions that have a global impact on Jellyfish, as well as our partners like Google, Amazon, Meta, and our clients. Your work should result in actionable insights and outcomes.

 Your responsibilities will also encompass driving the productization of high-quality prototypes, overseeing product execution by operational teams, and ensuring the successful delivery of the product. Furthermore, maintaining a vibrant team culture characterized by accountability, performance, and skill development is a key aspect of this role.



 Qualifications
  Basic Qualifications
 To excel in this role, you should possess:

 A comprehensive understanding of the marketing ecosystem and measurement framework, including paid media, organic channels, web, and app.
 Proven experience leading complex technical projects for enterprise clients.
 Strong expertise in data analytics, enabling you to define clients' data strategies, frame business challenges, and craft appropriate data solutions.
 A track record of successfully leading and nurturing a data science team while reinforcing tech best practices and fostering a culture of excellence.
 Experience building predictive models (e.g., econometric modeling, propensity models, etc.).
 Proficiency in programming with Python and SQL.
 Experience in visualizing data using tools like Looker or Tableau.
 Proficiency in collaborative code development practices, including the use of GitHub.
 Excellent communication skills, with the ability to distill and translate complex analyses into actionable insights.

 Preferred Qualifications
 In addition to the basic qualifications, the following are preferred:

 An advanced degree (MS or Ph.D.) in Computer Science, Mathematics, Physics, or related fields.
 Deep expertise in Ad Tech and MarTech, with a history of building data products in this domain.
 Experience in building Generative AI solutions.
 Familiarity with Google Cloud Platform and have GCP certifications.
 Experience in building econometric models or Media Mix Modeling (MMM)
 Experience in incrementality tests and experimentation, such as geo lift studies and A/B tests.

 Key Attributes
 To thrive in this role, you should embody the following attributes:

 Exceptional written and verbal communication skills, allowing you to effectively convey ideas to both technical and non-technical audiences.
 Adaptability and composure under pressure.
 Meticulous attention to detail combined with a thoughtful approach to processes and excellent problem-solving skills.
 Proactive and passionate about developing innovative data solutions.
 Openness, honesty, and directness, with a willingness to give and receive constructive feedback.
 Proactive in building positive relationships within the team and with other capabilities, partners, and clients, thriving in a collaborative environment.

 Additional Information
  Benefits

 Flexible hybrid working 40% onsite, 60% WFH
 Annual Bonus
 Training and Development
 Life Assurance
 Employee Assistance Programme - Counseling

 The salary banding for this role is between 190K - 212K USD annually based in NYC.
 All your information will be kept confidential according to EEO guidelines.

 Equal Opportunity Employer: Jellyfish is committed to making adjustments in our recruitment process to enable you to demonstrate your full potential. Should you require reasonable accommodation, please fill out the form here.

 Flexible working
 Annual Bonus
 Training and Development
 Life Assurance
 Employee Assistance Programme - Counseling

",190000,"['python', 'tableau', 'gcp', 'sql']"
"Mathematician I (HYBRID) Chicago, IL",Everi,IL,Full-time,"Are you ready to be part of something great? Everi is looking for talented candidates to join our Game Development Studio! As a Mathematician, you will be responsible for writing and testing production code, while implementing mathematical logic for game. You will be working with developers to create the best games in the industry. 

 This is a hybrid position located out of Chicago, IL. 

 This position is an exciting, challenging position with opportunities for new challenges regularly. If this sounds interesting, we want to talk to you! 
What Will You Be Doing? 
Implement mathematical logic of game for prize determination to match specifications of math design. 
Develop mathematical and statistical models for games; test table math models for functionality and adherence to specifications. 
Work with cross-functional teams to ensure correct implementation of game math and to answer questions about math implementation. 
Develops and generates theoretical par sheets demonstrating gaming probabilities and mathematical payout of games via calculation and/or simulation. 
Use proprietary tools for generating slot, bingo, and lottery math files. 


Skills, Knowledge, & Expertise for the job:
Qualifications:
 Bachelor’s Degree in Mathematics, Computer Science, or IT 
Mathematical probability education and/or experience 
Statistics education and/or experience 
Programming education and/or experience 
You will be learning and must be able to absorb new concepts. 


Nice to have's:
 Experience with SQL, C#, C++, JavaScript, or TypeScript is a big plus! 
Gaming industry knowledge (VLT and HHR) 
Knowledge of Everi products 
What's In It For You? 
Everi’s benefits package includes Medical, Dental, Vision, 401k with company match, life insurance, maternity and paternity leave, adoption assistance, pet insurance, gym reimbursement, and more! 
Discretionary Time Off (DTO) - No more “banking hours” to take a day off and the perfect way to prevent burnout and improve productivity. 
Building on a solid culture and resounding positive feedback from Everi employees in 2021, Everi continued to receive recognition as a Top Workplace in 2022. Everi was recognized nationally as a Top Workplace 2022 USA and received a second regional award for its HQ in Las Vegas as a Nevada Top Workplace 2022. This most recent award brings Everi’s total number of Top Workplaces awards in 2021 and 2022 to a whopping 10 awards!!! 
﻿ 
﻿﻿ 
﻿ 
Everi is committed to expanding its innovative and creative reach, building a culture based on the tenets of respect and transparency. We are proud to be the gaming industry’s single-source provider of financial technology, loyalty solutions, games, and intelligence solutions. Let’s Go! ﻿ 

 ﻿The compensation for this role considers a wide range of factors, including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential for the location at which the position may ultimately be filled. At Everi, it is not typical for all individuals to be hired at or near the end of the range; compensation decisions depend on each case’s facts and circumstances. A reasonable estimate of the current range is $70,000 - $75,000 annually. 

 Everi is an Equal Opportunity Employer. All qualified applicants and employees will be afforded equal employment opportunities without discrimination because of race, creed, color, national origin, sex, age, disability, marital status, or any other characteristic or class protected by federal, state, or local law. 

 ** For All External Staffing Agencies ** 

 Everi does not accept unsolicited agency submittals. Please do not forward resumes to our Executive team, Management team, or any current Everi employee for review. Everi is not responsible for any fees related to unsolicited resumes. 

 #LI-DE1 

 About Everi 
We believe in the values of Collaboration, Integrity, Inclusion, Excellence, and Fun!",70000,['sql']
Senior Applied Scientist,Microsoft,WA,Full-time,"

  Security represents the most critical priorities for our customers in a world awash in digital threats, regulatory scrutiny, and estate complexity. Microsoft Security aspires to make the world a safer place for all. We want to reshape security and empower every user, customer, and developer with a security cloud that protects them with end to end, simplified solutions. The Microsoft Security organization accelerates Microsoft’s mission and bold ambitions to ensure that our company and industry is securing digital technology platforms, devices, and clouds in our customers’ heterogeneous environments, as well as ensuring the security of our own internal estate. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. In doing so, we create life-changing innovations that impact billions of lives around the world.
 


 Do you have a passion for data and machine learning (ML)? Do you want to apply it to deploy AI solutions that helps protect millions of customers from threat actors around the globe? Are you curious, analytical, and motivated by new challenges? If so, we would like to hear from you! The Azure Security team is developing a cloud scale service that provides high precision detections for abuse activities across Microsoft Cloud. This solution is based on state-of-the-art machine learning and other techniques that rely on aggregating large-scale information. The team uses various detection strategies to identify evolving patterns to combat abuse. We are seeking a Senior Applied Scientist to help us grow and modernize our data science and detection strategies.
 


 Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.
 
 Responsibilities

 Provide technical leadership to our team by proposing, developing, and deploying ML models in an experimental framework.
 Monitor and analyze data to uncover gaps in signal and coverage
 Work with security threat analysts, engineers, and other ML Scientists to identify performant features and models and deploy them at scale.
 Act as a resident consultant for machine learning, statistics, and experimental design.

 Qualifications

 Required/Minimum Qualifications




     Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics predictive analytics, research)
   



       OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research)
     


       OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 1+ year(s) related experience (e.g., statistics, predictive analytics, research)
     


       OR equivalent experience.
     



 Other Requirements



 Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings:
 

 Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter.


 Additional or Preferred Qualifications


 3+ years experience creating publications (e.g., patents, libraries, peer-reviewed academic papers).
 Experience presenting at conferences or other events in the outside research/industry community as an invited speaker.
 3+ years experience conducting research as part of a research program (in academic or industry settings).
 1+ year(s) experience developing and deploying live production systems, as part of a product team.
 1+ year(s) experience developing and deploying products or systems at multiple points in the product cycle from ideation to shipping.


   Applied Sciences IC4 - The typical base pay range for this role across the U.S. is USD $112,000 - $218,400 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $145,800 - $238,600 per year.
 

 Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay
 


 #MSFTSecurity
  Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
",112000,"['machine learning', 'azure']"
Operation Research Analyst (Senior Financial Data Scientist),"US Treasury, Departmental Offices",VA,Full-time,"

Duties
As a/an Operation Research Analyst (Senior Financial Data Scientist), you will: 

Lead diverse and complex analytical studies.
Oversee and provide leadership and direction to broad financial data research projects on areas related to statistical methods, programing, data product development, big data, and feature engineering.
Assist the Associate Director for Data Products in utilizing the scientific and technical capabilities within the OFR to support ongoing and future data analytics projects.
Provide expert consultation to OFR Staff, and when requested, FSOC and FSOC member agencies pertaining to theory and application of data science and data analytics principles.
Conduct exploratory data analysis and predictive analysis to identify influential features and inform data-driven decisions.




Requirements
Conditions of Employment

The experience may have been gained in either the public, private sector or volunteer service. One year of experience refers to full-time work; part-time work is considered on a prorated basis. To ensure full credit for your work experience, please indicate dates of employment by month/day/year, and indicate number of hours worked per week on your resumé.
 Key Requirements:


Please refer to ""Conditions of Employment""


Click ""Print Preview"" to review the entire announcement before applying


Must be U.S. Citizen or U.S. National.

All new hires will be required to comply with federal ethics laws. A review of financial or other interests may be conducted to determine if they create any real or apparent conflict of interests with official Treasury duties. 
  

Qualifications

    You must meet the following requirements by the closing date of this announcement.
    

SPECIALIZED EXPERIENCE: For the 
    OR-60, you must have one year of specialized experience at a level of difficulty and responsibility equivalent to the 
    OR-53 grade level in the Federal service
    . Specialized Experience for this position includes: 
    
Analyzing data using statistical and mathematical techniques to evaluate program effectiveness; AND
Experience writing code in a statistical or computer programming language such as SAS, R or Python to aid in analysis; AND
Developing models, recommendations, and reports to solve problems with nationwide impact.




Education
Basic Requirements:   Degree: in operations research; or at least 24 semester hours in a combination of operations research, mathematics, probability, statistics, mathematical logic, science, or subject-matter courses requiring substantial competence in college-level mathematics or statistics. At least 3 of the 24 semester hours must have been in calculus.   Evaluation of Education:   The primary requirement of operations research work is competence in the rigorous methods of scientific inquiry and analysis rather than in the subject matter of the problem. Therefore, applicants should have sufficient knowledge of applied mathematics to understand and use the fundamental concepts and techniques of operations research methods of analysis. In addition, some positions may require knowledge of a specific subject area.   Courses acceptable for qualifying for operations research positions may have been taken in departments other than Operations Research, e.g., Engineering (usually Industrial Engineering), Science, Economics, Mathematics, Statistics, or Management Science.   The following are illustrative of acceptable courses: optimization; mathematical modeling; queueing theory; engineering; physics (except descriptive or survey courses); econometrics; psychometrics; biometrics; experimental psychology; physical chemistry; industrial process analysis; managerial economics; computer science; measurement for management; mathematical models in social phenomena; and courses that involved application of operations research techniques and methodologies to problems of management, marketing, systems design, and other specialized fields; or other comparable quantitative analysis courses for which college-level mathematics or statistics is a prerequisite. Courses in theory of probability and statistics are highly desirable, but are not specified as minimum educational requirements because to do so would possibly exclude some applicants who would otherwise be well qualified. 


Additional information

OTHER INFORMATION: 

We may select from this announcement or any other source to fill one or more vacancies.
This is a non-bargaining unit position.
A recruitment incentive may be offered.
Relocation expenses will not be paid.
Student loan repayment may be offered.
We offer opportunities for telework.
We offer opportunities for flexible work schedules.

CONDITIONS OF EMPLOYMENT:

A one year probationary period may be required.
Complete a Declaration for Federal Employment to determine your suitability for Federal employment, at the time requested by the agency.
Have your salary sent to a financial institution of your choice by Direct Deposit/Electronic Funds Transfer.
If you are a male applicant born after December 31, 1959, certify that you have registered with the Selective Service System or are exempt from having to do so.
Go through a Personal Identity Verification (PIV) process that requires two forms of identification from the Form I-9. Federal law requires verification of the identity and employment eligibility of all new hires in the U.S.
This position requires that the successful candidate undergo personnel vetting, which includes a background investigation and enrollment upon onboarding into ""Continuous Vetting."" Enrollment in Continuous Vetting will result in automated record checks being conducted throughout one's employment with Treasury. The successful candidate will also be enrolled into FBI's Rap Back service, which will allow Treasury to receive notification from the FBI of criminal matters (e.g., arrests, charges, convictions) involving enrolled individuals in near real-time. For more information about individual rights, Noncriminal Justice Applicant's Privacy Rights - FBI, FD-258 Privacy Act Statement - FBI, and SEAD-3-Reporting-U.pdf (dni.gov).

Our comprehensive benefits are very generous. Our benefits package includes:

Challenging work, opportunities for advancement, competitive salaries, bonuses and incentive awards.
Eleven paid holidays, 13 days of sick leave, and 13 to 26 days of vacation time each year.
Access to insurance programs that may be continued after you retire.
A wide choice of health insurance plans, coverage for pre-existing conditions, and no waiting periods. We pay a substantial amount (up to 75%) of the health insurance premiums.
A retirement program which includes employer-matching contributions.
Learn more about Federal benefits programs at: https://help.usajobs.gov/index.php/Pay_and_Benefits







Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 


Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.
Your application includes your resumé, responses to the online questions, and required supporting documents. Please be sure that your resumé includes detailed information to support your qualifications for this position; failure to provide sufficient evidence in your resumé may result in a ""not qualified"" determination.  Rating: Your application will be evaluated in the following areas: research and analysis, technical, and communication. 
 Category rating will be used to rank and select eligible candidates. If qualified, you will be assigned to one of three quality level categories, A (highest quality category), B (middle quality category), or C (minimally qualified category) depending on your responses to the online questions, regarding your experience, education, and training related to this position. Your rating may be lowered if your responses to the online questions are not supported by the education and/or experience described in your application. Your application may be reviewed by a Subject Matter Expert.
 Referral: If you are among the top qualified candidates, your application may be referred to a selecting official for consideration. You may be required to participate in a selection interview.
   
 If you are a displaced or surplus Federal employee (eligible for the Career Transition Assistance Plan (CTAP)/Interagency Career Transition Assistance Plan (ICTAP)) you must be assigned the middle category or better to be rated as ""well qualified"" to receive special selection priority. 
  




Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 


Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
It is anticipated that there will be significant interest in the announcement. As a result, the announcement will close at 11:59 p.m. ET on the date of receipt of the 150th application or at 11:59 p.m. ET on the date of closure; whichever occurs first. Any required documents should be submitted at the time that you apply as documents will not be accepted after the vacancy closes.  A complete application includes:  1. A resume: All applicants are required to submit a resume either by creating one in USAJOBS or uploading one of their own choosing. (Cover letters are optional.) 

Please limit your resume to 5 pages. If more than 5 pages are submitted, your resume will still be accepted, however only the first 5 pages will be reviewed and considered for qualifications and eligibility determination in whether or not the minimum qualifications for the position have been met.
To receive full credit for relevant experience, please list the month/date/year and number of hours worked for experience listed on your resume.
It is suggested that you preview the online assessment questionnaire, to ensure that your resume thoroughly describes how your skills and experience align to the criteria defined in the ""Qualifications"" section of this announcement and support your responses to the online assessment questionnaire.
For resume writing guidance, please visit USAJOBS Resources Center.

2. 
Vacancy assessment question responses: All applicants are required to complete vacancy question responses by clicking the apply online button of this vacancy announcement.
     

3. 
Submission of any required documents identified below, if applicable: Please note that if you do not provide all required information, as specified in this announcement, you may not be considered for this position (or may not receive the special consideration for which you may be eligible). 
     
VETERANS' PREFERENCE DOCUMENTATION: If you are claiming veterans preference, please see applicant guide for required documentation. In order to be considered for veterans preference, you must submit all required documentation as outlined in the applicant guide.
CAREER TRANSITION ASSISTANCE PLAN (CTAP) OR INTERAGENCY CAREER TRANSITION ASSISTANCE PLAN (ICTAP) DOCUMENTATION: If you are a displaced or surplus Federal employee, click CTAP/ICTAP for eligibility and a detailed list of required documents you must submit in order to be eligible.
EDUCATION DOCUMENTATION: 
       
You are not required to submit transcripts for this initial phase of the application process. Candidates will be referred for consideration based on their self-certification. If you are selected for a position which has a positive education requirement (as described in the vacancy announcement) and/or you are qualifying solely on your education, you will be required to submit official transcripts verifying your qualifications prior to a job offer being issued.
A college or university degree generally must be from an accredited (or pre-accredited) college or university recognized by the U.S. Department of Education. For a list of schools which meet these criteria, please refer to Department of Education Accreditation page. If you are qualifying based on foreign education, you must submit proof of creditability of education as evaluated by a credentialing agency. Refer to the OPM instructions.




If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating. 


How to Apply


DO has partnered with the Treasury's Bureau of the Fiscal Service to provide certain personnel services to its organization. Fiscal Service's responsibilities include advertising vacancies, accepting and handling applications, and extending job offers. The following instructions outline our application process. You must complete this application process and submit any required documents by 11:59 p.m. Eastern Time (ET) on the closing date of this announcement. We are available to assist you during business hours (normally 8:00 a.m. - 5:00 p.m. ET, Monday - Friday). If applying online poses a hardship, please contact us by noon ET on the announcement's closing date.  The Bureau provides reasonable accommodation to applicants with disabilities on a case-by-case basis. Please contact us if you require this for any part of the application and hiring process. 

To begin, click Apply to access the online application. You will need to be logged into your USAJOBS account to apply. If you do not have a USAJOBS account, you will need to create one before beginning the application.
Follow the prompts to select your resumé and/or other supporting documents to be included with your application package. You will have the opportunity to upload additional documents to include in your application before it is submitted. Your uploaded documents may take several hours to clear the virus scan process.
After acknowledging you have reviewed your application package, complete the Include Personal Information section as you deem appropriate and click to continue with the application process.
You will be taken to the online application which you must complete in order to apply for the position. Complete the online application, verify the required documentation is included with your application package, and submit the application.
To verify the status of your application:
      

Log into your USAJOBS account (USAJOBS Login). A list of announcements in which you have applied is at the Welcome screen.
Under ""application status,"" click ""Track this application"" and you will be taken to the agency website where you can check your application status.

 For more information regarding the job and applicant status, please refer to https://www.usajobs.gov/Help/how-to/application/status/
      
 If you wish to make changes/updates to your application and the vacancy is still open, you can click on the job announcement and ""Update Application"" to be taken back to your application. No updates can be made once the announcement has closed.
      
 Please notify us if your contact information changes after the closing date of the announcement. Also, note that if you provide an email address that is inaccurate or if your mailbox is full or blocked (e.g., spam-blocker), you may not receive important communication that could affect your consideration for this position.
      
 For additional information on how to apply, please visit the Partnership for Public Service's Go Government website.
      
 To preview the assessment questionnaire: https://apply.usastaffing.gov/ViewQuestionnaire/12198573
      


Agency contact information
Applicant Call Center 


Phone
304-480-7300 
Email
doinquiries@fiscal.treasury.gov 


Address


Domestic Finance-Office of Financial Research

Administrative Resource Center

Parkersburg, WV 26101

US 




Next steps

Once the online questionnaire is received, you will receive an acknowledgement email that your submission was successful. We will review your resumé and transcript(s) (if appropriate) to ensure you meet the basic qualification requirements. We will evaluate each applicant who meets the basic qualifications on the information provided and may interview the best-qualified applicants. After making a tentative job offer, we will conduct any required suitability and/or security background investigation. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents

It is anticipated that there will be significant interest in the announcement. As a result, the announcement will close at 11:59 p.m. ET on the date of receipt of the 150th application or at 11:59 p.m. ET on the date of closure; whichever occurs first. Any required documents should be submitted at the time that you apply as documents will not be accepted after the vacancy closes.  A complete application includes:  1. A resume: All applicants are required to submit a resume either by creating one in USAJOBS or uploading one of their own choosing. (Cover letters are optional.) 

Please limit your resume to 5 pages. If more than 5 pages are submitted, your resume will still be accepted, however only the first 5 pages will be reviewed and considered for qualifications and eligibility determination in whether or not the minimum qualifications for the position have been met.
To receive full credit for relevant experience, please list the month/date/year and number of hours worked for experience listed on your resume.
It is suggested that you preview the online assessment questionnaire, to ensure that your resume thoroughly describes how your skills and experience align to the criteria defined in the ""Qualifications"" section of this announcement and support your responses to the online assessment questionnaire.
For resume writing guidance, please visit USAJOBS Resources Center.

2. 
Vacancy assessment question responses: All applicants are required to complete vacancy question responses by clicking the apply online button of this vacancy announcement.
   

3. 
Submission of any required documents identified below, if applicable: Please note that if you do not provide all required information, as specified in this announcement, you may not be considered for this position (or may not receive the special consideration for which you may be eligible). 
   
VETERANS' PREFERENCE DOCUMENTATION: If you are claiming veterans preference, please see applicant guide for required documentation. In order to be considered for veterans preference, you must submit all required documentation as outlined in the applicant guide.
CAREER TRANSITION ASSISTANCE PLAN (CTAP) OR INTERAGENCY CAREER TRANSITION ASSISTANCE PLAN (ICTAP) DOCUMENTATION: If you are a displaced or surplus Federal employee, click CTAP/ICTAP for eligibility and a detailed list of required documents you must submit in order to be eligible.
EDUCATION DOCUMENTATION: 
     
You are not required to submit transcripts for this initial phase of the application process. Candidates will be referred for consideration based on their self-certification. If you are selected for a position which has a positive education requirement (as described in the vacancy announcement) and/or you are qualifying solely on your education, you will be required to submit official transcripts verifying your qualifications prior to a job offer being issued.
A college or university degree generally must be from an accredited (or pre-accredited) college or university recognized by the U.S. Department of Education. For a list of schools which meet these criteria, please refer to Department of Education Accreditation page. If you are qualifying based on foreign education, you must submit proof of creditability of education as evaluated by a credentialing agency. Refer to the OPM instructions.




If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.






 Help 
 This job is open to




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.




Career transition (CTAP, ICTAP, RPL)
Federal employees who meet the definition of a ""surplus"" or ""displaced"" employee.



Clarification from the agency
U.S. citizens or U.S. Nationals; no prior Federal experience is required.

",149739,['python']
Machine Learning Engineer,Booz Allen Hamilton,VA,Full-time,"


Job Description










         Location: 
        

         Arlington,VA,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0185074
        


















         Machine Learning Engineer
          The Opportunity:
 Do you enjoy creating innovative solutions to complex challenges while working within a community of dynamic technology professionals? As an experienced data professional, you know that machine learning is critical to understanding and processing massive datasets. We need your technical expertise to support federal healthcare.

 As a machine learning engineer, you’ll train, test, deploy, and maintain models that learn from data. Your ability to conduct statistical analyses on business processes using machine learning (ML) techniques is key and makes you an integral part of delivering a customer-focused solution. In this role, you’ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You’ll be part of a large community of machine learning engineers across the firm and collaborate with data engineers, data scientists, solutions architects, and product owners to deliver world class solutions to deliver mentorship, training, and solutions to real world problems, process data and information at a massive scale, perform A/B testing tasks on statistical models, ML algorithms, and systems. Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks. If you have the drive to solve real-world challenges and define ML strategy for healthcare in federal government, there’s a place for you here. At Booz Allen, you’ll make a difference with us, and, in return, we’ll invest in your future.

 Join us. The world can’t wait.

 You Have:

 2+ years of experience with data science, machine learning engineering, or postdoctoral research for machine learning
 Experience with natural language processing and language models, including working with transformers
 Experience with machine learning, including linear, reinforcement learning, tree based or deep learning-based methods, and regularization approaches for each
 Experience with deploying machine learning models into a production environment
 Experience with programming in Python, Java, or C++
 Experience with databases, including SQL
 Secret clearance
 Bachelor's degree


 Nice If You Have:

 Experience with developing software architectures with containerization tools, including Docker and Kubernetes
 Experience with software development, including API development or database management, and model deployment and usage with Javascript frameworks, including React, Angular or Node.js
 Knowledge of AWS, Azure, and GCP
 Ability to work in a Linux environment with bash scripting
 Master's degree


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['python', 'machine learning', 'deep learning', 'aws', 'azure', 'docker', 'gcp', 'sql']"
Machine Learning Engineer (Entry Level),"SRC, Inc",NY,Full-time,"
SRC, Inc. is seeking an entry level engineer to work in the machine learning (ML) and artificial intelligence (AI) domains for our Syracuse, NY or Rome, NY office. The rapid advancement of deep learning continues to enable new and innovative applications, solutions, and capabilities for our products, including ground and airborne radar systems, electronic warfare (EW) systems, optical sensors, and more. The selected candidate will have the opportunity to design, develop, and field solutions using deep learning and other machine learning models on state-of-the-art hardware to solve a variety of challenges of national significance.

 What You'll Do

Applying machine learning models, tools, and techniques to imagery, video, signals, and other data products
Work with a team in the development of machine learning solutions for our customers
Performing data collections and running simulations to create, curate, and label machine learning datasets
Developing and delivering visualizations, demonstrations, and presentations for customers
Travel to technical conferences and various test sites in the United States
Remain current on state-of-the-art ML techniques and technologies

What You'll Bring

Bachelor's degree in computer science, electrical engineering, computer engineering, math, or physics. Other degrees may be considered if the candidate possesses a strong machine learning background.
Experience applying ML/AI to Department of Defense (DoD) and/or Intelligence Community (IC) problem domains, including radar, optical or infrared imagery, and electronic warfare systems.
Coursework in computer vision, machine learning, or neural networks
Technical proficiency in MATLAB, Python, and common deep learning frameworks (e.g., Tensorflow, PyTorch).
Excellent written and verbal communication and presentation skills.

Ways to Stand Out – Preferred Requirements:

Experience designing and developing ML/AI solutions for deployment on embedded platforms.
Familiar with signal processing algorithms, techniques, and related technologies
Technical proficiency in C++ for edge deployment

What Sets SRC, Inc. Apart? SRC, Inc. is a not-for-profit research and development company that combines information, science, technology to deliver innovative, advanced defense solutions and products that are redefining possible®. Our commitment is to our employees, our customers, and our communities, not the bottom line. We are committed to ensuring an inclusive and equitable workplace for all our employees. When you join our team, you’ll collaborate with more than 1,300 engineers, scientists and professionals — with 20 percent of those employees having served in the military — helping to keep America and its allies safe and strong.
 Total compensation for this role is market competitive. The anticipated salary range for this position based out of Syracuse, NY is estimated at $69,000 to $87,000 annually. The actual salary will vary based on applicant’s experience, skills, and abilities, geographic location as well as other business and organizational needs. SRC offers competitive benefit options, for more details please visit our website.

",69000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
"Machine Learning Engineer, Senior",Booz Allen Hamilton,DC,Full-time,"


Job Description










         Location: 
        

         Washington,DC,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0185012
        


















         Machine Learning Engineer, Senior
          The Opportunity:
 At a certain point, experience-based system design can start to look like clairvoyance. When you’ve developed so many systems that you can not only orchestrate the best solution for any technology-based challenge, but you can also anticipate and preempt future issues, you’re a solutions architect. You’ve evolved your skills into strategy through a long path of software development accomplishments and the curiosity to understand how all the pieces of an IT ecosystem fit together. Are you ready to use your combination of knowledge, skill, and experience to take on the toughest challenges in our nation’s public health system?

 As a solution architect on our team, you'll translate your customer’s IT needs and future goals into a plan by crafting architecture products, design specifications, and Agile frameworks that drive innovative, technical solutions. Through your leadership, we’ll help transform the way the federal health sector uses technology, including Cloud migration, integrating advanced technology, and modernizing legacy systems. And, what do you do next in a career where you’ve reached this level? You mentor the next set of developers to help them grow into tomorrow’s solutions architects. As a technical leader, you’ll shape the digital solutions business and identify opportunities for growth.

 Work with us and build the future of technology in healthcare for the better.

 Join us. The world can’t wait.

 You Have:

 4+ years of experience with software engineering, artificial intelligence, data science, machine learning engineering, or data engineering, including in a research or professional role
 Experience working with artificial intelligence and machine learning technology stack and practices
 Experience software development and artificial intelligence implementation and deployment projects
 Experience with coding languages, including Python, SQL, and Java
 Experience with modern Cloud computing technologies, including AWS, Azure, and GCP
 Knowledge of the data life cycle, including data acquisition, discovery, sharing, consumption, synthesis, conversion, and disposition
 Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements
 Bachelor’s degree


 Nice If You Have: 

Experience with technology consulting
 Experience with establishing enterprise-wide Data Platform architecture, frameworks, design, and development standards
 Experience with developing high-quality briefings for senior Federal Government leadership
 Ability to select and implement the appropriate data platform tools and systems to support data technology goals, including R, Python, or Jupyter Notebooks
 Ability to design, develop, and manage large-scale complex data engineering pipelines and data governance models
 AWS, Google Cloud, or Microsoft Azure certification


 Vetting: Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",93300,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'sql']"
"Principal Performance Engineer, AI Applications",NVIDIA,CA,Full-time,"

  We are seeking a highly motivated performance engineer to join our AI Applications organization to work on distributed cloud native accelerated video analytics applications. Our team is building distributed cloud native accelerated real-time video streaming AI inference and video analytics platforms running on the Edge and cloud in a Kubernetes environment as part of the Metropolis ecosystem. As a performance engineer, you will work with the Application teams to understand the architecture, profile, identify bottlenecks and optimize. You will build a good understanding of application resource utilization characteristics across CPU, GPU and network accelerators. A good understanding of distributed systems performance is must to scale these applications across multiple CPU and GPU nodes. Your duties include collecting data and information on the applications you wish to optimize, identifying areas for improvement and developing strategies to bring about those positive changes.
 


   What you'll be doing:
 



     You will plan, enable and drive performance initiatives across our Cloud Native application teams
   


     Review, Develop, deploy and manage tools and strategies to systematically run performance experiments
   


     Collect and organize performance data and share with key partners.
   


     Work closely with application teams to understand application resource utilization characteristics. Identify performance issues through profiling of the various components
   


     You will learn and have a good understanding of various accelerators in the system for an application workload and recommend E2E performance optimizations relative to capabilities of the system
   


     You will assist developers and product teams on best accelerators and systems for E2E system performance
   


     Improve and Standardize Performance measurement processes across our applications and GPU systems
   


     Work closely with GPU cloud native teams at Nvidia to deploy the latest and most optimal GPU resource sharing strategies for our applications in a kubernetes environment
   



   What we need to see:
 



     Masters's degree or PhD in Computer Science or a related field, or equivalent experience
   


     15+ years of experience in optimizing system design, complexity analysis, software design in Unix/Linux systems, performance, and application issues
   


     Experience in real-time streaming AI inference systems
   


     A history of working on distributed accelerated systems and solving sophisticated performance problems
   


     Deep hands-on experience with Distributed systems based on Kubernetes
   


     Experience with on-prem and cloud systems
   


     Ability to work with partners across multiple teams
   


     Experience using and handling and optimizing modern Cloud and container-based Enterprise computing architectures.
   


     Strong verbal and written communication and teamwork skills.
   


     Ability to multitask effectively in a multifaceted environment.
   


     Action driven with strong analytical skills.
   



   Ways To Stand out from the Crowd:
 



     Background with real-time computer vision AI inference and/or Analytics platforms
   


     Experience in application issues, algorithms, and data structures
   


     Understanding of the functioning of AI services, deep learning and AI
   


     Exposure to scheduling and resource management systems.
   


     Knowledge of GPU programming such as OpenCL or CUDA and knowledge of Multi-node GPU setups, GPU clusters, or Cloud computing
   



   NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing and Visualization. The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services. Our work opens new universes to explore, enables outstanding creativity and discovery, and powers what were once science fiction inventions from artificial intelligence to autonomous cars. NVIDIA is looking for phenomenal people like you to help us accelerate the next wave of artificial intelligence. Widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us. If you're creative and passionate about new technologies we want you on our team!
 
 The base salary range is 268,000 USD - 414,000 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
 







          You will also be eligible for equity and 
         
          benefits
         . 
         NVIDIA accepts applications on an ongoing basis.








 NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

",268000,['deep learning']
Senior Machine Learning Engineer,Forrester,MA,Full-time,"

  At Forrester, we’re trusted to work on trailblazing, mission critical problems that business and technology leaders face today. That’s why we’re always looking to empower talented individuals to perform at their best every single day. We’re proud of our community of smart people and vibrant voices who come together to do what’s right by our clients and each other. Our success is driven by curiosity, courage and customer obsession. The confidence and drive to be bold at work. Join us and build an extraordinary future.
 


   Employer
 

   Forrester Research, Inc.
 


   Job Title
 

   Senior Machine Learning Engineer
 


   Job Requisition
 

   FR 12122.80
 


   Salary
 

   $150,000 per Year
 


   Job Location
 

   Cambridge, MA
 


   Job Duties
 



     Develop production applications and APIs employing cutting-edge AI, natural language, and machine learning algorithms.
   


     Work closely with a dynamic technical team and partners in product management, digital experience design, QA, and DevOps to build high-value software.
   


     Work with our data scientists to implement new machine learning approaches, feedback mechanisms, and data pipelines that help us better respond to client needs.
   


     Develop unit tests, regression suites, and software to monitor the algorithms in pro.
   


     Telecommuting permitted up to 100%
   



   Job Requirements
 

   Employer will accept a Master’s degree or foreign equivalent in Computer Science, Data Science, or a related field and three years of experience in the job offered or in a Senior Machine Learning Engineer-related occupation.
 


   Experience must include:
 

   3 years of experience with each of the following:
 



     Machine Learning (ML) algorithms, natural language approaches, and parallel systems including neural networks, transformers, entity recognitions, sparkML, word2vec embeddings, and text classification;
   


     Operationalizing ML as applied to search and recommendations with feedback loop incorporation and observability;
   


     Working Core Computer Science areas including Object Oriented Design, Data Structures, and Algorithms;
   


     Contributing to the system design or architecture (architecture, design patterns, reliability, and scaling) of new and current systems;
   


     Relational and No SQL Databases including Datawarehouse concepts, normalization, large scale query optimization, and procedural language;
   


     Hands on experience in at least 2 databases: Oracle, Teradata, SQL Server, or Postgre;
   


     Engineering solutions using at least 2 modern programming language including: Python, JavaScript, C#, or Java;
   


     Modern Continuous Integration & Continuous Deployment (CI/CD) tools, containerization, automated testing frameworks, and source control technologies;
   


     GraphQL and scalable API’s.
   


     Design of experiments including A/B Testing and Multi arm bandits;
   


     Big-data Analytics including, Spark, Cloudera, and Kafka;
   


     Practical experience writing large scale web applications including architectural decisions, language choices, frameworks, and implementation;
   


     Debugging full stack systems and perform root cause analysis, which includes frontend including React or Vue, backend and backend frameworks including Flask or Django, databases, and DevOps.
   


     Telecommuting permitted up to 100%
   



   Foreign Language, Licenses, and Certifications
 

   N/A
 


   Contact Instructions
 

   How to apply: Email resume, including job history to Ty Milton at tmilton@forrester.com referencing FR 12122.80. EOE. Forrester Research, Inc. is an Equal Opportunity Employer.
 




     We’re a network of knowledge and experience leading to richer, fuller careers. Here, we’re always learning. Whether you want to hone your strengths or discover new ones, Forrester is the place to go for it. It’s a place where everyone is given the tools, support, and runway they need to go far. We’ll be right there beside you, every step of the way.
   





 Let’s be bold, together.
  



   Explore #ForresterLife on:
 


    Instagram
  



    LinkedIn
  



    Glassdoor
  



   FLSA Status:
  Exempt
 

 Here at Forrester, we welcome people from all backgrounds and perspectives. Our aim is for all candidates to be able to fully participate in Forrester’s recruitment process. If you would like to discuss a reasonable accommodation, please reach out to 
  
   accommodationrequest@forrester.com
  .
 


   Forrester Research, Inc. is an Equal Opportunity/Affirmative Action Employer that is committed to equal employment opportunity for all qualified individuals without regard to race, color, religion, national origin, ancestry, sex, age, disability, sexual orientation, gender identity and expression, marital status, genetic information, military service, veteran status, or any other status protected by applicable law. Minorities, Women, Individuals with Disabilities, and Veterans are especially encouraged to apply.
 

",150000,"['python', 'machine learning', 'sql', 'kafka']"
Data Scientist,Lendistry,CA,Full-time,"

ABOUT LENDISTRY
 Lendistry is the country’s largest minority-led and technology-enabled small business and commercial real estate lender with Community Development Financial Institution (CDFI) and Community Development Entity (CDE) certification. We are a national employer whose mission is to provide economic opportunities and progressive growth for small business owners and their underserved communities as a source of financing and financial education.


 POSITION OVERVIEW
 The Data Scientist will help shape business strategy and product development decisions through data-driven insights. This is an exciting role for someone to make a direct impact on risk, product, and revenue strategy of Lendistry. Success in this role hinges on your technical aptitude, quantitative abilities, and business acumen: you know how to plow through data with SQL/Python/R/, surface insights using math/statistics/ML techniques, and measure the business impact using efficiency/conversion/profit metrics.


 GENERAL RESPONSIBILITIES

The data scientist will support the Consumer Credit department by leveraging big data technologies to aggregate and structure data, perform statistical analysis, and build algorithmic solutions to reduce fraud and credit losses.
As a member of the credit risk team, you will research and develop new methodologies and techniques to improve the overall effectiveness of risk management.
Mine and analyze massive amount of unique internal and external data to gain deep business knowledge and insight on customer activity and usage behaviors and their relationships with fraud, credit risks, and other types of behaviors.
Acts as the technical owner of projects that may require significant customization of existing analytic tools, techniques, processes, or development of new ones.
Perform statistical data analysis and understanding, ensure data quality, and develop tracking and reporting systems to determine the effectiveness of models, rules, and other risk initiatives and programs.
Design and create systems to structure, aggregate, and turn petabytes of messy information into statistically significant features for modeling purposes.
Manage and implement new risk strategies in our Risk Systems.



 PROFICIENCIES

Excellent verbal and written communication skills.
Strong knowledge of 1 or more scripting and programming languages (Python, Java, SQL, Scala, etc.)
Background in a variety modeling techniques: GBM, logistic regression, clustering
Experience in utilizing and implementing credit strategies in decision engine systems like Provenir, GDS-Link, Zoot, etc is a plus.
Sophisticated word processing and computer database skills, especially in Microsoft Word, PowerPoint and Excel.
Ability to think creatively and innovatively.
Good interpersonal skills with the ability to work effectively with individuals and groups at all organizational levels, ability to work independently and as part of a team.



 EDUCATION AND EXPERIENCE

Bachelors degree in a quantitative field: engineering, math, statistics etc. MS/PHD preferred
3+ years of experience in business analysis, customer segmentation, and/or predictive modeling, preferably in the financial services industry
2+ years in using machine learning packages such as Python, R, SAS



 SALARY

$80,000 - $110,000/Annually, depending on location and experience.


 Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
 The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)
",80000,"['python', 'machine learning', 'sql']"
Data Scientist,US Department of Veterans Affairs,DC,Full-time,"This position is located in the Department of Veterans Affairs (VA), Office of Enterprise Integration (OEI), Office of Data Governance and Analytics (DGA). DGA is responsible for leading data management, data analytics, and business intelligence capabilities to inform VA-wide decision making.
Major Duties:

Plans and conducts, as project member of a study team, relevant research and analytical studies of VA complex issues to support critical operational problems and/or decisions using advance state-of-the art data theories beyond established parameters.
Identifies, develops, and integrates data from internal and external sources, through various data collection procedures and technologies, including emerging data science and big data methodologies.
Performs a wide range of complex analytical, mathematical and statistical research that inform operational requirements.
Extracts relevant information from historical datasets.

For the GS-11:Specialized experience is defined as analyzing and interpreting data modeling, algorithms, and coding data requirements; Analyzing and providing information from multiple systems to prepare data reports; Conducting analysis using software and/or programming languages; Using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation.
For the GS-12:Specialized experience is defined as identifying data required for use in the management and direction of programs; Implementing algorithms, machine learning, and other AI systems; Using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation; Applying statistical analyses to determine the fitness-for-use of new or combined data sources, machine learning outputs, and data science methods.
Job Type: Full-time
Pay: $78,592.00 - $122,459.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Professional development assistance
Retirement plan
Tuition reimbursement
Vision insurance

Experience level:

3 years
4 years
5 years

Schedule:

8 hour shift

Work Location: In person",78592,['machine learning']
Data Scientist,INFICON,NY,Full-time,"
 Company Description
  INFICON is a leading provider of innovative instrumentation, critical sensor technologies, and Smart Manufacturing/Industry 4.0 software solutions that enhance productivity and quality of tools, processes, and complete factories. These analysis, measurement and control products are essential for gas leak detection in air conditioning/refrigeration and automotive manufacturing. They are vital to equipment manufacturers and end-users in the complex fabrication of semiconductors and thin film coatings for optics, flat panel displays, solar cells and industrial vacuum coating applications. Other users of our vacuum-based processes include the life sciences, research, aerospace, packaging, heat treatment, laser cutting and many other industrial processes. We also leverage our expertise in vacuum technology to provide unique, toxic chemical analysis products for emergency response, security, and environmental health and safety.



 Job Description
  Apply your mastery of state-of-the-art machine learning technologies to difficult problems on noisy high-dimensional data. Work in a multi-disciplinary team that includes experts in Physics, Computer Science, Mathematics, Chemistry, Electronics, and Semiconductor Manufacturing. Your research will have high visibility due to its high potential to increase the value of global products.



 Qualifications
  Responsibilities:

 Research and develop models for identification of chemical compounds in sensor data from instruments
 Develop experiments and software to collect and process datasets for training and testing of your models
 Qualify and quantify performance of prototypes, both in the lab and in the field

 Required background:

 3-5+ years of professional experience as a Data Scientist at the enterprise level (required)
 Masters degree in Computer Science or Applied Mathematics, with specialization in Data Science and Machine Learning. Candidates with a PhD are strongly encouraged to apply
 Fluency with Python, Linux, Scientific Computing, and Machine Learning Libraries
 Accomplished Software Developer with experience training and testing ML modules on large data sets

 Preferred background:

 Demonstrated ability with statistical ML and with neural networks
 Signal processing
 Published papers and/or code for analyzing sensor data or process control data
 Prior work with unsupervised or semi-supervised ML for anomaly detection
 Experience with pyTorch or Tensorflow
 Experience with multivariate time series analysis and modeling techniques
 Knowledge of Physics or Chemometrics or Process Control
 C++ Software Development

 Additional Information
  For New York, the expected salary range for this position is between $110,000 and $135,000 per year. In addition, INFICON employees are eligible for a profit sharing bonus with a target of 10%. The actual compensation will be determined based on experience, location, and other factors permitted by law

 INFICON provides a dynamic work environment that promotes diversity, equity, and inclusion. Our employees experience ongoing green initiatives, flexible work hours, and a variety of health and wellness programs.
 INFICON’s forward-thinking approach offers countless opportunities to design, support, and manufacture a diverse product portfolio that expands globally. Our Lean and Agile work environment offers competitive compensation, relocation assistance, a discretionary bonus, and generous employee benefits; major medical, dental, health, vision, 401K, vacation and sick time, tuition reimbursement, and more!
 INFICON is committed to ensuring that our online application process provides an equal opportunity to all job seekers that apply without regard to race, religion, ethnicity, national origin, citizenship, gender, age, protected veteran status, disability status, genetic information, sexual orientation, or any other protected characteristic. A notice describing Federal equal employment opportunity laws is available here and here to reaffirm this commitment.
 INFICON, Inc. strictly complies with all aspects of the Export Administration Regulations ('EAR'), including those sections dealing with deemed exports to foreign nationals.
",110000,"['tensorflow', 'pytorch', 'python', 'machine learning']"
Research Statistician,UC San Diego Health,CA,Full-time,"








        Payroll Title:
        RSCH DATA ANL 3 
       
        Department:
        PEDIATRICS 
       
        Hiring Pay Scale
        $68,235 - $102,000 /year 
       
        Worksite:
        La Jolla 
       
        Appointment Type:
        Career 
       
        Appointment Percent:
        100% 
       
        Union:
        Uncovered 
       
        Total Openings:
        1 
       
        Work Schedule:
        Days, 8 hour shifts, Monday - Friday 
      




#126451 Research Statistician
Filing Deadline: Thu 11/30/2023






UC San Diego values equity, diversity, and inclusion. If you are interested in being part of our team, possess the needed licensure and certifications, and feel that you have most of the qualifications and/or transferable skills for a job opening, we strongly encourage you to apply.





UCSD Layoff from Career Appointment: Apply by 11/06/2023 for consideration with preference for rehire. All layoff applicants should contact their Employment Advisor.
Special Selection Applicants: Apply by 11/16/2023. Eligible Special Selection clients should contact their Disability Counselor for assistance.

 DESCRIPTION
 Department of Pediatrics is one of the largest departments within the UCSD School of Medicine with comprehensive clinical programs, extensive basic science and clinical research, and diverse educational opportunities for students, residents, and fellows. The internationally renowned faculty play a major role in medical and graduate student training, providing educational and programmatic offerings that span several disciplines, and provide diversity to meet the interests of a broad spectrum of students and scholars. More than one hundred trainees at the graduate student and postdoctoral level, as well as more than 300 professional, research, and administrative staff who along with the department administrators interact closely with the faculty. The diverse mix of ages, backgrounds, and talents creates a robust work environment with challenging career opportunities and a commitment to continued growth potential. We constantly seek to recruit highly motivated, technologically-advanced and interested individuals to become a part of our dynamic cutting-edge research, clinical, and educational environment.
 The Research Data Analyst 3, serving as a statistician, independently consults with and assists principal investigators in the development and implementation of new major research projects, principally within the Pediatric Immunization Advancement Research Group. The incumbent will independently perform routine and advanced statistical analyses; develop complex mathematical models and custom statistical programs; research novel statistical methods and tools and apply them to data analyses; participate as a team member in grant writing, study design, data analysis, and accurate interpretation and presentation of the research results; actively engage in co-authoring scientific manuscripts; independently train investigators, trainees, and research staff in data quality control and use and implementation of statistical techniques using statistical software. Develops understanding and overview of the area of application.
 Uses skills as a seasoned, experienced research professional with a full understanding of in-depth statistical analyses and/or research software programming techniques. Demonstrates good judgment in selecting methods and techniques for obtaining solutions. 
MINIMUM QUALIFICATIONS

 Seven (7) years of related experience, education/training, OR a Bachelor's degree in related area plus three (3) years of related experience/training.
 Thorough knowledge of research function. Knowledge in science, such as biology, epidemiology, and/or clinical research. Demonstrated ability to read scientific, biomedical, or public health literature and to understand the scientific context of statistical analyses.
 Thorough skills associated with statistical analysis and systems programming. Knowledge of statistics and application of basic statistical analysis methods (examples: Chi-square tests, t-tests, regression modeling). MS in statistics or a comparable combination of education and experience preferred.
 Demonstrated scientific writing skills in an academic medical setting. Understanding of principles of scientific method (constructing and testing hypotheses), experience in developing research plans based on objectives and purposes of various studies, previous research, and restrictions inherent in the study.
 Experience programming in R or equivalent statistical software, and in scripting languages such as Markdown or Knitr. Extensive experience using statistical software (e.g., R) to analyze the data with standard and advanced statistical methods, such as, but not limited to, multivariable and multivariate modeling, longitudinal analyses, and machine learning.
 Experience in the creation and presentation of reports and graphical displays of data in various formats to both professional and lay communities.Expertise developing effective tables and figures for manuscripts and conference presentations.
 Thorough skills in analysis and consultation. Advanced skill to critically review data analyses done by trainees and guide them on correct interpretation of the results and decision-making.
 Skills in project management. Demonstrated experience contributing to study design by helping investigators to choose design scheme that maximizes chances of statistically significant findings.
 Research skills at a level to evaluate alternate solutions and develop recommendations. Advanced skill to recommend changes to deficient procedures that will improve scientific outcomes and efficiency.
 Demonstrated knowledge and understanding of statistical principles and approaches.
 Proven ability to adapt and apply statistical or data analysis techniques developed in different scientific fields or found in the statistical literature.
 Demonstrated experience writing custom statistical code to prepare data for analyses.
 Proven ability to research and learn new and developing statistical methods and tools through self-learning, seminars, and other modes of learning.

 PREFERRED QUALIFICATIONS

 Ability to provide one-on-one consultations and group training on statistical methods and their implementation in statistical software.
 Demonstrated experience co-authoring scientific manuscripts: independently writes description of statistical methodology, writes results section, researches and provides relevant references, reviews, and edits entire manuscript drafts.

 SPECIAL CONDITIONS

 Employment is subject to a criminal background check.
 Must be willing to work evenings and weekends as necessary.


 Pay Transparency Act
 Annual Full Pay Range: $63,400 - $142,800 (will be prorated if the appointment percentage is less than 100%) 
Hourly Equivalent: $30.36 - $68.39 
Factors in determining the appropriate compensation for a role include experience, skills, knowledge, abilities, education, licensure and certifications, and other business and organizational needs. The Hiring Pay Scale referenced in the job posting is the budgeted salary or hourly range that the University reasonably expects to pay for this position. The Annual Full Pay Range may be broader than what the University anticipates to pay for this position, based on internal equity, budget, and collective bargaining agreements (when applicable).









If employed by the University of California, you will be required to comply with our Policy on Vaccination Programs, which may be amended or revised from time to time. Federal, state, or local public health directives may impose additional requirements.  If applicable, life-support certifications (BLS, NRP, ACLS, etc.) must include hands-on practice and in-person skills assessment; online-only certification is not acceptable.

UC San Diego Health Sciences is comprised of our School of Medicine, Skaggs School of Pharmacy and Pharmaceutical Sciences, The Herbert Wertheim School of Public Health and Human Longevity Science, and our Student Health and Well-Being Department. We have long been at the forefront of translational - or ""bench-to-bedside"" - research, transforming patient care through discovery and innovation leading to new drugs and technologies. Translational research is carried out every day in the hundreds of clinical trials of promising new therapies offered through UC San Diego Health, and in the drive of our researchers and clinician-scientists who are committed to having a significant impact on patient care. We invite you to join our team!

Applications/Resumes are accepted for current job openings only. For full consideration on any job, applications must be received prior to the initial closing date. If a job has an extended deadline, applications/resumes will be considered during the extension period; however, a job may be filled before the extended date is reached.

To foster the best possible working and learning environment, UC San Diego strives to cultivate a rich and diverse environment, inclusive and supportive of all students, faculty, staff and visitors. For more information, please visit UC San Diego Principles of Community.
 
UC San Diego Health is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, age, protected veteran status, gender identity or sexual orientation. For the complete University of California nondiscrimination and affirmative action policy see: http://www-hr.ucsd.edu/saa/nondiscr.html 
UC San Diego is a smoke and tobacco free environment. Please visit smokefree.ucsd.edu for more information.
UC San Diego Health maintains a marijuana and drug free environment. Employees may be subject to drug screening.








",68235,['machine learning']
"Sr Director, Statistical Programming",Olema Oncology,MA,Full-time,"

Who We Are >>> Why You Should Work With Us
 Olema Oncology is a clinical-stage biopharmaceutical company focused on the discovery, development and commercialization of targeted therapies for women’s cancers. Olema’s lead product candidate, palazestrant (OP-1250), is a proprietary, orally-available small molecule with dual activity as both a complete estrogen receptor (ER) antagonist (CERAN) and a selective ER degrader (SERD). It is currently being evaluated both as a single agent in an ongoing Phase 2 clinical trial, and in combination with CDK4/6 inhibitors (palbociclib and ribociclib) and a PI3Ka inhibitor (alpelisib), in patients with recurrent, locally advanced or metastatic ER-positive (ER+), human epidermal growth factor receptor 2-negative (HER2-) breast cancer. Palazestrant has been granted FDA Fast Track designation for the treatment of ER+/HER2- metastatic breast cancer that has progressed following one or more lines of endocrine therapy with at least one line given in combination with a CDK4/6 inhibitor. Olema is headquartered in San Francisco and has operations in Cambridge, Massachusetts. For more information, please visit us at www.olema.com, or follow us on Twitter and LinkedIn.
 Onto something big, together. Olema is made up of people who are passionate beyond measure. Each and every day, we come together to do amazing things – for each other, for science, and for women with cancer.
 Our modern hybrid workplace model encourages employees to split their week between working from home and at our lab/office, while also providing several allowances to help with both home office and commute expenses.
 While at the lab/office, our teams build their camaraderie, opening the door for more authentic mentorship and career development opportunities. While at home, employees can make the most of their time – whether that’s picking up the kids from school, going on a mid-day run, or catching up on chores. Through this model, we strive to offer our employees the best of both work models.

As the Senior Director of Statistical Programming reporting to the Vice President of Biostatistics, you will be accountable for all statistical programming deliverables in adherence to company SOPs and ICH/GCP. You will also work with the Vice President, Biostatistics to create and implement Statistical Programming policies and procedures.
 This role is based out of our San Francisco, CA or Cambridge, MA office and will require 10% travel.
 Your work will primarily encompass:

Build out the statistical programming group and set up SOPs and processes for operational excellence
Collaborate with the IT team to build and maintain secure statistical computing environment and programming infrastructure
Conduct statistical programming for CSR, publications, presentations, DSUR, IB, safety data review, and ad hoc analyses
Lead the statistical programming activities for regulatory submissions following CDISC standards
Collaborate with the study statistician and study team in project planning
Review key study-related documents including but not limited to SAP, CRFs and data management plan
Author SDTM and ADAM specifications in collaboration with the study statistician
Effectively manage the CRO to ensure high-quality deliverables within timeline and budget
Validate/QC key TFLs generated by the CRO
Responsible for one or more studies with concurrent tasks and timelines
Manage one junior statistical programmer
Other duties, as assigned

Ideal Candidate Profile >>>
 A love of challenging, important work. We are a pragmatic team, driven to imagine and develop meaningful therapies for improving lives. All employees within our company play a unique and crucial role in our success, both in accomplishing our mission and building a positive company culture. As such, we are looking for someone with the right combination of knowledge, experience, and attributes for this role.
 Knowledge:

Bachelor or Master's Degree in Statistics, Life Sciences, Computer Science or related fields
Thorough understanding of clinical trial reporting process, as well as regulatory reporting requirements including electronic data submissions and CDISC implementation
Thorough knowledge of SDTM/ADaM specifications and programming
Strong SAS programming skill
Able to guide the successful completion of major programs and projects
Strong analytical and communication skills
Knowledge and experience in meeting regulatory guidelines, including both FDA and international regulatory agencies
Broad knowledge of medical/biological terminology in relevant therapeutic areas

Experience:

10+ years statistical programming experience in biotech/pharmaceutical industry
Experience in managing the Statistical Programming team
Extensive experience of leading both early and late-phase clinical studies including programming and validation of SDTM and ADaM data sets, tables, figures, and listings
Expert level SAS programmer with experience in delivering complex programming assignments, macros and analyses
Experience with oncology trials is preferred
Experience with R is a plus
Experience with BLA or NDA/sNDA to FDA/EMA is preferred. Experience with other major global health authority submission is a plus
Experience in management of CROs with respect to statistical programming
Building and maintaining strong collaboration with key stakeholders from different disciplines across the organization

Attributes:

Leadership skills in proactive strategy setting, priority evaluations, adapting to changes, conflict resolution, and effective partnership
Statistical programming expertise and experience in managing the activities of clinical trials
Strong verbal and written communication skills
Ability to effectively represent Biostatistics Programming in multidisciplinary meetings
A commitment to excellence
Self-motivated and enthusiastic; fast learner who can identify the core project challenges and expeditiously change course as required in a fast-paced organization
Have impeccable professional ethics, integrity and judgment

The base pay range for this position is expected to be $223,000 - $270,000 annually, however the base pay offered may vary depending on location, market, job related knowledge, skills and capabilities, and experience. The total compensation package for this position also includes equity, bonus, and benefits.
 #LI-MK1

Important Information >>> 
We provide equal opportunity to all employees and applicants for employment and believe that great ideas and discoveries come from a mix of expertise, background, and experience. Olema is building a culture where the value of difference is celebrated.
 We offer a competitive compensation and benefits package, seeking to provide an open, flexible, and friendly work environment to empower employees and provide them with a platform to develop their long-term careers. A Summary of Benefits is available for all applicants.
 Olema also requires all employees to be fully vaccinated against COVID-19, subject to approved medical or religious exemptions or disability accommodations. The health and safety of our employees is important to us!
 Please note: Olema doesn’t accept agency resumes and is not responsible for any fees related to unsolicited resumes. Thank you.
 Additional Note/Fraud Alert: Olema will not conduct interviews via text message or messaging platforms and will not ask you to download anything as part of your interview. Though we use third party tools to help with advertising our jobs, please be vigilant in checking that the communication is in fact coming from Olema.

",223000,['gcp']
Python Data Scientist,Synovize,Remote,Full-time,"Synovize is a leading technology company specializing in advanced data analytics and intelligence solutions. Our mission is to empower businesses with the tools and insights they need to make data-driven decisions and drive innovation. We are committed to delivering exceptional results by combining our expertise in cutting-edge technologies with our passion for creating impactful solutions.
Job Description:
As a Python Data Scientist at Synovize, you will play a crucial role in analyzing complex datasets, developing statistical models, and extracting valuable insights for our clients. You will collaborate with a talented team of data scientists, engineers, and domain experts to deliver innovative data-driven solutions. Your expertise in Python programming and data science techniques will contribute to solving challenging business problems and driving meaningful outcomes.

Job Title: Python Data Scientist
Company: Synovize
Number of Positions: Multiple
Location: Remote Length: Full-time, permanent
Salary: Competitive
Work Authorization: US Citizen or valid work permit

Skills Needed:

Strong proficiency in Python programming language.
Experience in data manipulation, cleaning, and preprocessing using Python libraries (e.g., NumPy, Pandas).
Proficiency in statistical analysis, machine learning, and predictive modeling techniques.
Familiarity with data visualization tools (e.g., Matplotlib, Seaborn) to present insights effectively.
Knowledge of deep learning frameworks (e.g., TensorFlow, PyTorch) is a plus.
Experience with SQL and database querying.
Strong problem-solving skills and ability to analyze complex datasets.
Excellent communication and storytelling skills to convey insights to non-technical stakeholders.
Strong collaboration and teamwork abilities.

Responsibilities:

Collaborate with cross-functional teams to understand business objectives and data requirements.
Perform data cleaning, transformation, and preprocessing tasks using Python libraries.
Apply statistical analysis and machine learning techniques to develop models and uncover actionable insights.
Develop and implement data-driven solutions to address complex business problems.
Create visually appealing and informative data visualizations to communicate insights.
Collaborate with data engineers to optimize data storage, retrieval, and processing.
Stay up-to-date with emerging trends and advancements in data science and machine learning.
Continuously improve data analysis methodologies and processes.

Requirements:

Bachelor's or master's degree in computer science, statistics, or a related field.
Proven experience as a Python Data Scientist or similar role, with a strong understanding of Python and data science techniques.
Strong proficiency in Python programming language.
Experience in data manipulation, cleaning, and preprocessing using Python libraries.
Proficiency in statistical analysis, machine learning, and predictive modeling techniques.
Familiarity with data visualization tools for effective presentation of insights.
Knowledge of deep learning frameworks is a plus.
Experience with SQL and database querying.
Strong problem-solving skills and ability to analyze complex datasets.
Excellent communication and storytelling skills.
Strong collaboration and teamwork abilities.

Join Synovize and be part of a dynamic team that is at the forefront of data science. Together, we will drive meaningful change and unlock the full potential of data-driven decision-making.
Job Types: Full-time, Contract
Pay: $70.00 - $120.00 per hour
Benefits:

401(k)
Dental insurance
Paid time off
Vision insurance

Schedule:

4 hour shift
8 hour shift
Choose your own hours

Application Question(s):

Are you a US citizen?

Experience:

DevOps Engineering: 1 year (Preferred)

Security clearance:

Secret (Preferred)

Work Location: Remote",140000,"['tensorflow', 'pytorch', 'python', 'numpy', 'pandas', 'machine learning', 'deep learning', 'sql']"
Data Scientist,Lendistry,CA,Full-time,"

ABOUT LENDISTRY
 Lendistry is the country’s largest minority-led and technology-enabled small business and commercial real estate lender with Community Development Financial Institution (CDFI) and Community Development Entity (CDE) certification. We are a national employer whose mission is to provide economic opportunities and progressive growth for small business owners and their underserved communities as a source of financing and financial education.


 POSITION OVERVIEW
 The Data Scientist will help shape business strategy and product development decisions through data-driven insights. This is an exciting role for someone to make a direct impact on risk, product, and revenue strategy of Lendistry. Success in this role hinges on your technical aptitude, quantitative abilities, and business acumen: you know how to plow through data with SQL/Python/R/, surface insights using math/statistics/ML techniques, and measure the business impact using efficiency/conversion/profit metrics.


 GENERAL RESPONSIBILITIES

The data scientist will support the Consumer Credit department by leveraging big data technologies to aggregate and structure data, perform statistical analysis, and build algorithmic solutions to reduce fraud and credit losses.
As a member of the credit risk team, you will research and develop new methodologies and techniques to improve the overall effectiveness of risk management.
Mine and analyze massive amount of unique internal and external data to gain deep business knowledge and insight on customer activity and usage behaviors and their relationships with fraud, credit risks, and other types of behaviors.
Acts as the technical owner of projects that may require significant customization of existing analytic tools, techniques, processes, or development of new ones.
Perform statistical data analysis and understanding, ensure data quality, and develop tracking and reporting systems to determine the effectiveness of models, rules, and other risk initiatives and programs.
Design and create systems to structure, aggregate, and turn petabytes of messy information into statistically significant features for modeling purposes.
Manage and implement new risk strategies in our Risk Systems.



 PROFICIENCIES

Excellent verbal and written communication skills.
Strong knowledge of 1 or more scripting and programming languages (Python, Java, SQL, Scala, etc.)
Background in a variety modeling techniques: GBM, logistic regression, clustering
Experience in utilizing and implementing credit strategies in decision engine systems like Provenir, GDS-Link, Zoot, etc is a plus.
Sophisticated word processing and computer database skills, especially in Microsoft Word, PowerPoint and Excel.
Ability to think creatively and innovatively.
Good interpersonal skills with the ability to work effectively with individuals and groups at all organizational levels, ability to work independently and as part of a team.



 EDUCATION AND EXPERIENCE

Bachelors degree in a quantitative field: engineering, math, statistics etc. MS/PHD preferred
3+ years of experience in business analysis, customer segmentation, and/or predictive modeling, preferably in the financial services industry
2+ years in using machine learning packages such as Python, R, SAS



 SALARY

$80,000 - $110,000/Annually, depending on location and experience.


 Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
 The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)
",80000,"['python', 'machine learning', 'sql']"
Data Scientist,Hireups,Remote,Full-time,"Data ScientistHireups Inc. – Remote
Research Scientist | Computational Protein Engineer | Remote 
Job Overview:
Research Scientist | Computational Protein Engineer - Consultant | Full-Time Possible | Flexible Schedule, C2C, 100% Remote, 1099
Intro:
As a data scientist, you will be at the forefront of developing cutting-edge technology. Be a part of the collaborative and emerging scientific evolution. Hireups Inc. works alongside top engineers to build services for our clients. Join our team of data, science, and cloud professionals. Hireups provides an alternative work environment where you will have substantial opportunities to make a tangible and positive impact across various technologies.
Protein engineering is the conception and production of unnatural polypeptides, often through modification of amino acid sequences that are found in nature. Synthetic protein structures and functions can now be designed entirely on a computer or produced through directed evolution in the laboratory.
The position calls for research scientists/computational protein engineers. The ideal candidate is responsible for writing research papers and collaborating with developers. Candidates should have a background in data science, immersed
Responsibilities:

Writing research papers on different methods of protein-folding
Working with flow cytometry(a cell-analysis technique)
Screening involving DNA sequencing
Developing computational pipelines for protein engineering utilizing PyRosetta/sequence-based approaches
Engage in detailed research and collaboration with a team of scientists/developers

Required:

Excellent programming skills and mastery of one or more programming languages, including Unix, PowerShell, or Python (PyRosetta preferred)
PhD or equivalent in molecular biology, biochemistry, bioengineering, biophysics, physics, computer science, computational biology, quantitative biology, or related field
2+ years of experience with any of the following technologies: Python, Protein Folding, Data Science
Significant hands-on technical experience with modeling software such as Rosetta, Molecular Operating Environment (MOE), and/or Schrodinger
Familiarity with machine learning algorithms applicable to model data
Must be familiar with Jupyter Notebooks, Bayesian, and/or common statistics found in other Biology related projects.

Preferred:

US Citizen with core daylight hours
The ability to design and develop a rich, comprehensive protein engineering pipeline

Strong communication skills with the ability to articulate technical details to different audiences * Hands-on experience in the compilation, assembly, and development of protein structures

Five years plus of demonstrated experience working for a company in a similar roleJoin the Team!

Hireups jobs offer flexible hours with tremendous career growth. Moonlighters are welcome. Employees are offered comprehensive and beneficial training relative to their field. Here at Hireups, we focus on the health and growth of our team members.
We are an equal opportunity employer and considers all qualified applicants equally without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, or disability status.

LGBTQ+ friendly workplace
Age-inclusive

Job Types: Part-time, Contract
Pay: $70.00 - $120.00 per hour
Benefits:

Flexible schedule

Experience:

React: 1 year (Preferred)
JavaScript: 1 year (Preferred)

Security clearance:

Secret (Preferred)

Work Location: Remote",140000,"['python', 'machine learning']"
Data Scientist,US Department of Veterans Affairs,DC,Full-time,"This position is located in the Department of Veterans Affairs (VA), Office of Enterprise Integration (OEI), Office of Data Governance and Analytics (DGA). DGA is responsible for leading data management, data analytics, and business intelligence capabilities to inform VA-wide decision making.
Major Duties:

Plans and conducts, as project member of a study team, relevant research and analytical studies of VA complex issues to support critical operational problems and/or decisions using advance state-of-the art data theories beyond established parameters.
Identifies, develops, and integrates data from internal and external sources, through various data collection procedures and technologies, including emerging data science and big data methodologies.
Performs a wide range of complex analytical, mathematical and statistical research that inform operational requirements.
Extracts relevant information from historical datasets.

For the GS-11:Specialized experience is defined as analyzing and interpreting data modeling, algorithms, and coding data requirements; Analyzing and providing information from multiple systems to prepare data reports; Conducting analysis using software and/or programming languages; Using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation.
For the GS-12:Specialized experience is defined as identifying data required for use in the management and direction of programs; Implementing algorithms, machine learning, and other AI systems; Using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation; Applying statistical analyses to determine the fitness-for-use of new or combined data sources, machine learning outputs, and data science methods.
Job Type: Full-time
Pay: $78,592.00 - $122,459.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Professional development assistance
Retirement plan
Tuition reimbursement
Vision insurance

Experience level:

3 years
4 years
5 years

Schedule:

8 hour shift

Work Location: In person",78592,['machine learning']
Data Scientist,INFICON,NY,Full-time,"
 Company Description
  INFICON is a leading provider of innovative instrumentation, critical sensor technologies, and Smart Manufacturing/Industry 4.0 software solutions that enhance productivity and quality of tools, processes, and complete factories. These analysis, measurement and control products are essential for gas leak detection in air conditioning/refrigeration and automotive manufacturing. They are vital to equipment manufacturers and end-users in the complex fabrication of semiconductors and thin film coatings for optics, flat panel displays, solar cells and industrial vacuum coating applications. Other users of our vacuum-based processes include the life sciences, research, aerospace, packaging, heat treatment, laser cutting and many other industrial processes. We also leverage our expertise in vacuum technology to provide unique, toxic chemical analysis products for emergency response, security, and environmental health and safety.



 Job Description
  Apply your mastery of state-of-the-art machine learning technologies to difficult problems on noisy high-dimensional data. Work in a multi-disciplinary team that includes experts in Physics, Computer Science, Mathematics, Chemistry, Electronics, and Semiconductor Manufacturing. Your research will have high visibility due to its high potential to increase the value of global products.



 Qualifications
  Responsibilities:

 Research and develop models for identification of chemical compounds in sensor data from instruments
 Develop experiments and software to collect and process datasets for training and testing of your models
 Qualify and quantify performance of prototypes, both in the lab and in the field

 Required background:

 3-5+ years of professional experience as a Data Scientist at the enterprise level (required)
 Masters degree in Computer Science or Applied Mathematics, with specialization in Data Science and Machine Learning. Candidates with a PhD are strongly encouraged to apply
 Fluency with Python, Linux, Scientific Computing, and Machine Learning Libraries
 Accomplished Software Developer with experience training and testing ML modules on large data sets

 Preferred background:

 Demonstrated ability with statistical ML and with neural networks
 Signal processing
 Published papers and/or code for analyzing sensor data or process control data
 Prior work with unsupervised or semi-supervised ML for anomaly detection
 Experience with pyTorch or Tensorflow
 Experience with multivariate time series analysis and modeling techniques
 Knowledge of Physics or Chemometrics or Process Control
 C++ Software Development

 Additional Information
  For New York, the expected salary range for this position is between $110,000 and $135,000 per year. In addition, INFICON employees are eligible for a profit sharing bonus with a target of 10%. The actual compensation will be determined based on experience, location, and other factors permitted by law

 INFICON provides a dynamic work environment that promotes diversity, equity, and inclusion. Our employees experience ongoing green initiatives, flexible work hours, and a variety of health and wellness programs.
 INFICON’s forward-thinking approach offers countless opportunities to design, support, and manufacture a diverse product portfolio that expands globally. Our Lean and Agile work environment offers competitive compensation, relocation assistance, a discretionary bonus, and generous employee benefits; major medical, dental, health, vision, 401K, vacation and sick time, tuition reimbursement, and more!
 INFICON is committed to ensuring that our online application process provides an equal opportunity to all job seekers that apply without regard to race, religion, ethnicity, national origin, citizenship, gender, age, protected veteran status, disability status, genetic information, sexual orientation, or any other protected characteristic. A notice describing Federal equal employment opportunity laws is available here and here to reaffirm this commitment.
 INFICON, Inc. strictly complies with all aspects of the Export Administration Regulations ('EAR'), including those sections dealing with deemed exports to foreign nationals.
",110000,"['tensorflow', 'pytorch', 'python', 'machine learning']"
Lead Data Scientist,Opinion Dynamics,Remote,Full-time,"
Opinion Dynamics is growing and is seeking a new team member to join our Data Analytics team. In this role, you will provide analytical leadership and technical innovation backed by extensive knowledge of and experience in the clean energy space. Our ideal candidate will bring a strong quantitative skillset at the cross-section of data science, statistics, and econometrics combined with the ability to effectively navigate the dynamic and collaborative environment of a consulting firm. You will have demonstrated applied experience performing advanced analytics of interval energy consumption and equipment telematics data streams in support of load impact, forecasting, and disaggregation studies of clean energy interventions, including energy efficiency, demand response, electric vehicles, and other distributed energy resources (DERs).
 As a member of the Data Analytics team, you will lead the analytic design process and oversee the effective execution of a portfolio of analytically complex and computationally intensive projects. You will work in collaboration with our in-house Data Management, Engineering, and other teams to ensure that analytical solutions are supported and enhanced by sound data management and building science practices. While your primary function on projects will be defining analytic design process and oversight of the work, this is a hands-on role, and you are someone who jumps into the details of analyses to guide staff and provide the necessary oversight and support to ensure high-quality, accurate work products. As a methodological expert in the organization, you will participate in client-facing conversations, contribute to proposals and business development efforts, and effectively translate concepts between technical and non-technical audiences.


 Required Qualifications

Advanced degree in economics, statistics, data science, quantitative social science, political science, or related field and 8+ years of relevant experience. A bachelor's degree with sufficient applied professional experience will be considered.
At least 4+ years in the clean energy space, ideally conducting advanced analyses leveraging load and other data streams in the context of research and consulting environment.
Expertise with advanced statistical approaches and evaluation and measurement practices and standards, specifically as applied to flexible load, time-varying rates, managed charging, decarbonization, energy efficiency, and grid resiliency programs and interventions.
Demonstrated experience conducting advanced statistical analyses with large volumes of interval load data.
Passionate about cultivating analytical innovation; comfortable tackling complex statistical problems through new and unexplored methods and data streams.
Passionate about mentoring and training junior staff.
Critical thinker who is curious, comfortable with complexity, a strong communicator, and has a strong consulting mindset.
Excited to serve in a hands-on role to ensure 1) the choice of rigorous and appropriate methodological solutions, 2) the successful execution of analytical tasks within agreed-upon timelines and budgets, and 3) the production of client-ready analytic outputs.
Advanced programmer in R or Python.
Skilled in data visualization and data management practices.

Additional Desired Qualifications

Knowledge of DER data streams (e.g., solar generation, battery charge/discharge, vehicle and device telematics)
Experience conducting DER valuation studies and analyses
Experience with rate design
Experience with integrated research planning studies
Skilled in big data analytics and corresponding tools and practices
Knowledge of machine learning and data science approaches and methodologies
Experience with version control software (e.g. Git) and collaborative code development



 Salary Range: $135K - 160K. Salary is negotiable depending on experience.


 ABOUT OPINION DYNAMICS
 Opinion Dynamics advances knowledge to address emerging energy and social issues through sound and insightful research. Our inter-disciplinary team of consultants develops actionable and insightful research to support an array of clients, including electric and gas utilities, regulators, and stakeholders. Our research supports planning, assessment, and optimizing energy efficiency, demand response, and renewable energy programs. Our team uses a customized approach leveraging innovative methodologies to answer our client's questions. Our company fosters innovative thought, collegiality, and growth opportunities for our employees.
 Opinion Dynamics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
 Opinion Dynamics is also committed to fostering a more diverse workforce. BIPOC, women, members of the LGBTQIA+ community, veterans, and individuals with disabilities are encouraged to apply.

",135000,"['python', 'machine learning', 'git']"
Artificial Intelligence Engineer(15+ years),Tech Matrix Software Solutions Pvt. Ltd,Remote,Full-time,"Role: Senior Artificial Intelligence Engineer
Remote
Required Exp: 15+ years
Job Description:

Develop on-premise GenAI applications, leveraging open-source or proprietary large language models (LLMs) and following responsible AI practices
Write Python code in Jupyter Notebook for data preprocessing, feature extraction, API calls, and application orchestration
Integrate GenAI application components like vector databases, API endpoints, document databases, and other endpoints for full end-to-end solution
Configure LLM libraries for use on on-premise servers
Coordinate with IT Technology Team to troubleshoot and optimize application components
Maintaining code repositories in GitHub, ensuring proper versioning and collaboration
Deploy and evaluate AI models and related infrastructure
Actively participate in Agile ceremonies and collaborate with cross-functional teams, providing regular updates to the Product Owner

Qualifications:

Degree in computer science, data science, analytics, or similar discipline
Working knowledge of Python NLP/LLM libraries, GitHub, Jupyter Notebook, vector databases, API endpoints, and containerization
Previous experience delivering AI or GenAI applications within a large financial services organization (i.e., banking or insurance)
Basic understanding of NLP models, including a key concepts like embeddings and the inner workings of LLMs
Demonstrated ability to debug and evaluate the performance of GenAI models
Strong familiarity with Agile methodologies and practices for efficient project delivery

Job Types: Full-time, Contract
Salary: $75.00 - $80.00 per hour
Experience level:

11+ years
3 years
5 years

Schedule:

8 hour shift

Application Question(s):

We need minimum 15+ years of exp for this role? do you have

Experience:

Artificial Intelligence: 10 years (Preferred)
large language models (LLMs): 5 years (Preferred)
Python: 5 years (Preferred)
GenAI application: 6 years (Preferred)
Configure LLM: 5 years (Preferred)

Work Location: Remote",150000,['python']
AI Engineering Manager,Agilon Health,Remote,Full-time,"agilon health is transforming healthcare by empowering community-based physicians with the resources and expertise they need to innovate the payment and delivery of care for seniors.
The agilon health Total Care Model is powered by our purpose-built platform and frees physicians from the constraints of the traditional fee-for-service reimbursement model, all enabled through a growing national network of like-minded physician partners.
With agilon health, physicians are able to practice team-based, coordinated care to serve the individual needs of their senior patients and to transition to a sustainable and predictable, long-term business model.
As you might imagine, analytics and insights are the heart of how we support our physician partners and is agilon’s special sauce. We have a strong team in place already and are looking for someone to help lead the AI team in solving some of the hardest problems in healthcare.
The team builds traditional predictive and learning ML models across many different business problems to drive targeted and actionable insights and is also looking to apply LLMs to solve our strategic needs, so you will gain exposure to and will be able to make an impact in a large number of domains.
You will coach the team, engage with stakeholders, and have the opportunity to make your own contributions with direct line of sight to improving patient outcomes and reducing medical waste. Come join the team and help make a meaningful impact in our senior members’ lives!
More about this role:

Lead an agile AI team in designing, training, and deploying models to support a wide range of health care use cases.
Build strong collaborations with agilon’s leadership and many different cross-functional teams, including UX, Product, Technology, Clinical, Medical Programs, Finance, and Operations.
Drive successful project execution and clinical and business value delivery.
Mentor data scientists to grow and live up to their full potential, and coach high-performing engineering teams.
Provide guidance to your team on code quality, model training, and MLOps workflows in production.

Qualifications:

Advanced degree (PhD, MS, MBA, MD) and at least five years of experience working in production environments.
Strong record of delivering value from machine learning projects.
Proven experience leading teams and collaborating with stakeholders in an agile setting.
Three years of experience with machine learning and deep learning models, ideally with hands-on experience with large language models (LLMs) or other forms of generative AI.
Fluent with Python and SQL.
Comfortable with AWS and hands-on experience with AWS managed services.
Ability to consistently achieve results, even under tough circumstances.
Excellent communicator and a nimble learner.

If you have an entrepreneurial spirit, a record of leading successful machine learning projects, and are excited about leveraging technology to have a meaningful impact on doctors and patients, we would love to hear from you.
Job Type: Full-time
Pay: $160,000.00 - $190,000.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Vision insurance

Compensation package:

Bonus opportunities
Performance bonus
RSU
Yearly pay

Experience level:

8 years

Schedule:

Monday to Friday

Work Location: Remote",160000,"['python', 'machine learning', 'deep learning', 'aws', 'sql']"
Sr Big Data and Machine Learning Engineer,eTeam Inc.,VA,Full-time,"
Title: Data Engineer

Location: ClientLean, VA (Hybrid)

Duration: 12 Months contract (possible extension)

Pay Range: $70/hr - $80/hr on C2C


Interview: 45 60 mins 1 round.


Tech Stack:

Top Skills: Python, Spark, AWS, Data pipelines, Airflow, EMR
Maintaining and building new data pipelines
5+ years exp required.


About:

This team has lot of data pipelines.
Modernization and maintaining these pipelines.
New development and some of the existing compliance work would be there.
This is for Platform, for internal fraud platform.

",140000,"['python', 'aws', 'airflow']"
Natural Language Processing (NLP) Researcher,Kitware,NC,Full-time,"

Team Description:


   Kitware is a leader in the creation of cutting-edge algorithms and software for automated image, video, text, and multimodal analysis. Our solutions embrace artificial intelligence adding measurable value to government agencies, commercial organizations, and academic institutions worldwide. We understand the difficulties in extracting, interpreting, and utilizing information across images, video, metadata, and text, and we recognize the need for robust, affordable solutions. We seek to advance artificial intelligence, computer vision, and other related fields through research and development and through collaborative projects that build on our open source software platforms, such as VIAME and Telesculptor.
 


 About the Projects:


   Natural Language Processing (NLP) and Computer Vision research is increasingly interrelated, with common computational approaches and the increasing availability of text + image/video benchmarks. Several current projects leverage recent advances in large language models (LLMs), with applications to diverse domains and use cases like information extraction, decision-making, reasoning, and disinformation mitigation. Related projects entail emphasis on knowledge extraction and representation, multimodal media asset exploitation, understanding written instructions, and more.
 


 Kitware’s employees have unique opportunities to interact and collaborate directly with customers, visit interesting customer sites, and participate in live field tests and demonstrations. Much of Kitware’s work involves applying state-of-the-art artificial intelligence approaches to dynamic, real-world problems. In this case, you will have the opportunity to contribute your skills to projects focused on national security, making a difference on a daily basis to protect our country. Research and Development Engineers at Kitware also enjoy benefits commonly associated with a position in academia, such as support and encouragement for the publication of novel work. There are also frequent opportunities to collaborate with world renowned academic partners on ongoing research projects.
 


 We partner with premier government R&D agencies such as DARPA, IARPA, AFRL, NVESD, NOAA, ONR, other branches of the US military, and multiple members of the Intelligence Community on a range of efforts including prime contracts, SBIRs, and STTRs. In addition, we provide commercial services to companies ranging from startups to Fortune 500 companies. Kitware employs an open source business model to foster extended, collaborative communities, and to provide flexible, high-quality technical solutions. If you’ve used CMake, ITK, or VTK, you know our work and the impact it has on the communities we help build.
 
In This Position You Will:

 Develop robust solutions in the areas of Natural Language Processing, Large Language Models, Foundation Models, ML, and AI.
 Develop and evaluate algorithms to understand the textual content of textual and multi-modal data, and/or perform reasoning on extracted data.
 Enjoy support and encouragement for participation in national and international NLP, machine learning, AI, and/or computer vision conferences.
 Be encouraged to seek funding to grow and develop your own research areas, if you desire.

 Required Qualifications:

 PhD in Computer Science or related field.
 Strong publication history in NLP (ACL, EMNLP, NAACL) conferences, or other AI venues incorporating NLP (AAAI, ICML, ICLR, NeurIPS).
 Experience with natural language text generation, foundation models, large language models (LLMs), using one or more of GPT, Claude, BERT, or similar.
 Highly innovative and demonstrated track record for solving difficult technical challenges.
 Experience collaborating successfully with others and thriving in a fast-paced and dynamic work environment.
 Candidates should include a detailed list of publications as part of their resume/CV.

 Preferred Qualifications:

 Experience with multiple large multimodal AI models including image, text, and speech modalities.
 Past work on adapting NLP and LLMs to different domains and applications, including decision-making, reasoning, and inference. 


Company Description:


   Kitware is a research and development software solutions provider with a mission to advance science, make a positive impact, and share our results all within a collaborative, employee-focused work environment that is friendly, fair, and flexible. Our work is improving healthcare outcomes, increasing national security, and advancing our national computing infrastructure. Our customers and collaborators include top universities from around the world, government organizations, national research labs, medical device manufacturers, car manufacturers, financial institutions, and many others.
 


 Kitware is proud to be 100% employee-owned, and Great Place to Work-Certified™.
 


 Additional Information:


   Our team members enjoy a small company environment, flexibility in work assignments, and high levels of independence and responsibility. Besides a great work environment, our comprehensive benefits package includes a competitive compensation plan, tuition reimbursement program, flexible working hours, six weeks paid time off, 401(k), health insurance, life insurance, short- and long-term disability insurance, bonus plan, and free coffee, drinks, and snacks.
 


 For more information on our benefit offerings please visit: https://www.kitware.com/careers/.
 


 Kitware actively subscribes to a policy of equal employment opportunity. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, age, protected veteran status, uniformed service member status, or any other characteristics protected by applicable law.
 


 Any unsolicited resume sent to Kitware, including to Kitware's mailing addresses, fax machines or email addresses, whether directly to Kitware employees or to Kitware's applicant tracking system, will be considered Kitware property. Kitware will not pay a fee for any placement resulting from the receipt of an unsolicited resume, and will consider any candidate submitted by a recruitment agency without a fully executed contract with Kitware to have been referred free of any charges or fees.
 


 If you need assistance with applying or interviewing for a role due to a disability or special need, please reach out directly to our HR team at hr@kitware.com at any time during the hiring process.
 
",125000,['machine learning']
Principal Machine Learning Engineer - Motion Planning,Motional,Remote,Full-time,"
The Machine Learning Motion Planning team specializes in the fusion of Machine Learning and Classical Methods, researches and develops new heuristic and deep learning approaches, and builds deep neural networks, algorithms, and software to make an impact across navigation, behavior, route planning, as well as trajectory optimization, numerical optimization, and model predictive control. The team owns the full development cycle of ML Planner, from ideation, experimentation, validation, simulation, in-vehicle testing, and final deployment into production.


 Motional's Machine Learning team has produced groundbreaking advancements in the autonomous vehicle industry, including nuScenes (https://www.nuscenes.org), PointPillars (https://arxiv.org/abs/1812.05784), and PointPainting (http://arxiv.org/abs/1911.10150)


 What You'll Do:

Lead the effort of cutting-edge motion planning systems with Machine Learning and optimization-based methods.
Lead and develop a variety of algorithms for planning for autonomous driving, including but not limited to search-based methods, sampling-based methods, optimization-based methods, linear-temporal logic, and decision-making under uncertainty.
Lead and develop core deep learning algorithms for efficient training and testing pipelines.
Use your top-notch software development expertise to inspire others to develop better software practices and principles.
Design and build a robust and scalable codebase that enables rapid exploration and evaluation of different motion planning approaches and algorithms.
Interface with perception and prediction components upstream and trajectory optimization and tracking & control components downstream
Refine and improve the data-driven model according to the performance of AV in real-world complex environment
Deploy solutions directly to an autonomous vehicle and analyze their impact
Provide a vision for the team and our system—guide and mentor junior team members to develop a culture of product-focused engineering, research, and development.



 What You'll Bring:

Bachelor's, Masters, or PhD degree preferred in Machine Learning, Robotics, Computer Science, Computer Engineering, Mechanical Engineering, Applied Mathematics, Statistics, or a related field
7+ years of software development experience
5+ years of C++ software development experience preferred
Experience designing, training, analyzing, and deploying neural networks with PyTorch or other deep learning frameworks
Experience owning and leading technical development on features from problem formulation through implementation and deployment
Thirst for knowledge and continuous innovation



 The salary range for this role is an estimate based on a wide range of compensation factors including but not limited to specific skills, experience and expertise, role location, certifications, licenses, and business needs. The estimated compensation range listed in this job posting reflects base salary only. This role may include additional forms of compensation such as a bonus or company equity. The recruiter assigned to this role can share more information about the specific compensation and benefit details associated with this role during the hiring process.
 Candidates for certain positions are eligible to participate in Motional's benefits program. Motional's benefits include but are not limited to medical, dental, vision, 401k with a company match, health saving accounts, life insurance, pet insurance, and more.

 Salary Range

    $199,000—$266,500 USD
  


 Motional is a driverless technology company making autonomous vehicles a safe, reliable, and accessible reality. We're driven by something more.
 Our journey is always people first.
 We aren't just developing driverless cars; we're creating safer roadways, more equitable transportation options, and making our communities better places to live, work, and connect. Our team is made up of engineers, researchers, innovators, dreamers and doers, who are creating a technology with the potential to transform the way we move.
 Higher purpose, greater impact.
 We're creating first-of-its-kind technology that will transform transportation. To do so successfully, we must design for everyone in our cities and on our roads. We believe in building a great place to work through a progressive, global culture that is diverse, inclusive, and ensures people feel valued at every level of the organization. Diversity helps us to see the world differently; it's not only good for our business, it's the right thing to do.
 Scale up, not starting up.
 Our team is behind some of the industry's largest leaps forward, including the first fully-autonomous cross-country drive in the U.S, the launch of the world's first robotaxi pilot, and operation of the world's longest-standing public robotaxi fleet. We're driven to scale; we're moving towards commercialization of our technology, and we need team members who are ready to embrace change and challenges.
 Formed as a joint venture between Hyundai Motor Group and Aptiv, Motional is fundamentally changing how people move through their lives. Headquartered in Boston, Motional has operations in the U.S and Asia. For more information, visit www.Motional.com and follow us on Twitter, LinkedIn, Facebook, Instagram and YouTube.


 Motional AD Inc. is an EOE. We celebrate diversity and are committed to creating an inclusive environment for all employees. To comply with Federal Law, we participate in E-Verify. All newly-hired employees are queried through this electronic system established by the DHS and the SSA to verify their identity and employment eligibility.

",199000,"['pytorch', 'machine learning', 'deep learning']"
"Sr. Director, Statistical Programming",Olema Oncology,CA,Full-time,"

Who We Are >>> Why You Should Work With Us
 Olema Oncology is a clinical-stage biopharmaceutical company focused on the discovery, development and commercialization of targeted therapies for women's cancers. Olema's lead product candidate, palazestrant (OP-1250), is a proprietary, orally-available small molecule with dual activity as both a complete estrogen receptor (ER) antagonist (CERAN) and a selective ER degrader (SERD). It is currently being evaluated both as a single agent in an ongoing Phase 2 clinical trial, and in combination with CDK4/6 inhibitors (palbociclib and ribociclib) and a PI3Ka inhibitor (alpelisib), in patients with recurrent, locally advanced or metastatic ER-positive (ER+), human epidermal growth factor receptor 2-negative (HER2-) breast cancer. Palazestrant has been granted FDA Fast Track designation for the treatment of ER+/HER2- metastatic breast cancer that has progressed following one or more lines of endocrine therapy with at least one line given in combination with a CDK4/6 inhibitor. Olema is headquartered in San Francisco and has operations in Cambridge, Massachusetts. For more information, please visit us at www.olema.com, or follow us on Twitter and LinkedIn.
 Onto something big, together. Olema is made up of people who are passionate beyond measure. Each and every day, we come together to do amazing things – for each other, for science, and for women with cancer.
 Our modern hybrid workplace model encourages employees to split their week between working from home and at our lab/office, while also providing several allowances to help with both home office and commute expenses.
 While at the lab/office, our teams build their camaraderie, opening the door for more authentic mentorship and career development opportunities. While at home, employees can make the most of their time – whether that's picking up the kids from school, going on a mid-day run, or catching up on chores. Through this model, we strive to offer our employees the best of both work models.

 As the Senior Director of Statistical Programming reporting to the Vice President of Biostatistics, you will be accountable for all statistical programming deliverables in adherence to company SOPs and ICH/GCP. You will also work with the Vice President, Biostatistics to create and implement Statistical Programming policies and procedures.
 This role is based out of our San Francisco, CA or Cambridge, MA office and will require 10% travel.
 Your work will primarily encompass:

Build out the statistical programming group and set up SOPs and processes for operational excellence
Collaborate with the IT team to build and maintain secure statistical computing environment and programming infrastructure
Conduct statistical programming for CSR, publications, presentations, DSUR, IB, safety data review, and ad hoc analyses
Lead the statistical programming activities for regulatory submissions following CDISC standards
Collaborate with the study statistician and study team in project planning
Review key study-related documents including but not limited to SAP, CRFs and data management plan
Author SDTM and ADAM specifications in collaboration with the study statistician
Effectively manage the CRO to ensure high-quality deliverables within timeline and budget
Validate/QC key TFLs generated by the CRO
Responsible for one or more studies with concurrent tasks and timelines
Manage one junior statistical programmer
Other duties, as assigned

Ideal Candidate Profile >>>
 A love of challenging, important work. We are a pragmatic team, driven to imagine and develop meaningful therapies for improving lives. All employees within our company play a unique and crucial role in our success, both in accomplishing our mission and building a positive company culture. As such, we are looking for someone with the right combination of knowledge, experience, and attributes for this role.
 Knowledge:

Bachelor or Master's Degree in Statistics, Life Sciences, Computer Science or related fields
Thorough understanding of clinical trial reporting process, as well as regulatory reporting requirements including electronic data submissions and CDISC implementation
Thorough knowledge of SDTM/ADaM specifications and programming
Strong SAS programming skill
Able to guide the successful completion of major programs and projects
Strong analytical and communication skills
Knowledge and experience in meeting regulatory guidelines, including both FDA and international regulatory agencies
Broad knowledge of medical/biological terminology in relevant therapeutic areas

Experience:

10+ years statistical programming experience in biotech/pharmaceutical industry
Experience in managing the Statistical Programming team
Extensive experience of leading both early and late-phase clinical studies including programming and validation of SDTM and ADaM data sets, tables, figures, and listings
Expert level SAS programmer with experience in delivering complex programming assignments, macros and analyses
Experience with oncology trials is preferred
Experience with R is a plus
Experience with BLA or NDA/sNDA to FDA/EMA is preferred. Experience with other major global health authority submission is a plus
Experience in management of CROs with respect to statistical programming
Building and maintaining strong collaboration with key stakeholders from different disciplines across the organization

Attributes:

Leadership skills in proactive strategy setting, priority evaluations, adapting to changes, conflict resolution, and effective partnership
Statistical programming expertise and experience in managing the activities of clinical trials
Strong verbal and written communication skills
Ability to effectively represent Biostatistics Programming in multidisciplinary meetings
A commitment to excellence
Self-motivated and enthusiastic; fast learner who can identify the core project challenges and expeditiously change course as required in a fast-paced organization
Have impeccable professional ethics, integrity and judgment

The base pay range for this position is expected to be $223,000 - $270,000 annually, however the base pay offered may vary depending on location, market, job related knowledge, skills and capabilities, and experience. The total compensation package for this position also includes equity, bonus, and benefits.
 #LI-MK1

 Important Information >>> 
We provide equal opportunity to all employees and applicants for employment and believe that great ideas and discoveries come from a mix of expertise, background, and experience. Olema is building a culture where the value of difference is celebrated.
 We offer a competitive compensation and benefits package, seeking to provide an open, flexible, and friendly work environment to empower employees and provide them with a platform to develop their long-term careers. A Summary of Benefits is available for all applicants.
 Olema also requires all employees to be fully vaccinated against COVID-19, subject to approved medical or religious exemptions or disability accommodations. The health and safety of our employees is important to us!
 Please note: Olema doesn't accept agency resumes and is not responsible for any fees related to unsolicited resumes. Thank you.
 Additional Note/Fraud Alert: Olema will not conduct interviews via text message or messaging platforms and will not ask you to download anything as part of your interview. Though we use third party tools to help with advertising our jobs, please be vigilant in checking that the communication is in fact coming from Olema.

",223000,['gcp']
Senior Spatial Data Scientist (Active TS/SCI required),"Xcellent Technology Solutions, Inc.",VA,Full-time,"Are you a highly driven Data Scientist looking to lead and take your expertise deeper into Machine Learning and Artificial Intelligence?
This is your perfect opportunity to advance your data-driven ability further into the leading edge of Artificial Intelligence (AI)! In a data-driven world and AI being at the forefront, the need of utilizing and interpreting data—big or small is more crucial than ever. You will be looked upon to your expertise in processing, analyzing, cleansing, transforming, and modeling geospatial imagery data to help make discoveries to ultimately empower the National Geospatial-Intelligence Agency (NGA) in making AI-driven solutions. As the Senior Data Scientist, you will be the driving force behind NGA’s AI-powered initiatives, leading your team in transforming data into actionable insights and predictive models. Join XTS today as we continue to leverage the power of data to drive success and bring modern geospatial analysis solutions to support the Intelligence Community!
Requirements

Current active Top Secret/SCI clearance with the willingness to take a polygraph exam
Bachelor’s Degree in Data Science, Statistics, Mathematics, Computer Science, Geographic Information Science or similar + 6 years of experience OR 10 + years of relevant experience
Demonstrated experience with data collection, data cleaning and processing, data visualization, statistical analysis, data interpretation, etc. in order to extract valuable insights, make informed decisions, and drive organizations success.
Programming language experience in order to create machine-learning models and deal with large datasets. (i.e., Python, R, SQL, Java, JavaScript, C++, etc.)
Knowledge and or experience with Text mining and machine learning techniques to extract and structure text data information for analysis

Desired Skills

Experience with Spatial Data Geometry Storage to perform spatial queries, manipulate and visualize geospatial data, and apply specialize algorithms for geospatial analysis
Experience with distributed data and computing tools to handle large-scale data processing efficiently, and visualization tools to facilitate data exploration, communication, and the presentation of insights (i.e., ArcGIS, SPSS, SAS, MATLAB, Tableau, etc.)
Experience manipulating data in PostgreSQL, ORACLE, SQL, or ACCESS database management system to ensure correct format, quality, and structure for analysis, modeling and producing valuable insights

If you are a driven Data Scientist looking to contribute and advance your data analysis skills in assisting the NGA push the boundaries of AI and ML in geospatial analysis, please send your resume directly to Lanchi Lai, (Lanchi.Lai@xts-inc.com).
XTS is a veteran-owned company that is highly employee focused. Offering exceptional tailored health care to fit employee’s lifestyle and needs--dental, vision, PTO, and 401K with employer matching. Our continuation of fostering training and pathway towards career advancement to excel and meet your vision and goals. XTS continues to make a difference in our employee developments and providing the Intelligence Community with elite work forces to accomplish real world missions.
Job Type: Full-time
Pay: $120,000.00 - $135,000.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Flexible spending account
Health insurance
Health savings account
Paid time off
Vision insurance

Schedule:

8 hour shift
Monday to Friday

Ability to commute/relocate:

Springfield, VA: Reliably commute or planning to relocate before starting work (Preferred)

Application Question(s):

Do you have a current active Top Secret/SCI clearance?
Are you willing to take a polygraph exam?
Do you have a Bachelor’s Degree in Data Science, Statistics, Mathematics, Computer Science, Geographic Information Science or similar + 6 years of experience OR 10 + years of relevant experience?
Do you have programming language experience in Python, R, SQL, Java, JavaScript, or C++?
Do you have knowledge or experience with Text mining and machine learning techniques?
Do you have experience with spatial data geometry storage?
What is your desired salary?

Work Location: In person",120000,"['python', 'machine learning', 'tableau', 'postgresql', 'sql']"
Critical Infrastructure and Data Analytics Scientist (Scientist 3),Los Alamos National Laboratory,NM,Full-time,"
What You Will Do

 The Information Sciences and Modeling group (A-1) is looking for an outstanding scientist in the field of risk modeling, optimization, and machine learning, with additional expertise in data signal processing and telecommunications network and protocols.
 
 As a Scientist 3 in this role, you will have the opportunity to work on projects that address emerging and challenging problems in critical infrastructure, specifically focusing on the telecommunication system, electric power, and water distribution, simulation, and risk modeling and analysis. The work will involve working closely with a team of researchers, contributing to collaborative projects, and actively publishing research in peer-reviewed journals. Presenting research findings at conferences and workshops will also be an important part of the role.
 

What You Need

 The required expertise for this position encompasses a broad range of fields, including statistics, stochastic methods, machine learning, control theory, dynamical systems, discrete and continuous optimization, statistical physics, and graphical modeling.This diverse skill set highlights the interdisciplinary nature of the work and the need for collaboration with experts from different disciplines. This position will serve as a mentor and leader to lower level team members.
 

Minimum Job Requirements:


 Experience in predictive modeling and risk modeling.
 Scientific/numerical programming experience in Julia, C, C++, Python, R, MATLAB, or Java
 Publication record in one or more of the following areas: machine learning, mathematical programming, industrial engineering, control theory, computational science, telecommunication, or applied mathematics
 Demonstrated ability to work effectively in a collaborative and multi-disciplinary scientific environment.
 Demonstrated excellent written skills.
 Ability to build from existing institutional technical capabilities and contribute to the development of new capabilities.

 Education:
 
 Master's degree in a STEM field (electrical engineering, computer science, computer engineering, applied mathematics, operations research, applied mathematics, or a related field) from an accredited college or university and 6 years of relevant experience or an equivalent combination of education and experience directly related to the occupation. A Ph.D. in a STEM field is preferred.
 

Desired Qualifications:


 Experience in solving practical science and engineering problems, especially in the context of infrastructure networks
 Experience in the telecommunication industry and with telecommunication infrastructure.""
 Background in applied mathematics disciplines such as optimization, control theory, and machine learning
 Experience with parallel computation, containerization, and cloud computing and/or HPC environments
 Mathematical programming experience with AMPL, GAMS, JuMP.
 Experience with commercial and open-source solvers (Mosek, Gurobi, IPOPT, etc.)
 Experience with relational databases, SQL, time series/column-oriented databases.
 Experience in digital signal processing, statistical modeling, and stochastic processes.
 Ability to obtain DOE Q and SCI clearances, which typically requires U.S. Citizenship

 Work Location: The work location for this position is onsite and located in Los Alamos, NM. All work locations are at the discretion of management.
 

Note to Applicants:

 For further questions, please contact Paolo Patelli at paolopatelli@lanl.gov. To apply, please use the ""apply now"" button below. Include the candidate's CV with 3 references listed.
 
Where You Will Work

 Located in northern New Mexico, Los Alamos National Laboratory (LANL) is a multidisciplinary research institution engaged in strategic science on behalf of national security. LANL enhances national security by ensuring the safety and reliability of the U.S. nuclear stockpile, developing technologies to reduce threats from weapons of mass destruction, and solving problems related to energy, environment, infrastructure, health, and global security concerns. Los Alamos provides access to activities like hiking, mountain biking, skiing, rock climbing, and camping and a local public school system that is consistently ranked amongst the best in the nation every year. Our generous benefits package includes:
 

 PPO or High Deductible medical insurance with the same large nationwide network
 Dental and vision insurance
 Free basic life and disability insurance
 Paid childbirth and parental leave
 Award-winning 401(k) (6% matching plus 3.5% annually)
 Learning opportunities and tuition assistance
 Flexible schedules and time off (paid sick, vacation, and holidays)
 Onsite gyms and wellness programs
 Extensive relocation packages (outside a 50 mile radius)

 Additional Details


Directive 206.2 - Employment with Triad requires a favorable decision by NNSA indicating employee is suitable under NNSA Supplemental Directive 206.2. Please note that this requirement applies only to citizens of the United States. Foreign nationals are subject to a similar requirement under DOE Order 142.3A.
 

Clearance: Q /SCI (Position will be cleared to this level). Selected applicants will be subject to a background investigation conducted by or on behalf of the Federal Government, and must meet eligibility requirements* for access to classified matter. This position requires a Q clearance. and obtaining such clearance requires US Citizenship except in extremely rare circumstances. Dependent upon the position, additional authorization to access classified information may be required, which may or may not be available to dual citizens. Receipt of a Q clearance and additional access authorization ultimately is a decision of the Federal Government and not of Triad.
 


Eligibility requirements: To obtain a clearance, an individual must be at least 18 years of age; U.S. citizenship is required except in very limited circumstances. See DOE Order 472.2 for additional information.

 New-Employment Drug Test: The Laboratory requires successful applicants to complete a new-employment drug test and maintains a substance abuse policy that includes random drug testing. Although New Mexico and other states have legalized the use of marijuana, use and possession of marijuana remain illegal under federal law. A positive drug test for marijuana will result in termination of employment, even if the use was pre-offer.
 
 Term position: Regular-status Laboratory employees applying for term-status positions may retain regular status with approval of the cognizant Principle Associate Director.
 
 Internal Applicants: Regular appointment employees who have served the required period of continuous service in their current position are eligible to apply for posted jobs throughout the Laboratory. If an employee has not served the required period of continuous service, they may only apply for Laboratory jobs with the documented approval of their Division Leader. Please refer to Policy Policy P701 for applicant eligibility requirements.
 
 Equal Opportunity: Los Alamos National Laboratory is an equal opportunity employer and supports a diverse and inclusive workforce. All employment practices are based on qualification and merit, without regard to race, color, national origin, ancestry, religion, age, sex, gender identity, sexual orientation or preference, marital status or spousal affiliation, physical or mental disability, medical conditions, pregnancy, status as a protected veteran, genetic information, or citizenship within the limits imposed by federal laws and regulations. The Laboratory is also committed to making our workplace accessible to individuals with disabilities and will provide reasonable accommodations, upon request, for individuals to participate in the application and hiring process. To request such an accommodation, please send an email to applyhelp@lanl.gov or call 1-505-665-4444 option 1.
",119200,"['python', 'machine learning', 'sql']"
Lead Data Scientist - Remote,Symetra Financial,Remote,Full-time,"
Symetra has an exciting opportunity to join our team as a Lead Data Scientist!
 About the role
 As the Lead Data Scientist you will be tasked with solving end-to-end data problems and performs exploratory data analysis to understand relationships and opportunities to influence outcomes. You'll identify business needs and translate them into concrete Data Science outcomes, find relevant sources of data, conduct analysis, modeling, and deliver results to the business. The lead data scientist collaborates across various teams, are intensely curious about data, and champion standard processes across teams.
 What you will do

Translate product and strategy questions into quantifiable metrics.
Apply expertise to capture, query, cleanse/validate, explore, visualize, and model data.
 Take ownership of and supports a broad range of data-driven projects and makes recommendations for future opportunities.
Commit to attaining industry, product, and technical knowledge and self-development.
Partner with collaborators & analytics engineering teams on building out analytics solutions.
Communicate and carries out Data Science standard processes and develops multi-functional partnership.
Mentor junior Data Science team members and promotes analytics and experimentation



 Why work at Symetra
 Here’s what some of our employees have to say about why they work at Symetra:


 “Symetra is a great place if you are looking for the opportunity to contribute, to grow, to be seen and valued.” Vernell K. – Auditor


 “We're big enough to make an impact on the country, but small enough to care and know who you are and what you're contributing to the organization. All new ideas are welcome!” Stephanie F. – VP Customer Service & Operations
 What we offer
 We don’t take a “one-size-fits-all” approach when it comes to our employees. Our programs are crafted to make your life better both at work and at home.

Flexible full-time or hybrid telecommuting arrangements
Plan for your future with our 401(k) plan and take advantage of immediate vesting and company matching up to 6%
Paid time away including vacation and sick time, flex days and ten paid holidays
Give back to your community and double your impact through our company matching
Want more details? Check out our Symetra Benefits Overview

Compensation
 Salary Range: $107,200 - $178,700 plus eligibility for annual bonus program.
 Your experience and skills

Experienced knowledge of SQL and Python or R, or other relevant programming experience.
Understanding of common machine-learning methods as well as full data science project cycle from data and business understanding through data preparation, modeling, validation and deployment.
 Experience using business intelligence and data visualization tools (e.g. Power BI, Tableau) and databases (e.g. Snowflake).
Analytical mind and discernment.
Strong math skills (e.g. statistics, algebra).
Problem-solving proficiency.
 Superb communication and presentation skills

We empower inclusion
 At Symetra, we aspire to be the most inclusive insurance company in the country. We’re building a place where every employee feels valued, respected, and has opportunities to contribute. Inclusion is about recognizing our assumptions, considering multiple perspectives, and removing barriers.
 We accept and celebrate diverse experiences, identities, and perspectives, because lifting each other up fuels thought and builds a stronger, more innovative company. We invite you to learn more about our efforts here.


 Creating a world where more people have access to financial freedom
 Symetra is a national financial services company dedicated to helping people achieve their financial goals and feel confident about the future. In our daily work, we’re guided by the principles of Value, Transparency and Sustainability. This means we provide products and services people need at a competitive price, we communicate clearly and openly so people understand what they’re buying, and we design products—and operate our company—to stand the test of time. We’re committed to showing up for our communities, lifting up our employees, and standing up for diversity, equity and inclusion (DEI). Join our team and help us create a world where more people have access to financial freedom.
 For more information about our careers visit: Symetra.com/Careers


 Work Authorization
 Employer work visa sponsorship and support are not provided for this role. Applicants must be currently authorized to work in the United States at hire and must maintain authorization to work in the United States throughout their employment with our company.


 #LI-ML1
 #REMOTE
",107200,"['python', 'tableau', 'sql']"
Postdoctoral Scientist - Tatonetti Lab - Data-Driven Precision Pharmacology,CEDARS-SINAI,CA,Full-time,"
Join us as we translate today's discoveries into tomorrow's medicine!
The Postdoctoral Scientist in the Tatonetti Lab at Cedars-Sinai will create and lead research to improve drug safety by leveraging clinical and molecular data. In the Tatonetti Lab we use advanced data science methods, including artificial intelligence and machine learning, to investigate drug safety, drug-drug interactions, and cancer pharmacology. Using emerging resources, such as electronic health records (EHR) and genomics databases, we are working to advance the science of pharmacology with a focus on serving traditionally underrepresented populations.
To learn more, visit TLab – Data-Driven Drug Safety (tatonettilab.org).
Are you ready to be a part of breakthrough research?
Working independently but in close cooperation and in consultation with the Dr. Tatonetti and other Research Scientists, the Postdoctoral Scientist will perform routine and complex laboratory procedures throughout training period. May develop, adapt, and implement new research techniques and protocols. Analyzes and interprets data. May assist in preparation of grant proposals. Participates in publications and presentations as author or co-author. Not responsible for generating grant funds.
Primary Duties and Responsibilities:

May assist in the preparation of grant proposals, but is not responsible for generating grant funds.
May participate in publications and presentations as author or co-author.
Designs and performs experiments. Will keep appropriate experimental records and documentation and analyze the results with the PI.
Analyzes, interprets, summarizes, and compiles data.
Operates and maintains equipment and instruments.
May observe MD-patient or MD-human research subject interactions as it pertains directly to the research being performed.


Education:

Doctorate (MD, PhD, VMD, or DDS) in area directly related to field of research specialization. 

Experience and Skills:

Acquires thorough technical and theoretical knowledge of research project and objectives during one to five (1-5) year post-doctoral appointment.
Works independently on research projects designed by a mentor (typically the PI) within the area of specialization.
Demonstrated aptitude to perform experimental protocols and procedures, including detailed data collection, and analysis, operation and maintenance of specialized equipment.
Excellent written and oral communication skills are essential.
Knowledge of safety standards.


Working Title: Postdoctoral Scientist - Tatonetti Lab - Data-Driven Precision Pharmacology
 
Department: Computational BioMedicine
 
Business Entity: Cedars-Sinai Medical Center
 
Job Category: Academic/Research
 
Job Specialty: Postdoctoral
 
Position Type: Full-time
 
Shift Length: 8 hour shift
 
Shift Type: Day
 
Base Pay:$64,500.00 - $93,600.00
",64500,['machine learning']
Senior Data Analyst,General Dynamics Information Technology,Remote,Full-time,"Clearance Level None Category Data Analysis Location Remote, Working from the USA 


Public Trust: None 
Requisition Type: Regular 
Your Impact 
Own your opportunity to work alongside federal civilian agencies. Make an impact by providing services that help the government ensure the well being of U.S. citizens.
 Job Description

 GDIT is seeking an experienced Senior Data Analyst to work in a dynamic agile team environment. The Data Analyst will be part of a technically diverse Support team supporting Centers for Medicare and Medicaid Services (CMS) via the Integrated Data Repository Support (IDRS) contract. The Integrated Data Repository (IDR) is a high-volume data warehouse integrating Medicare Parts A, B, C, D, and DME claims, Medicaid claims, beneficiary and provider data sources, along with ancillary data such as contract information, risk scores, and many others. Access to this robust integrated data supports a variety of strategic analytics across CMS.

 It’s this team’s vision/goal to support these analytics at CMS through:

 Continuous and improved information sharing with CMS Stakeholders and IDR users
 Simplified User Onboarding and system access processes
 Enhancing data quality and integration with other systems
 Strengthening query and analytic capabilities through constant and iterative enhancements
 Proactive evaluation and testing of tools/services to better support Analytical use cases


 This role is fully remote! 

**Please note: must have experience with Medicare and/or Medicaid data to be considered**

 Responsibilities:

 As a member of the Support team (an Agile Kanban team) the Senior Data Analyst will be responsible for:

 Triaging/investigating user reported issues
 Assisting users with data analysis at varying levels of complexity/use cases
 Addressing data questions and/or data discrepancies
 Debugging user queries and proactively identifying areas for improvements/enhancements
 Collaborating with other business subject matter and technical experts to resolve user questions/issues
 Identifying process improvements and opportunities for automation

 WHAT YOU’LL NEED TO SUCCEED

 Required Skills and Experience:

 Bachelors and 5+ years of experience
 Proficiency with utilizing Medicare and/or Medicaid data to perform analysis required
 Proficiency using Atlassian tools (Confluence, Jira) for task tracking and project documentation
 Familiarity with healthcare claims processes and data
 Extensive SQL experience
 Fundamental Architectural Knowledge of Snowflake


 Preferred Skills and Experience:

 Comfortable developing how-to and other user facing documentation to support the system user base
 Willingness to explore new tools, analyze new data, and in general want to continue expanding skill sets
 Supporting User Training initiatives through content suggestions (based on user support) and/or content development

 GDIT IS YOUR PLACE:

 Full-flex work week to own your priorities at work and at home
 401K with company match
 Comprehensive health and wellness packages
 Internal mobility team dedicated to helping you own your career
 Professional growth opportunities including paid education and certifications
 Cutting-edge technology you can learn from
 Rest and recharge with paid vacation and holidays


 #GDITHealth

",76000,['sql']
"Senior, Data Scientist, People.AI",Walmart,AR,Full-time,"
Position Summary...


What you'll do...

 Walmart employees more than 2.3 million employees worldwide, with 1.6 million associates in the U.S. Walmart hires 500,000 applicants a year to fill thousands of job profiles from engineers, designers, marketers to pilots and buyers and promotes more than 300,000 people to jobs of greater responsibility. People.AI team is responsible for developing and deploying AI/ML solutions supporting the Global People function.
 
 In this role, you will be building an LLM-powered chatbot for improving employee experience and productivity. You'll be responsible for designing and building an intelligent conversational interface that enhances communication, automates tasks, accesses data and insights, and provides personalized Q&A support to employees, ultimately creating a more efficient and engaging work environment.
 

About Team: 

 The Enterprise People Technology team supports the successful deployment and adoption of new People technology across the enterprise. As a Fortune #1 company, our work impacts millions of associates globally. We strive to continuously improve people technology and products to help managers and associates so they can focus on what matters most - supporting our customers and members. People Technology is one of the major segments of Walmart Global Tech's Enterprise Business Services, which is invested in building a compact, robust organization that includes service operations and technology solutions for Finance, People, and the Associate Digital Experience.
 

What you'll do: 



Work in a highly collaborative environment with a multidisciplinary team.
 Work with lead data scientists to design, architect, and build AI/ML model and model systems.
 Work with machine learning engineers to deploy, operate , and optimize scalable solutions
 Work with product managers to design user journeys, feedback loop and analyze user telemetry.
 Create opportunities to develop yourself with an end-to-end AI/ML product experience.
 Work with a set of robust work standards to ensure we build trustworthy AI/ML solutions


 What you'll bring: 



Ability to execute our trustworthy AI/ML practice in collaboration with stakeholders across the enterprise.
 Ability to effectively coach junior data scientists to work through technical issues and business understandings.
 Ability to communicate internally and externally through publication, presentations, and other mediums on research progress, major breakthroughs, and product innovation.
 Experience with statistical analysis and programming languages e.g. Python and mainstream machine learning frameworks, e.g. TensorFlow or PyTorch .



 Experience in building machine learning applications


 About Walmart Global Tech 

 Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.
 
 Flexible, hybrid work:
 
 We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.
 

Benefits: 

 Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.
 

Equal Opportunity Employer: 

 Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.
 
 The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.
 
 At Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
 
 You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .
 
 Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
 
 Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .
 
 The annual salary range for this position is $90,000.00-$180,000.00
 
 Additional compensation includes annual or quarterly performance incentives.
 
 Additional compensation for certain positions may also include:
 


Regional Pay Zone (RPZ) (based on location)



Stock equity incentives


 Minimum Qualifications... 

 Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.
 
 Option 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.
 

Preferred Qualifications... 

 Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.
 
 Data science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)
 

Primary Location... 
 PHYLLIS ST. N OF HWY 102, WEST SIDE OF STREET, BENTONVILLE, AR 72712, United States of America
",90000,"['tensorflow', 'pytorch', 'python', 'machine learning']"
Experienced Data Scientist,Principal Financial Group,IA,Full-time,"
 What You'll Do: 
 
   We’re looking for a Data Scientist III and a Senior Data Scientist 1 to join our Benefits and Protection Data and Analytics team. In these roles, you will work on machine learning models to drive business value while being a technical mentor to team members.
 

 Be responsible for complex data science projects that capture and integrate large volumes of data, perform analysis, interpret results, and develop practical insights and recommendations for use across the company.
 Implement standard methodologies and for evaluation, monitoring, and model integrity.
 Act as an internal advisor and expert for data science projects and innovations.
 Partner closely with collaborators to identify needs and deliver data science solutions.
 Coach and mentor junior data scientists and interns on the team


   Operating at the intersection of financial services and technology, Principal builds financial tools that help our customers live better lives. We take pride in being a purpose-led firm, motivated by our mission to make financial security accessible to all. Our mission, integrity, and customer focus have made us a trusted leader for more than 140 years.
  Who You Are: 
 
Graduate degree (M.S.) or Ph.D in a quantitative discipline preferred.
 M.S + 4+ OR Ph.D + 2+ Years professional experience in building machine learning/predictive models.
 Deep knowledge of Statistics, Mathematics, Optimization, Machine Learning theory and quantitative techniques.
 Extensive programming experience in at least one programming language (Python or R). Proficient with machine learning libraries such as SciKit-Learn, SciPy, Keras, Tensorflow, PyTorch etc.
 Experience working with large datasets including structured/unstructured data.
 Knowledge in evaluating and making decisions around the use of new or existing machine learning, data analysis, optimization techniques/tools for a project.
 Experience in model evaluation, tuning and performance.
 Experience with Big Data technologies like Spark and Cloud technologies (AWS, Azure, etc.).
 Passion for picking up new techniques/technologies.
 Self motivated demeanor and desire to work on applied problems.
 Salary Range Information: Salary ranges below reflect targeted base salaries. Non-sales positions have the opportunity to participate in a bonus program. Sales positions are eligible for sales incentives, and in some instances a bonus plan, whereby total compensation may far exceed base salary depending on individual performance. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Salary Range: $106400 - $167000 / year Additional Information: 
 Skills That Will Help You Stand Out 

Data science experience in the insurance industry
 Experience as a technical mentor
 ML (predictive and prescriptive)
 Large language models

 Work Environments

   This role offers in-office, hybrid (blending at least three office days in a typical workweek)
 
 Job level

   We’ll consider talent at the next level with the right experiences and skills.
 
 Work Authorization/Sponsorship 

  At this time, we're not considering applicants that need any type of immigration sponsorship (additional work authorization or permanent work authorization) now or in the future to work in the United States. This includes, but IS NOT LIMITED TO: F1-OPT, F1-CPT, H-1B, TN, L-1, J-1, etc. For additional information around work authorization needs please use the following links.
 
 Nonimmigrant Workers and Green Card for Employment-Based Immigrants

 Investment Code of Ethics 


  For Principal Asset Management positions, you’ll need to follow an Investment Code of Ethics related to personal and business conduct as well as personal trading activities for you and members of your household. These same requirements may also apply to other positions across the organization.
 
 Experience Principal 

  At Principal, we value connecting on both a personal and professional level. Together, we’re imagining a more purpose-led future for financial services – and that starts with you. Our success depends on the outstanding experiences, backgrounds, and talents of our employees. And we support our employees the same way we support our customers: with comprehensive, competitive benefit offerings crafted to protect their physical, financial, and social well-being. Check out our careers site to learn more about our purpose, values and benefits.
 
 Principal is an Equal Opportunity Employer 

  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.
  Posting Window: We will be accepting applications for at least 3 days from when the job was originally posted, after which we may keep open or remove the posting based upon applications we receive. Please submit applications in a timely manner as there is no guarantee the posting will be available beyond 3 days of the original posting date. Date First Posted (TTF): 11/16/2023 
 LinkedIn Hashtag : #LI-EW1
",106400,"['tensorflow', 'pytorch', 'python', 'machine learning', 'aws', 'azure']"
Data Scientist II,RTL Networks,CA,Full-time,"
Position Title: Data Scientist II
Location: San Diego, CA
Salary: $105k - $120k
Status: Full-time
Clearance: Secret
Required Certification(s): Possesses active relevant industry data scientist/data security certification.
About Us: RTL Networks, Inc. is a rapidly growing company primarily focused on providing information technology (IT) support services and personnel to a variety of commercial and government customers for long term contracts. By providing a wide array of professional services and products, we help our customers leverage technology and operate with total confidence in the predictability, security, and reliability of their technology resources to meet business objectives.
Summary:
RTL Networks is searching for a Mid-level Data Scientist (Data Scientist II) to support an upcoming effort at NAVWAR HQ in downtown San Diego. Data Scientists develop and implement a set of techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. The ideal candidate will have existing experience with US Navy or other DoD environments and applications.
Primary Responsibilities:

Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets.
Collaborate with cross-functional teams to understand business objectives and data requirements, and translate them into data-driven solutions.
Apply advanced statistical and mathematical concepts to analyze complex datasets and extract meaningful insights.
Develop and implement machine learning models to predict trends, identify patterns, and solve business challenges.
Utilize programming languages such as Python and R, along with relevant packages, for data analysis and modeling.
Employ data science techniques, data mining, statistics, and graph algorithms to support analytics objectives.
Apply structured query language (SQL), non-structured query language (NoSQL), and other data manipulation techniques.
Create and maintain data pipelines, integrate APIs, and interact with web application servers and search indexes.
Collaborate with IT teams to integrate data science solutions into business processes.
Present findings and insights to stakeholders through compelling visualizations and reports.

Qualifications:

Bachelor's degree in Cybersecurity, Computer, Electrical, or Electronics Engineer, or Mathematics with a concentration in computer science or equivalent.
Three (3) years of recent professional experience in data science.
DoD Secret Security Clearance.
Experience with software integration or testing, including analyzing and implementing test plans and scripts.
Experience with frequent scripting language use, such as Python and R and using packages commonly used in data science applications or advanced analytics.
Experience with data science, data mining, statistics, or graph algorithms to support analytics objectives.
Experience applying Structured Query Language (SQL), Non Structured Query Language (NoSQL), Application Program Interface (API) Building, Extract, Transform, and Load (ETL) pipelines, Web Application Servers, or Search Index.
Experience using programming languages and products such as Python, Jupyter Notebook, Pandas, Numpy, Requests, or Antigravity.
Experience applying complex mathematical and statistical concepts.
Experience applying statistical and operations research methods and tools.
Experience employing spreadsheets for data manipulation and visualization.
Possesses active relevant industry data scientist/data security certification, such as: Comp TIA Cloud Essentials; Microsoft Technical Associate (MTA); Certificate of Cloud Security (CCSK); CompTIA Security+; EMC Data Science Associate (EMCDSA); Cloudera Certified Data Scientists (CCDH); Certified Apache Hadoop Developer (HCAHD); Certified Information System Security Professional (CISSSP); Certified Cloud Professional (CCP); Microsoft Certified Professional Developer (MCPD); Microsoft Certified Solution Developer (MCSD); Microsoft Certified Solution Expert (MCSE); Private Cloud; Certified Administrator for Apache Hadoop (CCAH),

Preferred Qualifications:
Relevant industry certifications such as:

CompTIA Cloud Essentials/Microsoft Technical Associate (MTA)/Certificate of Cloud Security (CCSK)/CompTIA A+/CompTIA Security+/EMC.
Data Science Associate (EMCDS)/Cloudera Certified Data Scientist (CCDH)/Certified Apache Hadoop Developer (HCAHD) (Hortonworks)/Certified Information System Security Professional (CISSP)/Certified Cloud Professional (CCP).
(Cloudera)/Microsoft Certified Professional Developer.
(MCPD/Microsoft Certified Solution Developer.
(MCSD)/Microsoft Certified Solution Expert.
(MCSE)/Private Cloud/Certified Administrator for Apache Hadoop.
(CCAH) (Cloudera).

NOTE:

Applicant selected for this position must have a current security clearance.
U.S. Citizenship required.
Chosen applicants will be required to pass pre-employment drug screening and a criminal background check.
Copies of certifications are required.


RTL Networks, Inc., is proud to be an Equal Opportunity/Affirmative Action Employer making decisions without regard to, age 40 and over, color, disability, gender identity, genetic information, military or veteran status, national origin, race, religion, sex, sexual orientation or any other applicable status protected by state or local law.

",105000,"['python', 'numpy', 'pandas', 'machine learning', 'nosql', 'etl', 'sql', 'hadoop']"
Sr. Data Analyst,Madison Logic,Remote,Full-time,"


   About Madison Logic:
  


 Our team is reshaping B2B marketing and having fun in the process! As a truly global company, we take pride in the diverse backgrounds of our team. When joining Madison Logic, you are committing to giving 100% and always striving for more. Work with & learn from an incredible group of people who care about your success as much as they care about their own. Our team is at the heart of what we do and our success starts with you!
  


 Remote work note: 
   Please refer to the job posting detail to determine what (if any) remote work options apply to the specific job advertised. Not all positions are available for remote work or in all regions/countries. Where applicable
   , remote work must be conducted from your home office located in a jurisdiction in which Madison Logic has the legal right to operate. It requires availability and responsiveness on a full-time basis from a distraction free environment with access to high-speed internet. Please inquire for more details.
  


 About the Role:


    We are seeking a Sr. Data Analyst with a highly analytical mind who is skilled at understanding data and is able to translate it into actionable insights. In this role, you will write complex queries to create datasets for applications and Dashboards (BI) to use. Develop easy to understand reports using snowflake SQL. Optimize and streamline the way data is viewed. In this highly collaborative role, you will work closely with the architecture and data teams to reach business objectives.
  



Responsibilities:


 Develop, implement, and optimize queries using Snowflake.
 Develop queries for applications and business intelligence reporting.
 Use SQL(snowflake) to create reports, dashboards, and visualizations
 Aggregate/Model data and use that data to build reports in Domo
 Analyze data to help improve business performance
 Identify the best data sources for a given analysis
 Develop processes for data mining, data modeling, and data production
 Offer insights and recommendations to improve data reliability and quality






Basic Qualifications:


 University degree +7 years of practical experience
 1+ year’s experience with Python or Node.js
 4+ year’s experience with SQL or mySQL
 4+ year’s experience with cloud computing services (AWS)
 Experience working with data cleaning and standardizing process






Other Characteristics:


 Team player and proven relationship-builder
 Strong interpersonal skills, high level of professionalism and integrity
 Excellent organizational and project management skills
 Experience handling multiple responsibilities, tasks, and projects in a fast-paced environment preferred
 A positive attitude that approaches tasks/projects from a hands-on, roll up your sleeves frame of mind






   $105,000 - $115,000 a year
  

    Expected Compensation: (Dependent upon Experience)
  

    Base Salary 
   in NYC, Boston, and DC Metro Areas: $105,000 - $115,000
  

    Base Salary 
   in Colorado: -10% of posted range
  

    Base Salary 
   all other regions: Up to 
   -25% of posted range, please inquire for more information. 
  

   Additional Compensation (Annual Discretionary Bonus): $0 - $10,000
  



   Pay Transparency/Equity:
  

    We are committed to paying our team equitably for their work, commensurate with their individual skills and experience
   . Salary Range and additional compensation, including discretionary bonuses and incentive pay, are determined by a rigorous review process taking into account the experience, education, certifications and skills required for the specific role, equity with similarly situated team members, as well as employer-verified region-specific market data provided by an independent 3rd party partner. 
  

   We will provide more information about our perks & benefits upon request.
   




   Who We Are:
  


 Our Vision: We empower B2B organizations globally to convert their best accounts faster
   




   Our Values: 
   #TEAM #OWNIT #RESPECT #EXCEL #EMPOWER



 Our Commitment to Diversity & Inclusion:
  

    Madison Logic is proud to be an equal opportunity employer. We are committed to equal employment opportunity regardless of sex, race, color, religion, national origin, sexual orientation, age, marital status, disability, gender identity or Veteran status.
  


 Privacy Disclosure:
  

    All of the information collected in this form and/or by your application by submission of your online profile is necessary and relevant to the performance of the job applied for. We will process the information provided by you in this form, your CV (including physical and online resume profiles), by the referees you have noted, and by the educational institutions with whom we may undertake to verify your qualifications with, in accordance with our privacy policy and for recruitment purposes only.
  


 For more information on how we process the information you have provided including relevant lawful bases (where relevant) please see our privacy policy which is available on our website (https://www.madisonlogic.com/privacy/).
  

",105000,"['python', 'aws', 'mysql', 'sql']"
Interdisciplinary Computer Scientist/Computer Engineer/Data Scientist,US Office of the Secretary of Defense,VA,Full-time,"

Duties
This position is a DoD Cyber Excepted Service (CES) personnel system position in the Excepted Service under 10 U.S.C. 1599f.   This position is in the Excepted Service and does NOT convey eligibility to be converted to the Competitive Service. It is being recruited under 10 U.S.C. 1599f into the Cyber Excepted Service (CES) personnel system.   If you are a current Federal Career/Career-Conditional employee, you will be placed on an Excepted appointment.   This appointment does not confer eligibility to be non-competitively converted to an appointment in the competitive service.  For more information see https://public.cyber.mil/cw/dod-cyber-excepted-service-ces/  Incumbents typical work assignments may include the following: 

Serves as a Technical Product Manager in the Executive Decision Support Division incorporating Data, Machine Learning (ML), Artificial Intelligence (AI), and product management principles.
Provides technical expertise in current-market technologies that accelerate business analytics insights and drive decision advantage.
Develops the CDAO technical product strategy and leads its implementation, management, and lifecycle planning.
Works with external stakeholders to align technical requirements to product roadmaps and lead delivery of those products.
Collaborates through technical leadership within DCAO Divisions and manages external partnerships with DoD, Industry, and Academic partnerships.




Requirements
Conditions of Employment

U.S. Citizenship is required.
Males born after 12-31-59 must be registered or exempt from Selective Service (see https://www.sss.gov/Home/Registration).
A three year trial period may be required if not previously completed a trial or probationary period in the excepted or competitive service.
Must be determined suitable for federal employment.
Required to participate in the direct deposit program.
This position is subject to pre-employment and random drug testing.
This position is being recruited under 10 USC 1599f into the Cyber Excepted Service and does NOT convey eligibility to be converted to the Competitive Service.
For more information on the Cyber Excepted Service Personnel System, click here https://public.cyber.mil/cw/dod-cyber-excepted-service-ces/.
Must be able to obtain and maintain a Top Secret security clearance.
The employee may be required to work other than normal duty hours, which may include evenings, weekends, and/or holidays and/ or overtime.
The employee may be required to work other than normal duty hours, which may include evenings, weekends, and/or holidays and/ or overtime.
Work may occasionally require travel away from the normal duty station on military or commercial aircraft.


Qualifications


Applicant must have directly applicable experience that demonstrates the possession of knowledge, skills, abilities, and competencies necessary for immediate success in the position. Qualifying experience may have been acquired in any public or private sector job, but will clearly demonstrate past experience in the application of the particular competencies or knowledge, skills, and abilities necessary to successfully perform the duties of the position. Such experience is typically in or directly related to the work of the position to be filled.


Transcripts for Basic Requirement: Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.
     

Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.

 

Basic Requirements:


For the GG-0854 Professional Engineering Series: Degree: professional engineering. To be acceptable, the curriculum must: (1) be in a school of engineering with at least one curriculum accredited by the Accreditation Board for Engineering and Technology (ABET) as a professional engineering curriculum; or (2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statistics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics.
     

For the GG-1550 Computer Science Series: Bachelor's degree in computer science or bachelor's degree with 30 semester hours in a combination of mathematics, statistics, and computer science.
     

At least 15 of the 30 semester hours must have included any combination of statistics and mathematics that included differential and integral calculus. All academic degrees and course work must be from accredited or pre-accredited institutions.
     

For the GG-1560 Data Science Series: Bachelor's degree in mathematics, statistics, computer science, data science or field directly related to the position with 30 semester hours in a combination of mathematics, statistics, and computer science.
     

At least 30 semester hours must have included any combination of statistics and mathematics that included differential and integral calculus. All academic degrees and course work must be from accredited or pre-accredited institutions.
     

You may qualify at the GG-14 level, if you fulfill the following qualification requirement:


One year of specialized experience equivalent to the GG-13 grade level in the Federal service (experience may have been gained in the private sector) that demonstrates your experience developing and applying principles, theories, and techniques of computer science, software engineering, enterprise computing, commercial cloud adoption, and information engineering to research, develop, identify, and infuse new methodologies and technologies into organizational architecture and design.

 Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.
    

ACTIVE DUTY SERVICE MEMBERS: The VOW Act Chapter 21 of Title 5, United States Code (U.S.C.), Section 2108a, requires Federal agencies treat active duty service member as veterans, disabled veterans, and preference eligible, when they submit, at the time they apply for a Federal job, a ""certification"" of active service in lieu of a DD-214, assuming the service member is otherwise eligible. A ""certification"" letter should be on letterhead of the appropriate military branch of the service and contain (1) the military service dates including the expected discharge or release date; and (2) the character of service. The service member's military service dates are necessary in order to determine whether he or she meets the definition of ""veteran"" under 5 U.S.C. 2108(1). The ""certification"" must reflect the service member is expected to be discharged or released from active duty service in the armed forces under honorable conditions not later than 120 days after the date of submission. The ""certification"" must be signed by, or by direction of, the adjutant, personnel officer, or commander of your unit or higher headquarters and must indicate when your terminal leave will begin (if applicable), your rank, dates of active duty service, the type of discharge and character of service (i.e. honorable). Further, under paragraph (h) of the rule, agencies are required to verify a qualifying separation from military service prior to appointment, through the DD-214 or other appropriate documentation. Your preference and/or appointment eligibility will be verified prior to appointment. Active duty members that fail to provide a valid ""certification"" of service with their initial application will be found ""not eligible."" Military members may be appointed before the effective date of their military retirement/separation if member is on terminal leave.
    

Current or Former Political Appointees: Beginning January 1, 2010, agencies must seek prior approval from OPM before they can appoint a current or recent political appointee to a competitive or non-political excepted service position at any level under the provisions of title 5, United States Code. If you are currently or have been within the last 5 years, a political Schedule A, Schedule C, or Non-career SES employee in the executive branch, you MUST disclose that to the Human Resources Office. Submit a copy of your applicable SF-50, along with a statement that provides the following information regarding your most recent political appointment: 
    
Position title;
Type of appointment (Schedule A, Schedule C, Non-career SES, or Presidential Appointee);
Agency; and,
Beginning and ending dates of appointment.

All qualifications requirements must be met by the closing date of this announcement and clearly documented in your resume.



Education
Education cannot be substituted for experience. 


Additional information

MILITARY SPOUSE PREFERENCE: Military spouse preference applicants are required to apply to job announcement via USAJobs in order to exercise their preference status. The application must include signed Military Spouse PPP Self-Certification Checklist, Marriage Certificate or License, Sponsor's PCS orders at the time of application to be considered  Other priority consideration programs will continue under their current operating procedures.  A tentative offer of employment will be rescinded if the selectee fails to meet the pre-employment requirements, including failure to report to any of the scheduled appointments.  If you are unable to apply online, you must request an alternative application. Please view the following link for information on how to obtain an alternative application https://help.usastaffing.gov/Apply/index.php?%20title=Alternate_Application_Information  Appointment Authorities: For more information on appointment authority eligibility requirements: 

https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/individuals-with-disabilities/
https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/veterans/
https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/military-spouses/
Other Special Appointment Authorities https://www.usajobs.gov/
Interchange Agreements https://www.opm.gov/policy-data-oversight/hiring-information/competitive-hiring/#url=Types-of-Appointments

Employed Annuitants (Reemployed Annuitants): Applicants in receipt of an annuity based on civilian employment in the Federal Service are subject to the DoD Policy on The Employment of Annuitants. /www.esd.whs.mil/DD/DoD-Issuances/140025/
    

Nepotism: Under the provisions of 5 USC 3110, an individual may not be appointed into a position if the position is under the supervisory chain of command of a relative.
    

Additional vacancies may be filled by this announcement.
    





Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.
Once the announcement has closed, a review of your résumé and supporting documentation will be used to determine whether you meet the qualification requirements listed on this announcement. If you are minimally qualified, your résumé and supporting documentation will be compared against your responses to the assessment questionnaire to determine your level of experience. If, after reviewing your résumé and/or supporting documentation, a determination is made that you have inflated your qualifications and/or experience, you may lose consideration for this position. Please follow all instructions carefully when applying, errors or omissions may affect your eligibility. 

Communication
 Engineering and Technology
 Systems Testing and Evaluation
 Technical Competence


 Applicants who disqualify themselves will not be evaluated further. 
  




Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
YOU ARE REQUIRED TO DOCUMENT IN YOUR APPLICATION PACKAGE EVIDENCE THAT SUPPORTS YOUR ELIGIBILITY AND QUALIFICATION CLAIMS. You MUST upload the applicable documents with your application package. If you fail to provide these documents, you will be marked as having an incomplete application package and you will not be considered any further.  1. Your resume may be submitted in any format that includes your name and contact information (telephone number and/or email). If you submit more than one copy of your resume, only the most recent version will be reviewed. The latest timestamp will be used to determine which version of your resume is ""most recent.""  If your resume includes a photograph or other inappropriate material or content, it will not be used to make eligibility and qualification determinations and you will not be considered for this vacancy.  For qualifications determinations, it is recommended that applicants include their months and hours worked per week for each employment listed on their resume. If a determination is not able to be made about the length of your creditable experience for qualification requirements, you will be removed from consideration. about what you should include in your federal resume at https://www.usajobs.gov/Help/faq/application/documents/resume/what-to-include/  2. Other supporting documents: 

Cover Letter, optional
Most recent SF-50, ""Notification of Personnel Action"" showing you are/were in the competitive or excepted service and the highest grade held (WHS serviced employees SF-50s will be verified via eOPF).
College transcripts - Required. Official or unofficial transcripts are acceptable. (WHS serviced employees will be verified via eOPF or you may include them in your application package. However, it is the employee's responsibility to ensure that his/her eOPF contains the required transcript and is up-to-date).
DD-214, SF-15 Form and VA letter, or certification of expected discharge or release from active duty from Veterans for consideration under Veteran hiring authorities
Noncompetitive appointment authority documentation, if applicable
PPP Registrants/Eligibles: Must submit the following applicable documents: 1) PPP registration 2) PCS orders (if applicable)

ARE YOU A VETERAN CLAIMING SOLE SURVIVORSHIP PREFERENCE OR 5-POINT VETERANS' PREFERENCE?
 1. You must provide legible copy/copies of the following: DD-214, ""Certificate of Release or Discharge from Active Duty,"" showing all dates of service, as well as type of discharge and character of service (Honorable, General, etc.) or Statement of Service/Proof of Service (in lieu of a DD-214) from your command or local Personnel Support Detachment (PSD). The Statement of Service/Proof of Service must provide all dates of service, the expected date of discharge and anticipated character of service (Honorable, General, etc.). Veterans should upload their DD-214 once they receive it upon separation.
     
 2. You should also document your complete military service information in the Veterans Preference and Military Service Section of the assessment questionnaire (type of preference, dates of service, date of VA letter, character of service, disability claim and rank and date of retirement if retired).
     

ARE YOU A DISABLED VETERAN or CLAIMING 10-POINT VETERANS' PREFERENCE?
 1. Disabled veterans, veterans, widows, spouses or the mother of a veteran, who are eligible for 10-point veterans' preference, you must provide legible copies of the following: Applicable supporting documents as noted on Standard Form-15 (SF-15). To obtain a copy of SF-15, go to: https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/veterans/
     

DoD Components with CES positions apply Veterans' Preference to preference eligible candidates, as defined by Section 2108 of Title 5 U.S.C, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 3005, ""CES Employment and Placement."" If you are a veteran claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you must submit documents verifying your eligibility with your application package. 


How to Apply


To apply for this position, you must complete the online application and submit the documentation specified in the Required Documents section below.  A complete application package must be submitted by 11:59 PM (EST) on the closing date of the announcement (11/21/2023) to receive consideration. 

To begin, click Apply to access the online application. You will need to be logged into your USAJOBS account to apply. If you do not have a USAJOBS account, you will need to create one before beginning the application.
Follow the prompts to select your résumé and/or other supporting documents to be included with your application package. You will have the opportunity to upload additional documents to include in your application before it is submitted. Your uploaded documents may take several hours to clear the virus scan process.
After acknowledging you have reviewed your application package, complete the Include Personal Information section as you deem appropriate and click to continue with the application process.
You will be taken to the online application which you must complete in order to apply for the position. Complete the online application, verify the required documentation is included with your application package, and submit the application.
To view the assessment questionnaire, click here: https://apply.usastaffing.gov/ViewQuestionnaire/12166398
To verify the status of your application, log into your USAJOBS account (https://my.usajobs.gov/Account/Login) all of your applications will appear on the Welcome screen. The Application Status will appear along with the date your application was last updated. For information on what each Application Status means, visit: https://www.usajobs.gov/Help/how-to/application/status/.
      
 You are encouraged to apply online. Applying online will allow you to review and track the status of your application.
      
 Failure to submit a complete application package will result in an ineligible rating and loss of consideration.
       Do not email or send hard copy resumes/applications to the Contact Information or Agency Information listed in this vacancy announcement. All resumes/applications received at the addresses listed in the Contact Information or Agency Information will be destroyed and will not be considered for this vacancy announcement.
      

It is the applicant's responsibility to verify that all information in their resume and documents are legible and accurate. HR will not modify answers/documents submitted by an applicant.

 Washington Headquarters Services provides reasonable accommodations to applicants with disabilities. If you need a reasonable accommodation for any part of the application and hiring process, please view the ""Alternate Application"" method listed in the ""Other Information"" section of this announcement. Your requests for reasonable accommodation will be addressed on a case-by-case basis. Please visit the following link for more information http://http://www.esd.whs.mil/Directives/issuances/admin_inst/
      


Agency contact information
Washington HQ Services 


Phone
000-000-0000 
Email
whs.job.application.assistance@mail.mil 


Address


Chief Digital and Artificial Intelligence Office

4800 Mark Center Drive

Alexandria, VA 22350

US 




Next steps

Once your online application is submitted you will receive a confirmation notification by email. Your application will be evaluated by the Human Resources Office to determine your eligibility for the position. After the evaluation is complete, you will receive another notification regarding the status of your application.  Stay informed of changes to your application status by signing up for automatic email alerts at: https://www.usajobs.gov/Applicant/Application/ListApplications?  Washington Headquarters Services is an Equal Employment Opportunity employer. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents

YOU ARE REQUIRED TO DOCUMENT IN YOUR APPLICATION PACKAGE EVIDENCE THAT SUPPORTS YOUR ELIGIBILITY AND QUALIFICATION CLAIMS. You MUST upload the applicable documents with your application package. If you fail to provide these documents, you will be marked as having an incomplete application package and you will not be considered any further.  1. Your resume may be submitted in any format that includes your name and contact information (telephone number and/or email). If you submit more than one copy of your resume, only the most recent version will be reviewed. The latest timestamp will be used to determine which version of your resume is ""most recent.""  If your resume includes a photograph or other inappropriate material or content, it will not be used to make eligibility and qualification determinations and you will not be considered for this vacancy.  For qualifications determinations, it is recommended that applicants include their months and hours worked per week for each employment listed on their resume. If a determination is not able to be made about the length of your creditable experience for qualification requirements, you will be removed from consideration. about what you should include in your federal resume at https://www.usajobs.gov/Help/faq/application/documents/resume/what-to-include/  2. Other supporting documents: 

Cover Letter, optional
Most recent SF-50, ""Notification of Personnel Action"" showing you are/were in the competitive or excepted service and the highest grade held (WHS serviced employees SF-50s will be verified via eOPF).
College transcripts - Required. Official or unofficial transcripts are acceptable. (WHS serviced employees will be verified via eOPF or you may include them in your application package. However, it is the employee's responsibility to ensure that his/her eOPF contains the required transcript and is up-to-date).
DD-214, SF-15 Form and VA letter, or certification of expected discharge or release from active duty from Veterans for consideration under Veteran hiring authorities
Noncompetitive appointment authority documentation, if applicable
PPP Registrants/Eligibles: Must submit the following applicable documents: 1) PPP registration 2) PCS orders (if applicable)

ARE YOU A VETERAN CLAIMING SOLE SURVIVORSHIP PREFERENCE OR 5-POINT VETERANS' PREFERENCE?
 1. You must provide legible copy/copies of the following: DD-214, ""Certificate of Release or Discharge from Active Duty,"" showing all dates of service, as well as type of discharge and character of service (Honorable, General, etc.) or Statement of Service/Proof of Service (in lieu of a DD-214) from your command or local Personnel Support Detachment (PSD). The Statement of Service/Proof of Service must provide all dates of service, the expected date of discharge and anticipated character of service (Honorable, General, etc.). Veterans should upload their DD-214 once they receive it upon separation.
   
 2. You should also document your complete military service information in the Veterans Preference and Military Service Section of the assessment questionnaire (type of preference, dates of service, date of VA letter, character of service, disability claim and rank and date of retirement if retired).
   

ARE YOU A DISABLED VETERAN or CLAIMING 10-POINT VETERANS' PREFERENCE?
 1. Disabled veterans, veterans, widows, spouses or the mother of a veteran, who are eligible for 10-point veterans' preference, you must provide legible copies of the following: Applicable supporting documents as noted on Standard Form-15 (SF-15). To obtain a copy of SF-15, go to: https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/veterans/
   

DoD Components with CES positions apply Veterans' Preference to preference eligible candidates, as defined by Section 2108 of Title 5 U.S.C, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 3005, ""CES Employment and Placement."" If you are a veteran claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you must submit documents verifying your eligibility with your application package.






 Help 
 This job is open to




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.




Veterans




Clarification from the agency
This announcement is open to the Public.

",132368,['machine learning']
"Sr Director, Statistical Programming",Olema Oncology,MA,Full-time,"

Who We Are >>> Why You Should Work With Us
 Olema Oncology is a clinical-stage biopharmaceutical company focused on the discovery, development and commercialization of targeted therapies for women's cancers. Olema's lead product candidate, palazestrant (OP-1250), is a proprietary, orally-available small molecule with dual activity as both a complete estrogen receptor (ER) antagonist (CERAN) and a selective ER degrader (SERD). It is currently being evaluated both as a single agent in an ongoing Phase 2 clinical trial, and in combination with CDK4/6 inhibitors (palbociclib and ribociclib) and a PI3Ka inhibitor (alpelisib), in patients with recurrent, locally advanced or metastatic ER-positive (ER+), human epidermal growth factor receptor 2-negative (HER2-) breast cancer. Palazestrant has been granted FDA Fast Track designation for the treatment of ER+/HER2- metastatic breast cancer that has progressed following one or more lines of endocrine therapy with at least one line given in combination with a CDK4/6 inhibitor. Olema is headquartered in San Francisco and has operations in Cambridge, Massachusetts. For more information, please visit us at www.olema.com, or follow us on Twitter and LinkedIn.
 Onto something big, together. Olema is made up of people who are passionate beyond measure. Each and every day, we come together to do amazing things – for each other, for science, and for women with cancer.
 Our modern hybrid workplace model encourages employees to split their week between working from home and at our lab/office, while also providing several allowances to help with both home office and commute expenses.
 While at the lab/office, our teams build their camaraderie, opening the door for more authentic mentorship and career development opportunities. While at home, employees can make the most of their time – whether that's picking up the kids from school, going on a mid-day run, or catching up on chores. Through this model, we strive to offer our employees the best of both work models.

 As the Senior Director of Statistical Programming reporting to the Vice President of Biostatistics, you will be accountable for all statistical programming deliverables in adherence to company SOPs and ICH/GCP. You will also work with the Vice President, Biostatistics to create and implement Statistical Programming policies and procedures.
 This role is based out of our San Francisco, CA or Cambridge, MA office and will require 10% travel.
 Your work will primarily encompass:

Build out the statistical programming group and set up SOPs and processes for operational excellence
Collaborate with the IT team to build and maintain secure statistical computing environment and programming infrastructure
Conduct statistical programming for CSR, publications, presentations, DSUR, IB, safety data review, and ad hoc analyses
Lead the statistical programming activities for regulatory submissions following CDISC standards
Collaborate with the study statistician and study team in project planning
Review key study-related documents including but not limited to SAP, CRFs and data management plan
Author SDTM and ADAM specifications in collaboration with the study statistician
Effectively manage the CRO to ensure high-quality deliverables within timeline and budget
Validate/QC key TFLs generated by the CRO
Responsible for one or more studies with concurrent tasks and timelines
Manage one junior statistical programmer
Other duties, as assigned

Ideal Candidate Profile >>>
 A love of challenging, important work. We are a pragmatic team, driven to imagine and develop meaningful therapies for improving lives. All employees within our company play a unique and crucial role in our success, both in accomplishing our mission and building a positive company culture. As such, we are looking for someone with the right combination of knowledge, experience, and attributes for this role.
 Knowledge:

Bachelor or Master's Degree in Statistics, Life Sciences, Computer Science or related fields
Thorough understanding of clinical trial reporting process, as well as regulatory reporting requirements including electronic data submissions and CDISC implementation
Thorough knowledge of SDTM/ADaM specifications and programming
Strong SAS programming skill
Able to guide the successful completion of major programs and projects
Strong analytical and communication skills
Knowledge and experience in meeting regulatory guidelines, including both FDA and international regulatory agencies
Broad knowledge of medical/biological terminology in relevant therapeutic areas

Experience:

10+ years statistical programming experience in biotech/pharmaceutical industry
Experience in managing the Statistical Programming team
Extensive experience of leading both early and late-phase clinical studies including programming and validation of SDTM and ADaM data sets, tables, figures, and listings
Expert level SAS programmer with experience in delivering complex programming assignments, macros and analyses
Experience with oncology trials is preferred
Experience with R is a plus
Experience with BLA or NDA/sNDA to FDA/EMA is preferred. Experience with other major global health authority submission is a plus
Experience in management of CROs with respect to statistical programming
Building and maintaining strong collaboration with key stakeholders from different disciplines across the organization

Attributes:

Leadership skills in proactive strategy setting, priority evaluations, adapting to changes, conflict resolution, and effective partnership
Statistical programming expertise and experience in managing the activities of clinical trials
Strong verbal and written communication skills
Ability to effectively represent Biostatistics Programming in multidisciplinary meetings
A commitment to excellence
Self-motivated and enthusiastic; fast learner who can identify the core project challenges and expeditiously change course as required in a fast-paced organization
Have impeccable professional ethics, integrity and judgment

The base pay range for this position is expected to be $223,000 - $270,000 annually, however the base pay offered may vary depending on location, market, job related knowledge, skills and capabilities, and experience. The total compensation package for this position also includes equity, bonus, and benefits.
 #LI-MK1

 Important Information >>> 
We provide equal opportunity to all employees and applicants for employment and believe that great ideas and discoveries come from a mix of expertise, background, and experience. Olema is building a culture where the value of difference is celebrated.
 We offer a competitive compensation and benefits package, seeking to provide an open, flexible, and friendly work environment to empower employees and provide them with a platform to develop their long-term careers. A Summary of Benefits is available for all applicants.
 Olema also requires all employees to be fully vaccinated against COVID-19, subject to approved medical or religious exemptions or disability accommodations. The health and safety of our employees is important to us!
 Please note: Olema doesn't accept agency resumes and is not responsible for any fees related to unsolicited resumes. Thank you.
 Additional Note/Fraud Alert: Olema will not conduct interviews via text message or messaging platforms and will not ask you to download anything as part of your interview. Though we use third party tools to help with advertising our jobs, please be vigilant in checking that the communication is in fact coming from Olema.

",223000,['gcp']
Data Scientist,eHealth,Remote,Full-time,"

  Get your career started at eHealth
 


   eHealthInsurance has many exciting career opportunities in a number of locations, across various functions. Come join us today!
 


   At eHealth we are passionate about expertly guiding consumers through their health insurance and related options, when, where and how they prefer. We are seeking an exceptional Data Scientist to join our growing team, which develops cutting-edge machine learning products and solutions to drive better and faster decision making within our company and to better serve our customers. This is a fast-paced, collaborative, and iterative environment requiring quick learning, agility, and flexibility.
 


   Responsibilities
 


 Develop state of the art machine learning models and iterate to push the boundaries on what problems can be solved through data science


 Conduct open-ended data exploration to evaluate and solve complex problems, such as recommendation, call routing optimization, etc.


 Participate in all aspects of the project lifecycle from requirements gathering, data acquisition and preparation, hypothesis generation, ideation, coding, testing, and deployment of data science product
 Develop and implement online and offline testing to test hypothesis


 Work with business partners and cross functional teams to identify opportunities for innovation


 Work closely with engineers to productionize models
 Help foster a culture of supporting business needs when needed by providing data-driven insights



   Qualifications:
 

 Bachler degree in Computer Science, Physics, Mathematics, Statistics, Data Science or related technical discipline
 2+ years of industry experience in data science which includes building predictive or descriptive models and designing the associated metrics to evaluate these models
 2+ years of experience in with Python and scripting languages (Unix shell) as well as solid experience with git
 Experience with A/B and multivariate experimentation design and evaluation, ranking and recommendation systems.
 Experience with ML frameworks, such as Scikit-learn, Spark ML, Tensorflow, PyTorch, etc.
 Proficiency in SQL, experience with distributed systems (Snowflake, Spark), and NoSQL systems (MongoDB)
 Experience collaborate directly with cross functional team such as product, business stakeholders on collecting business requirement and presenting machine learning solutions
 Strong communication and interpersonal skills with the ability to present technical solutions to non-technical audiences


   #LI-Remote
 

   #LI-TB1
 
 The base pay range reflects the anticipated pay range for this position. The actual base pay offered will depend on various factors including individual skills, experience, performance, qualifications, the department budget, and the location where work is performed. Base pay is one component of eHealth’s total rewards package, which also includes an annual performance bonus, plus an array of benefits designed to support employees’ personal and professional wellness. For more information on our total rewards offerings, please visit our career site.
  Base Pay Range -$89,800 - $112,200
 


   eHealth is an Equal Employment Opportunity employer. It is our policy to provide equal opportunity to all employees and applicants and to prohibit any discrimination because of race, color, religion, sex, national origin, age, marital status, sexual orientation, genetic information, disability, protected veteran status, or any other consideration made unlawful by applicable federal, state or local laws. The foundation of these policies is our commitment to treat everyone fairly and equally and to have a bias-free work environment.
 


   If you are interested in applying for employment with eHealth and need special assistance or an accommodation to apply for a posted position contact us at: 
  
   accommodations@ehealthinsurance.com
  .
 

",89800,"['tensorflow', 'pytorch', 'python', 'machine learning', 'spark ml', 'nosql', 'sql', 'git']"
Data Scientist,General Atomics and Affiliated Companies,CA,Full-time,"
 General Atomics Aeronautical Systems, Inc. (GA-ASI), an affiliate of General Atomics, is a world leader in proven, reliable remotely piloted aircraft and tactical reconnaissance radars, as well as advanced high-resolution surveillance systems.
 
 This position is responsible for supporting research, product development, and sales efforts with insights gained from analyzing potentially large, unstructured complex datasets. Develop and code software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources. Assignments are normally accompanied by general instructions and suggestions, outlining possible approaches, sources or information, and potential problems to be encountered with work reviewed regularly for soundness of technical judgment, overall adequacy and accuracy. Tasks involve the exercise of independent judgment and discretion about matters of significance. 
 

DUTIES AND RESPONSIBILITIES:

 Design, develop and program methods, processes and systems to consolidate and analyze unstructured, diverse 'big data' sources to generate actionable insights and solutions for client services and product enhancement.
 Develop, refine, deploy, and support statistical and machine learning models utilizing state of the art approaches.
 Communicate insights and findings from analysis and experiments to product, service, and business managers.
 Recommend solutions to moderately complex technical and procedure issues.
 Create and utilize moderately complex algorithms and approaches, clean and synthesize training/test data, create/run simulations, and perform analysis of alternatives to best meet stakeholder requirements.
 May identify opportunities for product and customer process improvement using statistical and machine learning models to improve the effectiveness of different courses of action.
 Develop and deploy data visualization in order to communicate moderately complex concepts and data in a simple, actionable manner.
 Interact with product and service teams to identify questions and issues for data analysis and experiments.
 Document findings and may make technical presentations to business stakeholders as required.
 May create proposals, cost estimates, and whitepapers suitable for publication.
 Represents the organization as a contact with internal and external representatives.
 Maintain the strict confidentiality of sensitive information.
 Perform other duties as assigned or required.
 Responsible for observing all laws, regulations and other applicable obligations wherever and whenever business is conducted on behalf of the Company. 
Expected to work in a safe manner in accordance with established operating procedures and practices.
 We recognize and appreciate the value and contributions of individuals with diverse backgrounds and experiences and welcome all qualified individuals to apply.
  43050
 
Job Qualifications:

 Typically requires a bachelor's or master's degree in data science, applied mathematics, statistics, computer science, or related technical/quantitative discipline from an accredited institution and two or more years of data science experience with a bachelor's degree. May substitute equivalent experience in lieu of education.
 Must have a general understanding of data science concepts, principles, and theory with technical experience, demonstrating the application of those concepts.
 Must possess:
   
 The ability to understand new concepts quickly and apply them accurately throughout an evolving environment and organize work assignments to meet established timetables
 The ability to exercise independent judgment in solving issues of moderate scope and complexity.
 Good organizational, verbal and written communication skills to accurately document, report and present findings.
 Good interpersonal skills to effectively interface with all levels of employees including management and outside representatives.
 Good computer skills.

 The ability to work independently or in a team environment is essential, as is the ability to work extended hours and travel as required.


 Salary:$81,080 - $141,650
 Travel Percentage Required 0 - 25
 Relocation Assistance Provided Not Provided 
 US Citizenship Required? Yes
 Clearance Required? No 
 Clearance Levelnull 
 WorkstyleHybrid
",81080,['machine learning']
Data Scientist,CVS Health,TX,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary
 Join our fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability and performance of CVS Health’s IT operations.

 You will collaborate with team members leveraging the agile methodology to work on innovative and complex solutions with the use of Machine Learning and statistical analysis. Under general direction, you will develop models using Machine Learning, Deep Learning, and other similar technologies to predict and analyze data on hardware and software systems within a large server infrastructure to prevent outages and pinpoint errors. Independently support processes related to the implementation of systems into production, including integration of purchased solutions. Responsible for design, coding, testing, debugging, and documentation.


 Team Player: Willing to teach, share knowledge, and work with others to make the team successful.
 Communication: Exceptional verbal, written, organizational, presentation, and communication skills.
 Creativity: Ability to take written and verbal requirements and come up with other innovative ideas.
 Attention to detail: Systematically and accurately research future solutions and current problems.
 Strong work ethic: The innate drive to do work extremely well.
 Passion: A drive to deliver better products and services than expected to customers.

 Required Qualifications

 2+ years of experience in machine learning with domain knowledge and experience in the following areas: data-driven statistical modeling, discriminative methods, feature extraction and analysis, supervised learning.
 2+ years of experience with a programming language such as Python, R, SQL, etc.
 2+ years of experience with data extraction, wrangling, visualization, and analysis.

 Preferred Qualifications

 Experience processing data from various sources and via big data platforms (such as GCP, AWS, etc.)
 Experience creating scalable machine learning models and solutions.
 Experience researching and implementing statistical models, machine learning algorithms or other customized solutions that show significant impact solving complex business problems.
 Experience enhancing existing data pipelines by exploring unstructured data sources and engineering new features.
 Can provide technical support and expertise to the broader team.
 Master’s degree or greater in Statistics, Mathematics, Computer Science or other quantitative field; or equivalent working experience
 Knowledge of Machine Learning, Data Mining, Statistics, Applied Mathematics, or a related field.


 Education

 Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science or other quantitative field.


 Pay Range
 The typical pay range for this role is:
 $73,500.00 - $150,000.00
 
 This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",73500,"['python', 'machine learning', 'deep learning', 'aws', 'gcp', 'sql']"
Senior Data Scientist,Microsoft,WA,Full-time,"

  Are you excited to work on and help shape a product used by hundreds of millions of users all over the world? Do you want to work in a team full of high caliber, talented, passionate Data Scientists?
 


 Microsoft Edge is one of the world’s leading modern browsers. 
  The Edge Growth & Data Science team’s mission is to Provide Insights from Data, Experimentation and Customer Sentiment about the most promising levers for sustainable Edge Browser growth and Drive action on these insights. 
  The Measurement Science team, as part of the Edge Data Science team, evaluates if the product is growing; enables in-depth decomposition of Edge business performance through metrics, forecasts, attribution of initiatives, advanced analyses using Statistical and Machine Leanring (ML) modeling; communicates Edge business metric status to SLT clearly and effectively; partners with stakeholders across Edge, Windows and Web Experiences, Finance, Business teams to identify and drive growth opportunities.
 


 We are currently seeking a 
  Senior Data Scientist
 with highly proficient analytical abilities. This person will have a passion for owning and solving complex problems with a creative perspective by manipulating big data, applying hypothesis driven approach, and using statistical/ML modeling techniques.
 


 Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.
 


 In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.
 
 Responsibilities

 Develop right metrics to accurately measure product growth; build/improve/apply scientific and methodological decomposition and attribution to interpret, explain metric movement; work with Finance team to build forecast; be on rotation periodically for weekly Senior Leadership Team (SLT) reviews of the Edge business metrics, communicate status of the metrics clearly and effectively, and provide the SLT with clear and concise answers to their ad hoc questions in a timely manner usually within hours.
 Process and analyze big data datasets, usage funnels, long term trends using Statistical, Machine Learning modeling, and Hypothesis driven approach to identify opportunities, patterns, pain points in end user’s journey and provide recommendations to the leadership teams to help in driving customer satisfaction, acquisition, engagement, and retention. 
Research, propose and implement innovative solutions to enhance our tools, processes, and analytics capabilities.
 Collaborate not only with other Data Scientists, Developers, Product Managers, feature teams within Edge but also with Partner teams like Windows, Search, News, Finance, Business, Marketing teams etc. to help drive the Edge business growth.
 Demonstrate growth mindset, passion for learning and commitment to responsibilities.
 Contribute to team culture; mentor, lead other Data Scientists to help them grow


     Other
   

 Embody our Culture and Values


 Qualifications

 Required/Minimum Qualifications


 Bachelor's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 5+ years data-science experience (e.g., managing structured and unstructured data, applying statistical techniques and reporting results
   
 OR Master's Degree in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 3+ years data-science experience (e.g., managing structured and unstructured data, applying statistical and machine learning techniques and reporting results)
 OR Doctorate in Data Science, Mathematics, Statistics, Econometrics, Economics, Operations Research, Computer Science, or related field AND 1+ year(s) data-science experience (e.g., managing structured and unstructured data, applying statistical and machine learning techniques and reporting results)
 OR equivalent experience.



 Additional or Preferred Qualifications




 5+ years of professional experience in driving business growth by generating data driven hypotheses and insights using Statistical and ML modeling.


 Proficiency in data analysis tools such as Python, R, or similar.
 Experience of working in big data platforms like Microsoft Azure, Databricks, Cosmos or equivalent
 Superb problem solving and analytical abilities.
 Excellent in working in a highly collaborative, dynamic team and agile development environment.
 Ability to own an area/project and drive it to successful completion by creatively removing hurdles with minimal or no supervision.
 Effective Communication and Storytelling skills


   Data Science IC4 - The typical base pay range for this role across the U.S. is USD $112,000 - $218,400 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $145,800 - $238,600 per year.
  
 Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay
 

 Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
",112000,"['python', 'machine learning', 'azure']"
Data Scientist,US Office of Enterprise Integration,DC,Full-time,"

Duties
This is a non-bargaining unit position. The initial application review cut-off for this job announcement is 50 applications. The first 50 applications received will be considered first. Applications received after the initial cut-off number (50 applications) may not receive consideration unless otherwise requested by management. If management requests additional certificates, applicants will continue to be reviewed in groups of 50 in the order they applied.  Note: Submitting multiple applications will change the order in which your application is reviewed.


VA offers a comprehensive total rewards package: 
VA Total Rewards

Work Schedule: Monday - Friday, 8:00am - 4:30pm
   
Compressed/Flexible Schedule: Available
   
Telework: Available
   
Duty Location Status: Will work from a VA owned or leased space
   
Position Description Title/PD#: Data Scientist/ PD19926A and PD19927A
   
Relocation/Recruitment Incentives: Not Authorized
   
Permanent Change of Station (PCS): Not Authorized
   
Financial Disclosure Report: Not Required
   
Physical Demands: Work is primarily sedentary and does not require any special physical effort. 
   
 This position involves a multi-grade career ladder. The major duties listed below represent the full performance level of GS-12. At the GS-11 grade level, you will perform assignments of a more limited scope and with less independence. You will progressively acquire the background necessary to perform at the full performance level of GS-12. Promotion is at the discretion of the supervisor and is contingent upon satisfactory performance, availability of higher level work, and availability of funds. Promotion is not guaranteed and no promise of promotion is implied. 
   

Major Duties: 
   
Plans and conducts, as project member of a study team, relevant research and analytical studies of VA complex issues to support critical operational problems and/or decisions using advance state-of-the art data theories beyond established parameters. 
Identifies, develops, and integrates data from internal and external sources, through various data collection procedures and technologies, including emerging data science and big data methodologies. 
Performs a wide range of complex analytical, mathematical and statistical research that inform operational requirements.
Extracts relevant information from historical datasets.





Requirements
Conditions of Employment

You must be a U.S. citizen to apply for this job.
Selectees are subject to a background/suitability investigation.
Selectees may be required to serve a probationary period.
Selective Service Registration is required for males born after 12/31/1959.
A complete application package, i.e., Resume, Transcripts, etc., as required by job announcement.
Selected applicants will be required to complete an online onboarding process.
Participation in the Seasonal Influenza Prevention Program for VHA Health Care Personnel (HCP) is a requirement for all Department of Veterans Affairs HCP.
All applicants tentatively selected for VA employment in a testing designated position are subject to urinalysis to screen for illegal drug use prior to appointment. Applicants who refuse to be tested will be denied employment with VA.
Must be proficient in written and spoken English.
Pre-employment physical examination/evaluation may be required.
Participation in the Coronavirus Disease 2019 (COVID-19) vaccination program is a requirement for all Veterans Health Administration Health Care Personnel (HCP) - See ""Additional Information"" below for details.


Qualifications

    To qualify for this position, applicants must meet all requirements by the closing date of this announcement, 11/28/2023.
    
 You may qualify based on your education and experience as described below.
    
 A transcript must be submitted with your application if you are basing 
    all or part of; your qualifications on education. 
    Individual Occupational Requirements:


Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. or 


Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience. 


AND


For the GS-11:

Specialized Experience: You must have one year of specialized experience equivalent to at least the next lower grade GS-09 in the normal line of progression for the occupation in the organization. Specialized experience is defined as analyzing and interpreting data modeling, algorithms, and coding data requirements; Analyzing and providing information from multiple systems to prepare data reports; Conducting analysis using software and/or programming languages; Using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation.;
    

OR


Education: Applicants may substitute education for the required experience. To qualify based on education for this grade level you must have Education: Ph.D or equivalent doctoral degree or 3 full years of progressively higher level graduate education leading to such a degree in a field which demonstrates the knowledge, skills, and abilities necessary to do the work of the position;
    

OR


Combination: Applicants may also combine education and experience to qualify for this position as long as the computed percentage of the requirements is at least 100%. To compute the percentage of the requirements, divide your total months of experience by 12. Then divide the total number of completed graduate semester hours (or equivalent) beyond the second year (total graduate semester hours minus 36) by 18. Add the two percentages.
    

For the GS-12:

Specialized Experience: You must have one year of specialized experience equivalent to at least the next lower grade GS-11 in the normal line of progression for the occupation in the organization. Specialized experience is defined as identifying data required for use in the management and direction of programs; Implementing algorithms, machine learning, and other AI systems; Using data tools and techniques to process large, datasets into structured formats for matching, analysis, or estimation; Applying statistical analyses to determine the fitness-for-use of new or combined data sources, machine learning outputs, and data science methods.
    
 There is no education substitute or requirement for the GS-12 grade level.
    
 You will be rated on the following Competencies for this position: 
    
Mathematical Reasoning
Analytical Thinking
Database Management
Research
Critical Thinking

 Per Office of Personnel Management General Schedule Qualification Policies, federal employees are assumed to have gained experience by performing duties and responsibilities appropriate for their official series and grade level as described in their position description. Experience that would not normally be part of the employee's position is creditable when documented by satisfactory evidence (e.g., a memorandum from the manager, human resources director, or official documentation such as SF-52, SF-50 documenting an official detail/assignments, or other comparable documentation). The documentation must indicate whether the employee performed the duties full time or, if part-time, the percentage of times the employee performed the additional duties.
    
 To receive credit for experience in your resume that is not within the official series and grade level of your position, you must provide official documentation of such experience as indicated above.
    
 Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religions; spiritual; community; student; social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.
    

Note: 
    A full year of work is considered to be 35-40 hours of work per week. Part-time experience will be credited on the basis of time actually spent in appropriate activities. Applicants wishing to receive credit for such experience must indicate clearly the nature of their duties and responsibilities in each position and the number of hours a week spent in such employment.

 For more information on these qualification standards, please visit OPM's web site at http://www.opm.gov/qualifications/standards/indexes/alph-ndx.asp. 
   


Education
There is no education substitute for the GS-12 grade level.   PLEASE NOTE: Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications (particularly positions with a positive education requirement). Therefore, applicants must report only attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. Applicants can verify accreditation at the following website: http://www.ed.gov/admins/finaid/accred/index.html. All education claimed by applicants will be verified by the appointing agency accordingly. If you are using foreign education to meet qualification requirements, you must send a Certificate of Foreign Equivalency with your transcript in order to receive credit for that education. 


Additional information


Receiving Service Credit for Earning Annual (Vacation) Leave: Federal Employees earn annual leave at a rate (4, 6 or 8 hours per pay period) which is based on the number of years they have served as a Federal employee. VA may offer newly-appointed Federal employee's credit for their job-related non-federal experience or active duty uniformed military service. This credited service can be used in determining the rate at which they earn annual leave. Such credit must be requested and approved prior to the appointment date and is not guaranteed.   The Interagency Career Transition Assistance Plan (ICTAP) and Career Transition Assistance Plan (CTAP) provide eligible displaced VA competitive service employees with selection priority over other candidates for competitive service vacancies. To be well-qualified, applicants must possess experience that exceeds the minimum qualifications of the position including all selective factors if applicable, and must be proficient in most of the requirements of the job. Information about ICTAP and CTAP eligibility is on OPM's Career Transition Resources website which can be found at https://www.opm.gov/.  This job opportunity announcement may be used to fill additional vacancies.
If you are unable to apply online or need to fax a document you do not have in electronic form, view the following link for information regarding an Alternate Application.






Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.
IN DESCRIBING YOUR EXPERIENCE, PLEASE BE CLEAR AND SPECIFIC. WE WILL NOT MAKE ASSUMPTIONS REGARDING YOUR EXPERIENCE. Applicants will be referred in the order in which they were received. 




Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
Documents Accepted: 

 Performance Appraisal
 Resume
 Separation Notice (RIF)
 SF-50/ Notification of Personnel Action
 Transcript

 Documents Required:
     

Resume

 Please review the above list(s) to ensure you have included all necessary documents required for your application.Not every applicant will require the same documents, therefore it is the applicants responsibility to ensure that their application package includes all necessary documents to determine qualifications and eligibility for appointment, such as a copy of your SF-50, transcript, ICTAP/CTAP documentation (for displaced Federal employees).
     You will not be contacted for additional information. Applicants will be deemed ineligible if supporting documentation is not submitted.
     

Veterans' Preference: Since the Direct-Hire Recruitment Authority is being used, traditional Veterans' Preference rules do not apply. Qualified veterans will, however, be given full consideration for this position.
     

Applications are accepted online. Applying online will allow you to review and track the status of your application. 
     

If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating. 


How to Apply


All applicants are encouraged to apply online.  To apply for this position, you must complete the occupational questionnaire and submit the documentation specified in the Required Documents section. The complete application package must be submitted by 11:59 PM (EST) on 11/28/2023 to receive consideration. To preview the questionnaire click https://apply.usastaffing.gov/ViewQuestionnaire/12204974.  1. To begin, click Apply Online to create a USAJOBS account or log in to your existing account. Follow the prompts to select your USAJOBS resume and/or other supporting documents and complete the occupational questionnaire.  2. Click Submit My Answers to submit your application package.  NOTE: It is your responsibility to ensure your responses and appropriate documentation is submitted prior to the closing date. To verify your application is complete, log into your USAJOBS account, https://my.usajobs.gov/Account/Login, select the Application Status link and then select the More Information link for this position. The Details page will display the status of your application, the documentation received and processed, and any correspondence the agency has sent related to this application. Your uploaded documents may take several hours to clear the virus scan process.  To return to an incomplete application, log into your USAJOBS account and click Update Application in the vacancy announcement. You must re-select your resume and/or other documents from your USAJOBS account or your application will be incomplete.


Agency contact information
VHA National Recruitment Center 


Phone
(844)456-5208 
Email
VHANationalRecruitmentCenter@va.gov 


Address


AS Office of Enterprise Integration

810 Vermont Ave

Washington, DC 20420

US 




Next steps

After the vacancy announcement closes, applicants are evaluated to ensure qualification and eligibility requirements are met. After the review is complete, a referral certificate(s) is issued and applicants will be notified of their status by email. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents

Documents Accepted: 

 Performance Appraisal
 Resume
 Separation Notice (RIF)
 SF-50/ Notification of Personnel Action
 Transcript

 Documents Required:
   

Resume

 Please review the above list(s) to ensure you have included all necessary documents required for your application.Not every applicant will require the same documents, therefore it is the applicants responsibility to ensure that their application package includes all necessary documents to determine qualifications and eligibility for appointment, such as a copy of your SF-50, transcript, ICTAP/CTAP documentation (for displaced Federal employees).
   You will not be contacted for additional information. Applicants will be deemed ineligible if supporting documentation is not submitted.
   

Veterans' Preference: Since the Direct-Hire Recruitment Authority is being used, traditional Veterans' Preference rules do not apply. Qualified veterans will, however, be given full consideration for this position.
   

Applications are accepted online. Applying online will allow you to review and track the status of your application. 
   

If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.






 Help 
 This job is open to




Career transition (CTAP, ICTAP, RPL)
Federal employees who meet the definition of a ""surplus"" or ""displaced"" employee.




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.



Clarification from the agency
ALL US CITIZENS DIRECT HIRE AUTHORITY: This position is being filled using Direct-Hire Authority (5 CFR 337.201) for this occupation.

",78592,['machine learning']
Data Scientist Lead,JPMorgan Chase & Co,NJ,Full-time,"
JOB DESCRIPTION
 DESCRIPTION:
 Duties: Develop learning models and apply it to complex business critical problems in Cybersecurity, Software and Technology Infrastructure. Provide technical services and project leadership across range of artificial intelligence and machine learning (AI/ML) efforts. Assist with full life-cycle of data science work from prototype development to model testing and evaluation to production-ready deployment. Research new machine learning methods through independent study, attending industry-leading conferences and experimentation. Drive firmwide initiatives by developing large-scale frameworks to accelerate the application of machine learning models across different areas of the business. Present regularly on latest and advanced research AI/ML topics to team members and other senior stakeholders. Mentor and guide junior colleagues across the different phases of AI/ML work.
 QUALIFICATIONS:
 Minimum education and experience required: Master’s degree in Data Science, Computer Science, Computer Engineering, Electrical Engineering, Mathematics, or related field of study plus 5 years of experience in the job offered or as Data Scientist, Data Analyst, or related occupation. The employer will alternatively accept a Bachelor’s degree in Data Science, Computer Science, Computer Engineering, Electrical Engineering, Mathematics, or related field of study plus 7 years of experience in the job offered or as Data Scientist, Data Analyst, or related occupation.
 Skills Required: Requires experience in the following: Machine learning and deep learning toolkits such as TensorFlow, PyTorch, NumPy, Scikit-Learn, or Pandas designing experiences and training frameworks; At least one of the following programming languages: Python, JAVA, or R; Modeling tools and techniques including deep learning, time series analysis, text mining, regression, and classification; Outlining and evaluating intrinsic and extrinsic metrics for model performance aligned with business goals; big data and scalable model training using technologies such as Spark or Hadoop; AWS; communicating technical concepts and results to both technical and business audiences.
 Job Location: 575 Washington Boulevard, Jersey City, NJ, 07310. Telecommuting permitted up to 40% of the week.
 Full-Time. Salary: $178,000 - $210,000 per year.
ABOUT US


   JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management. 
  

We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)


We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.


JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans








ABOUT THE TEAM

 Our professionals in our Corporate Functions cover a diverse range of areas from finance and risk to human resources and marketing. Our corporate teams are an essential part of our company, ensuring that we’re setting our businesses, clients, customers and employees up for success.
",178000,"['tensorflow', 'pytorch', 'python', 'numpy', 'pandas', 'machine learning', 'deep learning', 'aws', 'hadoop']"
"Data Scientist, Lead",Booz Allen Hamilton,VA,Full-time,"


Job Description










         Location: 
        

         Arlington,VA,US 
        



         Remote Work: 
        

         No 
        



         Job Number: 
        

         R0184823
        


















         Data Scientist, Lead
          The Opportunity:
 Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection, to cancer research, to national intelligence — you know the answers are in the data.

 We have an opportunity for you to use your analytical skills to improve the defense industry. You’ll work closely with your customer to understand their questions and needs, then dig into their data-rich environment to find the pieces of their information puzzle. You’ll analyze algorithms, write scripts, build predictive analytics, use automation, apply machine learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help military leaders make informed decisions. You’ll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in the defense industry.

 Empower change with us.

 You Have:

 5+ years of experience working in a professional environment
 Experience with BI Dashboard tools, including Qlik Sense, Tableau, or Power BI
 Knowledge of SQL
 Ability to navigate a complex matrix environment and manage competing priorities
 Ability to obtain a security clearance
 Bachelor’s degree


 Nice If You Have:

 Experience with Qlik dashboarding, development functions, and mashups
 Experience with web technologies, including JavaScript, CSS, Node.js, or Enignma.js
 Experience with using Databricks to perform data transformations or modeling
 Experience with using Cloud Native Services
 Ability to comprehend stakeholder needs effectively, communicate development plans, and track progress milestones
 Possession of excellent organizational and time management skills to handle multiple tasks
 Possession of excellent critical thinking skills to assess numbers, trends, and data to reach new conclusions based on findings
 Possession of excellent quantitative skills, including statistical analysis, process design, and data management
 Qlik Data Architect, Qlik Data Analyst, or QlikView Developer Certification


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $106,200.00 to $242,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",106200,"['machine learning', 'tableau', 'sql']"
Data Scientist,US Assistant Secretary for Public and Indian...,DC,Full-time,"

Duties
The following are the duties of this position at the GS-13. If you are selected at a lower grade level, you will have the opportunity to learn to perform all these duties, and will receive training to help you grow in this position.  As a Data Scientist, you will: 

Serve as an authoritative source to PIH, REAC and other offices in data management and statistical areas with respect to all phases of study design, data analysis, and statistical interpretation of the results relating to projects under consideration. Evaluate study proposals in terms of appropriateness of study design, outcome measures, data collection and analysis methods, and quality control. This includes developing data sets, queries, and data storage methodologies and requires the application of data management principles, procedures, practices, methodologies, and tools such as modeling techniques, data backup, data recovery, data dictionaries, data warehousing, data mining, data disposal, and data standardization processes.
Conduct the planning, development, implementation, and administration data, reports, data storage, and data retrieval. Examples of data accessed include but is not limited to demographic data; program outcomes; program utilization metrics; risk and asset analytics, qualitative and quantitative program specific data; economic indicators; financial and economic data.
Translate medium to complex concepts, findings, and limitations into concise, plain language. Closely ties findings and conclusions into the agency mission, original problem statement, and team objectives. Research and design presentations and interpretations of analytical outputs tailored to specific audiences including the use of interactivity and narrative storytelling where appropriate. Collaborate with teammates, customers, and stakeholders in a reproducible and organized manner.
Consult with internal and external stakeholders and customers to identify the appropriate data, methodological approach, and design. Conduct observational analyses using software and/or advanced programming languages such as R, Python, or SAS to explore/group data, test hypotheses, predict outcomes, and inform decisions.
Derive meaning from big data (i.e., datasets that may be large, disparate, unstructured, and/or complex), including structured, loosely structured, and unstructured data.




Requirements
Conditions of Employment

Candidates will be selected for a job assigned to one of the official duty stations listed in this announcement. Failure to report to duty at the location for which the candidate is selected may be grounds for a disciplinary action, including removal.
 Key Requirements:

Must be U.S. Citizen or U.S. National.
A one year probationary period may be required.
Must successfully complete a background investigation.
Public Trust - Background Investigation will be required.
Complete a Declaration for Federal Employment to determine your suitability for Federal employment, at the time requested by the agency.
Have your salary sent to a financial institution of your choice by Direct Deposit/Electronic Funds Transfer.
If you are a male applicant born after December 31, 1959, certify that you have registered with the Selective Service System or are exempt from having to do so.
Go through a Personal Identity Verification (PIV) process that requires two forms of identification from the Form i-9. Federal law requires verification of the identity and employment eligibility of all new hires in the U.S.
Obtain and use a Government-issued charge card for business-related travel.
Please refer to ""Additional Information Section for additional Conditions of Employment.""



Qualifications


     You must meet the following requirements by the closing date of this announcement.
     

Specialized Experience: For the 
     GS-13 grade level, you must have one year (52 full weeks) of specialized experience at a level of difficulty and responsibility equivalent to the 
     GS-12 grade level in the Federal service
     . Specialized Experience for this position includes:
     


Performing quantitative and qualitative analysis to support executive decision making; AND
Experience developing a data warehouse using SQL, Python, R or similar data management technologies; AND
Preparing and delivering technical/narrative reports for making program decisions; AND
Creating consumable data visualizations to promote understanding of results or trends (graphs, charts, dashboards).


Specialized Experience: For the 
     GS-
12 grade level, you must have one year (52 full weeks) of specialized experience at a level of difficulty and responsibility equivalent to the 
     GS-
11 grade level in the Federal service
     . Specialized Experience for this position includes:-
     
 Experience developing a data warehouse using SQL, Python, R or similar data management technologies; AND
     

Creating consumable data visualizations to promote understanding of results or trends (graphs, charts, dashboards).


Specialized Experience: For the 
     GS-
11 grade level, you must have one year (52 full weeks) of specialized experience at a level of difficulty and responsibility equivalent to the 
     GS-
09 grade level in the Federal service
     . Specialized Experience for this position includes:
     


Experience utilizing data management technologies, such as SQL, Python, R or similar; AND
Preparing technical/narrative reports for making program decisions.


OR Education: You may substitute education for general or specialized experience as follows: 3 years of progressively higher level graduate education leading to a Ph.D. degree or an LL.M, if related or equivalent doctoral degree.
     

OR Combination: You may qualify by a combination of experience and education. To combine education and experience, the total percentage of experience at the required grade level compared to the specialized experience requirement, as well as the percentage of completed education compared to the education requirement must equal at least 100 percent. Only graduate level education in excess of 36 semester hours (54 quarter hours), may be used to combine education and experience.
     
 Experience may have been gained in either the public, private sector or
      
volunteer service. One year of experience refers to full-time work; part-time work is considered on a prorated basis. To ensure full credit for your work experience, please indicate dates of employment by month/day/year, and indicate number of hours worked per week on your resume.
    



Education
The education generally must be from an accredited (or pre-accredited) college or university recognized by the U.S. Department of Education. If you are qualifying based on foreign education, you must submit proof of creditability of education as evaluated by a credentialing agency. Refer to the OPM instructions.  To be qualified for this position, you must meet the basic educational and/or work experience requirements for Data Scientist positions in the federal government. These requirements are:   A) A degree in mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. OR B) A combination of education and experience with courses equivalent to a major field of study (30 semester hours/45 quarter hours) as shown in paragraph A above, plus additional education or appropriate experience. 


Additional information

OTHER INFORMATION: 

We may select from this announcement or any other source to fill one or more vacancies.
Relocation expenses will not be paid.
Relocation incentive will not be paid.
Recruitment incentive will not be paid.
This is a non-bargaining unit position.
This position is Exempt from the Fair Labor Standards Act (FLSA).
HUD offers alternative and flexible work schedules.
This announcement may be used to fill additional vacancies for similar positions across HUD. During the online application process, you will be asked to specify if you would like your application information shared with other hiring managers in the Program Office listed in this announcement or in other HUD Program Offices. Opting to share your application information will not impact your application for this announcement, nor will it guarantee further consideration for additional positions.

CONDITIONS OF EMPLOYMENT (CONTINUED):
HUD employees are subject to a number of government-wide and HUD specific ethics laws and regulations, including restrictions on working in a real estate related business, and having Section 8 tenants, along with other prohibited interests and activities. To review applicable ethics rules and HUD specific restrictions, please visit https://portal.hud.gov/hudportal/HUD?src=/program_offices/general_counsel/ethics.






Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.
Your application includes your resume, responses to the online questions, and required supporting documents. Please be sure that your resume includes detailed information to support your qualifications for this position; failure to provide sufficient evidence in your resume may result in a ""not qualified"" determination.  Rating: Your application will be evaluated in the following areas: Communication, Problem Solving, Research and Analysis, and Technical.  Category rating will be used to rank and select eligible candidates. If qualified, you will be assigned to one of three quality level categories: Best (highest quality category), Better (middle quality category), or Good (minimally qualified category) depending on your responses to the online questions, regarding your experience, education, and training related to this position. Your rating may be lowered if your responses to the online questions are not supported by the education and/or experience described in your application.  Veterans' preference is applied after applicants are assessed. Preference-eligibles will be listed at the top of their assigned category and considered before non-preference-eligibles in that category.  Referral: If you are among the top qualified candidates, your application may be referred to a selecting official for consideration. You may be required to participate in a selection interview.  If you are a displaced or surplus Federal employee (eligible for the Career Transition Assistance Plan (CTAP)/Interagency Career Transition Assistance Plan (ICTAP)) you must receive a score in the middle quality category or better to be rated as ""well qualified"" to receive special selection priority. 




Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
A complete application includes:   1. A resume: All applicants are required to submit a resume either by creating one in USAJOBS or uploading one of their own choosing. (Cover letters are optional.) 

To receive full credit for relevant experience, please list the month/date/year and number of hours worked for experience listed on your resume.
It is suggested that you preview the online assessment questionnaire, to ensure that your resume thoroughly describes how your skills and experience align to the criteria defined in the ""Qualifications"" section of this announcement and support your responses to the online assessment questionnaire.
For resume writing guidance, please visit USAJOBS Resources Center.


2. Vacancy assessment question responses: All applicants are required to complete vacancy question responses by clicking the apply online button of this vacancy announcement.
     

3. 
Submission of any required documents 
identified below, if applicable: Please note that if you do not provide all required information, as specified in this announcement, you may not be considered for this position (or may not receive the special consideration for which you may be eligible). 
     
VETERANS' PREFERENCE DOCUMENTATION:

If you are claiming veterans preference, please see applicant guide for required documentation In order to be considered for veterans preference, you must submit all required documentation as outlined in the applicant guide.



CAREER TRANSITION ASSISTANCE PLAN (CTAP) OR INTERAGENCY CAREER TRANSITION ASSISTANCE PLAN (ICTAP) ELIGIBLE INDIVIDUALS:

If you are a displaced or surplus Federal employee, in order to be eligible under one of these authorities you must submit all required documentation as outlined in this link: CTAP/ICTAP

EDUCATION DOCUMENTATION: 
       
For positions with an education requirement, or if you are qualifying for this position by substituting education or training for experience, you MUST submit a copy of your transcripts or equivalent. An official transcript will be required if you are selected. A college or university degree generally must be from an accredited (or pre-accredited) college or university recognized by the U.S. Department of Education. For a list of schools which meet these criteria, please refer to Department of Education Accreditation page. If you are qualifying based on foreign education, you must submit proof of creditability of education as evaluated by a credentialing agency. Refer to the OPM instructions




How to Apply


HUD has partnered with the Treasury's Bureau of the Fiscal Service to provide certain personnel services to its organization. Fiscal Service's responsibilities include advertising vacancies, accepting and handling applications, and extending job offers.  Please review the entire announcement before applying.  The following instructions outline our application process. You must complete this application process and submit any required documents by 11:59 p.m. Eastern Time (ET) on the closing date of this announcement. We are available to assist you during business hours (normally 8:00 a.m. - 5:00 p.m. ET, Monday - Friday). If applying online poses a hardship, please contact us by noon ET on the announcement's closing date.  HUD provides reasonable accommodation to applicants with disabilities on a case-by-case basis. Please contact us if you require this for any part of the application and hiring process. 

To begin, click Apply to access the online application. You will need to be logged into your USAJOBS account to apply. If you do not have a USAJOBS account, you will need to create one before beginning the application.
Follow the prompts to select your resume and/or other supporting documents to be included with your application package. You will have the opportunity to upload additional documents to include in your application before it is submitted. Your uploaded documents may take several hours to clear the virus scan process.
After acknowledging you have reviewed your application package, complete the Include Personal Information section as you deem appropriate and click to continue with the application process.
You will be taken to the online application which you must complete in order to apply for the position. Complete the online application, verify the required documentation is included with your application package, and submit the application.

To verify the status of your application:

Log into your USAJOBS account (USAJOBS Login) A list of announcements in which you have applied will be at the Welcome screen
Under ""application status,"" click ""Track this application"" and you will be taken to the agency website where you can check your application status. For more information regarding the job and applicant status, please refer to https://www.usajobs.gov/Help/how-to/application/status/.
If you wish to make changes/updates to your application and the vacancy is still open, you can click on the job announcement and ""Update Application"" to be taken back to your application. No updates can be made once the announcement has closed.
Please notify us if your contact information changes after the closing date of the announcement. Also, note that if you provide an email address that is inaccurate or if your mailbox is full or blocked (e.g., spam-blocker), you may not receive important communication that could affect your consideration for this position.
For additional information on how to apply, please visit the Partnership for Public Service's Go Government website.
      
 To preview the assessment questionnaire: https://apply.usastaffing.gov/ViewQuestionnaire/12206421
      


Agency contact information
Applicant Call Center 


Phone
304-480-7300 
Email
hudinquiries@fiscal.treasury.gov 


Address


Assistant Secretary for Public and Indian Housing

Administrative Resource Center

Parkersburg, WV 26101

US 




Next steps

Once the online questionnaire is received, you will receive an acknowledgement email that your submission was successful. We will review your resume and transcript(s) (if appropriate) to ensure you meet the basic qualification requirements. We will evaluate each applicant who meets the basic qualifications on the information provided and may interview the best-qualified applicants. After making a tentative job offer, we will conduct any required suitability and/or security background investigation. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents

A complete application includes:   1. A resume: All applicants are required to submit a resume either by creating one in USAJOBS or uploading one of their own choosing. (Cover letters are optional.) 

To receive full credit for relevant experience, please list the month/date/year and number of hours worked for experience listed on your resume.
It is suggested that you preview the online assessment questionnaire, to ensure that your resume thoroughly describes how your skills and experience align to the criteria defined in the ""Qualifications"" section of this announcement and support your responses to the online assessment questionnaire.
For resume writing guidance, please visit USAJOBS Resources Center.


2. Vacancy assessment question responses: All applicants are required to complete vacancy question responses by clicking the apply online button of this vacancy announcement.
   

3. 
Submission of any required documents 
identified below, if applicable: Please note that if you do not provide all required information, as specified in this announcement, you may not be considered for this position (or may not receive the special consideration for which you may be eligible). 
   
VETERANS' PREFERENCE DOCUMENTATION:

If you are claiming veterans preference, please see applicant guide for required documentation In order to be considered for veterans preference, you must submit all required documentation as outlined in the applicant guide.



CAREER TRANSITION ASSISTANCE PLAN (CTAP) OR INTERAGENCY CAREER TRANSITION ASSISTANCE PLAN (ICTAP) ELIGIBLE INDIVIDUALS:

If you are a displaced or surplus Federal employee, in order to be eligible under one of these authorities you must submit all required documentation as outlined in this link: CTAP/ICTAP

EDUCATION DOCUMENTATION: 
     
For positions with an education requirement, or if you are qualifying for this position by substituting education or training for experience, you MUST submit a copy of your transcripts or equivalent. An official transcript will be required if you are selected. A college or university degree generally must be from an accredited (or pre-accredited) college or university recognized by the U.S. Department of Education. For a list of schools which meet these criteria, please refer to Department of Education Accreditation page. If you are qualifying based on foreign education, you must submit proof of creditability of education as evaluated by a credentialing agency. Refer to the OPM instructions








 Help 
 This job is open to




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.



Clarification from the agency
U.S. citizens or U.S. Nationals; no prior Federal experience is required.

",69107,"['python', 'sql']"
Critical Infrastructure and Data Analytics Scientist (Scientist 3),Los Alamos National Laboratory,NM,Full-time,"
What You Will Do

 The Information Sciences and Modeling group (A-1) is looking for an outstanding scientist in the field of risk modeling, optimization, and machine learning, with additional expertise in data signal processing and telecommunications network and protocols.
 
 As a Scientist 3 in this role, you will have the opportunity to work on projects that address emerging and challenging problems in critical infrastructure, specifically focusing on the telecommunication system, electric power, and water distribution, simulation, and risk modeling and analysis. The work will involve working closely with a team of researchers, contributing to collaborative projects, and actively publishing research in peer-reviewed journals. Presenting research findings at conferences and workshops will also be an important part of the role.
 

What You Need

 The required expertise for this position encompasses a broad range of fields, including statistics, stochastic methods, machine learning, control theory, dynamical systems, discrete and continuous optimization, statistical physics, and graphical modeling.This diverse skill set highlights the interdisciplinary nature of the work and the need for collaboration with experts from different disciplines. This position will serve as a mentor and leader to lower level team members.
 

Minimum Job Requirements:


 Experience in predictive modeling and risk modeling.
 Scientific/numerical programming experience in Julia, C, C++, Python, R, MATLAB, or Java
 Publication record in one or more of the following areas: machine learning, mathematical programming, industrial engineering, control theory, computational science, telecommunication, or applied mathematics
 Demonstrated ability to work effectively in a collaborative and multi-disciplinary scientific environment.
 Demonstrated excellent written skills.
 Ability to build from existing institutional technical capabilities and contribute to the development of new capabilities.

 Education:
 
 Master's degree in a STEM field (electrical engineering, computer science, computer engineering, applied mathematics, operations research, applied mathematics, or a related field) from an accredited college or university and 6 years of relevant experience or an equivalent combination of education and experience directly related to the occupation. A Ph.D. in a STEM field is preferred.
 

Desired Qualifications:


 Experience in solving practical science and engineering problems, especially in the context of infrastructure networks
 Experience in the telecommunication industry and with telecommunication infrastructure.""
 Background in applied mathematics disciplines such as optimization, control theory, and machine learning
 Experience with parallel computation, containerization, and cloud computing and/or HPC environments
 Mathematical programming experience with AMPL, GAMS, JuMP.
 Experience with commercial and open-source solvers (Mosek, Gurobi, IPOPT, etc.)
 Experience with relational databases, SQL, time series/column-oriented databases.
 Experience in digital signal processing, statistical modeling, and stochastic processes.
 Ability to obtain DOE Q and SCI clearances, which typically requires U.S. Citizenship

 Work Location: The work location for this position is onsite and located in Los Alamos, NM. All work locations are at the discretion of management.
 

Note to Applicants:

 For further questions, please contact Paolo Patelli at paolopatelli@lanl.gov. To apply, please use the ""apply now"" button below. Include the candidate's CV with 3 references listed.
 
Where You Will Work

 Located in northern New Mexico, Los Alamos National Laboratory (LANL) is a multidisciplinary research institution engaged in strategic science on behalf of national security. LANL enhances national security by ensuring the safety and reliability of the U.S. nuclear stockpile, developing technologies to reduce threats from weapons of mass destruction, and solving problems related to energy, environment, infrastructure, health, and global security concerns. Los Alamos provides access to activities like hiking, mountain biking, skiing, rock climbing, and camping and a local public school system that is consistently ranked amongst the best in the nation every year. Our generous benefits package includes:
 

 PPO or High Deductible medical insurance with the same large nationwide network
 Dental and vision insurance
 Free basic life and disability insurance
 Paid childbirth and parental leave
 Award-winning 401(k) (6% matching plus 3.5% annually)
 Learning opportunities and tuition assistance
 Flexible schedules and time off (paid sick, vacation, and holidays)
 Onsite gyms and wellness programs
 Extensive relocation packages (outside a 50 mile radius)

 Additional Details


Directive 206.2 - Employment with Triad requires a favorable decision by NNSA indicating employee is suitable under NNSA Supplemental Directive 206.2. Please note that this requirement applies only to citizens of the United States. Foreign nationals are subject to a similar requirement under DOE Order 142.3A.
 

Clearance: Q /SCI (Position will be cleared to this level). Selected applicants will be subject to a background investigation conducted by or on behalf of the Federal Government, and must meet eligibility requirements* for access to classified matter. This position requires a Q clearance. and obtaining such clearance requires US Citizenship except in extremely rare circumstances. Dependent upon the position, additional authorization to access classified information may be required, which may or may not be available to dual citizens. Receipt of a Q clearance and additional access authorization ultimately is a decision of the Federal Government and not of Triad.
 


Eligibility requirements: To obtain a clearance, an individual must be at least 18 years of age; U.S. citizenship is required except in very limited circumstances. See DOE Order 472.2 for additional information.

 New-Employment Drug Test: The Laboratory requires successful applicants to complete a new-employment drug test and maintains a substance abuse policy that includes random drug testing. Although New Mexico and other states have legalized the use of marijuana, use and possession of marijuana remain illegal under federal law. A positive drug test for marijuana will result in termination of employment, even if the use was pre-offer.
 
 Term position: Regular-status Laboratory employees applying for term-status positions may retain regular status with approval of the cognizant Principle Associate Director.
 
 Internal Applicants: Regular appointment employees who have served the required period of continuous service in their current position are eligible to apply for posted jobs throughout the Laboratory. If an employee has not served the required period of continuous service, they may only apply for Laboratory jobs with the documented approval of their Division Leader. Please refer to Policy Policy P701 for applicant eligibility requirements.
 
 Equal Opportunity: Los Alamos National Laboratory is an equal opportunity employer and supports a diverse and inclusive workforce. All employment practices are based on qualification and merit, without regard to race, color, national origin, ancestry, religion, age, sex, gender identity, sexual orientation or preference, marital status or spousal affiliation, physical or mental disability, medical conditions, pregnancy, status as a protected veteran, genetic information, or citizenship within the limits imposed by federal laws and regulations. The Laboratory is also committed to making our workplace accessible to individuals with disabilities and will provide reasonable accommodations, upon request, for individuals to participate in the application and hiring process. To request such an accommodation, please send an email to applyhelp@lanl.gov or call 1-505-665-4444 option 1.
",119200,"['python', 'machine learning', 'sql']"
"Applied Data Scientist, ML and DL Engineer - Cybersecurity",NVIDIA,VA,Full-time,"

  NVIDIA has been redefining computer graphics, PC gaming, and accelerated computing for more than 25 years. It’s a unique legacy of innovation that’s fueled by great technology—and outstanding people! Today, we’re tapping into the unlimited potential of AI to define the next era of computing. An era in which our GPU acts as the brains of computers, robots, and self-driving cars that can understand the world. Doing what’s never been done before takes vision, innovation, and the world’s best talent. As an NVIDIAN, you’ll be immersed in a diverse, supportive environment where everyone is inspired to do their best work. Come join the team and see how you can make a lasting impact on the world!
 


   NVIDIA is hiring applied data scientists and ML/DL engineers to scale-up its cybersecurity development efforts that span accelerated computing (Morpheus), generative AI, confidential computing, and networking. You will need to have excellent analytical skills, a solid data science foundation, prior experience with data analysis at scale, and excellent communication skills. Together with other specialists, we will advance NVIDIA's capability to build and deploy core frameworks, revolutionizing cybersecurity applications for our customers.
 


   What You'll Be Doing:
 



     Working with a multi-functional team of backend engineers, data engineers, data scientists, and developers to build out cybersecurity SDKs and capabilities, adding critical new use cases and applications that increase out-of-the-box capabilities of SDKs like Morpheus while illustrating the power of the SDK for developers and ISVs
   


     Crafting proof-of-concept workflows rooted in first principles that apply modern data science techniques to security use cases
   


     Migrating prototyped workflows to hardened enterprise ready workflows, creating end-to-end pipelines that are suitable for deployment in production environments
   


     Collaborating with multiple teams (internal and external) to translate cybersecurity requirements and use cases into core functionality
   



   What We Need to See:
 



     BS or MS (or equivalent experience) in Computer Engineering, Computer Science, Data Science, or a closely related field
   


     8+ years of experience in a similar or related role
   


     Proven experience in data science or software development, including common PyData ecosystem toolkits
   


     Strong programming skills in Python, as well as comfort using Linux and typical development tools (e.g., GitHub, Docker)
   


     Great motivation, with strong interpersonal skills and the ability to communicate highly technical concepts with non-technical audiences
   



   Ways to Stand Out from the crowd:
 



     Demonstrated history of contributing to open-source software projects
   


     Prior experience developing ML/DL pipelines that apply deep learning techniques to novel problems
   


     Familiarity with implementing Python unit tests
   


     Previous real-world experiencing developing models for cybersecurity use cases or developing models that apply to data at large scales (TB+)
   


     Experience with ML deployment lifecycle including model monitoring and retraining
   



   Widely considered to be one of the technology world’s most desirable employers, NVIDIA offers highly competitive salaries and a comprehensive benefits package. As you plan your future, see what we can offer to you and your family www.nvidiabenefits.com/.
 
 The base salary range is 176,000 USD - 333,500 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
 







          You will also be eligible for equity and 
         
          benefits
         . 
         NVIDIA accepts applications on an ongoing basis.








 NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

",176000,"['python', 'deep learning', 'docker']"
"Data Scientist, Client Analytics",Ibotta,Hybrid,Full-time,"

  Would you like to be part of an industry-leading CPG analytics organization? Ibotta is seeking a Data Scientist, Client Analytics to join our innovative team and contribute to our mission to Make Every Purchase Rewarding. Ibotta captures billions of purchases annually, with over ten thousand brands and across hundreds of retailers, presenting the right candidate with the opportunity to work with one of the most comprehensive and unique (purchasing) data sets in the world.
 


   As a Data Scientist, shape the company's data, drive business impact across the Revenue organization, and advance technically and as a leader by contributing to best practices and learning from experienced team members. Seize the opportunity to own the data science technology in crucial business domains—from collaborating with stakeholders through the full model development lifecycle
 


   This position is located in Denver, Colorado as a hybrid position requiring 3 days in office, (Tuesday, Wednesday, and Thursday). Candidates must live in the United States.
 


   What you will be doing:
 



     Provide subject matter expertise and ownership of one or more of the company’s core business domains
   


     Contribute to creating best practices for the team
   


     Initiate and drive collaboration with stakeholders, architects, and data engineers to discover, define, cleanse, and refine the data needed for analysis and modeling
   


     Analyze large and novel datasets to extract actionable insights to inform model development and understand consumer behavior
   


     Provide customized views of large and complex datasets to support data analysis and business decision-making
   


     Inform experimental design to formulate solutions addressing major business challenges and innovation opportunities
   


     Build models using a variety of statistical and machine learning techniques, from selecting the best type of model for the problem to using techniques to measure and optimize model performance
   


     Harden data pipelines and models for production deployment and monitoring of performance over time
   


     Embrace and uphold Ibotta’s Core Values of 
    Integrity, Boldness, Ownership, Teamwork, Transparency, & A good idea can come from anywhere




   What we are looking for:
 



     3+ years of progressive experience in a professional data science, machine learning, statistics, or analytics role
   


     Bachelor's degree in Computer Science, Statistics, Data Science or similar field required; Advanced degree strongly preferred
   


     Experience with data analysis tools (e.g., Databricks, SQL Python/R, Spark, Hive, Airflow, Git/GitHub etc.), data pipelines and ETL/ELT processes
   


     Broad foundational skills in developing and applying a variety of machine learning and statistical algorithms, with hands-on experience in several areas of measurement and/or modeling techniques
   


     Demonstrated experience working on all stages of a data science project: scoping and gathering requirements, wrangling and cleaning complex datasets, developing and evaluating alternative technical solutions, productionalize models, and communicating value and insights to both technical and non-technical audiences.
   


     Exposure to release processes (automated testing and code reviews) and prototyping, building, releasing, and monitoring mission-critical models in high traffic applications a big plus
   


     Excellent communication skills in both written and verbal form, including development of data summaries, visualizations and other storytelling methods
   


     Self-motivated, proactive, and able to work effectively both independently and collaboratively in a dynamic, fast-paced environment.
   


     Solid analytical ability, intellectual curiosity, conceptual thinking, and creative problem-solving skills with a drive to go beyond the symptoms of a problem to diagnose root causes
   


     Excellent interpersonal skills with the proven ability to collaborate across functional areas, demonstrate empathy and manage stakeholder expectations and drive projects to completion with senior-level guidance and support
   



   About Us:
 


   Built and headquartered in Denver, Colo., Ibotta (""I bought a..."") is a performance marketing platform that allows brands to deliver digital promotions to millions of consumers through a network of publishers called the Ibotta Performance Network (IPN). Ibotta’s network allows marketers to influence what people buy, and where and how often they shop – all while paying only when their campaigns directly result in a sale.
 


   Guided by our values and our mission to Make Every Purchase Rewarding, we come to work energized by the business problems we get to solve, the technology we build, the innovative people we work (and have fun) with, and the consumers we get to help. To date, we have credited consumers $1.5B.
 







        Ibotta was named to the 2021 Inc. 5000 list of fastest-growing private companies in the U.S. for the fourth year in a row, after debuting on the list in 2018. The company has also been named as a Top Workplace by The Denver Post four consecutive times, made BuiltIn Colorado’s Best Places to Work list three years in a row and appeared on Inc.’s list of Best Workplaces in 2017 and 2023.
      







   To learn more about what our Tech teams are doing day to day, visit 
  
   Building Ibotta on Medium.com
  .
 


   Additional details:
 



     This position is located in Denver, CO and includes competitive pay, flexible time off, benefits package (including medical, dental, vision), Lifestyle Spending Account, 401k match, and equity. Denver office perks include paid parking, bagel Thursdays, snacks and occasional meals.
   


     Base compensation range: $90,000 - $120,000. This compensation range is specific to the United States labor market and may be adjusted based on actual experience. 
   


    Ibotta is an Equal Opportunity Employer. Ibotta’s employment decisions are made without regard of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other legally protected status.
   


     Applicants must be currently authorized to work in the United States on a full-time basis.
   


     For the security of our employees and the business, all employees are responsible for the secure handling of data in accordance with our security policies, identifying and reporting phishing attempts, as well as reporting security incidents to the proper channels.
   



   Recruiting Agency Notice
   Ibotta does not accept agency resumes and is not responsible for any fees related to unsolicited resumes. Please do not forward resumes to any Ibotta employees.
 


   #LI-Hybrid
 

   #BI-Hybrid
 

",90000,"['python', 'machine learning', 'etl', 'sql', 'airflow', 'git']"
"Applied Data Scientist, ML and DL Engineer - Cybersecurity",NVIDIA,VA,Full-time,"

  NVIDIA has been redefining computer graphics, PC gaming, and accelerated computing for more than 25 years. It’s a unique legacy of innovation that’s fueled by great technology—and outstanding people! Today, we’re tapping into the unlimited potential of AI to define the next era of computing. An era in which our GPU acts as the brains of computers, robots, and self-driving cars that can understand the world. Doing what’s never been done before takes vision, innovation, and the world’s best talent. As an NVIDIAN, you’ll be immersed in a diverse, supportive environment where everyone is inspired to do their best work. Come join the team and see how you can make a lasting impact on the world!
 


   NVIDIA is hiring applied data scientists and ML/DL engineers to scale-up its cybersecurity development efforts that span accelerated computing (Morpheus), generative AI, confidential computing, and networking. You will need to have excellent analytical skills, a solid data science foundation, prior experience with data analysis at scale, and excellent communication skills. Together with other specialists, we will advance NVIDIA's capability to build and deploy core frameworks, revolutionizing cybersecurity applications for our customers.
 


   What You'll Be Doing:
 



     Working with a multi-functional team of backend engineers, data engineers, data scientists, and developers to build out cybersecurity SDKs and capabilities, adding critical new use cases and applications that increase out-of-the-box capabilities of SDKs like Morpheus while illustrating the power of the SDK for developers and ISVs
   


     Crafting proof-of-concept workflows rooted in first principles that apply modern data science techniques to security use cases
   


     Migrating prototyped workflows to hardened enterprise ready workflows, creating end-to-end pipelines that are suitable for deployment in production environments
   


     Collaborating with multiple teams (internal and external) to translate cybersecurity requirements and use cases into core functionality
   



   What We Need to See:
 



     BS or MS (or equivalent experience) in Computer Engineering, Computer Science, Data Science, or a closely related field
   


     8+ years of experience in a similar or related role
   


     Proven experience in data science or software development, including common PyData ecosystem toolkits
   


     Strong programming skills in Python, as well as comfort using Linux and typical development tools (e.g., GitHub, Docker)
   


     Great motivation, with strong interpersonal skills and the ability to communicate highly technical concepts with non-technical audiences
   



   Ways to Stand Out from the crowd:
 



     Demonstrated history of contributing to open-source software projects
   


     Prior experience developing ML/DL pipelines that apply deep learning techniques to novel problems
   


     Familiarity with implementing Python unit tests
   


     Previous real-world experiencing developing models for cybersecurity use cases or developing models that apply to data at large scales (TB+)
   


     Experience with ML deployment lifecycle including model monitoring and retraining
   



   Widely considered to be one of the technology world’s most desirable employers, NVIDIA offers highly competitive salaries and a comprehensive benefits package. As you plan your future, see what we can offer to you and your family www.nvidiabenefits.com/.
 
 The base salary range is 176,000 USD - 333,500 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
 







          You will also be eligible for equity and 
         
          benefits
         . 
         NVIDIA accepts applications on an ongoing basis.








 NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

",176000,"['python', 'deep learning', 'docker']"
Manager Data Science (multiple openings) - IHM,Discover Financial Services,IL,Full-time,"Discover. A brighter future. 
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine. 

 Come build your future, while being the reason millions of people find a brighter financial future with Discover. 


Job Description:

Employer: Discover Products Inc 


Job Title: Manager Data Science (multiple openings) 


Job Location: Riverwoods, Illinois 


Job Type: Full Time 


Duties: Provide thought leadership and strategic thinking to solve business problems by leveraging techniques such as segmentation, optimization, advanced analytics, and machine learning. Closely monitor performance metrics and KPIs to ensure goals are met and course correct as necessary. Telecommuting and/or working from home may be permissible pursuant to company policies. 


Requirements: Employer will accept a Bachelor's degree in Business Analytics, Statistics, Mathematics, or a related field and 6 years of experience in Lead Data Science Analyst; Consultant or related occupation. Alternatively, employer will accept a Master's degree in Business Analytics, Statistics, Mathematics, or a related field and 4 years of experience in Lead Data Science Analyst; Consultant or related occupation. 


Position required skills: Six (6) years of progressively responsible experience in the job offered or related occupation with a Bachelor’s degree, OR Four (4) years of experience in the job offered or related occupation with a Master’s degree: utilizing SQL, SAS, and Python to extract and manipulate data, create reports, build machine learning, and forecast models; applying forecasting processes to predict call volume for various lines of businesses; using statistical procedures, including Predictive analytics, Descriptive statistical analysis, Causal analysis, and time series analysis to solve business problems; using Snowflake and cloud platform products to migrate, extract, and manipulate data; and performing data analysis using machine learning and Python. 

 Position eligible for incentives under Employee Referral Program. 


Rate of Pay: The base pay for this position generally ranges between $131,498.00 to $171,500.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position. We also offer a range of benefits and programs based on eligibility. Learn more at MyDiscoverBenefits.com . 


QUALIFIED APPLICANTS: Please apply directly through our website by clicking on “Apply Now.” No calls. Equal Opportunity Employer/disability/vet. 

 What are you waiting for? Apply today! 

 All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management. 

 Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)",131498,"['python', 'machine learning', 'sql']"
Senior Data Analyst,General Dynamics Information Technology,Remote,Full-time,"Clearance Level None Category Data Analysis Location Remote, Working from the USA 


Public Trust: None 
Requisition Type: Regular 
Your Impact 
Own your opportunity to work alongside federal civilian agencies. Make an impact by providing services that help the government ensure the well being of U.S. citizens.
 Job Description

 GDIT is seeking an experienced Senior Data Analyst to work in a dynamic agile team environment. The Data Analyst will be part of a technically diverse Support team supporting Centers for Medicare and Medicaid Services (CMS) via the Integrated Data Repository Support (IDRS) contract. The Integrated Data Repository (IDR) is a high-volume data warehouse integrating Medicare Parts A, B, C, D, and DME claims, Medicaid claims, beneficiary and provider data sources, along with ancillary data such as contract information, risk scores, and many others. Access to this robust integrated data supports a variety of strategic analytics across CMS.

 It’s this team’s vision/goal to support these analytics at CMS through:

 Continuous and improved information sharing with CMS Stakeholders and IDR users
 Simplified User Onboarding and system access processes
 Enhancing data quality and integration with other systems
 Strengthening query and analytic capabilities through constant and iterative enhancements
 Proactive evaluation and testing of tools/services to better support Analytical use cases


 This role is fully remote! 

**Please note: must have experience with Medicare and/or Medicaid data to be considered**

 Responsibilities:

 As a member of the Support team (an Agile Kanban team) the Senior Data Analyst will be responsible for:

 Triaging/investigating user reported issues
 Assisting users with data analysis at varying levels of complexity/use cases
 Addressing data questions and/or data discrepancies
 Debugging user queries and proactively identifying areas for improvements/enhancements
 Collaborating with other business subject matter and technical experts to resolve user questions/issues
 Identifying process improvements and opportunities for automation

 WHAT YOU’LL NEED TO SUCCEED

 Required Skills and Experience:

 Bachelors and 5+ years of experience
 Proficiency with utilizing Medicare and/or Medicaid data to perform analysis required
 Proficiency using Atlassian tools (Confluence, Jira) for task tracking and project documentation
 Familiarity with healthcare claims processes and data
 Extensive SQL experience
 Fundamental Architectural Knowledge of Snowflake


 Preferred Skills and Experience:

 Comfortable developing how-to and other user facing documentation to support the system user base
 Willingness to explore new tools, analyze new data, and in general want to continue expanding skill sets
 Supporting User Training initiatives through content suggestions (based on user support) and/or content development

 GDIT IS YOUR PLACE:

 Full-flex work week to own your priorities at work and at home
 401K with company match
 Comprehensive health and wellness packages
 Internal mobility team dedicated to helping you own your career
 Professional growth opportunities including paid education and certifications
 Cutting-edge technology you can learn from
 Rest and recharge with paid vacation and holidays


 #GDITHealth

",76000,['sql']
Lead Data Scientist - Remote,Symetra Financial,Remote,Full-time,"
Symetra has an exciting opportunity to join our team as a Lead Data Scientist!
 About the role
 As the Lead Data Scientist you will be tasked with solving end-to-end data problems and performs exploratory data analysis to understand relationships and opportunities to influence outcomes. You'll identify business needs and translate them into concrete Data Science outcomes, find relevant sources of data, conduct analysis, modeling, and deliver results to the business. The lead data scientist collaborates across various teams, are intensely curious about data, and champion standard processes across teams.
 What you will do

Translate product and strategy questions into quantifiable metrics.
Apply expertise to capture, query, cleanse/validate, explore, visualize, and model data.
 Take ownership of and supports a broad range of data-driven projects and makes recommendations for future opportunities.
Commit to attaining industry, product, and technical knowledge and self-development.
Partner with collaborators & analytics engineering teams on building out analytics solutions.
Communicate and carries out Data Science standard processes and develops multi-functional partnership.
Mentor junior Data Science team members and promotes analytics and experimentation



 Why work at Symetra
 Here’s what some of our employees have to say about why they work at Symetra:


 “Symetra is a great place if you are looking for the opportunity to contribute, to grow, to be seen and valued.” Vernell K. – Auditor


 “We're big enough to make an impact on the country, but small enough to care and know who you are and what you're contributing to the organization. All new ideas are welcome!” Stephanie F. – VP Customer Service & Operations
 What we offer
 We don’t take a “one-size-fits-all” approach when it comes to our employees. Our programs are crafted to make your life better both at work and at home.

Flexible full-time or hybrid telecommuting arrangements
Plan for your future with our 401(k) plan and take advantage of immediate vesting and company matching up to 6%
Paid time away including vacation and sick time, flex days and ten paid holidays
Give back to your community and double your impact through our company matching
Want more details? Check out our Symetra Benefits Overview

Compensation
 Salary Range: $107,200 - $178,700 plus eligibility for annual bonus program.
 Your experience and skills

Experienced knowledge of SQL and Python or R, or other relevant programming experience.
Understanding of common machine-learning methods as well as full data science project cycle from data and business understanding through data preparation, modeling, validation and deployment.
 Experience using business intelligence and data visualization tools (e.g. Power BI, Tableau) and databases (e.g. Snowflake).
Analytical mind and discernment.
Strong math skills (e.g. statistics, algebra).
Problem-solving proficiency.
 Superb communication and presentation skills

We empower inclusion
 At Symetra, we aspire to be the most inclusive insurance company in the country. We’re building a place where every employee feels valued, respected, and has opportunities to contribute. Inclusion is about recognizing our assumptions, considering multiple perspectives, and removing barriers.
 We accept and celebrate diverse experiences, identities, and perspectives, because lifting each other up fuels thought and builds a stronger, more innovative company. We invite you to learn more about our efforts here.


 Creating a world where more people have access to financial freedom
 Symetra is a national financial services company dedicated to helping people achieve their financial goals and feel confident about the future. In our daily work, we’re guided by the principles of Value, Transparency and Sustainability. This means we provide products and services people need at a competitive price, we communicate clearly and openly so people understand what they’re buying, and we design products—and operate our company—to stand the test of time. We’re committed to showing up for our communities, lifting up our employees, and standing up for diversity, equity and inclusion (DEI). Join our team and help us create a world where more people have access to financial freedom.
 For more information about our careers visit: Symetra.com/Careers


 Work Authorization
 Employer work visa sponsorship and support are not provided for this role. Applicants must be currently authorized to work in the United States at hire and must maintain authorization to work in the United States throughout their employment with our company.


 #LI-ML1
 #REMOTE
",107200,"['python', 'tableau', 'sql']"
Experienced Data Scientist,Principal Financial Group,IA,Full-time,"
 What You'll Do: 
 
   We’re looking for a Data Scientist III and a Senior Data Scientist 1 to join our Benefits and Protection Data and Analytics team. In these roles, you will work on machine learning models to drive business value while being a technical mentor to team members.
 

 Be responsible for complex data science projects that capture and integrate large volumes of data, perform analysis, interpret results, and develop practical insights and recommendations for use across the company.
 Implement standard methodologies and for evaluation, monitoring, and model integrity.
 Act as an internal advisor and expert for data science projects and innovations.
 Partner closely with collaborators to identify needs and deliver data science solutions.
 Coach and mentor junior data scientists and interns on the team


   Operating at the intersection of financial services and technology, Principal builds financial tools that help our customers live better lives. We take pride in being a purpose-led firm, motivated by our mission to make financial security accessible to all. Our mission, integrity, and customer focus have made us a trusted leader for more than 140 years.
  Who You Are: 
 
Graduate degree (M.S.) or Ph.D in a quantitative discipline preferred.
 M.S + 4+ OR Ph.D + 2+ Years professional experience in building machine learning/predictive models.
 Deep knowledge of Statistics, Mathematics, Optimization, Machine Learning theory and quantitative techniques.
 Extensive programming experience in at least one programming language (Python or R). Proficient with machine learning libraries such as SciKit-Learn, SciPy, Keras, Tensorflow, PyTorch etc.
 Experience working with large datasets including structured/unstructured data.
 Knowledge in evaluating and making decisions around the use of new or existing machine learning, data analysis, optimization techniques/tools for a project.
 Experience in model evaluation, tuning and performance.
 Experience with Big Data technologies like Spark and Cloud technologies (AWS, Azure, etc.).
 Passion for picking up new techniques/technologies.
 Self motivated demeanor and desire to work on applied problems.
 Salary Range Information: Salary ranges below reflect targeted base salaries. Non-sales positions have the opportunity to participate in a bonus program. Sales positions are eligible for sales incentives, and in some instances a bonus plan, whereby total compensation may far exceed base salary depending on individual performance. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Salary Range: $106400 - $167000 / year Additional Information: 
 Skills That Will Help You Stand Out 

Data science experience in the insurance industry
 Experience as a technical mentor
 ML (predictive and prescriptive)
 Large language models

 Work Environments

   This role offers in-office, hybrid (blending at least three office days in a typical workweek)
 
 Job level

   We’ll consider talent at the next level with the right experiences and skills.
 
 Work Authorization/Sponsorship 

  At this time, we're not considering applicants that need any type of immigration sponsorship (additional work authorization or permanent work authorization) now or in the future to work in the United States. This includes, but IS NOT LIMITED TO: F1-OPT, F1-CPT, H-1B, TN, L-1, J-1, etc. For additional information around work authorization needs please use the following links.
 
 Nonimmigrant Workers and Green Card for Employment-Based Immigrants

 Investment Code of Ethics 


  For Principal Asset Management positions, you’ll need to follow an Investment Code of Ethics related to personal and business conduct as well as personal trading activities for you and members of your household. These same requirements may also apply to other positions across the organization.
 
 Experience Principal 

  At Principal, we value connecting on both a personal and professional level. Together, we’re imagining a more purpose-led future for financial services – and that starts with you. Our success depends on the outstanding experiences, backgrounds, and talents of our employees. And we support our employees the same way we support our customers: with comprehensive, competitive benefit offerings crafted to protect their physical, financial, and social well-being. Check out our careers site to learn more about our purpose, values and benefits.
 
 Principal is an Equal Opportunity Employer 

  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.
  Posting Window: We will be accepting applications for at least 3 days from when the job was originally posted, after which we may keep open or remove the posting based upon applications we receive. Please submit applications in a timely manner as there is no guarantee the posting will be available beyond 3 days of the original posting date. Date First Posted (TTF): 11/16/2023 
 LinkedIn Hashtag : #LI-EW1
",106400,"['tensorflow', 'pytorch', 'python', 'machine learning', 'aws', 'azure']"
Data Scientist II,RTL Networks,CA,Full-time,"
Position Title: Data Scientist II
Location: San Diego, CA
Salary: $105k - $120k
Status: Full-time
Clearance: Secret
Required Certification(s): Possesses active relevant industry data scientist/data security certification.
About Us: RTL Networks, Inc. is a rapidly growing company primarily focused on providing information technology (IT) support services and personnel to a variety of commercial and government customers for long term contracts. By providing a wide array of professional services and products, we help our customers leverage technology and operate with total confidence in the predictability, security, and reliability of their technology resources to meet business objectives.
Summary:
RTL Networks is searching for a Mid-level Data Scientist (Data Scientist II) to support an upcoming effort at NAVWAR HQ in downtown San Diego. Data Scientists develop and implement a set of techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. The ideal candidate will have existing experience with US Navy or other DoD environments and applications.
Primary Responsibilities:

Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets.
Collaborate with cross-functional teams to understand business objectives and data requirements, and translate them into data-driven solutions.
Apply advanced statistical and mathematical concepts to analyze complex datasets and extract meaningful insights.
Develop and implement machine learning models to predict trends, identify patterns, and solve business challenges.
Utilize programming languages such as Python and R, along with relevant packages, for data analysis and modeling.
Employ data science techniques, data mining, statistics, and graph algorithms to support analytics objectives.
Apply structured query language (SQL), non-structured query language (NoSQL), and other data manipulation techniques.
Create and maintain data pipelines, integrate APIs, and interact with web application servers and search indexes.
Collaborate with IT teams to integrate data science solutions into business processes.
Present findings and insights to stakeholders through compelling visualizations and reports.

Qualifications:

Bachelor's degree in Cybersecurity, Computer, Electrical, or Electronics Engineer, or Mathematics with a concentration in computer science or equivalent.
Three (3) years of recent professional experience in data science.
DoD Secret Security Clearance.
Experience with software integration or testing, including analyzing and implementing test plans and scripts.
Experience with frequent scripting language use, such as Python and R and using packages commonly used in data science applications or advanced analytics.
Experience with data science, data mining, statistics, or graph algorithms to support analytics objectives.
Experience applying Structured Query Language (SQL), Non Structured Query Language (NoSQL), Application Program Interface (API) Building, Extract, Transform, and Load (ETL) pipelines, Web Application Servers, or Search Index.
Experience using programming languages and products such as Python, Jupyter Notebook, Pandas, Numpy, Requests, or Antigravity.
Experience applying complex mathematical and statistical concepts.
Experience applying statistical and operations research methods and tools.
Experience employing spreadsheets for data manipulation and visualization.
Possesses active relevant industry data scientist/data security certification, such as: Comp TIA Cloud Essentials; Microsoft Technical Associate (MTA); Certificate of Cloud Security (CCSK); CompTIA Security+; EMC Data Science Associate (EMCDSA); Cloudera Certified Data Scientists (CCDH); Certified Apache Hadoop Developer (HCAHD); Certified Information System Security Professional (CISSSP); Certified Cloud Professional (CCP); Microsoft Certified Professional Developer (MCPD); Microsoft Certified Solution Developer (MCSD); Microsoft Certified Solution Expert (MCSE); Private Cloud; Certified Administrator for Apache Hadoop (CCAH),

Preferred Qualifications:
Relevant industry certifications such as:

CompTIA Cloud Essentials/Microsoft Technical Associate (MTA)/Certificate of Cloud Security (CCSK)/CompTIA A+/CompTIA Security+/EMC.
Data Science Associate (EMCDS)/Cloudera Certified Data Scientist (CCDH)/Certified Apache Hadoop Developer (HCAHD) (Hortonworks)/Certified Information System Security Professional (CISSP)/Certified Cloud Professional (CCP).
(Cloudera)/Microsoft Certified Professional Developer.
(MCPD/Microsoft Certified Solution Developer.
(MCSD)/Microsoft Certified Solution Expert.
(MCSE)/Private Cloud/Certified Administrator for Apache Hadoop.
(CCAH) (Cloudera).

NOTE:

Applicant selected for this position must have a current security clearance.
U.S. Citizenship required.
Chosen applicants will be required to pass pre-employment drug screening and a criminal background check.
Copies of certifications are required.


RTL Networks, Inc., is proud to be an Equal Opportunity/Affirmative Action Employer making decisions without regard to, age 40 and over, color, disability, gender identity, genetic information, military or veteran status, national origin, race, religion, sex, sexual orientation or any other applicable status protected by state or local law.

",105000,"['python', 'numpy', 'pandas', 'machine learning', 'nosql', 'etl', 'sql', 'hadoop']"
Interdisciplinary Computer Scientist/Computer Engineer/Data Scientist,US Office of the Secretary of Defense,VA,Full-time,"

Duties
This position is a DoD Cyber Excepted Service (CES) personnel system position in the Excepted Service under 10 U.S.C. 1599f.   This position is in the Excepted Service and does NOT convey eligibility to be converted to the Competitive Service. It is being recruited under 10 U.S.C. 1599f into the Cyber Excepted Service (CES) personnel system.   If you are a current Federal Career/Career-Conditional employee, you will be placed on an Excepted appointment.   This appointment does not confer eligibility to be non-competitively converted to an appointment in the competitive service.  For more information see https://public.cyber.mil/cw/dod-cyber-excepted-service-ces/  Incumbents typical work assignments may include the following: 

Serves as a Technical Product Manager in the Executive Decision Support Division incorporating Data, Machine Learning (ML), Artificial Intelligence (AI), and product management principles.
Provides technical expertise in current-market technologies that accelerate business analytics insights and drive decision advantage.
Develops the CDAO technical product strategy and leads its implementation, management, and lifecycle planning.
Works with external stakeholders to align technical requirements to product roadmaps and lead delivery of those products.
Collaborates through technical leadership within DCAO Divisions and manages external partnerships with DoD, Industry, and Academic partnerships.




Requirements
Conditions of Employment

U.S. Citizenship is required.
Males born after 12-31-59 must be registered or exempt from Selective Service (see https://www.sss.gov/Home/Registration).
A three year trial period may be required if not previously completed a trial or probationary period in the excepted or competitive service.
Must be determined suitable for federal employment.
Required to participate in the direct deposit program.
This position is subject to pre-employment and random drug testing.
This position is being recruited under 10 USC 1599f into the Cyber Excepted Service and does NOT convey eligibility to be converted to the Competitive Service.
For more information on the Cyber Excepted Service Personnel System, click here https://public.cyber.mil/cw/dod-cyber-excepted-service-ces/.
Must be able to obtain and maintain a Top Secret security clearance.
The employee may be required to work other than normal duty hours, which may include evenings, weekends, and/or holidays and/ or overtime.
The employee may be required to work other than normal duty hours, which may include evenings, weekends, and/or holidays and/ or overtime.
Work may occasionally require travel away from the normal duty station on military or commercial aircraft.


Qualifications


Applicant must have directly applicable experience that demonstrates the possession of knowledge, skills, abilities, and competencies necessary for immediate success in the position. Qualifying experience may have been acquired in any public or private sector job, but will clearly demonstrate past experience in the application of the particular competencies or knowledge, skills, and abilities necessary to successfully perform the duties of the position. Such experience is typically in or directly related to the work of the position to be filled.


Transcripts for Basic Requirement: Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.
     

Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.

 

Basic Requirements:


For the GG-0854 Professional Engineering Series: Degree: professional engineering. To be acceptable, the curriculum must: (1) be in a school of engineering with at least one curriculum accredited by the Accreditation Board for Engineering and Technology (ABET) as a professional engineering curriculum; or (2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statistics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics.
     

For the GG-1550 Computer Science Series: Bachelor's degree in computer science or bachelor's degree with 30 semester hours in a combination of mathematics, statistics, and computer science.
     

At least 15 of the 30 semester hours must have included any combination of statistics and mathematics that included differential and integral calculus. All academic degrees and course work must be from accredited or pre-accredited institutions.
     

For the GG-1560 Data Science Series: Bachelor's degree in mathematics, statistics, computer science, data science or field directly related to the position with 30 semester hours in a combination of mathematics, statistics, and computer science.
     

At least 30 semester hours must have included any combination of statistics and mathematics that included differential and integral calculus. All academic degrees and course work must be from accredited or pre-accredited institutions.
     

You may qualify at the GG-14 level, if you fulfill the following qualification requirement:


One year of specialized experience equivalent to the GG-13 grade level in the Federal service (experience may have been gained in the private sector) that demonstrates your experience developing and applying principles, theories, and techniques of computer science, software engineering, enterprise computing, commercial cloud adoption, and information engineering to research, develop, identify, and infuse new methodologies and technologies into organizational architecture and design.

 Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.
    

ACTIVE DUTY SERVICE MEMBERS: The VOW Act Chapter 21 of Title 5, United States Code (U.S.C.), Section 2108a, requires Federal agencies treat active duty service member as veterans, disabled veterans, and preference eligible, when they submit, at the time they apply for a Federal job, a ""certification"" of active service in lieu of a DD-214, assuming the service member is otherwise eligible. A ""certification"" letter should be on letterhead of the appropriate military branch of the service and contain (1) the military service dates including the expected discharge or release date; and (2) the character of service. The service member's military service dates are necessary in order to determine whether he or she meets the definition of ""veteran"" under 5 U.S.C. 2108(1). The ""certification"" must reflect the service member is expected to be discharged or released from active duty service in the armed forces under honorable conditions not later than 120 days after the date of submission. The ""certification"" must be signed by, or by direction of, the adjutant, personnel officer, or commander of your unit or higher headquarters and must indicate when your terminal leave will begin (if applicable), your rank, dates of active duty service, the type of discharge and character of service (i.e. honorable). Further, under paragraph (h) of the rule, agencies are required to verify a qualifying separation from military service prior to appointment, through the DD-214 or other appropriate documentation. Your preference and/or appointment eligibility will be verified prior to appointment. Active duty members that fail to provide a valid ""certification"" of service with their initial application will be found ""not eligible."" Military members may be appointed before the effective date of their military retirement/separation if member is on terminal leave.
    

Current or Former Political Appointees: Beginning January 1, 2010, agencies must seek prior approval from OPM before they can appoint a current or recent political appointee to a competitive or non-political excepted service position at any level under the provisions of title 5, United States Code. If you are currently or have been within the last 5 years, a political Schedule A, Schedule C, or Non-career SES employee in the executive branch, you MUST disclose that to the Human Resources Office. Submit a copy of your applicable SF-50, along with a statement that provides the following information regarding your most recent political appointment: 
    
Position title;
Type of appointment (Schedule A, Schedule C, Non-career SES, or Presidential Appointee);
Agency; and,
Beginning and ending dates of appointment.

All qualifications requirements must be met by the closing date of this announcement and clearly documented in your resume.



Education
Education cannot be substituted for experience. 


Additional information

MILITARY SPOUSE PREFERENCE: Military spouse preference applicants are required to apply to job announcement via USAJobs in order to exercise their preference status. The application must include signed Military Spouse PPP Self-Certification Checklist, Marriage Certificate or License, Sponsor's PCS orders at the time of application to be considered  Other priority consideration programs will continue under their current operating procedures.  A tentative offer of employment will be rescinded if the selectee fails to meet the pre-employment requirements, including failure to report to any of the scheduled appointments.  If you are unable to apply online, you must request an alternative application. Please view the following link for information on how to obtain an alternative application https://help.usastaffing.gov/Apply/index.php?%20title=Alternate_Application_Information  Appointment Authorities: For more information on appointment authority eligibility requirements: 

https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/individuals-with-disabilities/
https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/veterans/
https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/military-spouses/
Other Special Appointment Authorities https://www.usajobs.gov/
Interchange Agreements https://www.opm.gov/policy-data-oversight/hiring-information/competitive-hiring/#url=Types-of-Appointments

Employed Annuitants (Reemployed Annuitants): Applicants in receipt of an annuity based on civilian employment in the Federal Service are subject to the DoD Policy on The Employment of Annuitants. /www.esd.whs.mil/DD/DoD-Issuances/140025/
    

Nepotism: Under the provisions of 5 USC 3110, an individual may not be appointed into a position if the position is under the supervisory chain of command of a relative.
    

Additional vacancies may be filled by this announcement.
    





Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.
Once the announcement has closed, a review of your résumé and supporting documentation will be used to determine whether you meet the qualification requirements listed on this announcement. If you are minimally qualified, your résumé and supporting documentation will be compared against your responses to the assessment questionnaire to determine your level of experience. If, after reviewing your résumé and/or supporting documentation, a determination is made that you have inflated your qualifications and/or experience, you may lose consideration for this position. Please follow all instructions carefully when applying, errors or omissions may affect your eligibility. 

Communication
 Engineering and Technology
 Systems Testing and Evaluation
 Technical Competence


 Applicants who disqualify themselves will not be evaluated further. 
  




Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
YOU ARE REQUIRED TO DOCUMENT IN YOUR APPLICATION PACKAGE EVIDENCE THAT SUPPORTS YOUR ELIGIBILITY AND QUALIFICATION CLAIMS. You MUST upload the applicable documents with your application package. If you fail to provide these documents, you will be marked as having an incomplete application package and you will not be considered any further.  1. Your resume may be submitted in any format that includes your name and contact information (telephone number and/or email). If you submit more than one copy of your resume, only the most recent version will be reviewed. The latest timestamp will be used to determine which version of your resume is ""most recent.""  If your resume includes a photograph or other inappropriate material or content, it will not be used to make eligibility and qualification determinations and you will not be considered for this vacancy.  For qualifications determinations, it is recommended that applicants include their months and hours worked per week for each employment listed on their resume. If a determination is not able to be made about the length of your creditable experience for qualification requirements, you will be removed from consideration. about what you should include in your federal resume at https://www.usajobs.gov/Help/faq/application/documents/resume/what-to-include/  2. Other supporting documents: 

Cover Letter, optional
Most recent SF-50, ""Notification of Personnel Action"" showing you are/were in the competitive or excepted service and the highest grade held (WHS serviced employees SF-50s will be verified via eOPF).
College transcripts - Required. Official or unofficial transcripts are acceptable. (WHS serviced employees will be verified via eOPF or you may include them in your application package. However, it is the employee's responsibility to ensure that his/her eOPF contains the required transcript and is up-to-date).
DD-214, SF-15 Form and VA letter, or certification of expected discharge or release from active duty from Veterans for consideration under Veteran hiring authorities
Noncompetitive appointment authority documentation, if applicable
PPP Registrants/Eligibles: Must submit the following applicable documents: 1) PPP registration 2) PCS orders (if applicable)

ARE YOU A VETERAN CLAIMING SOLE SURVIVORSHIP PREFERENCE OR 5-POINT VETERANS' PREFERENCE?
 1. You must provide legible copy/copies of the following: DD-214, ""Certificate of Release or Discharge from Active Duty,"" showing all dates of service, as well as type of discharge and character of service (Honorable, General, etc.) or Statement of Service/Proof of Service (in lieu of a DD-214) from your command or local Personnel Support Detachment (PSD). The Statement of Service/Proof of Service must provide all dates of service, the expected date of discharge and anticipated character of service (Honorable, General, etc.). Veterans should upload their DD-214 once they receive it upon separation.
     
 2. You should also document your complete military service information in the Veterans Preference and Military Service Section of the assessment questionnaire (type of preference, dates of service, date of VA letter, character of service, disability claim and rank and date of retirement if retired).
     

ARE YOU A DISABLED VETERAN or CLAIMING 10-POINT VETERANS' PREFERENCE?
 1. Disabled veterans, veterans, widows, spouses or the mother of a veteran, who are eligible for 10-point veterans' preference, you must provide legible copies of the following: Applicable supporting documents as noted on Standard Form-15 (SF-15). To obtain a copy of SF-15, go to: https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/veterans/
     

DoD Components with CES positions apply Veterans' Preference to preference eligible candidates, as defined by Section 2108 of Title 5 U.S.C, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 3005, ""CES Employment and Placement."" If you are a veteran claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you must submit documents verifying your eligibility with your application package. 


How to Apply


To apply for this position, you must complete the online application and submit the documentation specified in the Required Documents section below.  A complete application package must be submitted by 11:59 PM (EST) on the closing date of the announcement (11/21/2023) to receive consideration. 

To begin, click Apply to access the online application. You will need to be logged into your USAJOBS account to apply. If you do not have a USAJOBS account, you will need to create one before beginning the application.
Follow the prompts to select your résumé and/or other supporting documents to be included with your application package. You will have the opportunity to upload additional documents to include in your application before it is submitted. Your uploaded documents may take several hours to clear the virus scan process.
After acknowledging you have reviewed your application package, complete the Include Personal Information section as you deem appropriate and click to continue with the application process.
You will be taken to the online application which you must complete in order to apply for the position. Complete the online application, verify the required documentation is included with your application package, and submit the application.
To view the assessment questionnaire, click here: https://apply.usastaffing.gov/ViewQuestionnaire/12166398
To verify the status of your application, log into your USAJOBS account (https://my.usajobs.gov/Account/Login) all of your applications will appear on the Welcome screen. The Application Status will appear along with the date your application was last updated. For information on what each Application Status means, visit: https://www.usajobs.gov/Help/how-to/application/status/.
      
 You are encouraged to apply online. Applying online will allow you to review and track the status of your application.
      
 Failure to submit a complete application package will result in an ineligible rating and loss of consideration.
       Do not email or send hard copy resumes/applications to the Contact Information or Agency Information listed in this vacancy announcement. All resumes/applications received at the addresses listed in the Contact Information or Agency Information will be destroyed and will not be considered for this vacancy announcement.
      

It is the applicant's responsibility to verify that all information in their resume and documents are legible and accurate. HR will not modify answers/documents submitted by an applicant.

 Washington Headquarters Services provides reasonable accommodations to applicants with disabilities. If you need a reasonable accommodation for any part of the application and hiring process, please view the ""Alternate Application"" method listed in the ""Other Information"" section of this announcement. Your requests for reasonable accommodation will be addressed on a case-by-case basis. Please visit the following link for more information http://http://www.esd.whs.mil/Directives/issuances/admin_inst/
      


Agency contact information
Washington HQ Services 


Phone
000-000-0000 
Email
whs.job.application.assistance@mail.mil 


Address


Chief Digital and Artificial Intelligence Office

4800 Mark Center Drive

Alexandria, VA 22350

US 




Next steps

Once your online application is submitted you will receive a confirmation notification by email. Your application will be evaluated by the Human Resources Office to determine your eligibility for the position. After the evaluation is complete, you will receive another notification regarding the status of your application.  Stay informed of changes to your application status by signing up for automatic email alerts at: https://www.usajobs.gov/Applicant/Application/ListApplications?  Washington Headquarters Services is an Equal Employment Opportunity employer. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents

YOU ARE REQUIRED TO DOCUMENT IN YOUR APPLICATION PACKAGE EVIDENCE THAT SUPPORTS YOUR ELIGIBILITY AND QUALIFICATION CLAIMS. You MUST upload the applicable documents with your application package. If you fail to provide these documents, you will be marked as having an incomplete application package and you will not be considered any further.  1. Your resume may be submitted in any format that includes your name and contact information (telephone number and/or email). If you submit more than one copy of your resume, only the most recent version will be reviewed. The latest timestamp will be used to determine which version of your resume is ""most recent.""  If your resume includes a photograph or other inappropriate material or content, it will not be used to make eligibility and qualification determinations and you will not be considered for this vacancy.  For qualifications determinations, it is recommended that applicants include their months and hours worked per week for each employment listed on their resume. If a determination is not able to be made about the length of your creditable experience for qualification requirements, you will be removed from consideration. about what you should include in your federal resume at https://www.usajobs.gov/Help/faq/application/documents/resume/what-to-include/  2. Other supporting documents: 

Cover Letter, optional
Most recent SF-50, ""Notification of Personnel Action"" showing you are/were in the competitive or excepted service and the highest grade held (WHS serviced employees SF-50s will be verified via eOPF).
College transcripts - Required. Official or unofficial transcripts are acceptable. (WHS serviced employees will be verified via eOPF or you may include them in your application package. However, it is the employee's responsibility to ensure that his/her eOPF contains the required transcript and is up-to-date).
DD-214, SF-15 Form and VA letter, or certification of expected discharge or release from active duty from Veterans for consideration under Veteran hiring authorities
Noncompetitive appointment authority documentation, if applicable
PPP Registrants/Eligibles: Must submit the following applicable documents: 1) PPP registration 2) PCS orders (if applicable)

ARE YOU A VETERAN CLAIMING SOLE SURVIVORSHIP PREFERENCE OR 5-POINT VETERANS' PREFERENCE?
 1. You must provide legible copy/copies of the following: DD-214, ""Certificate of Release or Discharge from Active Duty,"" showing all dates of service, as well as type of discharge and character of service (Honorable, General, etc.) or Statement of Service/Proof of Service (in lieu of a DD-214) from your command or local Personnel Support Detachment (PSD). The Statement of Service/Proof of Service must provide all dates of service, the expected date of discharge and anticipated character of service (Honorable, General, etc.). Veterans should upload their DD-214 once they receive it upon separation.
   
 2. You should also document your complete military service information in the Veterans Preference and Military Service Section of the assessment questionnaire (type of preference, dates of service, date of VA letter, character of service, disability claim and rank and date of retirement if retired).
   

ARE YOU A DISABLED VETERAN or CLAIMING 10-POINT VETERANS' PREFERENCE?
 1. Disabled veterans, veterans, widows, spouses or the mother of a veteran, who are eligible for 10-point veterans' preference, you must provide legible copies of the following: Applicable supporting documents as noted on Standard Form-15 (SF-15). To obtain a copy of SF-15, go to: https://www.usajobs.gov/Help/working-in-government/unique-hiring-paths/veterans/
   

DoD Components with CES positions apply Veterans' Preference to preference eligible candidates, as defined by Section 2108 of Title 5 U.S.C, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 3005, ""CES Employment and Placement."" If you are a veteran claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you must submit documents verifying your eligibility with your application package.






 Help 
 This job is open to




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.




Veterans




Clarification from the agency
This announcement is open to the Public.

",132368,['machine learning']
Postdoctoral Scientist - Tatonetti Lab - Data-Driven Precision Pharmacology,CEDARS-SINAI,CA,Full-time,"
Join us as we translate today's discoveries into tomorrow's medicine!
The Postdoctoral Scientist in the Tatonetti Lab at Cedars-Sinai will create and lead research to improve drug safety by leveraging clinical and molecular data. In the Tatonetti Lab we use advanced data science methods, including artificial intelligence and machine learning, to investigate drug safety, drug-drug interactions, and cancer pharmacology. Using emerging resources, such as electronic health records (EHR) and genomics databases, we are working to advance the science of pharmacology with a focus on serving traditionally underrepresented populations.
To learn more, visit TLab – Data-Driven Drug Safety (tatonettilab.org).
Are you ready to be a part of breakthrough research?
Working independently but in close cooperation and in consultation with the Dr. Tatonetti and other Research Scientists, the Postdoctoral Scientist will perform routine and complex laboratory procedures throughout training period. May develop, adapt, and implement new research techniques and protocols. Analyzes and interprets data. May assist in preparation of grant proposals. Participates in publications and presentations as author or co-author. Not responsible for generating grant funds.
Primary Duties and Responsibilities:

May assist in the preparation of grant proposals, but is not responsible for generating grant funds.
May participate in publications and presentations as author or co-author.
Designs and performs experiments. Will keep appropriate experimental records and documentation and analyze the results with the PI.
Analyzes, interprets, summarizes, and compiles data.
Operates and maintains equipment and instruments.
May observe MD-patient or MD-human research subject interactions as it pertains directly to the research being performed.


Education:

Doctorate (MD, PhD, VMD, or DDS) in area directly related to field of research specialization. 

Experience and Skills:

Acquires thorough technical and theoretical knowledge of research project and objectives during one to five (1-5) year post-doctoral appointment.
Works independently on research projects designed by a mentor (typically the PI) within the area of specialization.
Demonstrated aptitude to perform experimental protocols and procedures, including detailed data collection, and analysis, operation and maintenance of specialized equipment.
Excellent written and oral communication skills are essential.
Knowledge of safety standards.


Working Title: Postdoctoral Scientist - Tatonetti Lab - Data-Driven Precision Pharmacology
 
Department: Computational BioMedicine
 
Business Entity: Cedars-Sinai Medical Center
 
Job Category: Academic/Research
 
Job Specialty: Postdoctoral
 
Position Type: Full-time
 
Shift Length: 8 hour shift
 
Shift Type: Day
 
Base Pay:$64,500.00 - $93,600.00
",64500,['machine learning']
Data Engineer,Booz Allen Hamilton,IL,Full-time,"


Job Description










         Location: 
        

         O'Fallon,IL,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184977
        


















         Data Engineer
          The Opportunity: 
Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there’s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need a data professional like you to help our clients find answers in their big data to impact important missions from fraud detection to cancer research, to national intelligence.

 As a big data engineer at Booz Allen, you’ll use your skills and experience to implement data engineering activities on some of the most mission-driven projects in the industry. You’ll develop and deploy the pipelines and platforms that organize and make disparate data meaningful.

 Here, you’ll work with a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You’ll sharpen your skills in analytical exploration and data examination while you support the assessment, design, development, and maintenance of scalable platforms for your clients.

 Work with us to use big data for good.

 Join us. The world can’t wait.

 You Have:

 2+ years of experience utilizing programming languages, including C++, Java, or Python
 2+ years of experience developing and maintaining scalable data stores that supply big data in forms needed for business analysis
 Experience creating software for retrieving, parsing, and processing structured and unstructured data
 Experience developing scalable ETL and ELT workflows for reporting and analytics
 Experience creating solutions within a collaborative, cross-functional team environment
 Ability to develop scripts and programs for converting various types of data into usable formats and support project team to scale, monitor, and operate data platforms
 Secret clearance
 Bachelor’s degree


 Nice If You Have:

 Experience in application development utilizing SQL or Scala
 Experience with data visualization technologies, including Tableau, PowerBI, QlikSense, Grafana, or Kibana
 Experience with a public cloud, including AWS, Microsoft Azure, or Google Cloud
 Experience with distributed data and computing tools such as Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka
 Experience working on real-time data and streaming applications
 Experience with NoSQL implementation using MongoDB or Cassandra
 Experience with data warehousing, including AWS Redshift, MySQL, or Snowflake
 Experience with UNIX or Linux, including basic commands and Shell scripting
 Experience with Agile engineering practices
 TS/SCI clearance with a polygraph


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",58300,"['python', 'machine learning', 'tableau', 'aws', 'azure', 'mysql', 'nosql', 'etl', 'sql', 'kafka', 'hadoop']"
"Data Scientist III, Walmart Data Ventures",Walmart,CA,Full-time,"
Position Summary...


What you'll do...

 Walmart Data Ventures operates with the agility of a nimble startup, dedicated to creating the best-in-class suite of Data Products. Walmart Luminate is the first product, which has been created to deliver actionable, customer-centric insights, empowering CPGs and Walmart merchants make data-driven decisions in a smarter, faster, and collaborative manner.
 
 As 
 Data Scientist III in the team, you will join our Customer Support and Experience team, playing a pivotal role in leveraging modern AI and ML methods to enhance the efficiency of our internal L1/L2/L3 support teams and improve the overall experience for Luminate users. You will be responsible for developing utilities and self-serve tools powered by Generative AI and other machine learning techniques. We are looking for candidates with a solid understanding of deep learning, particularly in the context of Natural Language Processing (NLP), and prior experience in building applications powered by modern Generative AI technologies.
 

About the Team: 

 Data Ventures exists to unlock the full value of Walmart's data by developing and productizing B2B data initiatives that empower merchants and suppliers to make better, faster decisions for the business. As part of this transformation, we're seeking entrepreneurial individuals to help drive data productization from concept to deployment.
 

What You'll Do:


 Collaborate with cross-functional teams (including our support teams) to identify opportunities for AI and ML solutions that enhance customer support efficiency and user experience.
 Develop and implement machine learning models, particularly focusing on deep learning and NLP, to address complex challenges.
 Build applications and tools that leverage Generative AI technologies to enhance user experience and support team operations.
 Stay up to date with the latest developments in AI and machine learning to ensure the team remains at the forefront of technology.
 Embrace a ""fail fast"" mentality by rapidly prototyping solutions and iterating on ideas to find innovative solutions.
 Continuously experiment and iterate on AI models and applications to improve their performance.
 Follow industry best practices, stay current with the latest development tools, technology ideas, patterns, and methodologies; drive innovation by contributing towards publications and patents; share knowledge by clearly articulating results and ideas to key stakeholders.
 Participate in internal technical councils and represent the organization in forums that involve community of data scientists and analysts across industry and academia.
 Promote and support company policies, procedures, mission, values, and standards of ethics and integrity.
 Communicate complex models, analysis and recommendations in a clear and precise manner.
 Manage priorities between research and deliverables effectively.


 What you'll Bring...


 Atleast 3+ years of experience in AI/ML with Computer Science or statistics or engineering or related field
 Strong understanding of deep learning concepts and their applications in NLP.
 Prior experience in building applications powered by modern generative AI technologies.
 Excellent problem-solving skills and a demonstrated ability to apply AI/ML techniques to real-world problems.
 Strong growth mindset and a passion for staying updated with the latest developments in the AI/ML community.
 Excellent communication and collaboration skills.

 The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.
 

About Global Tech

 Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered.
 
 We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.
 

Flexible, hybrid work

 We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.
 

Benefits & Perks:

 Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.
 

Equal Opportunity Employer:

 Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.
 
 At Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.
 
 You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .
 
 Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.
 
 Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .
 
 The annual salary range for this position is $117,000.00-$234,000.00
 
 Additional compensation includes annual or quarterly performance incentives.
 
 Additional compensation for certain positions may also include:
 


Regional Pay Zone (RPZ) (based on location)



Stock equity incentives


 Minimum Qualifications... 

 Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.
 
 Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics or related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field. Option 3: 4 years' experience in an analytics or related field.
 

Preferred Qualifications... 

 Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.
 
 Data science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)
 

Primary Location... 
 640 W California Avenue, Sunnyvale, CA 94086-4828, United States of America
",117000,"['tensorflow', 'python', 'machine learning', 'deep learning']"
"Generative AI Strategist, Senior",Booz Allen Hamilton,MD,Full-time,"


Job Description










         Location: 
        

         Bethesda,MD,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184858
        


















         Generative AI Strategist, Senior
          The Opportunity:
 Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there’s more structured and unstructured data available today than ever before. As a data strategist, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need a data professional like you to help our clients find answers in their big data to impact important missions from fraud detection to cancer research, to national intelligence.

 As a data strategist, you will work directly with government senior leadership and use your skills and experience to drive organization transformation, process improvement, data management, and data engineering activities on some of the most mission-driven projects in the industry. Your work will shape critical functional processes that develop and deploy data pipelines and platforms, making disparate data available and meaningful. You’ll work with a multi-disciplinary team of strategists, analysts, data engineers, data scientists, software developers, and data consumers in a fast-paced, Agile environment. You’ll sharpen your skills in analytical exploration and data examination while you support the assessment, design, development, and maintenance of scalable data platforms for your clients. Work with us to solve real-world data challenges for critical customer missions across the firm.

 Join us. The world can’t wait.

 You Have:

 5+ years of experience with data management consulting, including data management, data science, product or program management, or data analytics initiatives
 2+ years of experience with developing and implementing data standards, practices, and processes that improved data integrity and availability
 Experience with Artificial Intelligence (AI) and Data Science solutions, including ML or NLP tools, generative technologies, model development, data engineering, or strategic data planning
 Experience with business development activities, including developing and executing technical and business strategies
 Experience in interacting with customers and clients to understand their needs and present products and solutions
 Experience with creating solutions within a collaborative, cross-functional team environment
 Ability to comprehend business issues and data challenges quickly, and track multiple high-priority initiatives
 Ability to obtain a security clearance
 Bachelor’s degree


 Nice If You Have: 

Experience with a public Cloud, including AWS, Microsoft Azure, or Google Cloud
 Experience with common data programming languages, including SQL, Python, or R
 Experience with common data analytics and business intelligence tools, including Microsoft Excel, Tableau, or Qlik
 Experience with managing projects or programs
 Possession of excellent organizational skills
 Possession of excellent oral and written communication skills, including communicating complex technical and business concepts to leaders, key stakeholders, and team members in technical and non-technical roles
 Top Secret clearance
 PMP Certification


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:
 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",93300,"['python', 'machine learning', 'tableau', 'aws', 'azure', 'sql']"
AI Data Engineer,LPL Financial,CA,Full-time,"
Job Overview:
 We are looking for an experienced AI Data Engineer to join the AI Labs team, a team of data and technology professionals who build and operationalize complex machine learning models for LPL Financial. The successful candidate will build solutions using state of the art technologies to implement production grade for successful model deployment.

 As a AI Data Engineer, you will partner with a cross-functional team of experts to design, build and deploy machine learning models that solve real world business problems and that scale to handle the breadth of our business.

 Responsibilities:

 Design and develop data and machine learning pipelines to automate data ingestion, model training, data and model monitoring.
 Build robust data pipelines on Cloud using Airflow, Glue, Spark/EMR, Kinesis, Kafka, Lambda or other technologies
 Build sagemaker pipelines to incorporate and automate data and model quality, bias checks and model explainability.
 Create ML models using the Sagemaker suite of tools that address business problems and opportunities with high degree of a quality and confidence.
 Ensure all data design and model architecture align with enterprise standards.
 Work across business, product and technical teams to deliver solutions that drive commercial impact.


 What are we looking for?
 We want strong collaborators who can deliver a world-class client experience. We are looking for people who thrive in a fast-paced environment, are client-focused, team oriented, and are able to execute in a way that encourages creativity and continuous improvement.
 Requirements:

 BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
 3+ years of experience of Machine Learning/Deep Learning frameworks, libraries, data structures, and data modeling.
 2+ years programming experience in Python and Spark
 1+ years’ experience with AWS Sagemaker suite of tools
 Demonstrated track record of delivering business value using data science.
 Ability to clearly explain ML concepts to business users and articulate how they impact solutions.


 Preferences:

 Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
 Experience in CI/CD pipeline and code repositories like GitHub or Bit Bucket
 DevOps experience with Terraform
 Experience using JIRA and Agile Project Management software
 Oracle
 Batch Processing
 Informatica
 C#
 Nice to have experience with microservice development, Docker, Kubernetes
 Hands-on experience in BI Tools like Tableau, Power BI


 Pay Range: $131,200-$196,800/year
 
 Actual base salary varies based on factors, including but not limited to, relevant skill, prior experience, education, base salary of internal peers, demonstrated performance, and geographic location. Additionally, LPL Total Rewards package is highly competitive, designed to support your success at work, at home, and at play – such as 401K matching, health benefits, employee stock options, paid time off, volunteer time off, and more. Your recruiter will be happy to discuss all that LPL has to offer!
 
 Why LPL? 

At LPL, we believe that objective financial guidance is a fundamental need for everyone. As the nation’s leading independent broker-dealer, we offer an integrated platform of proprietary technology, brokerage, and investment advisor services. We provide you with a work environment that encourages your creativity and growth, a leadership team that is supportive and responsive, and the opportunity to create a career that has no limits, only amazing potential.

 We are one team on one mission. We take care of our advisors, so they can take care of their clients.

 Because our company is not too big and not too small, you can seize the opportunity to make a real impact. We are committed to supporting workplace equality, and we embrace the different perspectives and backgrounds of our employees. We also care for our communities, and we encourage our employees to do the same. This creates an environment in which you can do your best work.

 Want to hear from our employees on what it’s like to work at LPL? Watch this!

 We take social responsibility seriously. Learn more here

 Want to see info on our benefits? Learn more here

 Join the LPL team and help us make a difference by turning life’s aspirations into financial realities. Please log in or create an account to apply to this position. Principals only. EOE.

 Information on Interviews:

 LPL will only communicate with a job applicant directly from an @lplfinancial.com email address and will never conduct an interview online or in a chatroom forum. During an interview, LPL will not request any form of payment from the applicant, or information regarding an applicant’s bank or credit card. Should you have any questions regarding the application process, please contact LPL’s Human Resources Solutions Center at (800) 877-7210.

",131200,"['python', 'machine learning', 'deep learning', 'tableau', 'aws', 'docker', 'airflow', 'kafka']"
Senior AI Engineer,LPL Financial,CA,Full-time,"
Job Overview:
 We are looking for an experienced Sr. AI Engineer to join the AI Labs team, a team of data and technology professionals who build and operationalize complex machine learning models for LPL Financial. The successful candidate will build solutions using state of the art technologies to implement production grade for successful model deployment.

 As a Sr. AI Engineer, you will partner with a cross-functional team of experts to design, build and deploy machine learning models that solve real world business problems and that scale to handle the breadth of our business.

 Responsibilities:

 Act as a mentor and lead on a cross-functional team that includes business analysis, data engineering, data science and ml engineering.
 Design and develop data and machine learning pipelines to automate data ingestion, model training, data and model monitoring.
 Build robust data pipelines on Cloud using Airflow, Glue, Spark/EMR, Kinesis, Kafka, Lambda or other technologies
 Build sagemaker pipelines to incorporate and automate data and model quality, bias checks and model explainability.
 Create ML models using the Sagemaker suite of tools that address business problems and opportunities with high degree of a quality and confidence.
 Ensure all data design and model architecture align with enterprise standards.
 Work across business, product and technical teams to deliver solutions that drive commercial impact.


 What are we looking for?
 We want strong collaborators who can deliver a world-class client experience. We are looking for people who thrive in a fast-paced environment, are client-focused, team oriented, and are able to execute in a way that encourages creativity and continuous improvement.
 Requirements:

 BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
 5+ years of experience of Machine Learning/Deep Learning frameworks, libraries, data structures, and data modeling.
 3+ years programming experience in Python and Spark
 1+ years’ experience with AWS Sagemaker suite of tools
 Demonstrated track record of delivering business value using data science.
 Ability to clearly explain ML concepts to business users and articulate how they impact solutions.


 Preferences:

 Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
 Experience in CI/CD pipeline and code repositories like GitHub or Bit Bucket
 DevOps experience with Terraform
 Experience using JIRA and Agile Project Management software
 Oracle
 Batch Processing
 Informatica
 C#
 Nice to have experience with microservice development, Docker, Kubernetes
 Hands-on experience in BI Tools like Tableau, Power BI


 Pay Range: $150,480-$225,720/year
 
 Actual base salary varies based on factors, including but not limited to, relevant skill, prior experience, education, base salary of internal peers, demonstrated performance, and geographic location. Additionally, LPL Total Rewards package is highly competitive, designed to support your success at work, at home, and at play – such as 401K matching, health benefits, employee stock options, paid time off, volunteer time off, and more. Your recruiter will be happy to discuss all that LPL has to offer!
 
 Why LPL? 

At LPL, we believe that objective financial guidance is a fundamental need for everyone. As the nation’s leading independent broker-dealer, we offer an integrated platform of proprietary technology, brokerage, and investment advisor services. We provide you with a work environment that encourages your creativity and growth, a leadership team that is supportive and responsive, and the opportunity to create a career that has no limits, only amazing potential.

 We are one team on one mission. We take care of our advisors, so they can take care of their clients.

 Because our company is not too big and not too small, you can seize the opportunity to make a real impact. We are committed to supporting workplace equality, and we embrace the different perspectives and backgrounds of our employees. We also care for our communities, and we encourage our employees to do the same. This creates an environment in which you can do your best work.

 Want to hear from our employees on what it’s like to work at LPL? Watch this!

 We take social responsibility seriously. Learn more here

 Want to see info on our benefits? Learn more here

 Join the LPL team and help us make a difference by turning life’s aspirations into financial realities. Please log in or create an account to apply to this position. Principals only. EOE.

 Information on Interviews:

 LPL will only communicate with a job applicant directly from an @lplfinancial.com email address and will never conduct an interview online or in a chatroom forum. During an interview, LPL will not request any form of payment from the applicant, or information regarding an applicant’s bank or credit card. Should you have any questions regarding the application process, please contact LPL’s Human Resources Solutions Center at (800) 877-7210.

",150480,"['python', 'machine learning', 'deep learning', 'tableau', 'aws', 'docker', 'airflow', 'kafka']"
Data Scientist,US Heathcare Product Company,Remote,Full-time,"Job Title: Data Scientist (C2H role only)
Job Summary:
We are looking for a Data Scientist with strong statistics background to join our team. The ideal candidate will have a strong background in statistics and machine learning, and will be able to apply their knowledge to solve complex business problems. The candidate will work closely with other data scientists, software engineers, and product managers.
Responsibilities:
- Analyze large, complex data sets using statistical methods and machine learning techniques
- Develop predictive models to identify trends and patterns in data
- Communicate insights and recommendations to stakeholders, including executives, product managers, and engineers
- Collaborate with cross-functional teams to identify opportunities for data-driven decision-making
- Work with engineering teams to integrate statistical models into production systems
- Continuously monitor and improve the performance of statistical models
- Stay up-to-date with the latest developments in statistical modeling and machine learning
Requirements:
- Bachelor's or Master's degree in Computer Science, Statistics, Mathematics or related field.
- 5+ years experience applying statistics to solve complex business problems.
- Strong background in statistics and machine learning.
- Experience with programming languages such as Python, Java, or C++.
- Experience with data processing and analysis tools such as SQL.
- Solid experience writing complex SQL queries
- Strong problem-solving skills.
- Excellent communication skills.
- Ability to work independently and as part of a team.
- Experience with cloud computing platforms such as AWS, Azure, or GCP is a plus.
- Experience in healthcare is a plus.
Job Type: Contract
Salary: $55.00 - $60.00 per hour
Expected hours: 40 per week
Schedule:

8 hour shift

Application Question(s):

Interested in C2H role ? YES/NO

Experience:

complex data sets using statistical methods: 5 years (Preferred)
Machine learning: 3 years (Preferred)
Python: 5 years (Preferred)
AWS or Azure or GCP: 5 years (Preferred)
olid experience writing complex SQL queries: 5 years (Preferred)

Work Location: Remote",110000,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'sql']"
Data Scientist,Boston Services,MI,Full-time,"Position: Data Scientist
Work location: Auburn Hills, MI (Day 1 Onsite)
Duration: Long term contract
Unique Competencies:

8+ years of experience in Data Science and Analytical Domains
Understanding of machine-learning and operations research
Proficiency in Query languages SQL, Hive and scripting languages
Knowledge of R; familiarity with Scala, Java is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop, Google Cloud Platform, SAP)
Working knowledge of containers. For example, experience with Docker or podman
Comfortable with Git

Job Type: Contract
Pay: $65.00 - $73.00 per hour
Experience level:

7 years

Experience:

Python: 1 year (Preferred)
SQL: 1 year (Preferred)

Ability to Commute:

Auburn Hills, MI 48326 (Required)

Ability to Relocate:

Auburn Hills, MI 48326: Relocate before starting work (Required)

Work Location: In person",130000,"['python', 'tableau', 'docker', 'sql', 'git', 'hadoop']"
Data Scientist,Thalo Labs,NY,Full-time,"

  We’re Thalo Labs, an NYC-based company on a mission to transform the built environment into a powerful tool for fighting climate change. Where others see buildings as part of the problem, we see an incredible opportunity to leverage existing infrastructure to not only accelerate drawdown, but to transform the built environment from one of the biggest emitters to a carbon sink.
 

   Our team has built self-driving cars at Waymo, worked on satellite imagery at Google, designed systems for John Deere, developed space missions for NASA, engineered bikes for Peloton, led manufacturing design for Boom Supersonic jets and more. We are united by our shared goal of making products that help us decarbonize today, and we’re looking for awesome, energetic people to join us!
 


 We are seeking an experienced Data Scientist to join our team to drive development of data products across our entire business. You will be responsible for managing and analyzing large datasets, developing statistical models and algorithms, and providing insights to improve business outcomes and growth. The ideal candidate has strong attention to detail and is highly organized, creative, motivated, and passionate about achieving results. You will be one of the forces behind Thalo’s mission to measure and reduce scope 1 emissions through deep understanding of our data.
 
Responsibilities: 

Contribute to multiple levels of the Thalo’s data science process (cleaning, extraction, transformation, loading, analysis / inference / prediction)
 Present results, insights, and recommendations to both technical and non-technical stakeholders
 Measure product and customer performance, develop / refine core metrics, and create reporting to understand and monitor them
 Recommend ongoing improvements to methods, algorithms, and data infrastructure to unlock new findings / insights
 Consult with key internal and external stakeholders to understand and frame model requirements and potential applications.
 Build error analysis and propagation methods, tools, and systems

 Skills and Qualifications:

 M.S. or higher in a quantitative discipline such as computer science, engineering, physics, statistics, etc.
 Strong experience (4+ years) in applied data science, i.e. designing, conducting, analyzing, and interpreting experiments and/or investigations
 Proven track record of extracting business insights from unclean datasets, preferably working with real world sensor data
 Comprehensive understanding of statistics including error propagation, error analysis, and error reporting
 Experience with temporal prediction, forecasting, or forward modeling
 Experience hardening and deploying data science scripts/algorithms/code into production environments
 Extensive experience with Python and Git, as well as familiarity with relational and time-series databasesExcellent written, verbal, and data communication skills



 At our ground-floor seed stage, we place a strong emphasis on the value of equity. As an early stage company, our comp structure for this role is biased towards high equity, with a base salary ranging from $140,000 to $165,000
 

   Don’t worry if you don’t tick every box, we still would like to hear from you. We are building a diverse and balanced team that complements each other while covering the critical skills and experience.
 

",140000,"['python', 'git']"
Senior Data Analyst,Basis Technologies,IL,Full-time,"

WHO WE ARE



 Basis Technologies delivers software and services to automate digital media operations for more than 1,000 leading agencies and brands.
 


 Our comprehensive ad tech platform, Basis, supports the planning, reporting, and financial reconciliation of direct, programmatic, search, and social media, all in one place.
 


 We are deeply committed to building software that will change the ad tech industry for the better and are equally dedicated to building an inclusive culture of highly motivated individuals who create a positive and supportive environment together. We invest in our culture and support our employees so they can do their best work.
 


 Basis Technologies is headquartered in Chicago, and our employees have the flexibility to work in an office location, completely remote, or a hybrid of the two. Please note, we are hiring on a remote working basis only in the U.S. and Canada.
  




ABOUT THE TEAM



 The Business Intelligence team is responsible for conducting data analysis and reporting solutions to solve business problems and support decision-making across Basis Platform and Basis DSP. The Business Intelligence team collaborates with Product teams providing expertise in complex data analysis and feature measurement; supports the Data Science team through data extraction, integration, processing and validation operations; and leads business critical data analysis, making data-driven recommendations to Tech Leadership, Marketing, Product and Platform Operations. Business Intelligence is the ideal place for someone who thrives on working in a fast-paced growth environment, has a passion for working with data and technology, and is not afraid to take on some of the most complex challenges that Basis has to offer.
 


 WAYS YOU’LL CONTRIBUTE



 Reporting to the Director of Business Intelligence, the Sr Data Analyst will be responsible for conducting data analysis to support the development of new product features, establish systems for measuring feature usage and adoption, and report on product feature success. You will contribute by:
 
OTHER WAYS YOU WILL CONTRIBUTE:

 Conducting data analysis and research to provide insights, recommendations and drive solutions for product development
 Communicating results of analysis and recommendations clearly and concisely to a variety of stakeholders, including Product, tech leadership and Engineering.
 Collaborating with Product Managers to define success criteria.
 Supporting Product Managers’ research into feature development needs and the necessary data points to guide and prioritize feature development.
 Building monitoring processes to track feature usage and adoption against defined success criteria.
 Defining and run product experiments that deliver impactful results.
 Creating dashboards and reports to present product and feature level usage to Product and tech leadership.
 Understanding our data model, contribute to shared data model documentation, and recommend new data collection to Engineering when required to support objectives.
 Extracting, integrating, and validating sample data sets from various sources including big data environments.

 WHAT YOU BRING TO THE TABLE

 5+ years of professional experience, ideally in a similar role.
 Post-secondary education with a strong analytical component, e.g. statistics, business, social sciences, sciences.
 Able to prioritize and manage multiple projects across Product areas in a fast-paced environment.
 Resourceful and self-reliant; a strong self-starter with a passion for learning.
 Excellent communicator with an ability to clearly explain complex technical subjects to a variety of stakeholders.
 Ability to translate data analysis into stories, insights and recommendations.
 Experience applying statistical methodologies to test design, measurement and analysis.
 Knowledgeable about best practices around data manipulation, extracting data from big data systems, feature engineering and creating dashboards.
 Experience working with Relational Databases including SQL.
 Experience with Python, R or similar language for data analysis.
 Experience working with data visualization tools (e.g. PowerBI, Tableau).

 BONUS POINTS

 Knowledge of the digital advertising industry (e.g. AdWords, DSPs, ad-serving).
 Experience working with product analytics tools (e.g. Pendo).
 Experience defining and running experiments.


   Our salary ranges are determined by role, level, and location. Individual salary is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your location during the hiring process. The total compensation package for this position may also include commission or bonus, company equity, and competitive benefits.
 

   #BI-Remote
 

   #LI-Remote
 

   #LI-Hybrid
 


 ANYTHING ELSE?



 Don't think you have all the skills required for this role? That's okay, we recognize that experience can be built in many ways. If you have relevant skills that are not reflected in your resume, we welcome your candidacy and encourage you to share more in an optional cover letter, even if your experience doesn’t match our exact requirements.
 


 LIFE WITH BASIS TECHNOLOGIES



 We take care of our people and believe that our success depends on the growth and well-being of each one of our team members.
 


 We've been proudly recognized as:
 

   Ad Age, Best Places to Work 2023, 2022, 2013
 

   Built In, Best Workplaces 2023, 2022, 2021
 

   Crain's Best Companies to Work for in Chicago 2022, 2021, 2020, 2014, 2013, 2012, 2011
 

   Crain's Best Companies to Work for in New York 2022, 2021, 2014
 

   Dallas Morning News, Top Workplaces 2021, 2019, 2015
 

   Denver Post, Top Workplaces 2022, 2021, 2020
 

   Denver Business Journal's Largest Employers 2022, 2021, 2020
 

   Fortune Magazine, Best Workplaces 2022, 2021, 2020, 2015, 2014
 


 We provide a thoughtful perks and benefits package including competitive 401k/RRSP matching, mental health support, a funded health savings account, paid sabbatical, generous parental leave, a flexible work environment and time off policy, and more.
 


 We are proud to be an equal opportunity employer and are committed to building teams that are diverse in thought, perspective, and culture. We celebrate all team members regardless of gender identity, sexual orientation, race or cultural background, religion, disability, and age.
 


 Basis is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application processes. If you need assistance or an accommodation due to a disability, you may contact us at talent.acquisition@basis.net.
 


 Information collected and processed as part of any job applications you choose to submit is subject to Basis' privacy policy that you can view here.
 
",84000,"['python', 'tableau', 'sql']"
Data Manager I,DLH Corp,US,Full-time,"
 About Us: 
 
   DLH delivers improved health and national security readiness solutions for federal programs through science research and development, systems engineering and integration, and digital transformation. Our experts in public health, performance evaluation, and health operations solve the complex problems faced by civilian and military customers alike by leveraging advanced tools – including digital transformation, artificial intelligence, data analytics, cloud enablement, modeling, and simulation, and more. With over 3,200 employees dedicated to the idea that “Your Mission is Our Passion,” DLH brings a unique combination of government sector experience, proven methodology, and unwavering commitment to innovation to improve the lives of millions.
  Overview: 
 
   The project is a comprehensive, nationally representative health survey designed to assess the health and wellness of individuals across the country. Beyond traditional questionnaires and interviews, this survey incorporates biospecimen collection, allowing for a more in-depth analysis of participants' health. Participants will provide biological samples, such as blood, saliva, or urine, which will be meticulously analyzed to understand various physiological, genetic, and biochemical markers. This combination of survey data and biospecimen analysis aims to offer a holistic view of the nation's health, identifying trends, risk factors, and areas of concern.
 


 The Data Manager I: Works with team members to perform requirements gathering, design, coordination, and testing for reporting and analytic projects/tasks. Collaborates with business process owners, technical staff and project manager to leverage the use of data and data strategies. May participate in feasibility studies to assess cost/benefit, efficiency and technical viability of solutions to business problems. Provides necessary data elements and business knowledge to support the design and development of data models. Employs data warehouse analysis and design experience.
  Responsibilities: 
 
Developing, revising, testing and quality control of programs for a variety of analytic and operational projects.
 Develop, test and validate databases, data collection systems, and data analytics.
 Interpret data, analyze results using statistical techniques and provide ongoing reports.
 Acquire data from primary or secondary data sources and maintain databases/data systems.
 Identify, analyze, and interpret trends or patterns.
 Filter and clean data by reviewing reports and performance indicators to locate and correct code problems.
 Constructing codebooks and format files.
 Formatting tables and compiling reports.
 Producing graphical output.
 Contributing to the development and implementation of data management plans.
 Complying with federal regulations, client guidelines, corporate SOPs, and project work instructions related to data management.
 Performs other duties as assigned.
 Complies with all policies and standards.



 Base Compensation: $63,000.00- $70,000.00/yr
 

   The salary offered within this range will be based on the selected candidates skills, experience, education, market data, and internal parity. DLH may offer other rewards that may include performance incentives and program-specific awards. An applicant’s salary history will not be used to determine compensation.
 


 #LI-REMOTE
  Qualifications: 
 
 Education:


  Bachelor Degree in Computer Sciences or related technical field of study (or equivalent).
 


 Experience:


  One (1) year SAS or R for data management, which includes writing programs for cleaning and reporting of study data as well as generating analytical datasets. (Preferred)
 



 Knowledge of other software such as STATA, REDCap, Qualtrics, or Python.
 Familiarity with relational databases and electronic data capture systems is highly desirable.
 Strong verbal and written communication skills.
 Problem solving skills that demonstrate an ability to apply a data driven approach.
 Attention to detail to ensure data accuracy and to identify anomalies.
 Good teamwork and collaboration skills.
 Benefits: 
 
   DLH Corp offers our employees an excellent benefits package including - Personal Time Off (PTO), medical, dental, vision, supplemental life with AD&D, short and long-term disability, flexible spending accounts, parental leave, legal services and more. We want our employees to save for their future, therefore we offer a 401(k) Retirement Plan, which includes a matching component. DLH is dedicated to your career development, providing training to help drive success, with access to our best-in-class e-Learning suite for formal and informal learning, professional and technical certification preparation, and education assistance at accredited institutions.
  EEO: 
 
   DLH Corporation is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
 
",63000,['python']
"Generative AI Strategist, Senior",Booz Allen Hamilton,MD,Full-time,"


Job Description










         Location: 
        

         Bethesda,MD,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184858
        


















         Generative AI Strategist, Senior
          The Opportunity:
 Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there’s more structured and unstructured data available today than ever before. As a data strategist, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need a data professional like you to help our clients find answers in their big data to impact important missions from fraud detection to cancer research, to national intelligence.

 As a data strategist, you will work directly with government senior leadership and use your skills and experience to drive organization transformation, process improvement, data management, and data engineering activities on some of the most mission-driven projects in the industry. Your work will shape critical functional processes that develop and deploy data pipelines and platforms, making disparate data available and meaningful. You’ll work with a multi-disciplinary team of strategists, analysts, data engineers, data scientists, software developers, and data consumers in a fast-paced, Agile environment. You’ll sharpen your skills in analytical exploration and data examination while you support the assessment, design, development, and maintenance of scalable data platforms for your clients. Work with us to solve real-world data challenges for critical customer missions across the firm.

 Join us. The world can’t wait.

 You Have:

 5+ years of experience with data management consulting, including data management, data science, product or program management, or data analytics initiatives
 2+ years of experience with developing and implementing data standards, practices, and processes that improved data integrity and availability
 Experience with Artificial Intelligence (AI) and Data Science solutions, including ML or NLP tools, generative technologies, model development, data engineering, or strategic data planning
 Experience with business development activities, including developing and executing technical and business strategies
 Experience in interacting with customers and clients to understand their needs and present products and solutions
 Experience with creating solutions within a collaborative, cross-functional team environment
 Ability to comprehend business issues and data challenges quickly, and track multiple high-priority initiatives
 Ability to obtain a security clearance
 Bachelor’s degree


 Nice If You Have: 

Experience with a public Cloud, including AWS, Microsoft Azure, or Google Cloud
 Experience with common data programming languages, including SQL, Python, or R
 Experience with common data analytics and business intelligence tools, including Microsoft Excel, Tableau, or Qlik
 Experience with managing projects or programs
 Possession of excellent organizational skills
 Possession of excellent oral and written communication skills, including communicating complex technical and business concepts to leaders, key stakeholders, and team members in technical and non-technical roles
 Top Secret clearance
 PMP Certification


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:
 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",93300,"['python', 'machine learning', 'tableau', 'aws', 'azure', 'sql']"
AI Data Engineer,LPL Financial,CA,Full-time,"
Job Overview:
 We are looking for an experienced AI Data Engineer to join the AI Labs team, a team of data and technology professionals who build and operationalize complex machine learning models for LPL Financial. The successful candidate will build solutions using state of the art technologies to implement production grade for successful model deployment.

 As a AI Data Engineer, you will partner with a cross-functional team of experts to design, build and deploy machine learning models that solve real world business problems and that scale to handle the breadth of our business.

 Responsibilities:

 Design and develop data and machine learning pipelines to automate data ingestion, model training, data and model monitoring.
 Build robust data pipelines on Cloud using Airflow, Glue, Spark/EMR, Kinesis, Kafka, Lambda or other technologies
 Build sagemaker pipelines to incorporate and automate data and model quality, bias checks and model explainability.
 Create ML models using the Sagemaker suite of tools that address business problems and opportunities with high degree of a quality and confidence.
 Ensure all data design and model architecture align with enterprise standards.
 Work across business, product and technical teams to deliver solutions that drive commercial impact.


 What are we looking for?
 We want strong collaborators who can deliver a world-class client experience. We are looking for people who thrive in a fast-paced environment, are client-focused, team oriented, and are able to execute in a way that encourages creativity and continuous improvement.
 Requirements:

 BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
 3+ years of experience of Machine Learning/Deep Learning frameworks, libraries, data structures, and data modeling.
 2+ years programming experience in Python and Spark
 1+ years’ experience with AWS Sagemaker suite of tools
 Demonstrated track record of delivering business value using data science.
 Ability to clearly explain ML concepts to business users and articulate how they impact solutions.


 Preferences:

 Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
 Experience in CI/CD pipeline and code repositories like GitHub or Bit Bucket
 DevOps experience with Terraform
 Experience using JIRA and Agile Project Management software
 Oracle
 Batch Processing
 Informatica
 C#
 Nice to have experience with microservice development, Docker, Kubernetes
 Hands-on experience in BI Tools like Tableau, Power BI


 Pay Range: $131,200-$196,800/year
 
 Actual base salary varies based on factors, including but not limited to, relevant skill, prior experience, education, base salary of internal peers, demonstrated performance, and geographic location. Additionally, LPL Total Rewards package is highly competitive, designed to support your success at work, at home, and at play – such as 401K matching, health benefits, employee stock options, paid time off, volunteer time off, and more. Your recruiter will be happy to discuss all that LPL has to offer!
 
 Why LPL? 

At LPL, we believe that objective financial guidance is a fundamental need for everyone. As the nation’s leading independent broker-dealer, we offer an integrated platform of proprietary technology, brokerage, and investment advisor services. We provide you with a work environment that encourages your creativity and growth, a leadership team that is supportive and responsive, and the opportunity to create a career that has no limits, only amazing potential.

 We are one team on one mission. We take care of our advisors, so they can take care of their clients.

 Because our company is not too big and not too small, you can seize the opportunity to make a real impact. We are committed to supporting workplace equality, and we embrace the different perspectives and backgrounds of our employees. We also care for our communities, and we encourage our employees to do the same. This creates an environment in which you can do your best work.

 Want to hear from our employees on what it’s like to work at LPL? Watch this!

 We take social responsibility seriously. Learn more here

 Want to see info on our benefits? Learn more here

 Join the LPL team and help us make a difference by turning life’s aspirations into financial realities. Please log in or create an account to apply to this position. Principals only. EOE.

 Information on Interviews:

 LPL will only communicate with a job applicant directly from an @lplfinancial.com email address and will never conduct an interview online or in a chatroom forum. During an interview, LPL will not request any form of payment from the applicant, or information regarding an applicant’s bank or credit card. Should you have any questions regarding the application process, please contact LPL’s Human Resources Solutions Center at (800) 877-7210.

",131200,"['python', 'machine learning', 'deep learning', 'tableau', 'aws', 'docker', 'airflow', 'kafka']"
Senior AI Engineer,LPL Financial,CA,Full-time,"
Job Overview:
 We are looking for an experienced Sr. AI Engineer to join the AI Labs team, a team of data and technology professionals who build and operationalize complex machine learning models for LPL Financial. The successful candidate will build solutions using state of the art technologies to implement production grade for successful model deployment.

 As a Sr. AI Engineer, you will partner with a cross-functional team of experts to design, build and deploy machine learning models that solve real world business problems and that scale to handle the breadth of our business.

 Responsibilities:

 Act as a mentor and lead on a cross-functional team that includes business analysis, data engineering, data science and ml engineering.
 Design and develop data and machine learning pipelines to automate data ingestion, model training, data and model monitoring.
 Build robust data pipelines on Cloud using Airflow, Glue, Spark/EMR, Kinesis, Kafka, Lambda or other technologies
 Build sagemaker pipelines to incorporate and automate data and model quality, bias checks and model explainability.
 Create ML models using the Sagemaker suite of tools that address business problems and opportunities with high degree of a quality and confidence.
 Ensure all data design and model architecture align with enterprise standards.
 Work across business, product and technical teams to deliver solutions that drive commercial impact.


 What are we looking for?
 We want strong collaborators who can deliver a world-class client experience. We are looking for people who thrive in a fast-paced environment, are client-focused, team oriented, and are able to execute in a way that encourages creativity and continuous improvement.
 Requirements:

 BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
 5+ years of experience of Machine Learning/Deep Learning frameworks, libraries, data structures, and data modeling.
 3+ years programming experience in Python and Spark
 1+ years’ experience with AWS Sagemaker suite of tools
 Demonstrated track record of delivering business value using data science.
 Ability to clearly explain ML concepts to business users and articulate how they impact solutions.


 Preferences:

 Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
 Experience in CI/CD pipeline and code repositories like GitHub or Bit Bucket
 DevOps experience with Terraform
 Experience using JIRA and Agile Project Management software
 Oracle
 Batch Processing
 Informatica
 C#
 Nice to have experience with microservice development, Docker, Kubernetes
 Hands-on experience in BI Tools like Tableau, Power BI


 Pay Range: $150,480-$225,720/year
 
 Actual base salary varies based on factors, including but not limited to, relevant skill, prior experience, education, base salary of internal peers, demonstrated performance, and geographic location. Additionally, LPL Total Rewards package is highly competitive, designed to support your success at work, at home, and at play – such as 401K matching, health benefits, employee stock options, paid time off, volunteer time off, and more. Your recruiter will be happy to discuss all that LPL has to offer!
 
 Why LPL? 

At LPL, we believe that objective financial guidance is a fundamental need for everyone. As the nation’s leading independent broker-dealer, we offer an integrated platform of proprietary technology, brokerage, and investment advisor services. We provide you with a work environment that encourages your creativity and growth, a leadership team that is supportive and responsive, and the opportunity to create a career that has no limits, only amazing potential.

 We are one team on one mission. We take care of our advisors, so they can take care of their clients.

 Because our company is not too big and not too small, you can seize the opportunity to make a real impact. We are committed to supporting workplace equality, and we embrace the different perspectives and backgrounds of our employees. We also care for our communities, and we encourage our employees to do the same. This creates an environment in which you can do your best work.

 Want to hear from our employees on what it’s like to work at LPL? Watch this!

 We take social responsibility seriously. Learn more here

 Want to see info on our benefits? Learn more here

 Join the LPL team and help us make a difference by turning life’s aspirations into financial realities. Please log in or create an account to apply to this position. Principals only. EOE.

 Information on Interviews:

 LPL will only communicate with a job applicant directly from an @lplfinancial.com email address and will never conduct an interview online or in a chatroom forum. During an interview, LPL will not request any form of payment from the applicant, or information regarding an applicant’s bank or credit card. Should you have any questions regarding the application process, please contact LPL’s Human Resources Solutions Center at (800) 877-7210.

",150480,"['python', 'machine learning', 'deep learning', 'tableau', 'aws', 'docker', 'airflow', 'kafka']"
Data Scientist,US Heathcare Product Company,Remote,Full-time,"Job Title: Data Scientist (C2H role only)
Job Summary:
We are looking for a Data Scientist with strong statistics background to join our team. The ideal candidate will have a strong background in statistics and machine learning, and will be able to apply their knowledge to solve complex business problems. The candidate will work closely with other data scientists, software engineers, and product managers.
Responsibilities:
- Analyze large, complex data sets using statistical methods and machine learning techniques
- Develop predictive models to identify trends and patterns in data
- Communicate insights and recommendations to stakeholders, including executives, product managers, and engineers
- Collaborate with cross-functional teams to identify opportunities for data-driven decision-making
- Work with engineering teams to integrate statistical models into production systems
- Continuously monitor and improve the performance of statistical models
- Stay up-to-date with the latest developments in statistical modeling and machine learning
Requirements:
- Bachelor's or Master's degree in Computer Science, Statistics, Mathematics or related field.
- 5+ years experience applying statistics to solve complex business problems.
- Strong background in statistics and machine learning.
- Experience with programming languages such as Python, Java, or C++.
- Experience with data processing and analysis tools such as SQL.
- Solid experience writing complex SQL queries
- Strong problem-solving skills.
- Excellent communication skills.
- Ability to work independently and as part of a team.
- Experience with cloud computing platforms such as AWS, Azure, or GCP is a plus.
- Experience in healthcare is a plus.
Job Type: Contract
Salary: $55.00 - $60.00 per hour
Expected hours: 40 per week
Schedule:

8 hour shift

Application Question(s):

Interested in C2H role ? YES/NO

Experience:

complex data sets using statistical methods: 5 years (Preferred)
Machine learning: 3 years (Preferred)
Python: 5 years (Preferred)
AWS or Azure or GCP: 5 years (Preferred)
olid experience writing complex SQL queries: 5 years (Preferred)

Work Location: Remote",110000,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'sql']"
Data Scientist,Boston Services,MI,Full-time,"Position: Data Scientist
Work location: Auburn Hills, MI (Day 1 Onsite)
Duration: Long term contract
Unique Competencies:

8+ years of experience in Data Science and Analytical Domains
Understanding of machine-learning and operations research
Proficiency in Query languages SQL, Hive and scripting languages
Knowledge of R; familiarity with Scala, Java is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop, Google Cloud Platform, SAP)
Working knowledge of containers. For example, experience with Docker or podman
Comfortable with Git

Job Type: Contract
Pay: $65.00 - $73.00 per hour
Experience level:

7 years

Experience:

Python: 1 year (Preferred)
SQL: 1 year (Preferred)

Ability to Commute:

Auburn Hills, MI 48326 (Required)

Ability to Relocate:

Auburn Hills, MI 48326: Relocate before starting work (Required)

Work Location: In person",130000,"['python', 'tableau', 'docker', 'sql', 'git', 'hadoop']"
Data Scientist,Thalo Labs,NY,Full-time,"

  We’re Thalo Labs, an NYC-based company on a mission to transform the built environment into a powerful tool for fighting climate change. Where others see buildings as part of the problem, we see an incredible opportunity to leverage existing infrastructure to not only accelerate drawdown, but to transform the built environment from one of the biggest emitters to a carbon sink.
 

   Our team has built self-driving cars at Waymo, worked on satellite imagery at Google, designed systems for John Deere, developed space missions for NASA, engineered bikes for Peloton, led manufacturing design for Boom Supersonic jets and more. We are united by our shared goal of making products that help us decarbonize today, and we’re looking for awesome, energetic people to join us!
 


 We are seeking an experienced Data Scientist to join our team to drive development of data products across our entire business. You will be responsible for managing and analyzing large datasets, developing statistical models and algorithms, and providing insights to improve business outcomes and growth. The ideal candidate has strong attention to detail and is highly organized, creative, motivated, and passionate about achieving results. You will be one of the forces behind Thalo’s mission to measure and reduce scope 1 emissions through deep understanding of our data.
 
Responsibilities: 

Contribute to multiple levels of the Thalo’s data science process (cleaning, extraction, transformation, loading, analysis / inference / prediction)
 Present results, insights, and recommendations to both technical and non-technical stakeholders
 Measure product and customer performance, develop / refine core metrics, and create reporting to understand and monitor them
 Recommend ongoing improvements to methods, algorithms, and data infrastructure to unlock new findings / insights
 Consult with key internal and external stakeholders to understand and frame model requirements and potential applications.
 Build error analysis and propagation methods, tools, and systems

 Skills and Qualifications:

 M.S. or higher in a quantitative discipline such as computer science, engineering, physics, statistics, etc.
 Strong experience (4+ years) in applied data science, i.e. designing, conducting, analyzing, and interpreting experiments and/or investigations
 Proven track record of extracting business insights from unclean datasets, preferably working with real world sensor data
 Comprehensive understanding of statistics including error propagation, error analysis, and error reporting
 Experience with temporal prediction, forecasting, or forward modeling
 Experience hardening and deploying data science scripts/algorithms/code into production environments
 Extensive experience with Python and Git, as well as familiarity with relational and time-series databasesExcellent written, verbal, and data communication skills



 At our ground-floor seed stage, we place a strong emphasis on the value of equity. As an early stage company, our comp structure for this role is biased towards high equity, with a base salary ranging from $140,000 to $165,000
 

   Don’t worry if you don’t tick every box, we still would like to hear from you. We are building a diverse and balanced team that complements each other while covering the critical skills and experience.
 

",140000,"['python', 'git']"
Data Scientist,rds,Remote,Full-time,"We are seeking a Data Scientist to work on a Generative AI initiative to join our team. The ideal candidate will have a deep understanding of language models, text-to-image, and other generative AI models. They must possess knowledge of Python, and machine learning frameworks.
Responsibilities

Develop and implement generative AI models, including LLMs, text-to-image and generative AI models.
Train and evaluate models using large datasets.
Troubleshoot and debug code to ensure high-quality results.
Keep up to date with the latest developments in the field of generative AI and apply them to our projects.
Collaborate with other engineers, stakeholders and team members to develop innovative solutions.
Deep understanding of how to scale models and their limitations
Ability to quickly identify opportunities for model improvement

Requirements

Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
2+ years of experience in developing and training AI/ML models.
Experience with data querying languages like SQL, scripting languages like Python, and/or statistical/mathematical software e.g. R
Knowledge of state-of-the-art generative AI models such as GPT-3, DALL-E, and CLIP.
Experience with Cloud infrastructure and Platforms - Azure /GCP/AWS
Experience with training and evaluating large-scale models on high-performance computing clusters.
Strong understanding of deep learning, natural language processing, and computer vision.
Excellent problem-solving skills and ability to work independently and in a team environment.

Preferred Qualifications:

Bachelor's or master's degree in computer science, Data Science, Statistics, Math, Physics, or other Science related discipline with course work in AI/ML.
Demonstrated experience in developing and training AI models
Strong knowledge of deep learning, natural language processing, and computer vision.
Experience with scaling up generative models and deploying them in production environments.
Ability to work collaboratively in a team environment and communicate complex technical concepts to non-technical stakeholders.

Job Type: Contract
Salary: $80,906.49 - $176,960.04 per year
Experience level:

7 years

Schedule:

8 hour shift

People with a criminal record are encouraged to apply
Experience:

Artificial Intelligence(AI): 3 years (Preferred)
Azure /GCP/AWS: 3 years (Preferred)
Machine Learning(ML): 3 years (Preferred)

Work Location: Remote",80906,"['python', 'machine learning', 'deep learning', 'aws', 'azure', 'gcp', 'sql']"
Data Scientist,Brik Partners,Remote,Full-time,"Key Responsibilities:

Develop and implement advanced analytics solutions to extract valuable insights from large datasets.
Design and execute complex data analysis experiments, interpreting and communicating findings to stakeholders.
Led and mentored junior data scientists, fostering a collaborative and innovative work environment.
Stay abreast of industry trends and emerging technologies, integrating them into our data science strategies.

Requirements:

8+ years of proven experience in data science roles.
Strong proficiency in Python, R, or other relevant programming languages.
Expertise in machine learning, statistical analysis, and data modeling.
Advanced knowledge of data visualization tools (e.g., Tableau, Power BI).
Excellent communication skills with the ability to present complex findings in a clear and understandable manner.

Job Type: Contract
Salary: $80,906.49 - $176,960.04 per year
Schedule:

Monday to Friday

Application Question(s):

Would you now or in future need the H1 Sponsorship?

Experience:

Python: 7 years (Preferred)
SQL: 7 years (Preferred)
Data science: 8 years (Required)

Work Location: Remote",80906,"['python', 'machine learning', 'tableau', 'sql']"
Senior Data Analyst,Basis Technologies,IL,Full-time,"

WHO WE ARE



 Basis Technologies delivers software and services to automate digital media operations for more than 1,000 leading agencies and brands.
 


 Our comprehensive ad tech platform, Basis, supports the planning, reporting, and financial reconciliation of direct, programmatic, search, and social media, all in one place.
 


 We are deeply committed to building software that will change the ad tech industry for the better and are equally dedicated to building an inclusive culture of highly motivated individuals who create a positive and supportive environment together. We invest in our culture and support our employees so they can do their best work.
 


 Basis Technologies is headquartered in Chicago, and our employees have the flexibility to work in an office location, completely remote, or a hybrid of the two. Please note, we are hiring on a remote working basis only in the U.S. and Canada.
  




ABOUT THE TEAM



 The Business Intelligence team is responsible for conducting data analysis and reporting solutions to solve business problems and support decision-making across Basis Platform and Basis DSP. The Business Intelligence team collaborates with Product teams providing expertise in complex data analysis and feature measurement; supports the Data Science team through data extraction, integration, processing and validation operations; and leads business critical data analysis, making data-driven recommendations to Tech Leadership, Marketing, Product and Platform Operations. Business Intelligence is the ideal place for someone who thrives on working in a fast-paced growth environment, has a passion for working with data and technology, and is not afraid to take on some of the most complex challenges that Basis has to offer.
 


 WAYS YOU’LL CONTRIBUTE



 Reporting to the Director of Business Intelligence, the Sr Data Analyst will be responsible for conducting data analysis to support the development of new product features, establish systems for measuring feature usage and adoption, and report on product feature success. You will contribute by:
 
OTHER WAYS YOU WILL CONTRIBUTE:

 Conducting data analysis and research to provide insights, recommendations and drive solutions for product development
 Communicating results of analysis and recommendations clearly and concisely to a variety of stakeholders, including Product, tech leadership and Engineering.
 Collaborating with Product Managers to define success criteria.
 Supporting Product Managers’ research into feature development needs and the necessary data points to guide and prioritize feature development.
 Building monitoring processes to track feature usage and adoption against defined success criteria.
 Defining and run product experiments that deliver impactful results.
 Creating dashboards and reports to present product and feature level usage to Product and tech leadership.
 Understanding our data model, contribute to shared data model documentation, and recommend new data collection to Engineering when required to support objectives.
 Extracting, integrating, and validating sample data sets from various sources including big data environments.

 WHAT YOU BRING TO THE TABLE

 5+ years of professional experience, ideally in a similar role.
 Post-secondary education with a strong analytical component, e.g. statistics, business, social sciences, sciences.
 Able to prioritize and manage multiple projects across Product areas in a fast-paced environment.
 Resourceful and self-reliant; a strong self-starter with a passion for learning.
 Excellent communicator with an ability to clearly explain complex technical subjects to a variety of stakeholders.
 Ability to translate data analysis into stories, insights and recommendations.
 Experience applying statistical methodologies to test design, measurement and analysis.
 Knowledgeable about best practices around data manipulation, extracting data from big data systems, feature engineering and creating dashboards.
 Experience working with Relational Databases including SQL.
 Experience with Python, R or similar language for data analysis.
 Experience working with data visualization tools (e.g. PowerBI, Tableau).

 BONUS POINTS

 Knowledge of the digital advertising industry (e.g. AdWords, DSPs, ad-serving).
 Experience working with product analytics tools (e.g. Pendo).
 Experience defining and running experiments.


   Our salary ranges are determined by role, level, and location. Individual salary is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your location during the hiring process. The total compensation package for this position may also include commission or bonus, company equity, and competitive benefits.
 

   #BI-Remote
 

   #LI-Remote
 

   #LI-Hybrid
 


 ANYTHING ELSE?



 Don't think you have all the skills required for this role? That's okay, we recognize that experience can be built in many ways. If you have relevant skills that are not reflected in your resume, we welcome your candidacy and encourage you to share more in an optional cover letter, even if your experience doesn’t match our exact requirements.
 


 LIFE WITH BASIS TECHNOLOGIES



 We take care of our people and believe that our success depends on the growth and well-being of each one of our team members.
 


 We've been proudly recognized as:
 

   Ad Age, Best Places to Work 2023, 2022, 2013
 

   Built In, Best Workplaces 2023, 2022, 2021
 

   Crain's Best Companies to Work for in Chicago 2022, 2021, 2020, 2014, 2013, 2012, 2011
 

   Crain's Best Companies to Work for in New York 2022, 2021, 2014
 

   Dallas Morning News, Top Workplaces 2021, 2019, 2015
 

   Denver Post, Top Workplaces 2022, 2021, 2020
 

   Denver Business Journal's Largest Employers 2022, 2021, 2020
 

   Fortune Magazine, Best Workplaces 2022, 2021, 2020, 2015, 2014
 


 We provide a thoughtful perks and benefits package including competitive 401k/RRSP matching, mental health support, a funded health savings account, paid sabbatical, generous parental leave, a flexible work environment and time off policy, and more.
 


 We are proud to be an equal opportunity employer and are committed to building teams that are diverse in thought, perspective, and culture. We celebrate all team members regardless of gender identity, sexual orientation, race or cultural background, religion, disability, and age.
 


 Basis is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application processes. If you need assistance or an accommodation due to a disability, you may contact us at talent.acquisition@basis.net.
 


 Information collected and processed as part of any job applications you choose to submit is subject to Basis' privacy policy that you can view here.
 
",84000,"['python', 'tableau', 'sql']"
Data Scientist,Albertsons Companies,CA,Full-time,"
About the company 
Albertsons Companies is at the forefront of the revolution in retail. With a fixation on raising the bar with innovation and building belonging through our culture, our team is rallying our company around a unique purpose : to create joy around each table and inspire a healthier tomorrow for every community. 
Albertsons Companies is one of the largest food and drug retailers in the United States, with over 2,200 stores in 34 states and the District of Columbia. Our well-known banners include Albertsons, Safeway, Vons, Jewel-Osco, Shaw's, Acme, Tom Thumb, Randalls, United Supermarkets, Pavilions, Star Market, Haggen, Carrs, Kings Food Markets, and Balducci's Food Lovers Market. We support our stores with 22 distribution centers and 19 manufacturing plants. 
Placing a premium on adaptability, safety and family well-being, our work model, Presence with a Purpose, offers a hybrid work environment between remote work and office time. A one-size-fits-all approach does not apply to everyone, and teams are empowered to make decisions best for them. 
Bring your flavor 
Building the future of food and well-being starts with you. Join our team and bring your best self to the table. 
What you will be doing 
You will enjoy working with one of the richest data sets in the world, cutting edge technology, and the ability to see your insights turned into business impacts on regular basis. You'll work closely with other data scientists and business partners in identifying and defining data science projects, building machine learning algorithms and models on top of existing data platforms. The candidate will have a background in computer science or a related technical field with experiences working with large data sets and applying data-driven decision making. A successful candidate will be both technically strong and business savvy, with a passion to make an impact through creative storytelling and timely actions. You are a self-starter, smart yet humble, with a bias for action. 
This position is located in Pleasanton, California. 
Main responsibilities 

Collaborate with business teams to develop production grade machine learning models on large-scale datasets and improve customers’ overall shopping experience 
Apply machine learning to enhance recommendation engines and deliver personalized user experience on ecommerce website and loyalty mobile app 
Build models and algorithms to fuel growth initiatives for Digital, Merchandising, Marketing and Loyalty teams 
Scale up prototypes and implement reliable automated production workflow for models 
Collaborate with software development engineers to integrate models 
Apply predictive modeling techniques to optimize the forecasts for planning needs 
Detect anomaly in systems through various techniques and identify outliers in operational metrics 

The salary range is $109,600 to $142,420 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates. 
What we are searching for 

Masters or PhD degree in quantitative discipline: Computer Science, Engineering, Data Science, Math, Statistics or related fields 
2+ years of industry experience in applying data science and modeling methodologies: regression model, survival model, ensemble modeling, NLP, recommendation algorithm, clustering, deep learning algorithm, experimental design (Multivariate/A-B testing) and nonparametric Bayesian modeling etc. 
1+ years of experience and proficiency in SQL, Python and/or Spark-ML 
1+ years of SQL development skills writing queries, transforming data, mining structured and unstructured data. 
1+ years of hands-on experience in building data science solutions and production-ready systems on big data platforms such as Snowflake, Spark, Hadoop 
Strong teamwork and communication skill 
Ability to write production-level code in Python 
Experience with Snowflake, Azure Databricks is a strong plus 

What is it like at Albertsons? 
Our 290,000 associates have a passion for great service and building lasting relationships with our customers. Through a companywide focus on innovation, we are continually enhancing our digital and product offerings, making it easy for customers to get what they need, wherever they are.
",109600,"['python', 'machine learning', 'deep learning', 'azure', 'sql', 'hadoop']"
"Data Scientist, Membership Programs",Petco,CA,Full-time,"
Create a healthier, brighter future for pets, pet parents and people! 

If you want to make a real difference, create an exciting career path, feel welcome to be your whole self and nurture your wellbeing, Petco is the place for you. 

Our core values capture that spirit as we work to improve lives by doing what’s right for pets, people and our planet. 

We love all pets like our own
 We’re the future of the pet industry
 We’re here to improve lives
 We drive outstanding results together
 We’re welcome as we are


 Petco is a category-defining health and wellness company focused on improving the lives of pets, pet parents and Petco partners. We are 29,000 strong, working together across 1,500+ pet care centers, 250+ Vetco Total Care hospitals, hundreds of preventive care clinics, eight distribution centers and two support centers.
 Position Purpose:
 As a Data Scientist in the Enterprise Analytics and Data Science team at Petco, you'll work on projects to discover insights that will drive strategic decision-making and optimization for our customer membership programs. These insights will be generated through advanced customer analytics and the development of machine learning models, which will involve the following:

 Data generation: Use customer, operational and interaction data to build datasets that can be consumed by various models and reports in the company. Analytical modeling: Data modeling, exploratory data analysis, and feature selection using advanced statistical methods and techniques. Model Validation: Calibrating models to provide interpretable and repeatable outputs by using various metrics like ROC, RMSE, quantile loss, etc. Deployment: Model output will be consumed by various teams to create a customer experience that is the best in the industry. Documentation: Clear documentation of the objective, statistical model, and results.

 Scope:
 Essential Job Functions: The incumbent must be able to perform all of the following duties and responsibilities with or without a reasonable accommodation.

 Build, maintain, optimize, and productionize machine learning frameworks to quantify the impact our actions on Petco’s omni-channel business. Create new data pipelines using the latest technologies that seamlessly integrate with multiple databases at Petco. Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance. Analyze historical data to identify trends, support decision making, and identify scalable opportunities and collaborate with business stakeholders to assess impact. Utilize code (Python/R/SQL) for data analyzing and modeling algorithms. Apply statistical or machine learning knowledge and/or build decision-making models to identify and propose solutions for specific business problems. Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication. Conducts tracking and measurement of KPIs related to recommendations and socializes to the broader teams. Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters. Provide requirements to develop analytic capabilities, platforms, and pipelines. Mentor data scientists and associate data scientists on technique and process.

 Other Duties and Responsibilities

 Interact professionally and effectively through verbal and written communication with all professional contacts with emphasis on company interests.
 Independently prioritize and accomplish multiple tasks within established timeframes.
 Perform other related duties, tasks and responsibilities as required, assigned and directed.


 Education and Experience

 Advanced degree in Statistics, Math, Engineering, Economics or related field
 Ideal candidate will have experience working with Machine Learning/Deep Learning to address real world problems; related experience working in a retail organization and/or supporting subscription-based programs or services would be a strong plus
 2+ years’ experience in business analytics and data science 
Proficiency with SQL and multiple analytics tools required; Python or R strongly preferred 
Hands on experience with BI tools; Tableau /R shiny/Looker 
Must be self-driven and passionate about retail and must be customer centric. 
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment 
Ability to explain/present complicated/advanced analytical methodology and results to non-technical audiences 
Excellent communication skills as well as quantitative modeling, statistical analysis skills and problem-solving skills 


Competencies

 Demonstrate Adaptability and Desire to Learn - Works productively in the face of ambiguity or uncertainty. Demonstrates flexibility and resilience in response to obstacles, constraints, adversity, and mistakes. Constructively and resourcefully adapts to changing needs, conditions, priorities or opportunities. Seeks out opportunities to learn from new discoveries, innovations, ways of looking at things, knowledge, and ideas. Invites and incorporates feedback, without becoming defensive.



 Perform Analysis - Integrates information from a variety of sources to arrive at a broader understanding of issues (e.g., company reports plus in-store observations).Defines issues clearly despite incomplete or ambiguous information. Identifies the key issues in complex or ambiguous problems. Approaches problems or issues systematically, looking for connections, trends, and potential causes. Probes and looks past symptoms to determine the underlying causes of problems and issues.



 Plan and Execute - Develops realistic plans (e.g., action steps, timelines) to accomplish objectives. Acquires and leverages resources, processes, and tools to achieve business goals. Prioritizes and balances time, actions, and projects to ensure accomplishment of results. Holds him/herself and team accountable for outcomes (e.g., achieving goals and complying with policies and procedures). Anticipates and addresses obstacles, redirecting efforts to accelerate the work or improve quality.



 Produce Results - Initiates decisive, timely action to address important issues. Demonstrates a strong sense of ownership and a commitment to achieving meaningful results. Sets challenging, clear goals/targets and expectations for achieving business results. Drives initiatives/efforts to successful completion and closure. Takes personal responsibility to make decisions and take action.



 Good Partner - Identifies and anticipates customer requirements, expectations, and needs. Seeks feedback from customers to identify improvement opportunities. Follows up with customers to ensure problems are solved. Continually searches for ways to improve customer service (including the removal of barriers, and providing solutions).



 Use Professional Judgment - Makes logical, rational, and integrative decisions, and arrives at sound conclusions. Chooses the best alternative(s) based on a review of pros, cons, tradeoffs, timing, and probabilities. Evaluates the consequences and implications of alternatives, actions, or decisions (e.g., impact on sales, returns, customer loyalty). Makes timely decisions, balancing analysis with decisiveness.


 Work Environment
 Most tasks are performed while seated indoors at a personal computer. Limited travel to vendors, seminars and/or conferences may be required periodically throughout the year.

 Contacts
 Interaction with numerous internal departments including, but not limited to Information Systems, Analytical Services, Merchandising, Content, Creative and Marketing are a nearly daily occurrence and may range from the routine exchange of information to the analyses, evaluation and resolution of complex logistical issues. Externally, the position will work with technology & creative partners, and product/service vendors usually exchanging information, providing instruction, or resolving somewhat complex problems.

 The above description is meant to provide an overview/summary of the nature and level of work being performed; it should not be construed as an exhaustive list of all responsibilities, duties and requirements of the job. Petco reserves the right to modify the content formally or informally, either verbally or in writing, at any time without advance notice and employees are required to follow any other job-related duties/functions requested by their supervisor. Further, all employment at Petco is of an at-will nature and, as such, the company reserves its right to terminate any position or employee (with or without notice and with or without cause) within its discretion. 

Petco Animal Supplies, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or any other protected classification.

 The pay range(s) below are provided in compliance with state specific laws. Pay ranges may be different in other locations.
 $79,600.00 - $119,300.00
 
 / year

 Exact rate of pay will be based on position, location, and experience level. For a more detailed overview of Petco Total Rewards, including health and financial benefits, 401K, incentives, and PTO -see https://careers.petco.com/us/en/key-benefits 

To translate this webpage to Spanish or other languages on your internet browser click the translate button to the right of your browser address bar. Additional instruction can be found here: https://support.google.com/chrome/answer/173424?hl=en-GB&co=GENIE.Platform%3DDesktop

 Para traducir esta página web al español u otros idiomas en su navegador de Internet, haga clic en el botón de traducción a la derecha de la barra de direcciones de su navegador. Puede encontrar instrucciones adicionales aquí:
 https://support.google.com/chrome/answer/173424?hl=en-GB&co=GENIE.Platform%3DDesktop
",79600,"['python', 'machine learning', 'deep learning', 'tableau', 'sql']"
"Associate, Data Science",BlackRock,CA,Full-time,"






       Description 
        
About this role
 

Company: BlackRock Financial Management, Inc.
 Job Title: Associate, Data Science
 Location: 820 Ramona Street, Palo Alto, CA 94301
Summary of duties: Design, develop and program methods, processes, and systems to consolidate and analyze unstructured, diverse “big data” sources to generate actionable insights and solutions for client needs and/or product enhancements. Interact with stakeholder teams to identify questions and issues for data analysis, research opportunities for new uses of existing data and develop processes for data modeling, mining, and production. Utilize various techniques in machine learning, data mining, statistics, and big data infrastructures. Work with different datasets and run algorithms on large size data effectively and efficiently, staying up to date with all the latest cutting-edge technologies.
Qualifications: Bachelor's degree in Data Informatics, Computer Science, Computer Engineering, Mathematics, or a related field, and two (2) years of experience as an Associate, Aladdin Product Group; Analyst, Aladdin Product Group; Graduate Analyst Summer Intern; Programmer; Graduate Apprentice; or a related role. Two (2) years of experience with: utilizing data science principles to map applications into data science frameworks, including supervised learning, clustering, collaborated filtering, optimizations, and decision models; utilizing computer programming languages, including Python, JavaScript, SQL, Java, and Scala; applying financial market theory in capital market work, including financing models and asset valuations; applying mathematics and statistics to internal models and AI algorithms; and utilizing big data technology to distribute computing and data storage in cloud, including AWS, Azure, and Google.
Salary range: $145,000 – 152,500
To apply: please click the “Apply” button on this webpage.


 For California only the salary range for this position is $. Additionally, employees are eligible for an annual discretionary bonus, and benefits including heath care, leave benefits, and retirement benefits. BlackRock operates a pay-for-performance compensation philosophy and your total compensation may vary based on role, location, and firm, department and individual performance.
 
Our benefits
 To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
 
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.

About BlackRock
 
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being. Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
 
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.







",145000,"['python', 'machine learning', 'aws', 'azure', 'sql']"
Delivery Consultant - Sterling Data Exchange,IBM,TX,Full-time,"

Introduction
 This role has a thorough understanding of the nature of the business problems in a wide range of industries, and the products and solutions that provide value in solving those problems. Is knowledgeable in the trends and directions of the industry, the marketplace, and the players. The main focus will be to leverage their product and technical expertise with the IBM products to design, develop and customize solutions to fit each customer’s unique business and technical environments.
  

Your Role and Responsibilities
 This role has a thorough understanding of the nature of the business problems in a wide range of industries, and the products and solutions that provide value in solving those problems. Is knowledgeable in the trends and directions of the industry, the marketplace, and the players. The main focus will be to leverage their product and technical expertise with the IBM products to design, develop and customize solutions to fit each customer’s unique business and technical environments.
  

Required Technical and Professional Expertise


 Required skills include (but are not limited to) the following:
   







Direct experience in the following IBM products and technologies: IBM B2BI/SFG, IBM ITX/ITXA, IBM SSP/SEAS, ICC, PEM/PCM, Gentran, Connect Direct/Enterprise.




Strong knowledge of integration concepts and commonly used patterns, able to apply such knowledge in solution design




Experience or strong knowledge of communication and data handling protocols (AS2, PGP/GPG, S/MIME, HTTPS, FTPS/SFTP/SCP/OFTP, POP3/SMTP, Web Services/SOAP/REST, WebDAV, etc.)




Experience or strong knowledge of industry data standards (ACH, ANSI X12, EDIFACT, HIPAA, RosettaNet, SWIFT, TRADCOMS, etc.) 




Experience or strong knowledge of application programming/scripting technologies (Java/J2EE, AJX, ASP, BPEL/BPML, SQLXSLT, Linux/Unix/Windows shell scripts)




Demonstrated experience with enterprise database technologies like Oracle RAC, DB2, and MS SQL Server Enterprise




Highly skilled in complex problem solving, critical thinking, applying judgment, building consensus, and decision making




Excellent communication and interpersonal skills including the ability to work effectively with technical and non-technical staff




Strong business analysis, technical analysis, analytical thinking and decision-making ability









Preferred Technical and Professional Expertise



 Preferred skills include (but are not limited to) the following:
    







Knowledge of Cloud technologies




Knowledge of popular ERP systems, such as SAP




Strong experience working with senior IT and non-IT executives on a daily basis




Demonstrated experience in multi-shore management, teamwork and execution




B.S. in Computer Science, Software Engineering, or equivalent



Experience and strong business acumen with competing (non-IBM) integration and managed file transfer technologies.











About Business Unit
 IBM Software infuses core business operations with intelligence—from machine learning to generative AI—to help make organizations more responsive, productive, and resilient. IBM Software helps clients put AI into action now to create real value with trust, speed, and confidence across digital labor, IT automation, application modernization, security, and sustainability. Critical to this is the ability to make use of all data, because AI is only as good as the data that fuels it. In most organizations data is spread across multiple clouds, on premises, in private datacenters, and at the edge. IBM’s AI and data platform scales and accelerates the impact of AI with trusted data, and provides leading capabilities to train, tune and deploy AI across business. IBM’s hybrid cloud platform is one of the most comprehensive and consistent approach to development, security, and operations across hybrid environments—a flexible foundation for leveraging data, wherever it resides, to extend AI deep into a business.
 



 Your Life @ IBM
 In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.
   Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.
 Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.
 Are you ready to be an IBMer?



 About IBM
 IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.
  
 Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. 
  
 At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.
 



 Location Statement
 IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:
  


Healthcare benefits including medical & prescription drug coverage, dental, vision, and mental health & well being
 - Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short & long- term disability coverage, and opportunities for performance based salary incentive programs
  

Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law
Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals
Diverse and inclusive employee resource groups, giving & volunteer opportunities, and discounts on retail products, services & experiences

 The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year. 
  
 We consider qualified applicants with criminal histories, consistent with applicable law.
 



 Being You @ IBM
 IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
 
",101000,"['machine learning', 'sql']"
Data Scientist,ICF,VA,Full-time,"

  ICF International seeks an experienced Data Scientist to support the research and development of new cyber analytic capabilities that will help the US protect and defend its networks and critical information systems. The successful cleared candidate will act as a Data Scientist to support a large federal cyber security analytic program. Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate. Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large-scale.
 


 As the Data Scientist, your skillset will create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms. The ideal candidate is strong mathematically, can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. This is an opportunity to contribute to an important project from its beginning, work with the latest and emerging technologies, and all while building a great career at ICF!
 


 This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region.
 


 What You Will Be Doing:
 

 Perform knowledge elicitation from customer subject matter experts and convert that to derived algorithms
 Analyze large data sets to identify actionable insights with mathematical statistical rigor
 Rigorously critique and correct intermediate results to improve the algorithmic outcomes
 Design and deploy deep learning algorithms and predictive models
 Develop custom data models and algorithms to apply to data sets
 Assess the effectiveness and accuracy of new data sources and data gathering techniques
 Develop processes and tools to monitor and analyze model performance and data accuracy
 Interpret and communicate results to non-technical customers



 What You Must Have:
 

 3+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field. Education can be considered in lieu of experience.
 3 + years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering
 U.S. Citizenship required (required by federal government for position) SCI required.
 1 + years of experience with one or more programming languages (e.g., Python, JavaScript, R, etc.)



 Preferred Skills/Experience:
 

 Experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools
 Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
 Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables
 Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis
 Experience with statistical data analysis, experimental design, and hypotheses validation
 Experience with database querying like SQL
 Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
 Scaled Agile Framework (SAFe) experience
 CompTIA Security+ or higher certification level preferred



   Working at ICF
 
 ICF is a global advisory and technology services provider, but we’re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
 

   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our 
  
   EEO & AA policy
  .
 


   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email 
  
   icfcareercenter@icf.com
   and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: 
  
   Know Your Rights
   and 
  
   Pay Transparency Statement.
  



 Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:
  $77,890.00 - $132,413.00
  Arlington, VA (VA31)
",77890,"['python', 'machine learning', 'deep learning', 'sql']"
"Data Scientist, DentaQuest",DentaQuest,MA,Full-time,"
You are as unique as your background, experience and point of view. Here, you’ll be encouraged, empowered and challenged to be your best self. You'll work with dynamic colleagues - experts in their fields - who are eager to share their knowledge with you. Your leaders will inspire and help you reach your potential and soar to new heights. Every day, you'll have new and exciting opportunities to make life brighter for our Clients - who are at the heart of everything we do. Discover how you can make a difference in the lives of individuals, families and communities around the world.

 DentaQuest manages dental and vision benefits for more than 33 million Americans. Our outcomes-based, cost-effective solutions are designed for Medicaid and CHIP, Medicare Advantage, small and large businesses, and individuals. With a focus on prevention and value, we aim to make quality care accessible to improve the oral health of all.








 Job Description: 







Location: We welcome applicants from anywhere in the U.S.

 At Sun Life, we look for optimistic people who want to make life brighter for our Clients. We understand the value of diverse cultures, perspectives, and identities, and want you to bring your full and authentic self to work. Every day, you’ll be empowered and challenged by working with dynamic colleagues to find new and innovative ways to make Sun Life the best benefits company in America.

 The opportunity:

 Collaborating with operational leads and subject matter experts to develop and implement tactics and strategy for optimizing profitability, clinical performance, member and provider satisfaction and client satisfaction by developing and leveraging analytic tools, financial models and reports, marketing and outreach.
 Is an expert SAS/Python, SQL, Tableau and Excel developer, responsible for presenting recommendations, strategies and findings. Will organize, lead and support efforts to measure, analyze and report on trends enterprise-wide related to provider utilization, reimbursements, access to care, cost management, etc. and identify and promote strategies to positively influence access to quality, cost effective care and improved program performance.
 Works with other areas of the company, including Underwriting, Provider Services, Clinical Management and Client Services to assist in the understanding of provider cost and network trends impacting program costs and profitability and to recommend strategies for improvement wherever possible.


 How you will contribute:

 Working with DentaQuest data to manipulate and analyze data to extract insight, and to develop data science methodologies, and the implementation of actionable finding.
 Use SAS/Python, SQL and other tools to analyze complex business situations and support effort to optimize outcomes measurement, provider optimization, fraud detection, member behavior management.
 Present technical findings and methodologies and present recommendations to senior clients in written and visual presentations.
 Provide mentoring and support to analysts to assist in their development and ability to meet department needs.
 Monitor and track provider reimbursements to identify strategies to ensure access and profitability targets are met in a manner that is consistent with quality, cost effective value-based care.
 Work with other internal departments as necessary to develop strategies and programs to manage dental costs within each market to assure profitability and budgetary goals are met.
 Provide recommendations on department policies, objectives and initiatives. Evaluate and suggest changes as necessary to optimize processes and efficiencies.
 Participate in special projects as needed or requested.
 Adhere to DentaQuest and Business Analytics business processes, SOPs and quality control standards.


 What you will bring with you:

 Bachelor’s degree in Statistics, Computer Science, Math, Finance, Economics or business-related field or equivalent experience.
 5+ years’ experience in data management, analysis and reporting to include experience with combining clinical and financial data.
 Advanced experience with database and business intelligence tools such as SAS, Python, Tableau, MS Report Manager and Report Builder.
 Experience designing and implementing complex algorithms and/or quality metrics.
 Strong foundation in statistical theory and practice required.


 Preferred skills 

Knowledge of health care industry is preferred.
 Strong time management and business process skills.
 Ability work well with others.
 Ability to meet multiple deadlines in a fast-paced environment.

 Do you see yourself in this role even if you haven’t checked all the boxes above? We welcome all talented candidates and are committed to a culture that represents diversity in all forms. If you think you might thrive in this setting, we would love to hear from you.

 Not ready to apply yet but want to stay in touch? Join our talent community to stay connected until the time is right for you!

 Life is brighter when you work at Sun Life

 Excellent benefits and wellness programs to support the three pillars of your well-being – mental, physical and financial – including generous vacation and sick time, market-leading paid family, parental and adoption leave, a partially-paid sabbatical program, medical plans, company paid life and AD&D insurance as well as disability programs and more
 Retirement and Stock Purchase programs to help build and enhance your future financial security including a 401(k) plan with an employer-paid match as well as an employer-funded retirement account
 A flexible work environment with a friendly, caring, collaborative and inclusive culture
 Great Place to Work® Certified in Canada and the U.S.
 Named as a “Top 10” employer by the Boston Globe's “Top Places to Work” two years running


 All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

 If you are a California resident, the salary range for this position is:

 Southern region: $95,200-$142,800 annually 
Central region: $100,400-$150,600 annually 
Northern region: $107,400-$161,100 annually 


If you are a Colorado resident, the salary range for this position is $90,900- $13,400 annually.

 If you are a New York resident, the salary range for this position is $107,400-$161,100 annually.

 If you are Washington resident, the salary range for this position is $100,400-$150,600 annually.

 We consider various factors in determining actual pay including your skills, qualifications, and experience. In addition to salary, this position is eligible for incentive awards based on individual and business performance as well as a broad range of competitive benefits.

 Sun Life Financial is a leading provider of group insurance benefits in the U.S., helping people protect what they love about their lives. More than just a name, Sun Life symbolizes our brand promise of making life brighter -for our customers, partners, and communities. Join our talented, diverse workforce and launch a rewarding career. Visit us at www.sunlife.com/us to learn more.

 At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.

 #LI-remote 

Our Affirmative Action Program affirms our commitment to make reasonable accommodation to the known physical or mental limitation of otherwise-qualified individuals with disabilities or special disabled veterans, unless the accommodation would impose an undue hardship on the operation of our business. Please email recruitingUS@sunlife.com to request an accommodation.

 At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.








 For applicants residing in California, please read our employee California Privacy Policy and Notice.






















 Job Category: 













Advanced Analytics
 







 Posting End Date: 






28/01/2024
 
 All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran
",100400,"['python', 'tableau', 'sql']"
"Data Scientist 2 - Price Optimization - Hybrid - Seattle, WA, Los Angeles, CA, Denver, CO, or Chicago, IL",Nordstrom Inc,CO,Full-time,"
Job Description
 Nordstrom is a specialty retailer offering the very best in fashion and customer service since 1901. We live by five simple values that guide how we work together day-to-day and how we deliver data science & analytics products. We are customer-obsessed, owners at heart, curious and ever-changing, we extend ourselves to our peers and our customers, and we’re here to win!

 Our Pricing Data Science & Analytics team is re-imagining Nordstrom’s core pricing capabilities & developing innovative data products to drive value for our customers. As an integral part of the team, the Data Scientist 2 – Price Optimization will research and implement machine learning & optimization techniques across all areas of our pricing strategy. The ideal candidate is a relentless problem solver with strong technical skills and the ability to create robust data solutions end-to-end. They should be energized by the chance to solve open-ended, high-impact research questions and thrive when collaborating with both technical and non-technical partners.

 If you are passionate about problem solving and want to work on a team dedicated to a culture of inclusion, growth mindset and collaboration, we need you!

 A day in the life…

 Partner with key stakeholders to understand the challenges in the pricing landscape and their current processes and workflows
 Dive deep into complex business problems and immerse yourself in Nordstrom data & outcomes
 Research analytical approaches within the pricing domain and bring forth ideas
 Work on complex and highly ambiguous projects that may connect multiple domains (e.g. pricing, financial planning, demand forecasting)
 Develop, assess, and deploy statistical and machine learning and/or optimization models that make large scale pricing recommendations
 Present findings to business senior management team to inform business strategy and decisions
 Collaborate with cross-functional teams across discipline such as business, product, engineering partners to drive high quality end-to-end solutions from ideation to productionization
 Design experiments to measure success of pricing data products & interpret findings to share with audiences of all technical abilities


 You own this if you have…

 Ph.D. or MS degree in, Statistics, Economics, Machine Learning, Operations Research, Computer Science or other quantitative fields
 3+ years of professional experience analyzing complex data, drawing conclusions, and making recommendations, with direct experience in pricing a plus
 2+ years of experience in extracting & manipulating large data sets from relational databases using SQL
 Experience developing and implementing statistical and machine learning algorithms (e.g. regression, classification and/or clustering) from inception to deployment
 Familiarity with experimental design and the ability to identify, compute and validate the appropriate metrics to measure success
 Demonstrated success working in a highly collaborative technical environment (e.g., code sharing, using revision control, contributing to team discussions/workshops, and collaborative documentation)
 Passion and aptitude for turning complex business problems into concrete hypotheses that can be answered through rigorous data analysis and experimentation
 Proficient coding skills in Python or R
 Expertise in analytical storytelling and stellar communications skills


 #LI-EB1

 We’ve got you covered…

 Our employees are our most important asset and that’s reflected in our benefits. Nordstrom is proud to offer a variety of benefits to support employees and their families, including:

 Medical/Vision, Dental, Retirement and Paid Time Away
 Life Insurance and Disability
 Merchandise Discount and EAP Resources


 A few more important points...

 The job posting highlights the most critical responsibilities and requirements of the job. It’s not all-inclusive. There may be additional duties, responsibilities and qualifications for this job.

 Nordstrom will consider qualified applicants with criminal histories in a manner consistent with all legal requirements.

 Applicants with disabilities who require assistance or accommodation should contact the nearest Nordstrom location, which can be identified at www.nordstrom.com.

 © 2022 Nordstrom, Inc

 Current Nordstrom employees: To apply, log into Workday, click the Careers button and then click Find Jobs.

 Pay Range Details

 The pay range(s) below are provided in compliance with state specific laws. Pay ranges may be different in other locations.
 California: $130,000-$201,500 Annually, Colorado: $114,000-$176,500 Annually, Washington: $130,000-$201,500 Annually
  This position may be eligible for performance-based incentives/bonuses. Benefits include 401k, medical/vision/dental/life/disability insurance options, PTO accruals, Holidays, and more. Eligibility requirements may apply based on location, job level, classification, and length of employment. Learn more in the Nordstrom Benefits Overview by copying and pasting the following URL into your browser: https://careers.nordstrom.com/pdfs/Ben_Overview_17-19.pdf

",114000,"['python', 'machine learning', 'sql']"
Data Analyst I - Windreich Department of Artificial Intelligence & Human Health,Mount Sinai,NY,Full-time,"
Description
 Strength Through Diversity
 Ground breaking science. Advancing medicine. Healing made personal.
 Roles & Responsibilities:
 The Windreich Department of Artificial Intelligence and Human Health within the Icahn School of Medicine at Mount Sinai is searching for a Data Analyst to join Dr. Ipek Ensari’s research laboratory. Our group conducts research in the intersection of biomedical informatics, artificial intelligence, and women’s health. We have several studies that use patient-generated data obtained from various sources (e.g., wearables, sensors, electronic health records) and digital health technologies to investigate women’s reproductive disorders and design disease management strategies. The ideal candidate will possess a combination of technical, domain-specific, and soft skills to analyze complex datasets, evaluate data quality, and communicate insights clearly to technical and non-technical stakeholders.
 Responsibilities


 Acquire and manage patient-generated health data from various sources, ensuring data integrity, privacy, and security.
 Process, clean, and organize large datasets, making them suitable for analysis and modeling.
 Evaluate quality and integrity of the study data obtained from various sources (e.g., wearables, mobile phone Apps, electronic health records)
 Employ statistical techniques to interpret and analyze healthcare data.
 Work closely with healthcare professionals to understand the context and implications of data findings within the realm of women’s health.
 Aid the research team in formulating questions and hypotheses by providing insights from preliminary data analyses.
 Contribute to the design of research methods, ensuring that data-related aspects are adequately addressed.
 Review the latest literature and integrate findings to improve and innovate the lab’s approaches and methodologies.
 Clearly convey data findings, insights, and implications to both technical and non-technical stakeholders through reports, presentations, and discussions.


 Qualifications


 Bachelors degree in computer science, statistics and/or related field, or combination of equivalent work experience and education. Masters degree in relevant field of study preferred.
 2-3 years database application/management experience, preferably in a research or healthcare setting.
 Proficiency in statistical software (e.g. R, Python) and database management skills.
 Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
 Knowledge of data privacy and security.
 Experience with mixed-level modeling (or other similar models) and generalized additive models is a strong plus.
 Must be able to
   
 work closely with others.
 communicate effectively, both written and verbal.
 learn/grow skill sets.



 Employer Description


Strength Through Diversity
The Mount Sinai Health System believes that diversity, equity, and inclusion are key drivers for excellence. We share a common devotion to delivering exceptional patient care. When you join us, you become a part of Mount Sinai’s unrivaled record of achievement, education, and advancement as we revolutionize medicine together. We invite you to participate actively as a part of the Mount Sinai Health System team by:

Using a lens of equity in all aspects of patient care delivery, education, and research to promote policies and practices to allow opportunities for all to thrive and reach their potential.
Serving as a role model confronting racist, sexist, or other inappropriate actions by speaking up, challenging exclusionary organizational practices, and standing side-by-side in support of colleagues who experience discrimination.
Inspiring and fostering an environment of anti-racist behaviors among and between departments and co-workers.

We work hard to acquire and retain the best people and to create an inclusive, welcoming and nurturing work environment where all feel they are valued, belong and are able to professional advance. We share the belief that all employees, regardless of job title or expertise contribute to the patient experience and quality of patient care.
Explore more about this opportunity and how you can help us write a new chapter in our history!
“About the Mount Sinai Health System:
Mount Sinai Health System is one of the largest academic medical systems in the New York metro area, with more than 43,000 employees working across eight hospitals, more than 400 outpatient practices, more than 300 labs, a school of nursing, and a leading school of medicine and graduate education. Mount Sinai advances health for all people, everywhere, by taking on the most complex health care challenges of our time — discovering and applying new scientific learning and knowledge; developing safer, more effective treatments; educating the next generation of medical leaders and innovators; and supporting local communities by delivering high-quality care to all who need it. Through the integration of its hospitals, labs, and schools, Mount Sinai offers comprehensive health care solutions from birth through geriatrics, leveraging innovative approaches such as artificial intelligence and informatics while keeping patients’ medical and emotional needs at the center of all treatment. The Health System includes approximately 7,400 primary and specialty care physicians; 13 joint-venture outpatient surgery centers throughout the five boroughs of New York City, Westchester, Long Island, and Florida; and more than 30 affiliated community health centers. We are consistently ranked by U.S. News & World Report's Best Hospitals, receiving high ""Honor Roll"" status, and are highly ranked: No. 1 in Geriatrics and top 20 in Cardiology/Heart Surgery, Diabetes/Endocrinology, Gastroenterology/GI Surgery, Neurology/Neurosurgery, Orthopedics, Pulmonology/Lung Surgery, Rehabilitation, and Urology. New York Eye and Ear Infirmary of Mount Sinai is ranked No. 12 in Ophthalmology. U.S. News & World Report’s “Best Children’s Hospitals” ranks Mount Sinai Kravis Children's Hospital among the country’s best in several pediatric specialties. The Icahn School of Medicine at Mount Sinai is ranked No. 14 nationwide in National Institutes of Health funding and in the 99th percentile in research dollars per investigator according to the Association of American Medical Colleges. Newsweek’s “The World’s Best Smart Hospitals” ranks The Mount Sinai Hospital as No. 1 in New York and in the top five globally, and Mount Sinai Morningside in the top 20 globally.
The Mount Sinai Health System is an equal opportunity employer. We comply with applicable Federal civil rights laws and does not discriminate, exclude, or treat people differently on the basis of race, color, national origin, age, religion, disability, sex, sexual orientation, gender identity, or gender expression. We are passionately committed to addressing racism and its effects on our faculty, staff, students, trainees, patients, visitors, and the communities we serve. Our goal is for Mount Sinai to become an anti-racist health care and learning institution that intentionally addresses structural racism.”
EOE Minorities/Women/Disabled/Veterans




Compensation
 The Mount Sinai Health System (MSHS) provides a salary range to comply with the New York City Law on Salary Transparency in Job Advertisements. The salary range for the role is $58661 - $74250 Annually. Actual salaries depend on a variety of factors, including experience, education, and hospital need. The salary range or contractual rate listed does not include bonuses/incentive, differential pay or other forms of compensation or benefits.
",58661,['python']
"Sr Engineer - High-Performance Machine Learning Infra (Python, Kubernetes, PyTorch/TensorFlow)",TARGET,CA,Full-time,"
 The pay range is $92,000.00 - $198,700.00
 
 Pay is based on several factors which vary based on position. These include labor markets and in some instances may include education, work experience and certifications. In addition to your pay, Target cares about and invests in you as a team member, so that you can take care of yourself and your family. Target offers eligible team members and their dependents comprehensive health benefits and programs, which may include medical, vision, dental, life insurance and more, to help you and your family take care of your whole selves. Other benefits for eligible team members include 401(k), employee discount, short term disability, long term disability, paid sick leave, paid national holidays, and paid vacation. Find competitive benefits from financial and education to well-being and beyond at https://corporate.target.com/careers/benefits.

 JOIN TARGET AS A SENIOR ENGINEER – HIGH-PERFORMANCE MACHINE LEARNING INFRA TEAM

 About us:
 As a Fortune 50 company with more than 400,000 team members worldwide, Target is an iconic brand and one of America’s leading retailers. Working at Target means the opportunity to help all families discover the joy of everyday life. Caring for our communities is woven into who we are, and we invest in the places we collectively live, work, and play. We prioritize relationships, fuel and develop talent by creating growth opportunities, and succeed as one Target team. At our core, our purpose is ingrained in who we are, what we value, and how we work. It is how we care, grow, and win together.

 Behind one of the world’s best-loved brands is a uniquely capable and brilliant team of machine learning engineers, data pipeline engineers and applied data scientists. A role with the Target High-Performance Machine Learning (HPML) team means the chance to be a machine learning engineer who will create high-performance computing clusters, supercomputers, platforms, and cloud services for AI training and inference at scale. You will be challenged to harness Target’s impressive data centers and cloud environments to build the clusters that power solutions our partners in Computer Vision, Search, Personalization, Supply Chain Optimization, Cyber Security, and many more teams rely on.

 Use your skills, experience, and talents to be a part of groundbreaking thinking and visionary goals.

 As a Senior Machine Learning Engineer at High-Performance Machine Learning, you will have the opportunity to create software solutions using Agile practices, Infrastructure as Code and DevOps processes. Your responsibilities will include designing, implementing, debugging, and supporting high-quality, distributed, and large-scale software solutions to deploy, upgrade, and extend Kubernetes clusters for accelerated and distributed computing and dataset caches. You will develop scalable software systems while employing CI/CD practices. You will also partner with other engineers and team members to develop software that meets business needs. HPML team follows Agile methodology for software development and technical documentation, and we innovate constantly and stay current with the latest AI accelerator technologies. Your job is focused on solving AI server deployments and container orchestration problems at hand.  About you:

 Four-year degree in Computer Science or equivalent work experience
 3+ years of experience developing software solutions
 Proven track record in writing code that is correct, maintainable, testable, expressive, easy to change, efficient and fault-tolerant
 Extensive experience programming in Python or Go
 Experience with Infrastructure as Code
 Expertise in container orchestration, Kubernetes and high-performance computing clusters
 Familiarity with machine learning hardware like Tensor GPUs or AI chips
 Familiarity with machine learning frameworks: PyTorch, TensorFlow, or Jax
 Demonstrated knowledge of Linux services


 This position will operate as a Hybrid/Flex for Your Day work arrangement based on Target’s needs. A Hybrid/Flex for Your Day work arrangement means the team member’s core role will need to be performed both onsite at the Target Sunnyvale location the role is assigned to and virtually, depending upon what your role, team and tasks require for that day. Work duties cannot be performed outside of the country of the primary work location, unless otherwise prescribed by Target.

 Americans with Disabilities Act (ADA)

 Target will provide reasonable accommodations with the application process upon your request as required to comply with applicable laws. If you have a disability and require assistance in this application process, please visit your nearest Target store or Supply Chain Facility or reach out to Guest Services at 1-800-440-0680 for additional information.
 Qualifications:
",92000,"['tensorflow', 'pytorch', 'python', 'machine learning']"
Data Scientist - Computational Chemistry,Amgen,CA,Full-time,"
HOW MIGHT YOU DEFY IMAGINATION?
 You’ve worked hard to become the professional you are today and are now ready to take the next step in your career. How will you put your skills, experience and passion to work toward your goals? At Amgen, our shared mission—to serve patients—drives all that we do. It is key to our becoming one of the world’s leading biotechnology companies, reaching over 10 million patients worldwide. Come do your best work alongside other innovative, driven professionals in this meaningful role.
 Data Scientist - Computational Chemistry
 Live
 What you will do
 Let’s do this. Let’s change the world. We are actively seeking a highly qualified and motivated Data Scientist with a strong background in cheminformatics and AI/ML. The scientist will join the computational chemistry team within Amgen’s Center for Research Acceleration and Digital Innovation (CRADI). CRADI functions within our drug discovery engine to accelerate our pipeline from target inception through drug development. The computational chemistry team develops and applies tools to generate novel molecules and predict chemical properties to guide the discovery of small molecule therapeutics. In this vital role, you will collaborate with a multi-disciplinary team of scientists to train, deploy, and maintain ML models for small molecule data. Furthermore, you will play an active role in developing software packages used by both computational and medicinal chemists for drug discovery projects. An ability to communicate clearly and collaborate effectively with colleagues from different fields will be essential.
 Responsibilities:

 Participate on multiple interdisciplinary discovery project teams and play a key role in data collection, model training and deployment for chemical property prediction
 Apply structure-based, ligand-based and machine learning/generative design to guide experimental efforts
 Collaborate with engineers and data scientists to develop innovative cheminformatics tools that facilitate data access, model utilization, and output interpretation
 Clearly document methods and analyses to allow reproducible research
 Monitor, review, and critically interpret published computational research spanning small molecule computer-aided drug design
 Proactively scope and deploy novel ML/AI methods for chemical property prediction and molecule generation
 Contribute to guide infrastructure improvements, software portfolio recommendations and prospecting of relevant cutting-edge computational technologies/companies

 The preferred location for this position is at our Thousand Oaks (CA) site; but consideration will be given to remote candidates as well
 Win
 What we expect of you
 We are all different, yet we all use our unique contributions to serve patients. The dynamic professional we seek is a strong communicator with these qualifications.
 Basic Qualifications:
 Doctorate degree
 OR
 Master’s degree and 3 years of Cheminformatics and ML experience
 Or
 Bachelor’s degree and 5 years of Cheminformatics and ML experience
 Or
 Associate’s degree and 10 years of Cheminformatics and ML experience
 Or
 High school diploma / GED and 12 years of 4 years of experience Cheminformatics and ML experience
 Preferred Qualifications:

 PhD. in computer science, computational chemistry, or related field
 Fluency in scientific programming and tool development with Python
 Proven record of innovative thinking to propose and champion the development of novel algorithms and AI/ML models that generate interpretable and actionable results for practical applications
 Experience with software development best practices, including code versioning, documentation, and testing, amongst others
 Experience with deep learning frameworks (e.g., PyTorch)
 Experience with cloud computing
 Creative, open-minded and passionate about scientific research
 Demonstrated ability to thrive in a team environment
 Strong external publication record

 Thrive
 What you can expect of us
 As we work to develop treatments that take care of others, we also work to care for our teammates’ professional and personal growth and well-being.
 The annual base salary range for this opportunity in the U.S. is $135,935 - $163,269.
 In addition to the base salary, Amgen offers a Total Rewards Plan comprising health and welfare plans for staff and eligible dependents, financial plans with opportunities to save towards retirement or other goals, work/life balance, and career development opportunities including:

 Comprehensive employee benefits package, including a Retirement and Savings Plan with generous company contributions, group medical, dental and vision coverage, life and disability insurance, and flexible spending accounts.
 A discretionary annual bonus program, or for field sales representatives, a sales-based incentive plan
 Stock-based long-term incentives
 Award-winning time-off plans and bi-annual company-wide shutdowns
 Flexible work models, including remote work arrangements, where possible

 Apply now
 for a career that defies imagination
 Objects in your future are closer than they appear. Join us.
 careers.amgen.com

 Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.
 We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
",135935,"['pytorch', 'python', 'machine learning', 'deep learning']"
Data and Quality Supervisor - Research Scientist Supervisor 2,State of Minnesota,MN,Full-time,"



Job Details





Working Title: Data and Quality Supervisor Job Class: Research Scientist Supervisor 2 Agency: Health Department

Who May Apply: Open to all qualified job seekers
Date Posted: 11/15/2023
Closing Date: 12/06/2023
Hiring Agency/Seniority Unit: Health Department / Health-MMA
Division/Unit: Public Health Laboratory / PHL NBS Qual/Data Staff
Work Shift/Work Hours: Day Shift / 8:00 am - 4:30 pm
Days of Work: Monday - Friday
Travel Required: No
Salary Range: $36.72 - $52.79 / hourly; $76,671 - $110,225 / annually
Classified Status: Classified
Bargaining Unit/Union: 216 - Middle Management Association/MMA
FLSA Status: Exempt - Executive
Telework Eligible: No
Designated in Connect 700 Program for Applicants with Disabilities: Yes

 Make a difference in the lives of Minnesotans.
 The work you’ll do is more than just a job. Join the talented, engaged and inclusive workforce dedicated to creating a better Minnesota.






 Job Summary





Join the mission-driven team at the Public Health Laboratory and promote and protect the health of all Minnesotans! The purpose of the Data and Quality Supervisor is to provide management, direction, and leadership for the Data and Quality unit in the Newborn Screening Section at the Public Health Laboratory. The incumbent will represent MDH in public forums, including presentations at conferences and, when necessary, engagement with local and national media.
 The position leads all activities in the collection, analysis, and transmission of data; retention and management of records; as well as regulatory and quality system compliance. 
These leadership activities include:

Directs and prioritizes all staff activities. 
Investigates, evaluates, and implements processes to continually improve newborn screening data use and quality system. 
Incorporates continuous quality control/quality assurance measures.
Researches and applies statistics and data analytics in the determination of program performance.
Collaborates with key newborn screening stakeholders. 

All positions within the MDH Public Health Lab will work to cultivate an inclusive work environment for all, with respect to diversity and equity.






 Qualifications



Minimum Qualifications
 Experience in these areas must be clearly stated on your resume to be considered.

Supervisory or other leadership experience OR completion of a leadership development program (such as Emerging Leaders Institute, etc.)
3 years of experience with data management, analytic methods, or records management systems.
Experience in Newborn Screening

 Previous experience and understanding below is required to be considered a candidate and will be assessed during the interview process:

Knowledge of best practices for data visualizations
Experience working with a LIMS (laboratory information management system)
Knowledge of health information technology trends, requirements, and standards
An understanding of national privacy standards (i.e., HIPAA) as they pertain to conduction of Newborn Screening in the State of Minnesota to confirm program compliance
Understand diversity, equity, and inclusion principles, and how they can be applied in the workplace to promote an inclusive work environment for all

 Preferred Qualifications

An understanding of Minnesota Statutes 144.125-128 and 13.3805, Minnesota Rules 4615.0300-4615.0700
Knowledge of MDH record retention schedule and applicable statutes
Experience with newborn hearing screening, heart screening, and bloodspot testing for diseases in newborns
Experience working with quality for a laboratory and knowledge of CMS and CLIA regulations
Experience working with Tableau and creating data visualizations and dashboards
Experience performing internal audits for a laboratory

 Additional Requirements
 This position requires successful completion of a background check.






 Application Details



How to Apply 
Select “Apply for Job” at the top of this page. If you have questions about applying for jobs, contact the job information line at 651-259-3637 or email careers@state.mn.us. For additional information about the application process, go to http://www.mn.gov/careers. 
If you have questions about the position, contact Elizabeth Huckins at elizabeth.huckins@state.mn.us or 651-201-5609. 
To receive consideration as a Connect 700 Program applicant, apply online, email the Job ID#, the Working Title and your valid Proof of Eligibility Certificate by the closing date to Elizabeth Huckins at elizabeth.huckins@state.mn.us. 
About Health Department 
Come work for one of the best public health systems in the nation and you will contribute to our mission to protect, maintain and improve the health of all Minnesotans. We are working hard to achieve our vision for health equity in Minnesota, where all communities are thriving and all people have what they need to be healthy. 
Why Work for Us 
Diverse Workforce 
We are committed to continually developing a workforce that reflects the diversity of our state and the populations we serve. The varied experiences and perspectives of employees strengthen the work we do together and our ability to best serve the people of Minnesota. 
A recent engagement survey of State of Minnesota employees found: 

95% of employees understand how their work helps achieve their agency’s mission 
91% of employees feel trusted to do their jobs 
88% of employees feel equipped to look at situations from other cultural perspectives when doing their job 
87% of employees report flexibility in their work schedule 

Comprehensive Benefits 
Our benefits aim to balance four key elements that make life and work meaningful: health and wellness, financial well-being, professional development, and work/life harmony. As an employee, your benefits may include: 

Public pension plan 
Training and professional development 
Paid vacation and sick leave 
11 paid holidays each year 
Paid parental leave 
Low-cost medical and dental coverage 
Prescription drug coverage 
Vision coverage 
Wellness programs and resources 
Employer paid life insurance 
Short-term and long-term disability 
Health care spending and savings accounts 
Dependent care spending account 
Tax-deferred compensation 
Employee Assistance Program (EAP) 
Tuition reimbursement 
Federal Public Service Student Loan Forgiveness Program 

Programs, resources and benefits eligibility varies based on type of employment, agency, funding availability, union/collective bargaining agreement, location, and length of service with the State of Minnesota. 

AN EQUAL OPPORTUNITY EMPLOYER 
Minnesota state agencies are equal opportunity, affirmative action, and veteran-friendly employers. The State of Minnesota recognizes that a diverse workforce is essential and strongly encourages qualified women, minorities, individuals with disabilities, and veterans to apply. 
We will make reasonable accommodations to all qualified applicants with disabilities. If you are an individual with a disability who needs assistance or cannot access the online job application system, please contact the job information line at 651-259-3637 or email careers@state.mn.us and indicate what assistance is needed.




",73440,['tableau']
Senior Data Analyst,Integral Ad Science,IL,Full-time,"
Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for Senior Data Analyst. You will be responsible for ongoing monitoring and surfacing of new threats in the digital advertising ecosystem. This role and team will have extensive interaction with large data sets (we monitor hundreds of thousands of transactions per second and collect tens of billions of events each day)
 Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for Data Analysts. You will be responsible for ongoing monitoring and surfacing of new threats in the digital advertising ecosystem. This role and team will have extensive interaction with large data sets (we monitor hundreds of thousands of transactions per second and collect tens of billions of events each day) What you'll get to do:

Analyze and investigate impression level data in order to conceptualize stories, and write research reports, articles, blogs and bulletins
Partner with Marketing to drive publication and distribution of noteworthy stories coming from internal investigations
Apply business insight to research for C-Level thought leadership stories that define high level trends by industry, vertical or geographic area
Stay on top of emerging threats that could be first to market blogs
Assist product management, data science, and development in product/solution planning and prioritization

Qualifications/Requirements:

Bachelors or Master's degree in data science, computer science, computer engineering, digital forensics, cyber security, telecommunications, information assurance or security studies
At least 7+ years data analysis / data mining experience
Experience with ad tech strong preferred
Experience with the Threat Landscape and familiarity with threat tracking, attribution, and reporting
Ability to read/write Regex and Yara
Familiarity with ESX/VMware virtualization environments
Excellent analytical abilities and a strong ability to think creatively when approaching issues
Strong SQL skills including building functions & procedures, writing complex queries, and using SQL as an investigative tool
Familiarity with Python (Pandas/Numpy)
Ability to synthesize technical information about large datasets to communicate both qualitatively and quantitatively
Strong data mining skills
Strong interpersonal and presentation skills required – both oral and written, with the ability to educate others about complex technology/methodologies and clearly articulate business level benefits/impacts.
Strong verbal presentation and writing skills, including the demonstrated ability to write clear and concise text

New York Applicants: The salary range for this position is $100,000 - $172,000, actual pay may vary based on experience or geographic location.
 About Integral Ad Science

Integral Ad Science (IAS) is a leading global media measurement and optimization platform that delivers the industry's most actionable data to drive superior results for the world's largest advertisers, publishers, and media platforms. IAS's software provides comprehensive and enriched data that ensures ads are seen by real people in safe and suitable environments, while improving return on ad spend for advertisers and yield for publishers. Our mission is to be the global benchmark for trust and transparency in digital media quality. For more information, visit integralads.com.

Equal Opportunity Employer:
 IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.
 California Applicant Pre-Collection Notice:
 We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.
 To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN
 Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.
 #LI-Hybrid
",100000,"['python', 'numpy', 'pandas', 'sql']"
AI/ML Engineer II,kraken,Remote,Full-time,"


Location

     United States - Remote, Europe - Remote, Canada - Remote
   


 Type

     Full time
   


 Department


      Engineering
    
 AI & Machine Learning



 Compensation


 $135K – $203K




      This is the target annual salary range for this role. This range is not inclusive of other additional compensation elements, such as our Bonus program, Equity program, Wellness allowance, and other benefits [US Only] (including medical, dental, vision and 401(k)).
    


      The compensation range provided is influenced by various factors and represents the initial target range. Our salary offerings are dynamic and we strive to ensure that our base salary and total compensation package aligns and recognizes the top talent we aim to attract and retain. The compensation package of the successful candidate is based on various factors such as their skillset, experience, and job scope.
    





 





 Building the Future of Crypto

 Our Krakenites are a world-class team with crypto conviction, united by our desire to discover and unlock the potential of crypto and blockchain technology.

 What makes us different? 
Kraken is a mission-focused company rooted in crypto values. As a Krakenite, you’ll join us on our mission to accelerate the global adoption of crypto, so that everyone can achieve financial freedom and inclusion. For over a decade, Kraken’s focus on our mission and crypto ethos has attracted many of the most talented crypto experts in the world.

 Before you apply, please read the Kraken Culture page to learn more about our internal culture, values, and mission. 

As a fully remote company, we have Krakenites in 60+ countries who speak over 50 languages. Krakenites are industry pioneers who develop premium crypto products for experienced traders, institutions, and newcomers to the space. Kraken is committed to industry-leading security, crypto education, and world-class client support through our products like Kraken Pro, Kraken NFT, and Kraken Futures.

 Become a Krakenite and build the future of crypto!
 Proof of work

 The team

 Kraken is looking for an experienced Machine Learning engineer to join our AI/ML Team in the centralized Data organization. In this role you will be applying cutting edge AI/ML technology to solving the most complex and exciting problems in the quickly growing and evolving crypto industry. We are looking for an extremely strong communicator and team-player, who is able to break down large complex problems into smaller more manageable problems-to-solve. You will take initiative to identify business problems, explore different ways to resolve issues, and systematically find the most efficient and effective way to deliver business impact.

 The Opportunity



        Assist in designing, implementing, and deploying Machine Learning solutions to solve complex problems and deliver real business value ie. revenue, engagement and customer satisfaction.
      


        Collaborate with data scientists, software engineers, and business partners to identify AI/ML opportunities for improving operation scalability and efficiency.
      


        Assist in developing production-grade ML models to power personalized customer experience, content recommendation, fraud detection/prevention and more.
      


        Support the monitoring and improvement of model performance via data enhancement, feature engineering, experimentation and online/offline evaluation.
      


        Stay up-to-date in machine learning, and artificial intelligence trends and technologies, all while contributing to the growth of AI/ML in the Crypto industry.
      


 Skills you should HODL



        Experience in building, deploying, measuring, and maintaining machine learning models.
      


        Familiarity with the software development lifecycle, DevOps (build, continuous integration, deployment tools) and best practices.
      


        Programming skills in Python, Scala, Go or other languages.
      


        Good written and verbal communication skills and interpersonal skills.
      


        Experience or familiarity with ML frameworks, such as scikit-learn, Tensorflow, PyTorch.
      


        Experience or familiarity with Big Data tools – Spark, S3, Hadoop.
      


        Experience or familiarity with MLOps platforms, such as Kubeflow or MLFlow, is a plus.
      


        Knowledge of GenAI tools, such as Langchain, LlamaIndex, and open source Vector DBs, is a plus.
      


        Bachelor's degree in Computer Science, Machine Learning or related field.
      


        A minimum of 2 years of experience in AI/ML engineering, with a focus on learning and skill development.
      

 Location Tagging: #US #EU #LI-Remote

 Kraken is powered by people from around the world and we celebrate all Krakenites for their diverse talents, backgrounds, contributions and unique perspectives. We hire strictly based on merit, meaning we seek out the candidates with the right abilities, knowledge, and skills considered the most suitable for the job. We encourage you to apply for roles where you don't fully meet the listed requirements, especially if you're passionate or knowledgable about crypto!

 As an equal opportunity employer, we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.




",135000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'hadoop']"
SME Data Scientist,ManTech International Corporation,Remote,Full-time,"
Secure our Nation, Ignite your Future 

Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of solutions to promote efficient trade and travel. Further, effective solutions help CBP ensure the movement of people, capital, and products is legal, safe, and secure. 

In response to this challenge, ManTech, as a trusted mission partner of CBP, seeks capable, qualified, and versatile data scientists to help lead the development and delivery of high-quality predictive modelling solutions. Successful applicants will serve as recognized subject matter experts in the application of quantitative methods, machine learning algorithms, and predictive models to address complex national and homeland security challenges. They will help our team to leverage large structured and unstructured datasets to develop and operationalize models, tools, and applications that drive optimized decision making. Project tasks include data collection, mining, data and text analytics, clustering analysis, pattern recognition and extraction, automated classification and categorization, and entity resolution to implement and enhance automated risk assessment. The products we develop provide actionable insight with real and immediate impact on the safety and security of the United States, its citizens, visitors, and economy. 

The strongest applicants will offer multiple years of experience in highly dynamic, threat/risk driven operating environments. They will also have a proven track record of delivering production ready decision support tools and applications employed in the field and by mission-support entities. Further, highly competitive applicants will have a demonstrated capacity to: work closely and collaboratively with mission stakeholders; respond to emergent, mission-driven changes in priorities and expected outcomes; and, apply new and emerging tools and techniques. Within three - six months of joining the project, data scientists will be expected to: 

Perform hands-on analysis and modeling involving the creation of intervention hypotheses and experiments, assessment of data needs and available sources, determination of optimal analytical approaches, performance of exploratory data analysis, and feature generation (e.g., identification, derivation, aggregation). 
Collaborate with mission stakeholders to define, frame, and scope mission challenges where big data interventions may offer important mitigations and develop robust project plans with key milestones, detailed deliverables, robust work tracking protocols, and risk mitigation strategies. 
Demonstrate proficiency in extracting, cleaning, and transforming CBP transactional and mission data associated within an identified problem space to build predictive models as well as develop appropriate supporting documentation. 
Leverage knowledge of a variety of statistical and machine learning techniques and methods to define and develop programming algorithms; train, evaluate, and deploy predictive analytics models that directly inform mission decisions. 
Execute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching. 
Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior government stakeholders throughout the model development/ project lifecycle through written as well as in-person reporting. 

Education: 

Bachelor’s Degree (required), Master’s or Ph.D. degree (preferred) in operations research, industrial engineering, mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience. 
Qualifications (Degree/years):  HS Diploma/GED and 15+ years  AS/AA and 13-18 years  BS/BA and 7-12 years  MS/MA/MBA and 5-9 years  PhD/Doctorate and 3-7 years  

Required Qualifications 

5+ years of related experience 
Experience in developing machine learning models and applying advanced analytics solutions to solve complex business problems 
Experience with programming languages including: R, Python, Scala, Java. 
Proficiency with SQL programming 
Experience constructing and executing queries to extract data in support of EDA and model development 
Proficiency with statistical software packages including: SAS, SPSS Modeler, R, WEKA, or equivalent 
Experience with pattern recognition and extraction, automated classification, and categorization 
Experience with entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation) 
Experience with unsupervised and supervised machine learning techniques and methods 
Experience performing data mining, analysis, and training set construction 


Desired Qualifications 

Proficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc. 
Proficiency with Supervised Machine Learning methods including Decision Trees, Support Vector Machines, Logistic Regression, Random/Rotation Forests, Categorization/Classification, Neural Nets, Bayesian Networks, etc. 
Experience with pattern recognition and extraction, automated classification, and categorization 
Experience with entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation) 
Experience with visualization tools and techniques (e.g., Periscope, Business Objects, D3, ggplot, Tableau, SAS Visual Analytics, PowerBI) 
Experience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop) 
Master’s Degree in mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience 

Clearance: 
Selected applicants must be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) suitability. 
The projected compensation range for this position is $105,900-$175,800. There are differentiating factors that can impact a final salary/hourly rate, including, but not limited to, Contract Wage Determination, relevant work experience, skills and competencies that align to the specified role, geographic location (For Remote Opportunities), education and certifications as well as Federal Government Contract Labor categories. In addition, ManTech invests in it’s employees beyond just compensation. ManTech’s benefits offerings include, dependent upon position, Health Insurance, Life Insurance, Paid Time Off, Holiday Pay, Short Term and Long Term Disability, Retirement and Savings, Learning and Development opportunities, wellness programs as well as other optional benefit elections. 
 
For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone. 























ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law. 

If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services. 

If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access






















",105900,"['python', 'machine learning', 'tableau', 'sql', 'kafka', 'hadoop']"
Data Mining and Analytics Engineer (Junior),ICF,VA,Full-time,"

  ICF International seeks a Junior Data Mining and Analytics Engineer to support the research and development of new cyber analytic capabilities that will help the US protect and defend its networks and critical information systems. The successful cleared candidate will act as a Data Mining and Analytics Engineer to support a large federal cyber security analytic program. Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate. Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large-scale.
 


 As the Junior Data Mining and Analytics Engineer, your skillset will create useful and actionable insight for the customer through the development of analytic solutions (hardware, analytics, tools, techniques, practices, deployment, standards, performance specifications, etc.) for analytic use cases developed during the performance of this project. You will work closely with the Analytics Research team to identify platform enhancements that support the forward-looking analytics under consideration.
 


 The ideal candidate has extensive knowledge of a wide variety of systems and networks to include high-volume/high-availability systems. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. This is an opportunity to contribute to an important project from its beginning, work with the latest and emerging technologies, and all while building a great career at ICF!
 


 This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region.
 


 What You Will Be Doing:
 

 Perform knowledge elicitation from customer subject matter experts and convert that to build analytic solutions
 Design, engineer, and optimize sustainment of large-scale distributed computation platforms and supporting environment (ecosystems) for various stakeholders, business owners, and industry partners
 Oversee the transition of services from third-party vendors to the analytic environment and be responsible for ad hoc and formal end-user training
 Identify applicable data to perform analytics and create solutions to acquire, transform, and load or correlate data components to and from the analytic environment
 Develop custom data modeling procedures to assist with data mining, modeling, and production
 Assess the effectiveness and accuracy of new data sources and data gathering techniques
 Develop processes and tools to monitor and analyze model performance and data accuracy
 Interpret and communicate results to non-technical customers



 What You Must Have:
 

 Active high-level security clearance required as part of client contract requirements
 Bachelor’s degree in Computer Science, Mathematics, Engineering, or related field
 US Citizenship required as part of client contract requirements
 Practical working experience and advanced knowledge of cyber threats, tools, techniques, and processes.
 Experience in data modeling and working with datasets of all sizes using a variety of data mining and data analysis methods/tools



 Preferred Skills/Experience:
 

 Master’s degree in Computer Science, Mathematics, Engineering, or related field
 Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
 Experience in developing analytic tools, processes, and governance for storing, modeling, capturing, and delivering data to the client’s enterprise
 Experience with computational notebook software such as Zeppelin or Jupyter
 Experience with the application of visual analytics to computational analytic results
 Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)
 Experience with database querying like SQL
 Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
 Scaled Agile Framework (SAFe) experience
 Amazon Web Services (AWS) Certified Cloud Practitioner or higher desired
 CompTIA Security+ or higher cybersecurity certification preferred


   #cybsr1
 


   Working at ICF
 
 ICF is a global advisory and technology services provider, but we’re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
 

   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our 
  
   EEO & AA policy
  .
 


   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email 
  
   icfcareercenter@icf.com
   and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: 
  
   Know Your Rights
   and 
  
   Pay Transparency Statement.
  



 Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:
  $64,372.00 - $109,432.00
  Arlington, VA (VA31)
",64372,"['python', 'aws', 'sql']"
Sr. Data Analyst,BAXTER,IL,Full-time,"
This is where you save and sustain lives 

At Baxter, we are deeply connected by our mission. No matter your role at Baxter, your work makes a positive impact on people around the world. You’ll feel a sense of purpose throughout the organization, as we know our work improves outcomes for millions of patients.

 Baxter’s products and therapies are found in almost every hospital worldwide, in clinics and in the home. For over 85 years, we have pioneered significant medical innovations that transform healthcare.

 Together, we create a place where we are happy, successful and inspire each other. This is where you can do your best work.

 Join us at the intersection of saving and sustaining lives— where your purpose accelerates our mission.

 Your Role at Baxter:

 The Sr. Data Analyst is responsible for partnering across regions and functions to perform detailed analysis on various datasets. This role will collaborate with the global service commercial and marketing team, field service personnel, project management and all levels of service leadership to provide data and metrics that help guide business decisions.

 Your Team:

 Baxter offers dental, medical, and vision insurance, paid time off, parental leave, and more.

 What you'll be doing:

 Designs, develops, and maintains ongoing metrics, reports, analyses, dashboards applying Tableau, Power BI, SQL and other tools as needed.
 Performs detailed data analysis using SQL language and various datasets.
 Analyzes and manipulates data in Excel and handles and merges multiple Excel data files without error or data corruption.
 Partners and collaborates with the global service commercial and marketing team, field service personnel, project management and all levels of service leadership to provide data and metrics that help guide business decisions.
 Analyzes data sets, highlights anomalies in the data that could lead to business efficiency.
 Understands business partners data needs, captures, analyzes, and reports accurate business and financial data per user requirements, utilizes critical thinking skills to interpret the data and provides end user training on how to interpret and use data workbooks.
 Assists in continuous improvement projects, training, and initiatives that drive business and financial results.
 Travel up to 10% of the time for team meetings.


 What you'll bring:

 Bachelor’s degree in Business Administration, Information Management, Computer Science, Statistics, or Finance, required.
 3-5 years of experience within data analytics or related field, required.
 3+ years of experience with PowerBI, Microsoft SQL Server, T-SQL, Tableau, or similar report visualization tools and general report generation and relevant analytics experience, preferred.
 Experience with Power Automate, Python programming language, or R-programming language, preferred.
 Proficiency with MS Office (Word, Excel, PowerPoint).
 Excellent communication and strong interpersonal skills.
 Ability to work in a team-oriented environment, often cross-functionally, and handle tasks concurrently, with a high attention to detail.
 Ability to define problems, determine solutions and follow through to completion.
 Analytical background with ability to understand statistical concepts.


 We understand compensation is an important factor as you consider the next step in your career. At Baxter, we are committed to equitable pay for all employees, and we strive to be more transparent with our pay practices. The estimated base salary for this position is $80,000 - $110,000 annually. The estimated range is meant to reflect an anticipated salary range for the position. We may pay more or less than of the anticipated range based upon market data and other factors, all of which are subject to change. Individual pay is based on upon location, skills and expertise, experience, and other relevant factors. This position may also be eligible for discretionary bonuses. For questions about this, our pay philosophy, and available benefits, please speak to the recruiter if you decide to apply and are selected for an interview.

 #LI-JE1

 The successful candidate for this job may be required to verify that he or she has been vaccinated against COVID-19, subject to reasonable accommodations for individuals with medical conditions or religious beliefs that prevent vaccination, and in accordance with applicable law.

 Equal Employment Opportunity

 Baxter is an equal opportunity employer. Baxter evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status or any other legally protected characteristic.  EEO is the Law EEO is the law - Poster Supplement Pay Transparency Policy

 Reasonable Accommodations  Baxter is committed to working with and providing reasonable accommodations to individuals with disabilities globally. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please click on the link here and let us know the nature of your request along with your contact information.

 Recruitment Fraud Notice  Baxter has discovered incidents of employment scams, where fraudulent parties pose as Baxter employees, recruiters, or other agents, and engage with online job seekers in an attempt to steal personal and/or financial information. To learn how you can protect yourself, review our Recruitment Fraud Notice. 118048
  #LI-Remote
",80000,"['python', 'tableau', 'sql']"
Sr. Data Scientist,Saks,NY,Full-time,"Who We Are:
 Saks is a world-renowned luxury ecommerce destination. The company’s unique approach combines a focus on the digital customer experience with a strong connection to a network of extraordinary stores that extends that seamless experience into the real world.On its website and app, Saks offers an unparalleled selection of curated merchandise across fashion for women and men, beauty, jewelry, home décor and more. In addition to the shopping experience, customers come to Saks for inspiring editorial content, access to digital stylists, lifestyle experiences and other world-class services. The company is currently in the midst of a dramatic expansion, driven by significant enhancements to its platforms and offerings, with the goal of becoming the preeminent destination for luxury internationally. 


Role Summary:
 Saks.com LLC seeks Data Scientist in New York, NY, to analyze large amounts of information to discover trends and patterns to help Saks’ leadership team make data-driven decisions. Requirements: Master’s degree or foreign equivalent in Mathematics, Statistics or a related field and three (3) years of experience in the job offered or related occupation utilizing Structured Query Language (SQL), Python, R, and other programming languages to conduct business analytics tasks such as data processing, EDA (exploratory data analysis) and reporting. One (1) full year of experience designing and conducting Hypothesis Experiments for marketing campaign pilots and provide insights to improve business performance; utilizing machine learning technologies such as Tensorflow, Keras, and PyTorch to build algorithms for site personalization and advanced marketing strategies; utilizing cloud based tools such as Airflow, Docker, Kubernetes, and Snowflake to build MLops pipelines and for model production and integration with other applications; and applying algorithms including K Nearest Neighbors, Random Forest, GBM, Neural Networks, boosted trees, LDA, collaborative filtering, Bayesian to resolve business problems. Telecommuting and/or working from home may be permissible pursuant to company policies. When not telecommuting, must report to work site. Offered salary is between $135,782.00 and $140,000.00. Submit resume to jobs@saks.com. Please indicate job code KZ10302023EW. 


Your Life and Career at Saks:
 Exposure to rewarding career advancement opportunities 
A culture that promotes a healthy, fulfilling work/life balance 
Benefits package for all eligible full-time employees (including medical, vision and dental). 
An amazing employee discount 

 Thank you for your interest in Saks. We look forward to reviewing your application. 

 Saks provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Saks complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. 

 Saks welcomes all applicants for this position. Should you be individually selected to participate in an assessment or selection process, accommodations are available upon request in relation to the materials or processes to be used. 

 Saks.com is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. 



The above expected salary range may have some variability based upon factors including, but not limited to, a candidate’s overall experience, qualifications, and geographic location. If you are interested in the role, we encourage you to apply and, if selected to move forward in the interview process, you will have a chance to speak with our recruitment team regarding your specific salary expectations.
",135782,"['tensorflow', 'pytorch', 'python', 'machine learning', 'docker', 'sql', 'airflow']"
Data Science Engineer,GE Renewable Energy,NY,Full-time,"
Job Description Summary The Lead Fleet Analytics Developer will be responsible for developing analytics and data visualizations for GE Renewable Energy’s in-service wind fleet, as well as supporting contractual customer reporting. You will lead automation efforts, streamline current processes, and troubleshoot issues arising from analysis of data generated by GE’s global fleet of wind turbines.
 
 Job Description
 About us: GE’s Onshore Wind business has a total installed base of more than 50,000 wind turbines in more than 35 counties, with 100+ GW of global installed capacity. We harness increased onshore wind energy potential through a broad family of turbines that are uniquely suited for a variety of wind environments, including Cypress, GE’s most powerful onshore wind turbine, and GE’s 2MW platform, which has more than 20GW installed and in operation today. We are committed to our customers’ success in wind, offering a broad portfolio of products and services that make renewables the energy of choice for a cleaner future.

 Essential Responsibilities:
 In this role, you will:

 Develop essential tools that will support improvement of key fleet metrics (i.e. availability, down time, fault rates, production, etc.)
 Develop SQL queries against a data warehouse, Amazon Redshift and MS SQL database
 Streamline and automate processes and reports, including improvements to proprietary message handling logic, monthly and weekly customer reporting, and efficiency metrics
 Provide engineering and services support teams with actionable data and analysis to enable quick response and effective technical troubleshooting
 Produce customer-facing analytics and applications using a variety of programming languages
 Maintain and expand on existing tools and software
 Manage local databases and assist in management of data infrastructure
 Interact with key stakeholders in the business (Sales, Commercial, Services) to develop data standardization practices


 Required Qualifications:

 Bachelor’s Degree in Computer Science, Mathematics, Statistics, Mechanical Engineering, Electrical Engineering, or related technical field from an accredited college or university
 Minimum of 2 years experience in development with SQL, Python, Java, Matlab, R, or other comparable tools


 Desired Characteristics:

 Strong analytical skills, with the ability to improve / automate existing processes
 Familiarity with wind turbine performance metrics, including availability, fault rate, production ratio, etc.
 Working knowledge of Java and Python and ability to contribute to existing environment
 Ability to scrutinize data for quality and consistency
 Background in statistical analysis and significance testing
 Strong communication skills
 Demonstrated ability to deliver on commitments, on time and with high quality
 Ability to work independently and anticipate customer needs
 High flexibility and motivation to succeed


 The salary range for this position is $102,200 - $170,300 USD Annual. The specific salary offered to a candidate may be influenced by a variety of factors including the candidate’s experience, their education, and the work location. In addition, this position is eligible for a 10% variable incentive bonus. Available health and welfare benefits include healthcare, prescription drug, dental, and vision coverage; savings account options (such as a Health Care Flexible Savings Account, Health Reimbursement Account, Limited Purpose Flexible Spending Account, and Dependent Care Flexible Spending Account); and an employee assistance program. Additional benefits include a defined contribution 401(k) plan, employee life insurance, optional dependent life insurance, employee accidental death or dismemberment insurance coverage, short-term disability, optional long-term disability, pre-tax transportation/commuter program, paid holidays, paid time off, parental leave, a layoff plan for salaried employees, tuition refund program, use of CariLoop, adoption assistance, optional identity theft prevention insurance, optional personal legal assistance, and optional personal excess liability insurance.

 Additional Information







 GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.















 GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable). 















Relocation Assistance Provided: No







",102200,"['python', 'sql']"
"Sr. Data Scientist, CRM & Loyalty",Yum! Brands,TX,Full-time,"
As a CRM / Customer Engagement and Retention (CER) Data Analyst, you’ll closely support the CER team in making data-driven decisions about marketing campaign execution. This position will own critical analyses and integration projects from beginning to end, including opportunity identification, problem scoping, analysis framing / execution, and synthesizing results to project stakeholders as well as internal leadership.

Analyze CRM & Loyalty campaigns to provide actionable recommendations to the CER team
Identify areas of opportunity based on Loyalty/CRM analytics, customer segmentations, deployment tactics and audience targeting
Assist in creating test and learn plans to facilitate tactical optimization and strategic changes to our programs to increase customer annual value (CAV)
Partner closely with data science and loyalty vendor partners to monitor critical KPI’s

EDUCATION
 Bachelor’s degree in computer science, marketing, databases, or a related field with 4+ years of experience working in analytics positions in performance-driven marketing, e-commerce, or consulting organizations.
 MINIMUM REQUIREMENTS AND EXPERIENCE

Master Level of Experience using SQL; able to easily query complex data and construct data models as needed and experience working with relational databases (Snowflake), query authoring (SQL) as well as working familiarity with a variety of databases
Comfortable with multi-faceted analytics projects, integrating data from multiple sources, and synthesizing & presenting actionable insights from a variety of data-points
Working knowledge of a CDP (Treasure Data, Twilio, Bloomreach, Convertlab, Salesforce Data Cloud, etc.)
Working knowledge of at least one commonly applied BI tool (Tableau, Power BI, Domo, etc.) Digital Marketing -tools (e.g. Braze, Punchh, etc.) and Project Management tools (e.g. Atlassian, Jira, etc.)
Experience with data management and manipulation tools (Python, Scala, or R) and a desire to learn more
Excellent communication skills with a record of successfully advocating to turn insights into action, as well as the ability to synthesize quantitative results to determine implications and make actionable strategic recommendations

Salary Range: $108,700 to $136,300 annually + bonus eligibility. This is the expected salary range for this position. Ultimately, in determining pay, we'll consider the successful candidate’s location, experience, and other job-related factors.
 Benefits: Employees (and their eligible family members) may enroll in the following types of insurance coverage: medical, dental, vision, legal, and accidental death and dismemberment, as well as FSA/HSA (depending on enrolled medical plan). Yum! also provides short-term disability, long-term disability, and life insurance. Employees may enroll in our 401(k) plan. Yum! provides 4 weeks of vacation, paid sick leave, 10 paid holidays, a floating day off and 2 paid days for volunteer time each calendar year. To learn more about working at Yum! -Click here.  At Yum!, one of our core values is to Believe in ALL People. This means seeing the value in everyone and unlocking their full potential to be their best self. YUM! Brands, Inc. (including its subsidiaries Yum Restaurant Services Group, LLC (“YRSG”) and Yum Connect, LLC (“Yum Digital and Technology”)(collectively, “Yum”) is proud to be an equal opportunity employer and is committed to equity, inclusion, and belonging for all dimensions of diversity. We do not discriminate based on race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other protected characteristic. Yum! is committed to working with and providing reasonable accommodation to applicants with disabilities or special needs.
 US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and supplement and the Pay Transparency Policy Statement.


Who We Are  Founded in 1958, Pizza Hut - a subsidiary of Yum! Brands, Inc. - now operates more than 18,000 restaurants in more than 100 countries. Pizza Hut is leading the way in providing customers with great experiences, innovating with technology and new products, as well as delivering exceptional service.


Our People & Culture
We're looking for people who LOVE pizza and thrive in a fun, past paced, and customer-centric environment. At our corporate campuses, Pizza Hut has created the perfect place for you to grow your career. Every day, you’ll work to support our franchisees and teams across the U.S., continuously challenging yourself to feed more possibilities. In return, we’ll provide professional development and career growth opportunities so that you can become your best and achieve your goals. And we’ll sweeten the deal by immersing you in our world-class recognition culture and providing a robust array of benefits, some highlights include:

 4 weeks PTO, plus standard holidays and time off to volunteer 


 Generous parental leave (16 weeks for moms, 6 weeks for dads)


 401(k) with 6% match, vested immediately


 On-site daycare


 24/7 fitness center with laundry services


 Half-day Fridays, year round


 
Giving Back
As a global company, Pizza Hut aims to make the world better by acting responsibly with respect to food, planet and people. Whether it’s donating food through the Harvest Program or supporting literacy with the Pizza Hut BOOK IT! Program – the company, our franchisees and our team members are committed to improving the communities we serve.



Pizza Hut is an equal opportunity workplace and committed to fostering an inclusive, diverse culture. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability and genetic information (including family medical history).

",108700,"['python', 'tableau', 'sql']"
Senior Data Analyst,The American College of Radiology,VA,Full-time,"



American College of Radiology (ACR) is a progressive membership organization representing nearly 40,000 medical specialists in radiological care. As a member of our team, you will join a world leader in patient-centered care advocacy, policy and clinical research, quality and safety. Our culture encourages innovation, diversity, integrity and leadership. A nonprofit 501(c)(3), ACR (the American College of Radiology) has over 500 purpose-driven employees in the Greater Washington, DC and Philadelphia region.
 If you share our core values of: * Integrity * Visionary * Excellence * Leadership * Transparency * Member-Driven  we want you on our team!
 We are seeking a highly skilled and motivated Senior Data Analyst to join our team. As a Senior Data Analyst, you will be responsible for collecting, analyzing, and interpreting large volumes of data about ACR Membership, and using your strong SQL skills to provide valuable insights and support data-driven decision-making.
 As a Senior Data Analyst at ACR you will:

Analyze data from various sources, including a data lake and Salesforce, to support the development of reports, and the standardization of reporting templates, dashboards and guidelines to streamline workflows.
Collaborate with cross-functional teams to identify business requirements and translate them into analytical solutions.
Present findings and insights to stakeholders – including senior management – in a clear and concise manner, both orally and in written reports.
Identify opportunities for process improvement and recommend data-driven strategies to optimize business performance.
Monitor and track key performance indicators to provide regular updates and insights to stakeholders.

Qualified candidates should possess the following:

Bachelor's degree in a quantitative field such as Data Science, Statistics, Mathematics, or Computer Science.
7+ years’ work experience as a Data Analyst or Reporting Analyst, with a focus on data extraction, data mapping and reporting.
3+ years of SQL programming experience, including complex queries, stored procedures, views, materialized views, and functions. Experience working AWS Redshift, AWS Athena and MS SQL SERVER is highly desirable.
1+ years of Salesforce Data analytics experience. Should have good understanding of Salesforce objects and experience working with SoQL.
Experience with Association Management System data (especially Salesforce-based systems), or working in membership-based organizations, is highly desirable.
Proficiency in query optimization techniques and performance tuning.
Familiarity with inner joins, outer joins (left join, right join), and cross joins.
Experience with Common Table Expressions and view creation.
Understanding of database design principles and normalization.
Solid understanding of statistical concepts and data analysis techniques. The ability to apply statistical methods and predictive modeling techniques to identify patterns, trends, and correlations within the data is highly desirable.
Collaborate with stakeholders and IT to ensure high-quality communication and results.
Ability to work independently and as part of a team in a fast-paced environment, across multiple projects at once, and in a remote-first setting.
Excellent communication and presentation skills, and a solution-oriented mindset

~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~
 ******************************************************************* Although this position will work a fully remote schedule, candidates residing in the eastern time zone will have priority consideration, so as to to maintain our standard operating hours and attend ACR's annual meeting in the spring. Remote workers must be self-motivated, possess excellent time management, and be highly organized. Reliable internet connection is a must!
 *******************************************************************
 ACR is committed to a total rewards compensation philosophy that includes base salary in addition to our full suite of comprehensive benefits (https://www.acr.org/-/media/ACR/NOINDEX/HR/ACR-Benefits-Overview.pdf). ACR’s goal is to pay competitively and equitably. It is typical for individuals to be hired in the entry to middle of the range for their role, and compensation decisions depend on each case’s circumstances. A reasonable estimate of the compensation range is $96,200 – $128,300.
 *******************************************************************
 If you would like to put your experience to great use in a professional team-oriented environment, please apply online. To learn more about ACR’s rewarding employee experience, culture, and benefits, visit: https://www.acr.org/About-ACR/Work-With-Us
 ACR offers a rewarding employee experience: innovative culture, professional growth potential, competitive compensation and an exceptional benefits package, including a defined contribution pension plan, 403(b); generous paid time off package; insurance plans with the leading providers; flexible spending; tuition reimbursement; training opportunities; and wellness reimbursement.




",96200,"['aws', 'sql']"
"Sr Data Analyst, Clinical Analytics & Reporting - REMOTE",DAVITA,CO,Full-time,"
 2000 16th St, Denver, Colorado, 80202-5117, United States of America
 
 Davita’s Clinical Analytics & Reporting Team is responsible for designing, developing and overseeing analytical solutions for our clinical and operations executives in support of DaVita’s clinical strategy. Our team’s mission is to improve patient quality of life in terms of care safety, quality, and efficiency by transforming data into actionable information that guides strategic decisions, supports clinical innovation, and informs operating tactics.

 The Senior Data Analyst’s primary objective is to partner with diverse teams from around the enterprise to produce analytical insights that support analytical products across a broad range of clinical initiatives.

 A successful candidate exemplifies personal behaviors in line with DaVita’s core values: service excellence, integrity, team, continuous improvement, accountability, fulfillment, and fun. In this role, a successful candidate will also demonstrate a strong work ethic, creative mindset, adept communication skills, attention to detail, and demonstrated competence in clinical data analysis and statistical methods.

 Sound like you? Then you might be a great fit for the role of Senior Data Analyst on DaVita’s Clinical Analytics & Reporting team.

 Responsibilities include, but are not limited to:

 Convert complex business requirements into actionable, data driven reports and/or analyses
 Partner with clinical subject matter experts and operational leadership to identify key clinical questions that can be answered using data to drive clinical goals and objectives
 Create, maintain, and distribute reports related to clinical outcomes, surveillance, and risk mitigation on a regular basis
 Utilize multiple computational languages, platforms and environments to mine and manage data in preparation for analysis and/or reporting
 Synthesize results in a non-technical manner to inform recommendations and next steps for leadership
 Partner with cross-functional teams to socialize analytic findings and drive management processes to meaningful results
 Become a subject matter expert and thought partner in clinical and methodologic areas
 Mentor junior teammates
 Willing to travel (up to 10% of time)


 Technical Requirements:

 Bachelor’s degree required; quantitative fields such as biostatistics, statistics, informatics, computer science, or math strongly recommended
 2-5 years of prior relevant work experience preferred
 Minimum 2+ years using SQL (any dialect) at an intermediate level
 Proficiency in any of the following preferred: Tableau, Anaplan, Python, Power BI, etc.
 Proficiency in at least one data analysis platform/language: e.g. R, SAS, SPSS, etc.
 Microsoft Excel and PowerPoint proficiency required
 Advanced critical thinking, strong work ethic, creative mindset, adept communication skills, attention to detail, design-mindedness, flexibility with change, comfort with ambiguity, efficient time management, technical aptitude, and business acumen
 Ability and willingness to become proficient in additional platforms/programming languages (e.g. SQL, Tableau, Python, etc.)


 Why wait? Explore a career with DaVita today. Go to http://careers.davita.com to learn more or apply.

 What We’ll Provide:
 More than just pay, our DaVita Rewards package connects teammates to what matters most. Teammates are eligible to begin receiving benefits on the first day of the month following or coinciding with one month of continuous employment. Below are some of our benefit offerings.

 Comprehensive benefits: Medical, dental, vision, 401(k) match, paid time off, PTO cash out
 Support for you and your family: Family resources, EAP counseling sessions, access Headspace®, backup child and elder care, maternity/paternity leave and more


 Professional development programs: DaVita offers a variety of programs to help strong performers grow within their career and also offers on-demand virtual leadership and development courses through DaVita’s online training platform StarLearning.


 At DaVita, we strive to be a community first and a company second. We want all teammates to experience DaVita as ""a place where I belong."" Our goal is to embed Diversity & Belonging into everything we do in our Village, so that it becomes part of who we are. We are proud to be an equal opportunity workplace and an affirmative action employer. As such, individuals are recruited, hired, assigned and promoted without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, protected veteran status, or any other protected characteristic.

 Compensation for the role will depend on a number of factors, including a candidate’s qualifications, skills, competencies and experience and may fall outside of the range shown. DaVita offers a competitive total rewards package, which includes a 401k match, healthcare coverage and a broad range of other benefits. Learn more at https://careers.davita.com/benefits

 At DaVita, we strive to be a community first and a company second. We want all teammates to experience DaVita as ""a place where I belong."" Our goal is to embed Diversity & Belonging into everything we do in our Village, so that it becomes part of who we are. We are proud to be an equal opportunity workplace and an affirmative action employer. As such, individuals are recruited, hired, assigned and promoted without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, protected veteran status, or any other protected characteristic.


 Salary/ Wage Range $56,500.00 - $83,000.00 / year
 
 Compensation for the role will depend on a number of factors, including a candidate’s qualifications, skills, competencies and experience and may fall outside of the range shown. DaVita offers a competitive total rewards package, which includes a 401k match, healthcare coverage and a broad range of other benefits. Learn more at https://careers.davita.com/benefits


If this position is located in a region with minimum wage requirements, we will not pay less than the applicable minimum wage: Denver: $17.29/per hour for nonexempt roles, Colorado: $50k/year for exempt roles.

",56500,"['python', 'tableau', 'sql']"
Automation and Data Science Project Manager,Booz Allen Hamilton,VA,Full-time,"


Job Description










         Location: 
        

         McLean,VA,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184672
        


















         Automation and Data Science Project Manager
          The Opportunity:
 An effective project requires a manager who is passionate about guiding it through the complexities of its lifecycle. It requires someone who is dedicated to identifying challenges, mitigating risks, and supporting a team with vision and focus. That’s why we need you, a seasoned project manager who can ensure our analytics program achieves success.

 As a lead project manager on our team, you’ll design, implement, and maintain impactful programs by guiding our internal and AI team. Your customers will trust you to organize and coordinate program objectives, while your team will look to you for direction as they navigate requirements, budget constraints, and staffing challenges. You’ll identify opportunities to grow the business by supporting your client’s mission. You’ll also broaden your expertise in problem management, strategic planning, analytical concepts, automation methodologies, and more. This is your chance to drive analytics adoption while sharing your knowledge and expertise of program management methodologies. Due to the nature of work performed within this facility, U.S. citizenship is required.

 Join us. The world can’t wait.

 You Have:

 7+ years of experience in analytics, automation, data science, data engineering, or data strategy role
 3+ years of experience with analytics project management
 3+ years of experience with consulting, client management, and stakeholder engagement
 3+ years of experience with a wide range of automation methodologies, including robotic process automation or cognitive automation
 3+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining
 Experience using statistical programming languages, including Python or R
 Knowledge of application or implementation support
 Ability to explain complex technical solutions tailored to different audiences
 Ability to comprehend and translate business and end user requirements
 Bachelor's degree


 Nice If You Have:

 Experience leading architecture and design for RPA implementations, including UiPath
 Experience with financial systems or financial analytics
 Experience developing machine learning models, including supervised and unsupervised models
 Experience deploying models in production
 Experience working on multi-disciplinary teams
 Experience with DevSecOps, version control, and operationalizing models


 Create Your Career:

 Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $81,800.00 to $186,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",81800,"['python', 'machine learning']"
RESEARCH DATA SPECIALIST III,Department of Transportation,CA,Full-time,"













             Under the general direction of the Branch Chief (Senior Transportation Engineer) of the Business Intelligence and Automation Branch, of the Office of System Metrics & Automation, the Research Data Specialist III (RDS III) will independently perform a variety of tasks including data management, data analysis automation, data validation, data governance, and data visualization. The incumbent will work collaboratively with a variety of teams and staff at Caltrans to collect and maintain datasets, develop data visualizations and dashboards, update and correct database(s), document datasets for analysts, and perform varied related tasks that use data to enhance decision-making and traffic operations. The incumbent is expected to seek and incorporate user feedback and develop and update their products and datasets in an iterative and agile manner using version control and statistical programming languages and various data manipulation tools.
            


 The Business Intelligence and Automation Branch of the Traffic Operation Division is responsible for helping the division transform mobility and safety, adopt new technologies, enhance innovation, and support data-driven and performance-based decision-making. The branch also leads the development and maintenance of data processing platforms to serve the business needs of the Division of Traffic Operations and its leadership team.
            




             The RDS III will communicate with stakeholders about what data is available and how to use it for decision-making. The incumbent will also support various special and high-profile projects including the Highway Camera Pilot Project which evaluates the transportation data needs using emerging technologies such as Computer Vision and Artificial Intelligence. Effective handling of these complex tasks is critical to the department’s continued success.
             


This position may be eligible for telework. The amount of telework is at the discretion of the Department and based on Caltrans’s evolving telework policy. Caltrans supports telework, recognizing that in-person attendance may be required based on operational needs. Employees are expected to be able to report to their worksites with minimum notification if an urgent need arises. The selected candidate will be required to commute to the headquartered location as needed to meet operational needs. Business travel may be required, and reimbursement considers an employee’s designated headquartered location, primary residence, and may be subject to CalHR regulations or applicable bargaining unit contract provisions. All commute expenses to the headquartered location will be the responsibility of the selected candidate.  Eligibility for hire may be determined by your score on the Research Data Specialist III For those who do not have current eligibility (e.g., transfer, permissive reinstatement, or voluntary demotions) and/or who will be new to state civil services employment, you must be on the state examination list to be eligible for these positions. The Research Data Specialist III Exam is located here: CalCareers
 The Human Resources Contact is available to answer questions regarding the application process. The Hiring Unit Contact is available to answer questions regarding the position. 
PARF# 51-4-051 / JC-403511



You will find additional information about the job in the Duty Statement.



Working Conditions


This position’s headquartered location is Sacramento, CA.


 While at the base of operation, the incumbent works in a climate-controlled office under natural and artificial lighting. Due to periodic issues with heating and air conditioning, building temperatures may fluctuate. Multi-floor buildings are equipped with elevators and stairs.
            


 The incumbent may be required to travel periodically to other office buildings (federal and state offices, district offices, local agencies, etc.) and other indoor/outdoor field locations. While at field locations, the incumbent may be exposed to uneven surfaces, noise, varying climate conditions, and live traffic. The incumbent may be required to travel within the state and out-of-state for business operations.
             



New to State candidates will be hired into the minimum salary of the classification or minimum of alternate range when applicable.I
            





Minimum Requirements You will find the Minimum Requirements in the Class Specification.
            
 RESEARCH DATA SPECIALIST III 



Additional Documents

Job Application Package Checklist
 Duty Statement





Position Details



Job Code #:


               JC-403511 
              



Position #(s):



                913-350-5770-XXX
               





Working Title:


Research Data Specialist III





Classification:


               RESEARCH DATA SPECIALIST III 
               
                $7,315.00 - $9,155.00 A 
               





# of Positions:


               Multiple 
              



Work Location:


               Sacramento County 
              



Telework:


               Hybrid 
              



Job Type:


               Permanent, Full Time 
              




Department Information

Caltrans Mission: Provide a safe and reliable transportation network that serves all people and respects the environment.
 Caltrans Vision: A brighter future for all through a world-class transportation network.
 The Caltrans workforce is made up of diverse and unique individuals who contribute to our organizational success. Caltrans is about celebrating diversity, valuing one another, and recognizing that Caltrans is strong not in spite of the diverse attributes of our workforce, but because of our diversity.
 Department Website: www.dot.ca.gov 
Frequently Asked Questions for an Applicant: http://dot.ca.gov/jobs/docs/faq-ct-applicants-081617.pdf
 Director’s EEO Policy: https://dot.ca.gov/programs/equal-employment-opportunity

 Director’s EEO Policy Statement: https://dot.ca.gov/programs/equal-employment-opportunity
             






Special Requirements



Cover letter required.
 Possession of a valid driver’s license is required to operate a State owned, leased, and/or personal vehicle.




 A Statement of Qualifications (SOQ) is required. To be considered for the position, applicants must submit a SOQ along with their application. The SOQ is the candidates’ response to the questions below. The SOQ is a narrative discussion of how your education, training, experience, and skills qualifies you for the position. The SOQ serves as documentation of each applicant’s ability to present information clearly and concisely in writing. SOQs must be no more than two (2) pages in length and typed using no less than 12-point Arial font. Applicants who do not follow these requirements will not be considered for this job. The SOQ must be submitted along with the State Application.
              




Describe your experience in a programming/scripting language and SQL, working with large datasets- data retrieval systems, and reporting and resolving data definition, storage, analysis, and visualization issues.
 Describe one case that you used limited resources to successfully address a challenging problem that was beyond conventional approach.
 What new knowledge have you learned/used in the past two years that would contribute to the current role?





 (Include License/Certificate Requirements or Statement of Qualifications/Supplemental Questionnaire/Cover Letter Requirement)
               



 Possession of Minimum Qualifications will be verified prior to interview and/or appointment. If you are basing your eligibility on education, you must include your unofficial transcript(s)/diploma for verification. Unofficial, original, or official sealed transcripts will be accepted and may be required upon appointment. Applicants with foreign transcripts/degrees must provide a transcript/degree U.S. equivalency report evaluation that indicates the number of units and degree to which the foreign coursework is equivalent. Here is a list of evaluation agencies: https://www.naces.org/members. Please redact birthdates and social security numbers.
              






Application Instructions

Completed applications and all required documents must be received or postmarked by the Final Filing Date in order to be considered. Dates printed on Mobile Bar Codes, such as the Quick Response (QR) Codes available at the USPS, are not considered Postmark dates for the purpose of determining timely filing of an application. Final Filing Date: 12/5/2023 
             Who May Apply

              Individuals who are currently in the classification, eligible for lateral transfer, eligible for reinstatement, have list eligibility, are in the process of obtaining list eligibility, or have SROA and/or Surplus eligibility (please attach your letter, if available). SROA and Surplus candidates are given priority; therefore, individuals with other eligibility may be considered in the event no SROA or Surplus candidates apply. Individuals who are eligible for a Training and Development assignment may also be considered for this position(s). 
              
 Applications will be screened and only the most qualified applicants will be selected to move forward in the selection process. Applicants must meet the Minimum Qualifications stated in the Classification Specification(s). 
             
How To Apply

              Complete Application Packages (including your Examination/Employment Application (STD 678) and applicable or required documents) must be submitted to apply for this Job Posting. Application Packages may be submitted electronically through your CalCareer Account at www.CalCareers.ca.gov. When submitting your application in hard copy, a completed copy of the Application Package listing must be included. If you choose to not apply electronically, a hard copy application package may be submitted through an alternative method listed below:
              

Address for Mailing Application Packages
You may submit your application and any applicable or required documents to:





                  Department of Transportation 
                 

                  Attn: Caltrans DHR Contact 
                 

                  Certification Services MS-90 
                 

                  P O Box 168036 
                 

                  Sacramento, CA 95816-8036 
                 




Address for Drop-Off Application Packages
You may drop off your application and any applicable or required documents at:






                   Department of Transportation 
                  

                   Caltrans DHR Contact 
                  

                   Classification and Hiring Unit - ECOS 
                  

                   1727 30th Street, MS 90 
                  

                   Sacramento, CA 95816 
                  

                   Closed on weekends and State holidays 
                  

                   08:00 AM - 05:00 PM 
                  





Required Application Package Documents
The following items are required to be submitted with your application. Applicants who do not submit the required items timely may not be considered for this job: 

Current version of the State Examination/Employment Application STD Form 678 (when not applying electronically), or the Electronic State Employment Application through your Applicant Account at www.CalCareers.ca.gov. All Experience and Education relating to the Minimum Qualifications listed on the Classification Specification should be included to demonstrate how you meet the Minimum Qualifications for the position.
Resume is optional. It may be included, but is not required.
Statement of Qualifications - 
               
Statement of Qualifications (SOQ) is required. Please see the Special Requirements section for SOQ instructions.

Other - 
               
Cover letter required.


Applicants requiring reasonable accommodations for the hiring interview process must request the necessary accommodations if scheduled for a hiring interview. The request should be made at the time of contact to schedule the interview. Questions regarding reasonable accommodations may be directed to the EEO contact listed on this job posting. 
           



Benefits


            Click HERE to view the Benefits Summary for Civil Service Employees in the State of California.
           



Contact Information

The Human Resources Contact is available to answer questions regarding the application process. The Hiring Unit Contact is available to answer questions regarding the position. 
Human Resources Contact:  Julie Millard (279) 234-2397 Julie.Millard@dot.ca.gov 
Hiring Unit Contact:  Gayman Wong (916) 639-6131 gayman.wong@dot.ca.gov 

Please direct requests for Reasonable Accommodations to the interview scheduler at the time the interview is being scheduled. You may direct any additional questions regarding Reasonable Accommodations or Equal Employment Opportunity for this position(s) to the Department's EEO Office. 
EEO Contact:
 Caltrans EEO Office
             (844) 368-3367
             Ask.eeo@dot.ca.gov 
           
California Relay Service: 1-800-735-2929 (TTY), 1-800-735-2922 (Voice) TTY is a Telecommunications Device for the Deaf, and is reachable only from phones equipped with a TTY Device. 



Important Applications Instructions:


The State application (STD. 678) is required, and each section must be filled out completely and thoroughly. For mailed or hand delivered applications to be considered for this position, the Job Control number (JC-403511), PARF# 51-4-051 and title of the position (Research Data Specialist III) must be included on the STD. 678 form.



 Electronic applications through your CalCareers account are highly recommended and encouraged.



 Candidates that meet the minimum qualifications based on possession of EDUCATION, LICENSE, OR CERTIFICATE must include a copy of your DEGREE/TRANSCRIPTS, LICENSE, or CERTIFICATE, along with your State application (STD. 678), to be considered for this position.



 NOTE: Do not submit the “Equal Employment Opportunity” questionnaire (page 5) with your completed State application (STD. 678). This page is for examination use only.
            Do not include any confidential information on any documents you submit for this job vacancy, such as your state application, resume, or educational transcripts. Confidential information that should be 
excluded or removed
 from these documents includes, but is not limited to, your Social Security Number, birth date, driver’s license number, examination results, LEAP status, marital status, and age. The job application packet checklist is not required to apply for this position. Failure to follow these instructions may result in your application not being considered for this position.





Survey:


Please take this 1-minute Caltrans Recruitment survey to tell us how you found out about this job.



 https://forms.office.com/g/RyK102ty4G
          


 https://youtu.be/oC9wIp8QalI
          




Equal Opportunity Employer
The State of California is an equal opportunity employer to all, regardless of age, ancestry, color, disability (mental and physical), exercising the right to family care and medical leave, gender, gender expression, gender identity, genetic information, marital status, medical condition, military or veteran status, national origin, political affiliation, race, religious creed, sex (includes pregnancy, childbirth, breastfeeding and related medical conditions), and sexual orientation. 
It is an objective of the State of California to achieve a drug-free work place. Any applicant for state employment will be expected to behave in accordance with this objective because the use of illegal drugs is inconsistent with the law of the State, the rules governing Civil Service, and the special trust placed in public servants.











",7315,['sql']
Computational & Data Science Research Specialist 3,UC San Diego,CA,Full-time,"








        Payroll Title:
        CMPTL AND DATA SCI RSCH SPEC 3 
       
        Department:
        INSTITUTE NEURAL COMPUTATION 
       
        Hiring Pay Scale
        $75,000 - $100,000 / Year 
       
        Worksite:
       

        Appointment Type:
        Career 
       
        Appointment Percent:
        100% 
       
        Union:
        Uncovered 
       
        Total Openings:
        1 
       
        Work Schedule:
        8 hrs/day, Mon-Fri 
      




#126686 Computational & Data Science Research Specialist 3
Filing Deadline: Wed 11/29/2023






UC San Diego values equity, diversity, and inclusion. If you are interested in being part of our team, possess the needed licensure and certifications, and feel that you have most of the qualifications and/or transferable skills for a job opening, we strongly encourage you to apply.





UCSD Layoff from Career Appointment: Apply by 11/17/23 for consideration with preference for rehire. All layoff applicants should contact their Employment Advisor.
Special Selection Applicants: Apply by 11/29/23. Eligible Special Selection clients should contact their Disability Counselor for assistance.

 DESCRIPTION
 Applies skills as a seasoned, experienced IT research professional. Uses computational, computer science, data science, and CI software research and development principles, with relevant domain science knowledge where applicable, along with professional programming concepts for medium-sized projects or portions of larger projects. Develops and optimizes a variety of computational, data science, and CI research tools and components. Performs research on current and future HPC, data, and CI technologies, hardware and software projects. Works on algorithm development, optimization, programming, performance analysis and / or benchmarking assignments of moderate scope where the tasks involve knowledge of either domain / computer science research requirements and / or CI design / implementation requirements.
 Serves as the technical professional on the data modeling and data content for NIH-supported open source software projects, EEGLAB, a Matlab-based software environment for electrophysiological signal processing in use in many laboratories around the world. Currently comprising over 50,000 lines of Matlab code plus 30 or more plug-in packages published by the Swartz Center for Computational Neuroscience (SCCN) and outside groups, the incumbent works with the project Principal Investigator(s) to develop and implement professional software maintenance, management, and testing practices which may include signal processing approaches and participates in the development of new facilities. Other activities include writing and maintaining technical reference documentation and tutorial documentation for existing and created software. Provide training to other lab personnel, and serves as technical liaison with other units in the university, as well as collaborates with external research groups and consortia. Documents technical information about HPC resource for Grant proposal submissions to NIH and NSF.

The Institute for Neural Computation (INC) in University of California, San Diego, is committed to actively promoting our Principles of Community and continually advancing equity, diversity, and inclusion within all levels of our organization. In line with the goals of UCSD’s Strategic Plan for Inclusive Excellence supporting a diverse faculty, staff, and student body and fostering a positive and welcome climate where all are valued, we strongly encourage candidates from underrepresented communities, to apply.

 QUALIFICATIONS

 Bachelor's degree in Computer / Computational / Data Science, or Domain Sciences with computer / computational / data specialization and at least 4 years' experience, or equivalent experience/training.
 Intermediate knowledge of HPC / data science / CI. Working experience on submitting, canceling, updating jobs on HPC resources. Experience on automating processes and reporting.
 Advanced skills, and demonstrated experience associated with one or more of the following: HPC hardware and software power and performance analysis and research, design, modification, Implementation and deployment of HPC or data science or CI applications and tools. Strong experience with GPU usage on HPC resources, including using GIT tools for CI integration of released software.
 Demonstrated ability to regularly interface with management. Demonstrated experience in attending and participating in meetings with PI's and other research collaborators.
 Demonstrated ability to contribute research and technical content to grant proposals. Experience with documenting technical information about HPC resources for NIH and NSF Grant proposal submissions.
 Demonstrated effective communication and interpersonal skills. Demonstrated ability to communicate technical information to technical and non-technical personnel at various levels in the organization and to external research and education audiences. Good written and verbal communication skills. Ability to draft manuscript for publication and edit existing manuscripts.
 Proven skills and experience in independently resolving broad computing / data / CI problems using introductory and / or intermediate principles. Demonstrated ability to learn new CI methods as they become available.
 Self-motivated and works independently and as part of a team. Able to learn effectively and meet deadlines. Demonstrated ability to meet deadlines involving grant, conference, and paper submission deadlines.
 Thorough experience working in a complex computing / data / CI environment encompassing all or some of the following: HPC, data science infrastructure and tools / software, and diverse domain science application base.
 Proven ability to successfully work on multiple concurrent projects. Demonstrated ability to perform well under pressure and handle multiple tasks.
 Proven ability to understand research computing / data / CI needs, mapping use cases to requirements and how systems / software / infrastructure can support those needs and meet the requirements. Demonstrated ability to develop and implement such solutions. Ability to program new solution, including API, to interface existing automatically.
 Demonstrated broad experience in one or more of the following: optimizing, benchmarking, HPC performance and power modeling, analyzing hardware, software, and applications for HPC / data / CI. Ability to benchmark using code released by other researchers. Ability to adapt this code for specific lab-relevant application.
 Demonstrated experience and ability to collaborate effectively with all levels of staff; technical, students, faculty and administrators
 Demonstrated ability to write testing scripts, including unit testing, to ensure the robustness of the code developed.

 SPECIAL CONDITIONS

 This position is eligible for a flexible work arrangement, which could include a non-standard work schedule, and/or the ability to work off-site part of the time. The employee shall be available full-time during assigned work hours (specific hours to be discussed with supervisor).
 Job offer is contingent upon satisfactory clearance based on Background Check results.


 Pay Transparency Act
 Annual Full Pay Range: $63,400 - $142,800 (will be prorated if the appointment percentage is less than 100%) 
Hourly Equivalent: $30.36 - $68.39 
Factors in determining the appropriate compensation for a role include experience, skills, knowledge, abilities, education, licensure and certifications, and other business and organizational needs. The Hiring Pay Scale referenced in the job posting is the budgeted salary or hourly range that the University reasonably expects to pay for this position. The Annual Full Pay Range may be broader than what the University anticipates to pay for this position, based on internal equity, budget, and collective bargaining agreements (when applicable).









If employed by the University of California, you will be required to comply with our Policy on Vaccination Programs, which may be amended or revised from time to time. Federal, state, or local public health directives may impose additional requirements.
 To foster the best possible working and learning environment, UC San Diego strives to cultivate a rich and diverse environment, inclusive and supportive of all students, faculty, staff and visitors. For more information, please visit UC San Diego Principles of Community.
 
The University of California is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, age, protected veteran status, gender identity or sexual orientation. For the complete University of California nondiscrimination and affirmative action policy see: http://www-hr.ucsd.edu/saa/nondiscr.html 
UC San Diego is a smoke and tobacco free environment. Please visit smokefree.ucsd.edu for more information.








",75000,['git']
Data Science Analyst,The American College of Radiology,VA,Full-time,"



Founded in 1923, the American College of Radiology® is at the forefront of radiology evolution, representing nearly 40,000 radiologists, radiation oncologists, nuclear medicine physicians and medical physicists. We are seeking energetic and innovative individuals to further reinforce our core purpose of serving patients and society by empowering members to advance the practice, science and professions of radiological care.
 If you share our core values of: Leadership • Integrity • Quality • Innovation, we want you on our team!
 ACR's Data Science Institute (DSI) was created to make patient care safer, faster, cheaper, and more precise. We do this by working with clinicians, industry and government to create the infrastructure and services that facilitate the integration of Artificial Intelligence (AI) into the clinical workflow. As AI in medical imaging moves from early adopter to general use in practice, clinicians, industry, and patients are looking to the DSI to be the honest broker to ensure a high level of quality and trust in technologies applied in healthcare.
 ACR's data science analysts work at the nexus between clinicians, industry, patient advocates, and government bodies to create, manage, and apply standards for AI in medical imaging. At the core of this work is the development and execution of the clinical AI lifecycle. The AI lifecycle encompasses a series of services and projects such as use cases for industry guidance, technical standards creation, industry analysis and research, multi-center clinical trials, and post-market monitoring of deployed AI.
 To effectively advance AI in medical imaging, the data analyst role is involved in every aspect of the DSI, from discussion with clinicians and industry to executions of studies and services.
 The new hire will:

Collaborate with scientists, ACR leadership, government regulatory bodies, vendors, and clinicians to develop standards, guidelines, and research for applying AI in healthcare.


Apply technical knowledge to guide and support the development of AI standards and requirements.


Work directly with healthcare organizations, clinicians, and industry to execute the service line the DSI performs such as Define-AI, AI Central, Assess-AI, and Certify-AI.


Work with internal teams to develop and expand services lines and programs.



 The qualified candidate will possess the following:

Bachelor’s degree in a STEM field


3+ years of directly relevant experience in developing requirements and performing system analysis


Experience with statistical methods, information classification and/or machine learning


Organizational and analytical skills


Ability to take lead on cutting edge and ever evolving domain spaces


Ability to clearly communicate ideas and solution


Strong verbal and written communication skills, including presentation skills


Ability to manage ambiguity


Ability to work as a part of a team and individually



 Preferred experience includes:

Statistical analysis


Web content management


Medical terminology


Project Management


AWS (Amazon Web Services)


Algorithm development


AI (Artificial Intelligence)


SQL


Tableau


R or Python

 ******************************************************************* Although this position will work a fully remote schedule, candidates residing in the eastern time zone will have priority consideration, so as to to maintain our standard operating hours and attend ACR's annual meeting in the spring. Remote workers must be self-motivated, possess excellent time management, and be highly organized. Reliable internet connection is a must!
 *******************************************************************
 ACR is committed to a total rewards compensation philosophy that includes base salary in addition to our full suite of comprehensive benefits (https://www.acr.org/-/media/ACR/NOINDEX/HR/ACR-Benefits-Overview.pdf). ACR’s goal is to pay competitively and equitably. It is typical for individuals to be hired in the entry to middle of the range for their role, and compensation decisions depend on each case’s circumstances. A reasonable estimate of the compensation range is $85,500 – $114,000.
 *******************************************************************
 If you would like to put your experience to great use in a professional team-oriented environment, please apply online. To learn more about ACR’s rewarding employee experience, culture, and benefits, visit: https://www.acr.org/About-ACR/Work-With-Us
 ACR offers a rewarding employee experience: innovative culture, professional growth potential, competitive compensation and an exceptional benefits package, including a defined contribution pension plan, 403(b); generous paid time off package; insurance plans with the leading providers; flexible spending; tuition reimbursement; training opportunities; and wellness reimbursement.




",85500,"['python', 'machine learning', 'tableau', 'aws', 'sql']"
"Technical Program Manager, Data Infrastructure",Meta,CA,Full-time,"
 Are you passionate about helping those around you be more effective? Do you think about technology as a way to increase efficiency and change how business operates? We are looking for candidates that share our passion for tackling complexity head-on, to help build software platforms that can scale through multiple orders of magnitude.Data Infrastructure team is responsible for the end to end life cycle of data at Meta - from logging, ingesting, processing to making it available to users across the company for AI, ML and Analytics use cases. As a Technical Program Manager, you will play a key role within Data Infrastructure team, driving large cross functional projects that span the organization. Our team is comprised of varying levels of experience and backgrounds. Relevant experience is important, but ultimately less so than your demonstrated abilities and attitude. Meta’s infrastructure is constantly redefining what is possible, and we need Technical program managers that can do the same.
 


Technical Program Manager, Data Infrastructure Responsibilities:  

Build strong and aligned program teams to efficiently deliver on shared goals.
 Collaborate with Engineering and business owners to define program requirements, set priorities, and establish scope which includes defining the roadmap and long-term strategy of the teams that you are partnering with.
 Manage cross functional dependencies, risks, and changes effectively by optimizing scope, schedule, and resources accordingly.
 Develop and own communication plans to effectively and proactively communicate program status, issues, and risks to stakeholders.
 Partner with cross functional teams to drive technical analysis, design, development, testing, implementation, and post implementation phases.
 Define and track key metrics and key quality and performance indicators and drive cross functional execution of program deliverables.
 Proactively identify and analyze complex, long-term, critical infrastructure problems with engineering leaders and stakeholders.
 Influence product decisions to align with higher company initiatives.
 Drive internal and external process improvements across multiple teams and functions including reducing the manual efforts through automation.




Minimum Qualifications: 

 B.S. in Computer Science or a related technical discipline, or equivalent experience.
 Experience delivering tech programs or products from inception to delivery
 Knowledge of user needs, gathering requirements, and defining scope.
 Experience operating autonomously across multiple teams, demonstrated critical thinking, and thought leadership.
 Communication experience and experience working with technical management teams to develop systems, solutions, and products.
 Organizational, coordination and multi-tasking experience.
 Analytical and problem-solving experience with large-scale systems.
 Experience establishing work relationships across multi-disciplinary teams and multiple partners in different time zones.






About Meta:  Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.
 



  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. 
  
 Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
 
",87006,['machine learning']
Senior Data Scientist (Epi3) DOH7657,State of Washington Dept. of Health,WA,Full-time,"


Description






    This is a permanent position.
   


 Join us in making a real impact on public health and supporting a healthier future for our community!


     As a Senior Data Scientist on our team, you'll lead and execute data science projects aimed at enhancing public health. Your expertise in machine learning, statistical analysis, and programming (Python, SQL, R) will be essential. If you have experience in MLOps and data engineering, that's a significant advantage. While knowledge of public health principles is a plus, it's not a requirement – we value your data science skills and your ability to translate them into actionable solutions.
   


 We're looking for someone who's not afraid to roll up their sleeves and explore creative ways to tackle public health challenges using data. If you're passionate about extracting valuable insights from diverse data sources and believe that better health outcomes can be achieved through better data, you're the ideal candidate.
   


 In our team, collaboration is key. We work closely with internal and external partners because we recognize that no single person or team possesses all the necessary knowledge and experience. We're ambitious, unafraid of taking risks, and we're seeking an intellectually curious and motivated individual who's eager to contribute to our mission of turning data into actionable insights that benefit our communities.
   


 This position plays a pivotal role in accelerating the transformation of data into meaningful actions that protect and improve the health and well-being of our state's diverse population. Your passion for data science and your drive to make a difference will be at the heart of our collaborative efforts.
   


 Responsibilities:
   

 Lead and participate in the procurement, design, development, implementation, and enhancement of public health data systems and supporting databases, in collaboration with program areas, IT teams, and vendors.
 Design and implement public health information systems and programs, including use cases and workflow analyses.
 Administer program-specific data sets, ensuring data quality evaluation and improvement.
 Develop and maintain automated data pipelines for efficient data processing.
 Independently propose and oversee public health-related projects, including serving as a principal investigator for research grants.
 Track and report on project progress, barriers, and next steps.
 Engage with stakeholders to assess, manage, and communicate changes resulting from surveillance system and data analytics activities.
 Provide project updates and deliverables within specified timelines.
 Perform complex data modeling and analysis, including data gathering and processing, model development, descriptive and statistical analysis.
 Create and optimize disease-specific datasets for modeling and analytics.
 Analyze data and model results for reports, presentations, and recommendations.
 Offer public health data science expertise for data management, analysis, and reporting.
 Provide leadership to direct reports, including coaching for improved effectiveness and performance.
 Handle hiring, disciplinary actions, and staff requests promptly.
 Mentor and instruct staff in project management, stakeholder communication, and analytics methods.
 Deliver training and system familiarization to data system end users and technical staff.



 Required Qualifications: Your experience may have been gained concurrently and through a combination of education, professional experience and paid or unpaid lived experience.
   




 A degree in in Health Informatics, Public Health, Science, Epidemiology, Public Policy or Health Policy, Health Services Research, Health Information Sciences, Computer Science, or closely related field PLUS experience in a healthcare or public health setting with health informatics responsibilities that include conducting and/or supporting informatics projects including scientific investigations information architecture management and implementing data and information standards.





 Option 1: Ten (10) years of combined relevant education, training, professional experience and lived experience. Experience may have been gained from paid or unpaid activities and can substitute for education on a year for year basis.





 Option 2: Bachelor’s Degree + six (6) years of experience.





 Option 3: Master’s Degree + four (4) years of experience.




 OR




 Option 4: A Doctoral level degree in Informatics, Public Health (Dr.PH.), Health Science (D.H.Sc.), Management Information Systems and Technology, Computer Science, or a related field. AND two (2) years of experience doing senior-level public health informatics work.





 One of the above options ANDthe following:
     
 An Understanding of Public health, disease surveillance, healthcare informatics/surveillance systems and epidemiologic practices
 An understanding of strategies for achieving effective data acquisition, management, quality, storage, use, and application to address clinical care and population health needs.
 Data communications security and privacy techniques; legal and ethical issues regarding confidentiality and use of individually identifiable public health and medical record data.
 Experience interpreting and evaluating information to analyze, summarize, and prepare reports.
 Experience interpreting and analyzing medical, health and other data obtained from a variety of sources.
 Experience Conveying complex information effectively using oral and written communication.




 Desired Skills and Preferred Experience:
   

 Additional years of professional experience in a public health practice or healthcare setting, with responsibilities including conducting and/or supporting the following informatics related functions:
     
 complex data cleaning
 analysis
 visualization/reporting
 information architecture management with open-source programming tools

 Experience in the following:
     
 Computer programming and statistical analysis languages such as R and/or Python
 Relational databases including writing Structured Query Language (SQL) queries.
 Performing statistical analyses, data cleaning, data wrangling, and similar tasks using R and/or Python
 Generating automated alerts and file management and analytics processes
 Developing instruments and methodologies for an integrated public health surveillance system such as aberration detection algorithms, data mining programs, and for matching and de-duplication of individual records when integrating different data sources
 Leveraging visualization and reporting tools
 Providing technical assistance to achieve statewide program goals and objectives, health information exchange, data linking and system integration.
 Engaging with diverse audiences and multiple business partners to assess information needs; and collaborate across agencies and programs to meet shared goals.
 Providing guidance on analytics workflow best practices given the needs and constraints of business partners

 An understanding of the following:
     
 Programming, analysis reproducibility, package/library development and management, code versioning, and code performance optimization
 Data modeling and the design of data systems
 Fundamental machine learning concepts
 Public health, disease surveillance, healthcare informatics/surveillance systems and epidemiologic practices
 Business and/or technical requirement documentation for information system development and enhancement
 Cloud analytics technologies




 Key Competencies and Expectations:
   

 Plan, organize, and prioritize projects, time, and workload assignments for a variety of informatics/surveillance projects.
 Manage multiple projects in a fast-paced and high-pressure environment.



 About the Washington State Department of Health (DOH)


     At DOH, we safeguard public health in an ever-evolving world. Through collaboration with local health jurisdictions and state, federal, and private partners, our programs, and services impact every Washingtonian and visitor daily. We're driven by Equity, Innovation, and Engagement, as outlined in our 
    Transformational Plan for the future of Washington health.
   


 CEPEA: Shaping the future of public health with data, equity, and innovation!


     The Center for Epidemiology Practice, Equity, & Assessment (CEPEA) is committed to advancing epidemiology as a tool for Health and Equity for all. We specialize in Equity & Health Assessment, partnering with local and tribal epidemiology centers to enhance data practices, support data integration, and develop equitable assessment resources and policies.
   


 In the realm of Population Survey Operations, we are your trusted experts in designing and conducting large-scale population surveys. Our proficiency extends to the analysis and reporting of results, with a focus on critical surveys such as the Behavioral Risk Factor Surveillance System (BRFSS), the Healthy Youth Survey (HYS), and the upcoming Child Wellness Survey (CWS). These surveys are essential for informed, public health-driven decision-making.
   


 In Epidemiology & Biostatistical Methods, we lead with unwavering commitment, developing and implementing standard approaches while pushing the boundaries of innovation. From infectious disease modeling to emerging health challenges, our quest for excellence drives expertise in cutting-edge techniques for advancing health equity.
   


 Benefits and Lifestyle


     We prioritize your work-life balance and offer one of the most competitive benefits packages nationwide, tailored to support your lifestyle. Discover more about ""Why DOH"" by visiting 
    Work@Health.
   


 Location and Flexibility


     Homebased – Our approach to work is flexible. You'll primarily work remotely from your home location with an occasional on-site presence at the DOH office in Tumwater, WA. We're extending our reach to include remote applicants from across Washington State, the Oregon/Washington border, and the Idaho/Washington border.
   


 Application Process:
   

 Remember to showcase your relevant education and experience in your application materials.
 DO NOT attach any documents that include photos, letters of recommendation, or private information (transcripts, social security number, year of birth, etc.).
 Click ""Apply"" to submit your detailed application profile along with the following:
     
 A cover letter (without personal pictures) describing how you meet the qualifications and why you are interested in this position.
 A current resume (without personal pictures).
 Three (3) or more professional references, to be listed in your profile under the references section, which includes at least one supervisor, peer, and (if you have supervised staff) someone you have supervised or led.




 Veterans Preference: Applicants wishing to claim Veterans Preference must attach a copy of their DD-214 (Member 4 copy), NGB 22, or signed verification of service letter from the United States Department of Veterans Affairs to their application. Please remove or cover any personally identifiable data such as social security numbers and birth year.
   


 Equity, Diversity, and Inclusion: We regard diversity as the foundation of our strength, recognizing that differing insights and abilities enable us to reflect the unique needs of the communities we serve.
   


 DOH is an equal-opportunity employer. We prohibit discrimination based on race/ethnicity/color, creed, sex, pregnancy, age, religion, national origin, marital status, the presence or perception of a disability, veteran’s status, military status, genetic information, sexual orientation, gender expression, or gender identity.
   


 Questions and Accommodations: If you have questions, need accommodation in the application or selection process, or need information in an alternative format, contact 
    Shawnelle Goalder at 
    shawnelle.goalder@doh.wa.gov. For general DOH recruitment questions, email the 
    Talent Acquisition Team at employment@doh.wa.gov. Deaf or hard of hearing contact Washington Relay Service at 7-1-1; individuals outside of Washington State contact Washington Relay Service at 1-800-833-6874.
   


 Technical Support: Reach out to NEOGOV directly at 1-855-524-5627 for technical support and login issues.
   


 Conditions of Employment:


 I am prepared, with or without accommodations, to do the following:


 Commit to a full-time 40-hour work week schedule. (Please note that flexible work schedule requests will be subject to supervisor approval.)
 Adjust my work schedule occasionally to align with business needs, which may entail working evenings and weekends.
 Perform my job duties either remotely from home or in-person at the designated DOH site location.
 Travel periodically within the state of Washington.
 Possess the legal ability to operate a state or privately-owned vehicle or arrange alternative transportation for official state business.
 Engage in emergency response exercises and high-priority assignments as assigned during emergency events.



 SUBSCRIBE to DOH Job Alerts




Supplemental Information




Supplemental Information


     This recruitment may be used to fill positions of the same job classification across the agency. Once all the position(s) from the recruitment are filled, the candidate pool may be used to fill additional open positions for the next sixty (60) days.
   


 Only applicants who follow the directions and complete the Application Process in-full will have their responses reviewed for consideration.
   


 Experience and education selected, listed, or detailed in the Supplemental Questions must be verifiable on the submitted applicant profile.
   



",86208,"['python', 'machine learning', 'sql']"
Data Engineer,Booz Allen Hamilton,DC,Full-time,"


Job Description










         Location: 
        

         Washington,DC,US 
        



         Remote Work: 
        

         Yes 
        



         Job Number: 
        

         R0184980
        


















         Data Engineer
          The Opportunity:
 At a certain point, experience-based system design can start to look like clairvoyance. When you’ve developed so many systems that you can not only orchestrate the best solution for any technology-based challenge, but you can also anticipate and preempt future issues, you’re a solutions architect. You’ve evolved your skills into strategy through a long path of software development accomplishments and the curiosity to understand how all the pieces of an IT ecosystem fit together. Are you ready to use your combination of knowledge, skill, and experience to take on the toughest challenges in our nation’s public health system?

 As a solution architect on our team, you'll translate your customer’s IT needs and future goals into a plan by crafting architecture products, design specifications, and Agile frameworks that drive innovative, technical solutions. Through your leadership, we’ll help transform the way the federal health sector uses technology, including Cloud migration, integrating advanced technology, and modernizing legacy systems. And, what do you do next in a career where you’ve reached this level? You mentor the next set of developers to help them grow into tomorrow’s solutions architects. As a technical leader, you’ll shape the digital solutions business and identify opportunities for growth.

 Work with us and build the future of technology in healthcare for the better.

 Join us. The world can’t wait.

 You Have:

 3+ years of experience with software engineering, artificial intelligence, data science, machine learning engineering, or data engineering, including in a research or professional role
 Experience working with artificial intelligence and machine learning technology stack and practices
 Experience leading software development and artificial intelligence implementation and deployment projects
 Experience with coding languages, including Python, SQL, and Java
 Experience with modern Cloud computing technologies, including AWS, Azure, and GCP
 Knowledge of the data life cycle, including data acquisition, discovery, sharing, consumption, synthesis, conversion, and disposition
 Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements
 Bachelor’s degree


 Nice If You Have: 

Experience with technology consulting
 Experience with establishing enterprise-wide Data Platform architecture, frameworks, design, and development standards
 Experience with developing high-quality briefings for senior Federal Government leadership
 Ability to select and implement the appropriate data platform tools and systems to support data technology goals, including R, Python, or Jupyter Notebooks
 Ability to design, develop, and manage large-scale complex data engineering pipelines and data governance models
 AWS, Google Cloud, or Microsoft Azure certification


 Vetting: Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'sql']"
"Finance Manager, Data Center",Meta,CA,Full-time,"
 Meta is seeking a Finance Manager to join our Data Center Finance & Business Planning (FBP) team. FBP’s mission is to enable Meta to plan, prioritize, and execute as effectively as possible. FBP brings an independent and objective perspective to the data and decisions that we support and always advocates for intellectual honesty. You will be responsible for supporting the Design, Engineer and Construction team within Meta, which designs and builds our global data center infrastructure footprint for Meta. You will serve as the key liaison between Finance and the Data Center team and oversee issues related to data center strategy, design, cost profile, financial reporting & forecasting, and planning, i.e., resource prioritization and business management related to Meta’s multi-billion-dollar investments. With a deep understanding of the business levers underlying the operations of our Data Center team, you will be responsible for helping the business to drive toward well-informed decisions.
 


Finance Manager, Data Center Responsibilities:  

Serve as the primary finance adviser to the Head of Design, Engineering and Construction team, as well as leaders across the constituent teams, including design, planning, engineering and delivery teams
 Partner with business to build cost effective and schedule optimized strategies for future data center projects
 Perform analyses to provide ad hoc decision support, create total cost of ownership frameworks and reviews of key financial metrics
 Lead FP&A activities for the business including budgeting, forecasting, and long-range planning across CapEx, OpEx and headcount
 Drive reporting that includes financial performance, detailed reporting of key expense and other metrics, and executive level explanations of variances and trends
 Lead the preparation of financial analysis, commentary and presentation materials for financial updates to the CFO
 Lead key initiatives to continuously improve and automate Meta’s financial controls and operations




Minimum Qualifications: 

 8+ years of finance experience
 Experience with infrastructure, semiconductor, telecom and/or related markets
 Experience building cross-functional relationships and partnering with senior leadership of organizations
 Experience analyzing and translating large amounts of data into useful information
 Communication skills to tailor messaging as needed for audiences of varying level of seniority and technical expertise




Preferred Qualifications: 

 8+ years of experience in financial planning
 Experience working at an internet related company
 Experience in web infrastructure, capital spending, and tech ops




About Meta:  Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.
 



  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. 
  
 Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
 
",138000,['machine learning']
Statistician (Medicine),US Veterans Health Administration,VA,Full-time,"

Duties
***JOA updated on 11/16/2023 to reflect: The salary range listed reflects the GS base rate (not including locality). Upon selection, the salary will be adjusted to include locality.  This is a bargaining unit position.  The initial application review cut-off for this job announcement is 75 applications. The first 75 applications received will be considered first. Applications received after the initial cut-off number (75 applications) may not receive consideration unless otherwise requested by management. If management requests additional certificates, applicants will continue to be reviewed in groups of 75 in the order they applied.  Note: Submitting multiple applications will change the order in which your application is reviewed.


VA offers a comprehensive total rewards package: 
VA Total Rewards

Work Schedule: Monday - Friday, 8:00 am - 4:30 pm
   
Compressed/Flexible Schedule: Not available
   
Telework: Available
   
Duty Location Status: Will work remotely from home
   
Position Description Title/PD#: Statistician (Medicine)/ PD689-02007-0
   
Relocation/Recruitment Incentives: Not authorized
   
Permanent Change of Station (PCS): Not authorized
   
Financial Disclosure Report: Not required
   
Physical Demands: The work involves physical activities typically found in an office-based work environment i.e., some standing, walking, bending, and lifting of light items.
   


Major Duties:
   

Conduct univariate and multivariable statistical data analyses including: ordinary least squares regression, logistic regression, longitudinal mixed effects models, and survival models.
Check validity of data and programs through evaluation of frequencies, listings, and summaries, and oversee and advise on the calculation of meaningful data metrics (e.g., cost per day, average length of stay, or others as appropriate).
Advise investigators on statistical matters that may affect study methodology and data analysis.
Develop and implement statistical analysis plans and specification documents.
Develop complex and accurate programs in the SAS statistical software application.





Requirements
Conditions of Employment

You must be a U.S. citizen to apply for this job.
Selectees are subject to a background/suitability investigation.
Selectees may be required to serve a probationary period.
Selective Service Registration is required for males born after 12/31/1959.
A complete application package, i.e., Resume, Transcripts, etc., as required by job announcement.
Selected applicants will be required to complete an online onboarding process.
Participation in the Seasonal Influenza Prevention Program for VHA Health Care Personnel (HCP) is a requirement for all Department of Veterans Affairs HCP.
All applicants tentatively selected for VA employment in a testing designated position are subject to urinalysis to screen for illegal drug use prior to appointment. Applicants who refuse to be tested will be denied employment with VA.
Must be proficient in written and spoken English.
Pre-employment physical examination/evaluation may be required.
Participation in the Coronavirus Disease 2019 (COVID-19) vaccination program is a requirement for all Veterans Health Administration Health Care Personnel (HCP) - See ""Additional Information"" below for details.


Qualifications

    To qualify for this position, applicants must meet all requirements by the closing date of this announcement, 11/30/2023.
    
 You may qualify based on your education/experience/combination as described below.
    
 A transcript must be submitted with your application. 
    Individual Occupational Requirements - Basic Requirements:


Degree: that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. or 


Combination of education and experience - courses as shown in A above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance;


AND


Specialized Experience: You must have one year of specialized experience equivalent to at least the next lower grade GS-11 in the normal line of progression for the occupation in the organization. Specialized experience is defined as: 
    
Conducting statistical data analyses;
Applying data collection procedures and concepts to review quality of data, identify and resolve problems with data collection; 
Using appropriate software and database (e.g., MS Access, SQL) computer programs to construct and manage datasets and databases relevant to research projects; 
Contributing to statistical and data analysis for grant proposals, reports, abstracts and/or written or verbal presentations;


OR


Education: Possess a Ph.D. or equivalent doctoral degree in an area of study directly related to the position.
    
 You will be rated on the following Competencies for this position: 
    
Arithmetic/Mathematical Reasoning
Data Management
Project Management
Communication

 Per Office of Personnel Management General Schedule Qualification Policies, federal employees are assumed to have gained experience by performing duties and responsibilities appropriate for their official series and grade level as described in their position description. Experience that would not normally be part of the employee's position is creditable when documented by satisfactory evidence (e.g., a memorandum from the manager, human resources director, or official documentation such as SF-52, SF-50 documenting an official detail/assignments, or other comparable documentation). The documentation must indicate whether the employee performed the duties full time or, if part-time, the percentage of times the employee performed the additional duties.
    
 To receive credit for experience in your resume that is not within the official series and grade level of your position, you must provide official documentation of such experience as indicated above.
    
 Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religions; spiritual; community; student; social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.
    

Note: 
    A full year of work is considered to be 35-40 hours of work per week. Part-time experience will be credited on the basis of time actually spent in appropriate activities. Applicants wishing to receive credit for such experience must indicate clearly the nature of their duties and responsibilities in each position and the number of hours a week spent in such employment.

 For more information on these qualification standards, please visit OPM's web site at http://www.opm.gov/qualifications/standards/indexes/alph-ndx.asp. 
   


Education
PLEASE NOTE: Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications (particularly positions with a positive education requirement). Therefore, applicants must report only attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. Applicants can verify accreditation at the following website: http://www.ed.gov/admins/finaid/accred/index.html. All education claimed by applicants will be verified by the appointing agency accordingly. If you are using foreign education to meet qualification requirements, you must send a Certificate of Foreign Equivalency with your transcript in order to receive credit for that education. 


Additional information


Receiving Service Credit for Earning Annual (Vacation) Leave: Federal Employees earn annual leave at a rate (4, 6 or 8 hours per pay period) which is based on the number of years they have served as a Federal employee. VA may offer newly-appointed Federal employee's credit for their job-related non-federal experience or active duty uniformed military service. This credited service can be used in determining the rate at which they earn annual leave. Such credit must be requested and approved prior to the appointment date and is not guaranteed.  The Interagency Career Transition Assistance Plan (ICTAP) and Career Transition Assistance Plan (CTAP) provide eligible displaced VA competitive service employees with selection priority over other candidates for competitive service vacancies. To be well-qualified, applicants must possess experience that exceeds the minimum qualifications of the position including all selective factors if applicable, and must be proficient in most of the requirements of the job. Information about ICTAP and CTAP eligibility is on OPM's Career Transition Resources website which can be found at https://www.opm.gov/.  This job opportunity announcement may be used to fill additional vacancies.  If you are unable to apply online or need to fax a document you do not have in electronic form, view the following link for information regarding an Alternate Application.






Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.
IN DESCRIBING YOUR EXPERIENCE, PLEASE BE CLEAR AND SPECIFIC. WE WILL NOT MAKE ASSUMPTIONS REGARDING YOUR EXPERIENCE. Applicants will be referred in the order in which they were received. 




Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
Documents Accepted: 

 Performance Appraisal
 Resume
 Separation Notice (RIF)
 SF-50/ Notification of Personnel Action
 Transcript

 Documents Required:
     

Resume
 Transcript


 Please review the above list(s) to ensure you have included all necessary documents required for your application. Not every applicant will require the same documents, therefore it is the applicants responsibility to ensure that their application package includes all necessary documents to determine qualifications and eligibility for appointment, such as a copy of your SF-50, transcript, ICTAP/CTAP documentation (for displaced Federal employees). 
     You will not be contacted for additional information. Applicants will be deemed ineligible if supporting documentation is not submitted.
     

Veterans' Preference: Since the Direct-Hire Recruitment Authority is being used, traditional Veterans' Preference rules do not apply. Qualified veterans will, however, be given full consideration for this position.
     

Applications are accepted online. Applying online will allow you to review and track the status of your application. 
     

If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating. 


How to Apply


All applicants are encouraged to apply online.  To apply for this position, you must complete the occupational questionnaire and submit the documentation specified in the Required Documents section. The complete application package must be submitted by 11:59 PM (EST) on 11/30/2023 to receive consideration. To preview the questionnaire click https://apply.usastaffing.gov/ViewQuestionnaire/12191630.  1. To begin, click Apply Online to create a USAJOBS account or log in to your existing account. Follow the prompts to select your USAJOBS resume and/or other supporting documents and complete the occupational questionnaire.  2. Click Submit My Answers to submit your application package.  NOTE: It is your responsibility to ensure your responses and appropriate documentation is submitted prior to the closing date. To verify your application is complete, log into your USAJOBS account, https://my.usajobs.gov/Account/Login, select the Application Status link and then select the More Information link for this position. The Details page will display the status of your application, the documentation received and processed, and any correspondence the agency has sent related to this application. Your uploaded documents may take several hours to clear the virus scan process.  To return to an incomplete application, log into your USAJOBS account and click Update Application in the vacancy announcement. You must re-select your resume and/or other documents from your USAJOBS account or your application will be incomplete.


Agency contact information
VHA National Recruitment Center 


Phone
(844)456-5208 
Email
VHANationalRecruitmentCenter@va.gov 


Address


West Haven ORD VISN 1

950 Campbell Avenue

West Haven, CT 06516-2770

US 




Next steps

After the vacancy announcement closes, applicants are evaluated to ensure qualification and eligibility requirements are met. After the review is complete, a referral certificate(s) is issued and applicants will be notified of their status by email. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents

Documents Accepted: 

 Performance Appraisal
 Resume
 Separation Notice (RIF)
 SF-50/ Notification of Personnel Action
 Transcript

 Documents Required:
   

Resume
 Transcript


 Please review the above list(s) to ensure you have included all necessary documents required for your application. Not every applicant will require the same documents, therefore it is the applicants responsibility to ensure that their application package includes all necessary documents to determine qualifications and eligibility for appointment, such as a copy of your SF-50, transcript, ICTAP/CTAP documentation (for displaced Federal employees). 
   You will not be contacted for additional information. Applicants will be deemed ineligible if supporting documentation is not submitted.
   

Veterans' Preference: Since the Direct-Hire Recruitment Authority is being used, traditional Veterans' Preference rules do not apply. Qualified veterans will, however, be given full consideration for this position.
   

Applications are accepted online. Applying online will allow you to review and track the status of your application. 
   

If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.






 Help 
 This job is open to




Career transition (CTAP, ICTAP, RPL)
Federal employees who meet the definition of a ""surplus"" or ""displaced"" employee.




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.



Clarification from the agency
DIRECT HIRE AUTHORITY: This position is being filled using Direct-Hire Authority (5 CFR 337.201) for this occupation. All U.S. Citizens are eligible to apply.

",71099,['sql']
Sr. Scientist in Computational Biology / Data Science - LPAZ26894,"TechData Service Company, LLC",MD,Full-time,"Company: Large Pharmaceutical Company
Title: Senior Scientist in Computational Biology / Data Science
Contract Position: 6 months with potential extension
``Duties```
- Apply advanced statistical and predictive modeling techniques to analyze large datasets and extract insights.- Develop and implement machine learning algorithms and models to solve complex business problems.- Collaborate with cross-functional teams to identify data-driven solutions and drive decision-making processes.- Clean, preprocess, and validate data to ensure accuracy and reliability.- Conduct exploratory data analysis to identify patterns, trends, and correlations.- Communicate findings and insights to stakeholders through visualizations, reports, and presentations.- Stay up-to-date with the latest advancements in data science and technology.
```Requirements```
- Bachelor's or Master's degree in Data Science, Computer Science, Statistics, or a related field.- Strong knowledge of statistical analysis, machine learning algorithms, and predictive modeling techniques.- Proficiency in programming languages such as Python or R for data manipulation, analysis, and visualization.- Experience with SQL for data extraction and manipulation from relational databases.- Familiarity with scripting languages such as Bash or PowerShell for automation tasks.- Understanding of molecular biology, biochemistry, epidemiology, or clinical trials is a plus.- Knowledge of bioinformatics tools and techniques is highly desirable.- Excellent problem-solving skills with the ability to think critically and analytically.- Strong communication skills to effectively present complex findings to both technical and non-technical stakeholders.
Note: This job description is intended to provide a general overview of the position. Duties may vary depending on the specific needs of the company.
Job Type: Contract
Pay: $64.00 - $66.00 per hour
Benefits:

401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance

Schedule:

8 hour shift

Work Location: In person",128000,"['python', 'machine learning', 'sql']"
Senior Data Analyst (Business Intelligence Analyst),TRILLIUM HEALTH RESOURCES,NC,Full-time,"

Pay Plan Title: Senior Data Analyst
 

 Working Title: Business Intelligence Analyst
 

 FLSA Status: Exempt
 

 Posting Salary Range: $51,500 - $73,166
 

 Office Location: Remote with offices available in Greenville, NC and Wilmington, NC
 

 POSTING DETAILS:
 Make an Impact
 Trillium Health Resources is a local governmental agency (LME/MCO) in North Carolina that manages serious mental health, substance use, and intellectual/developmental disability services. Serving in 28 counties, we help individuals and their families strengthen well-being and build foundations for a healthy life.
 Join our team as we empower others to live their best lives by providing access to quality healthcare. We offer a challenging, engaging work environment where staff take home more than a paycheck. Every day, we see the results of our dedication – in the smiles of children on our accessible playgrounds and in the pride on the face of an adult cooking a meal for the first time. Working at Trillium Health Resources is more than just a job; it is an opportunity to make a direct impact on the communities we serve.
 At Trillium, we know that empowering others begins with supporting and developing our team. That’s why we offer competitive benefits and work-from-home flexibility so that our employees thrive outside of the office. We’re also committed to building a diverse, inclusive culture where all employees have the potential to grow professionally and personally.
 What We’re Looking For
 We’re seeking a Business Intelligence Analyst who wants to grow their IT career by helping us conduct data analysis activities for Trillium. You’ll work directly with team members from all parts of our organization to assure compliance with the DMH and DMA contract requirements as well as other external and internal reporting needs. The Business Intelligence Analyst is responsible for the validation of data collected and ensuring data integrity. You’ll be a valued member of the Informatics Data Report
 On a typical day, you might:

 Ensure that data from reports are presented in a user-friendly format and made accessible to staff, consumers and community members.
 Analyze and report statistical data on populations, disabilities and cultural factors.
 Provide technical assistance to other Trillium department staff or provider agencies regarding data collection, analysis, and reporting.
 Use SQL and various analytical programs such as R, SPSS, or Python for analysis of data.
 Uses KACE and Team Foundation Server (TFS) to respond to organizational requests, document and track progress, and maintain version control of reports and code

 Employee Benefits:
 Trillium knows that work/life balance is important. That’s why we offer our employees competitive benefits and flexibility that is second to none. Take a look at what we have to offer:

 Flexible Work Schedules. Remote work was a strong part of our culture prior to COVID-19, and currently, employees may work remotely 100% of the time, with an in-office option available for those who prefer that.
 Paid Time Off (PTO) of 23 days per year, plus 10 paid holidays both in first year of employment
 Health Insurance - no premium for employee coverage
 NC Local Government retirement pension. This is a defined-benefit retirement plan that will pay you a monthly amount upon retirement, for the rest of your life, with as little as five years of service. For more information, go to:

 https://files.nc.gov/retire/documents/files/Actives/LGERSHandbook.pdf

 401k with 5% employer match & immediate vesting
 Public Service Loan Forgiveness Qualifying Employer
 Flexible Spending Accounts

 Qualifications:
 Education: Associate’s Degree OR, Based on required experience / Bachelor’s Degree

 Required Experience: Associate’s degree in Information Technology, Actuarial/ Statistics, Data Analytics, Business, or Human Service field (such as Psychology, Social Work, etc.) and four (4) years’ experience in Information Technology, Actuarial/ Statistics, Data Analytics, Business, Human Service field (such as Psychology, Social Work, etc.).
 

   OR
 

   Bachelor’s degree in Information Technology, Actuarial/ Statistics, Data Analytics, Business, or Human Service field (such as Psychology, Social Work, etc.) and a minimum two (2) years’ experience in Information Technology, Actuarial/ Statistics, Data Analytics, Business, Human Service field (such as Psychology, Social Work, etc.).
 

   OR
 
 Equivalent combination of education/experience
 License/Certification: None Identified
 Preferred License/Certification (if applicable): CSPA, Certified Machine Learning – Specialty (AWS), Predictive Analytics Certificate (SOA), and/or CAHIMS, ITIL v3 or equivalent certifications preferred
 Must have a valid driver’s license
 Remote with office locations available in Greenville or Wilmington, NC
 Deadline for application: Posting closed on Wednesday, November 22, 2023 at 11:59 p.m.
 To be considered for employment, all candidates are required to submit an application through ADP and upload a current resume. Your resume must provide your level of education and detailed work experience, including:

 Employer Name
   
 Dates of service (month & year)
 Average number of hours worked per week
 Essential duties of the job as related to the position you’re applying for

 Education
   
 Degree type
 Date degree was awarded
 Institution

 Licensure/certification, if applicable

 After submitting your application through our career center in ADP, your resume will be reviewed to ensure that your skills and experience meet the essential criteria for the role you have applied for.
 Join our Talent Community through our ADP career center to stay informed about positions you may qualify for. Remember to keep an update resume in the Talent Community profile.
 The diversity of the communities we serve is reflected in our employees. Trillium Health Resources is an Equal Employment Opportunity (EEO) employer.
 Trillium Health Resources is a drug-free workplace. Candidates are required to pass a drug test as a condition of employment.
 #Innovation #Technology #Careers #NorthCarolina #BehavioralHealth
",51500,"['python', 'machine learning', 'aws', 'sql']"
Data Scientist,Resource Innovations,CO,Full-time,"

Resource Innovations is seeking a Mid-Level level Data Scientist to join our growing team ideally in Louisville, Colorado or (USA), Toronto, Ontario (Canada), however, other locations will be considered as well. As a Data Scientist with Resource Innovations, you will be responsible for providing analytical solutions for our utility, software, and energy efficiency delivery teams and clients.
 Specific responsibilities will include supporting: application development, data analysis, and identifying solutions for electric and gas utilities. Candidates with more than 3 years of work experience are encouraged to apply. 
Resource Innovations (RI) is a women-led energy transformation firm focused on impact. Building on our expertise in energy efficiency, we’re constantly expanding our portfolio of clean energy solutions to guide utilities through increasingly complex, connected challenges. Load flexibility. Electrification. Carbon reduction. With every step, we’re leading the charge to power change.
 Duties and Responsibilities

Develop data-driven solutions to operational needs, regulatory mandates, and customer outreach.
Familiarity with the full data science stack, with a focus on machine learning, data visualization and communication of complex results to a variety of audiences
Write production-level machine learning pipeline code.
Create solution architectures including integration with Amazon Web Services (AWS) and /or Azure.
Participate in meetings, conference calls, and email exchanges with clients.
Track energy industry trends and emerging issues
Other duties as assigned.


Requirements

A Bachleor's Degree in a quantitative field is required
Previous work experience in one or more of the following disciplines: data science, economics, statistics, public policy with a quantitative focus, or computer science
Experience performing advanced customer data analytics, including propensity modeling and high frequency consumption data analysis
Coursework and/or practical experience in machine learning, applied econometrics and/or statistical program evaluation
Real world experience scraping and/or munging large data sets
Programming experience using R, Python and SQL to build and deploy regression, classification, and other statistical models
Experience building machine learning pipelines
Strong written and oral communication skills
Experience with model selection and validation methods
Strong data visualization skills
Understanding of relational databases and basic architectural principles
Preferred Qualifications
Experience with AWS and/or Azure to deliver data-driven solutions
AWS certifications are highly preferred
Experience using Tableau or other data visualization software
Familiar with the use of version control (e.g. git/Github)

Benefits
 Resource Innovations offers competitive salaries based on candidate's qualifications. Resource Innovations also offers three weeks paid vacation per year, paid holidays, a 401(k) plan with employee matching funds, a discretionary bonus and an overall comprehensive benefits package.
 About Resource Innovations Resource Innovations (RI) is a women-led energy transformation firm focused on impact. Building on our expertise in energy efficiency, we’re constantly expanding our portfolio of clean energy solutions to guide utilities through increasingly complex, connected challenges. Load flexibility. Electrification. Carbon reduction. With every step, we’re leading the charge to power change.
 Resource Innovations is an Equal Opportunity Employer, committed to ensuring equal employment opportunities for all job applicants and employees without regard to race, color, religion, national origin, gender, age, disability, marital status, genetics, protected veteran status, sexual orientation, or any other protected status. In addition to federal law requirements, Resource Innovations complies with applicable state and local laws governing non-discrimination in employment in every location in which the company does work.
 The above job description and job requirements are not intended to be all inclusive. Resource Innovations retains the right to make changes or adjustments to job descriptions and/or job requirements at any time without notice.
 The compensation range for this exempt position is $110000- $160000. The stated range is based on a good faith estimate of the compensation range for the duties, responsibilities and skills / experience required for the position. Starting pay will be dependent on experience and internal equity. This provided range may exceed this range for well-qualified candidates, especially with industry experience.
",82000,"['python', 'machine learning', 'tableau', 'aws', 'azure', 'sql', 'git']"
Senior Statistical Modeler,Kalibrate,Remote,Full-time,"
Why join Kalibrate?

 Kalibrate exists to create a world without guesswork. For decades, we’ve combined the power of data science, human ingenuity, and machine learning to help retail and service-based organizations of all sizes make location-critical business decisions with confidence – so they can understand risk, identify opportunities, and outperform the competition.

 What you will do:

 Data Analysis: Derive insights and build solutions using a variety of data sources.
 Predictive Modeling: Develop statistical models that are grounded in solid principles of consumer behavior and retail geography.
 Programing: Demonstrate comfort working with regression analysis and other analytical techniques in statistical software programs, and in encoding those models in other environments.
 Collaboration: Contribute to our team culture. Be innovative. Criticize constructively. Solicit input from project stakeholders. Effectively communicate results with technical and non-technical audiences.
 Workflow Management: Organize workflows and data clearly and consistently with thorough documentation. Manage multiple projects of varying complexity while balancing priorities and timelines.

 Required Skills & Experience:


 Bachelor’s degree in relevant discipline, including Economics, Geography, Statistics, Mathematics, Decision Sciences, or other related fields.
 Familiar with principles of consumer behavior, market research, retail geography
 Statistical programming in SAS, JMP, R, Stata, SPSS, or other similar programs
 Comfort using Microsoft Excel
 Strong Excel skills (Pivot tables, look-ups, advanced filtering)
 Understanding of statistical concepts including: correlation, variance, significance, and predictive model fitting.
 Excellent verbal and written communication skills, with the ability to present findings internally and articulate Kalibrate’s requirements to potential data partners
 Strong communication and cross-functional collaboration abilities
 Ability to identify issues and recommend solutions independently
 Commitment to accuracy and transparency

 Desirable Skills & Experience:

 Experience using Alteryx, Python, Tableau, SQL, GIS/mapping platforms is a plus
 Master’s degree is a plus.

 This role has a solid benefits package with health insurance, paid time off and pension scheme. The salary range for this role is $60k +. We have an office in Dallas or Ann Arbor. The preference is for a hybrid work set-up, however, we are open to discussing a remote option.

 If this is you, then click that apply button!
",60000,"['python', 'machine learning', 'tableau', 'sql']"
AI/ML Engineer,lucid technologies,OH,Full-time,"Role: AI/ML Engineer
Job Location:- Woodland Hills, CA / Mason, OH (Day 1 onsite -5 Days at Mason ,OH/Woodland Hills, CA Client office is Mandatory)
Duration: Long Term Contract
We are Looking for AI/Client Engineer-Data Scientist for one of our Healthcare Client

Experience in LLM and Generative AI
Experience in Document extraction/chat
Strong experience in Python, NLP
Experience working in a cloud-native environment such as AWS
Should have hands on experience with AWS Neptune or Neo4J graph database
Experience in building and maintaining open-domain or health care domain-specific ontologies
Understanding of knowledge graphs
Have experience in building graph-based ontology from scratch and working with structured and unstructured data
Experience supporting Client models development on big data infrastructure (on knowledge graph would be a bonus)
Hands on python to build knowledge Graph/ontologies.
Experience with AWS Textract, Comprehend Medical (nice to have)

--
---------------------------------------------------------
Siva Prasad | Sr Technical Recruiter
50 California Street, Suite 1500San Francisco CA 94111 USA
Direct +1 669-201-5398 | Cell+1 669-900-0305
sivaprasad@spiceorb.com
www.spiceorb.com
https://www.linkedin.com/in/siva-prasad-426521217/
Certified Woman-Owned Business Enterprise (WMBE)
Job Type: Contract
Salary: $70.00 - $75.00 per hour
Ability to commute/relocate:

Mason, OH 45040: Reliably commute or planning to relocate before starting work (Required)

Experience:

Python: 1 year (Preferred)
SQL: 1 year (Preferred)

Work Location: In person",140000,"['python', 'aws', 'sql']"
Generative AI Practice Leader,ehub global,NJ,Full-time,"Title: Generative AI Practice Leader
Location: New Jersey
Fulltime Role
Job Description:
Expectations

Experience in Banking, Insurance and / or Capital Market (BFSI) domain
Create differentiated solution & Services offerings and translate into revenue growth.
Drive strategic account growth and be responsible for the delivery of consulting services to our customers.
Actively search for opportunities to expand business within existing accounts and help win new clients.
Building new technology capabilities, and building team competencies
Marketing of technology & domain solutions / service offerings to internal/external stakeholders
Manage business relationship with the technology partners & start-up eco systems and demonstrate edge over competition.
Passionate about technology and customer success with excellent communication and articulation skills
Ability to communicate technical concepts and solutions at a level appropriate for technical and non-technical audiences.
Research, curate, and record tutorials on various applications of data science and machine learning
Ability to work effectively in a dynamic, research-oriented group that has several concurrent projects.

Behavior Competencies

Excellent Communication
Consulting and Advisory
Conflict Resolution
Solutioning
Customer Service
Accountability
Judgement and decision making

Technical Skills

At least 5+ years of hands-on experience with building language models, machine learning and AI models leveraging industry tools, products, and / or Azure cognitive services.
Deep and hands-on expertise in (as an individual contributor) Undertaking data collection, Data mining, preprocessing and analysis of structured and unstructured data.

Hands-on expertise in large language models (LLMs/LSTMs/BERT) that can perform complex reasoning in few- and zero-shot settings by generating intermediate chain of thought (CoT) reasoning steps
Experience of building / customizing and fine-tuning AI models including LLM models via OpenAI (Azure), Bert (AWS) for rapid PoCs
Experience on LLM Model Governance, LLMSecOps, Hallucination and bias handling
Deep and hands-on experience in applying machine learning algorithms.
Strong data science and data engineering background both with open source and cloud distributed machines learning and AI tools especially Azure Cognitive Services, Azure Machine Learning and AWS Sagemaker and Bedrocks

Strong understanding of Azure cloud technology including Cognitive Services viz. Vision, Speech, Language, Decision, Search and GenAI and its implementation
Proven experience with, and applied knowledge of, at least one scripting language, such as Python, or R

Job Type: Full-time
Salary: $140,000.00 - $170,000.00 per year
Benefits:

401(k)
Dental insurance
Health insurance
Vision insurance

Schedule:

8 hour shift

Work Location: In person",140000,"['python', 'machine learning', 'aws', 'azure']"
Solution Architect (Machine Learning and Azure Cloud),Alpha Silicon,Remote,Full-time,"Title - Solution Architect (Machine Learning and Azure Cloud)
Duration - 9+ Months
Location – Minneapolis, MN
Responsibilities :

Machine Learning / AI PlatformDesign, develop and document cutting-edge ML solutions, using existing and emerging technology platforms

Architect extensible technical architectures to deliver the latest in machine learning, AI, and other emerging technology solutionsProvide technical vision, technical solutions and directions to build modern Machine Learning Platforms, Tooling and Services for ML/AI at Scale.Contribute to building a platform to streamline all phases of data-centric innovation, including data organization, data access, data exploration, data science prototyping, productionization, testing, and ongoing monitoring of machine learning pipelinesEvangelize and drive adoption of the ML platform, and strive for operational excellenceOversee the day-to-day operation of the platform, ensuring high availability, scalability and performance and a data-driven approach to continuous measurement and optimization

IntegrationDefines architecture blueprints for end-to-end systems to including integration of applications, systems, platforms and technical infrastructure

Design infrastructure, tools, utilities, and automated workflowsOperate as a trusted advisor for the Machine Learning space, helping to shape use cases and implementation in an integrated mannerSupport the productionization and deployment of data science models and pipelines

OptimizationDefine standards and create reference implementations pattern for machine learning / AI solution and Azure PaaS

Responsible for successful analysis, high-level design and delivery of cloud projectsPartner with data scientists and machine learning engineers to review and co-optimize technical designsOptimize machine learning and relevant data processing code for scale and robustness

Cost ManagementFacilitate in determining architecture goals, cost estimating solutions and reviewing existing cloud deployments for potential improvements to design, availability, recoverability and cost optimization

Engage in a highly collaborative team environment where your expertise is required to suggest best options to lay foundations for cloud data architecture, scaling, and data development opportunities, cost savings, and vulnerabilitiesPartner with business stakeholders, management, and technology teams to identify needs and guide the delivery of cost-effective, high-performance technology capabilities leveraging enterprise information architecture principles and core data assets
Qualifications:

Knowledge of Azure relevant certifications such as Azure Solutions Architect, Azure AI Engineer
Deep knowledge in the Machine Learning and data space including designing, building, optimizing and scaling data-intensive ML solutions using distributed computing
Ability to see and implement patterns that enable solution simplification
Ability to influence through persuasion

Experience:

BS, MS, or PhD in Computer Science, Electrical/Computer Engineering, Physics, Mathematics, or other Engineering fields or equivalent experience
5+ years of experience in an architecture or engineering role focusing on machine learning models and deploying them into production at scale
Experience with next generation architectural concepts, including Integrations, advanced analytics, cloud analytics, big data, artificial intelligence, and/or machine learning
Expertise in Python and SQL, with working experience in Apache Spark, Hadoop, Databricks, Snowflake, or other big data systems
Experience working with DevOps on prem or in cloud environments, including but not limited to Deep understanding of compute, storage, networking, Docker/Containers, Kubernetes, cloud APIs and IaaS
Experience with orchestration frameworks
Experience with natural language processing or deep learning frameworks such as Tensorflow, Pytorch, or HuggingFace, etc
Strong analytical and problem-solving skills
Self-motivated individual that thrives in a dynamic environment

Job Type: Contract
Salary: $55.00 - $60.00 per hour
Expected hours: 40 per week
Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance

Compensation package:

Bonus opportunities

Experience level:

9 years

Schedule:

8 hour shift

Work Location: Remote",110000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'azure', 'docker', 'sql', 'hadoop', 'apache spark']"
Statistical Data Analyst,Neotech Solutions,IL,Full-time,"Statistical/Data Analyst // CAT // Peoria IL // Full Time
Details and Requirement:
· Statistical Analysis/Uncertainty Quantification.
· Capable of designing hypothesis test
· Deep understanding of the confidence interval estimation
· M.S. degree with 4 to 5 years of experience in statistical analysis is acceptable.
· Applied Math major with a good amount of engineering experience is acceptable.
· Strong Knowledge in Python.
· Automotive industries experience is preferred.
Thanks & Regards
Karthik Siddi | Senior Engineering RecruiterD: 908-356-6657 | karthik@neotechusa.comOne Cragwood Rd | South Plainfield, NJ 07080 eFax: 888-828-9871| www.neotechusa.com
Job Type: Full-time
Salary: $58,495.15 - $70,445.77 per year
Benefits:

401(k)
Dental insurance
Health insurance

Schedule:

8 hour shift

Work Location: In person",58495,['python']
Data Analyst/ Statistical,Neotech solutions,IL,Full-time,"Role:Data Analyst/ Statistical
Location: Peoria, IL (Onsite)
Duration: Full Time
Must have:
Correlation Analysis experience Engineering Background, hypothesis test, Interval estimation, Python, reliability/performance
-Candidate must worked for Engineering companies
Details and Requirement:
Statistical Analysis/Uncertainty Quantification.
Capable of designing hypothesis test
Deep understanding of the confidence interval estimation
M.S. degree with 4 to 5 years of experience in statistical analysis is acceptable.
Applied Math major with a good amount of engineering experience is acceptable.
Strong Knowledge in Python.
Automotive industries experience is preferred.
Job Type: Full-time
Salary: $60,000.00 - $65,000.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Life insurance
Paid time off
Parental leave
Relocation assistance
Vision insurance

Experience level:

4 years
5 years
6 years
7 years
8 years
9 years

Schedule:

8 hour shift

Work Location: In person",60000,['python']
Senior AI Engineer,LPL Financial,CA,Full-time,"
Job Overview:
 We are looking for an experienced Sr. AI Engineer to join the AI Labs team, a team of data and technology professionals who build and operationalize complex machine learning models for LPL Financial. The successful candidate will build solutions using state of the art technologies to implement production grade for successful model deployment.

 As a Sr. AI Engineer, you will partner with a cross-functional team of experts to design, build and deploy machine learning models that solve real world business problems and that scale to handle the breadth of our business.

 Responsibilities:

 Act as a mentor and lead on a cross-functional team that includes business analysis, data engineering, data science and ml engineering.
 Design and develop data and machine learning pipelines to automate data ingestion, model training, data and model monitoring.
 Build robust data pipelines on Cloud using Airflow, Glue, Spark/EMR, Kinesis, Kafka, Lambda or other technologies
 Build sagemaker pipelines to incorporate and automate data and model quality, bias checks and model explainability.
 Create ML models using the Sagemaker suite of tools that address business problems and opportunities with high degree of a quality and confidence.
 Ensure all data design and model architecture align with enterprise standards.
 Work across business, product and technical teams to deliver solutions that drive commercial impact.


 What are we looking for?
 We want strong collaborators who can deliver a world-class client experience. We are looking for people who thrive in a fast-paced environment, are client-focused, team oriented, and are able to execute in a way that encourages creativity and continuous improvement.
 Requirements:

 BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
 5+ years of experience of Machine Learning/Deep Learning frameworks, libraries, data structures, and data modeling.
 3+ years programming experience in Python and Spark
 1+ years’ experience with AWS Sagemaker suite of tools
 Demonstrated track record of delivering business value using data science.
 Ability to clearly explain ML concepts to business users and articulate how they impact solutions.


 Preferences:

 Strong experience with writing complex programs, implementing architectures, and enabling automation in these environments
 Experience in CI/CD pipeline and code repositories like GitHub or Bit Bucket
 DevOps experience with Terraform
 Experience using JIRA and Agile Project Management software
 Oracle
 Batch Processing
 Informatica
 C#
 Nice to have experience with microservice development, Docker, Kubernetes
 Hands-on experience in BI Tools like Tableau, Power BI


 Pay Range: $150,480-$225,720/year
 
 Actual base salary varies based on factors, including but not limited to, relevant skill, prior experience, education, base salary of internal peers, demonstrated performance, and geographic location. Additionally, LPL Total Rewards package is highly competitive, designed to support your success at work, at home, and at play – such as 401K matching, health benefits, employee stock options, paid time off, volunteer time off, and more. Your recruiter will be happy to discuss all that LPL has to offer!
 
 Why LPL? 

At LPL, we believe that objective financial guidance is a fundamental need for everyone. As the nation’s leading independent broker-dealer, we offer an integrated platform of proprietary technology, brokerage, and investment advisor services. We provide you with a work environment that encourages your creativity and growth, a leadership team that is supportive and responsive, and the opportunity to create a career that has no limits, only amazing potential.

 We are one team on one mission. We take care of our advisors, so they can take care of their clients.

 Because our company is not too big and not too small, you can seize the opportunity to make a real impact. We are committed to supporting workplace equality, and we embrace the different perspectives and backgrounds of our employees. We also care for our communities, and we encourage our employees to do the same. This creates an environment in which you can do your best work.

 Want to hear from our employees on what it’s like to work at LPL? Watch this!

 We take social responsibility seriously. Learn more here

 Want to see info on our benefits? Learn more here

 Join the LPL team and help us make a difference by turning life’s aspirations into financial realities. Please log in or create an account to apply to this position. Principals only. EOE.

 Information on Interviews:

 LPL will only communicate with a job applicant directly from an @lplfinancial.com email address and will never conduct an interview online or in a chatroom forum. During an interview, LPL will not request any form of payment from the applicant, or information regarding an applicant’s bank or credit card. Should you have any questions regarding the application process, please contact LPL’s Human Resources Solutions Center at (800) 877-7210.

",150480,"['python', 'machine learning', 'deep learning', 'tableau', 'aws', 'docker', 'airflow', 'kafka']"
Data Scientist,US Heathcare Product Company,Remote,Full-time,"Job Title: Data Scientist (C2H role only)
Job Summary:
We are looking for a Data Scientist with strong statistics background to join our team. The ideal candidate will have a strong background in statistics and machine learning, and will be able to apply their knowledge to solve complex business problems. The candidate will work closely with other data scientists, software engineers, and product managers.
Responsibilities:
- Analyze large, complex data sets using statistical methods and machine learning techniques
- Develop predictive models to identify trends and patterns in data
- Communicate insights and recommendations to stakeholders, including executives, product managers, and engineers
- Collaborate with cross-functional teams to identify opportunities for data-driven decision-making
- Work with engineering teams to integrate statistical models into production systems
- Continuously monitor and improve the performance of statistical models
- Stay up-to-date with the latest developments in statistical modeling and machine learning
Requirements:
- Bachelor's or Master's degree in Computer Science, Statistics, Mathematics or related field.
- 5+ years experience applying statistics to solve complex business problems.
- Strong background in statistics and machine learning.
- Experience with programming languages such as Python, Java, or C++.
- Experience with data processing and analysis tools such as SQL.
- Solid experience writing complex SQL queries
- Strong problem-solving skills.
- Excellent communication skills.
- Ability to work independently and as part of a team.
- Experience with cloud computing platforms such as AWS, Azure, or GCP is a plus.
- Experience in healthcare is a plus.
Job Type: Contract
Salary: $55.00 - $60.00 per hour
Expected hours: 40 per week
Schedule:

8 hour shift

Application Question(s):

Interested in C2H role ? YES/NO

Experience:

complex data sets using statistical methods: 5 years (Preferred)
Machine learning: 3 years (Preferred)
Python: 5 years (Preferred)
AWS or Azure or GCP: 5 years (Preferred)
olid experience writing complex SQL queries: 5 years (Preferred)

Work Location: Remote",110000,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'sql']"
Data Scientist,Boston Services,MI,Full-time,"Position: Data Scientist
Work location: Auburn Hills, MI (Day 1 Onsite)
Duration: Long term contract
Unique Competencies:

8+ years of experience in Data Science and Analytical Domains
Understanding of machine-learning and operations research
Proficiency in Query languages SQL, Hive and scripting languages
Knowledge of R; familiarity with Scala, Java is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop, Google Cloud Platform, SAP)
Working knowledge of containers. For example, experience with Docker or podman
Comfortable with Git

Job Type: Contract
Pay: $65.00 - $73.00 per hour
Experience level:

7 years

Experience:

Python: 1 year (Preferred)
SQL: 1 year (Preferred)

Ability to Commute:

Auburn Hills, MI 48326 (Required)

Ability to Relocate:

Auburn Hills, MI 48326: Relocate before starting work (Required)

Work Location: In person",130000,"['python', 'tableau', 'docker', 'sql', 'git', 'hadoop']"
Data Scientist,rds,Remote,Full-time,"We are seeking a Data Scientist to work on a Generative AI initiative to join our team. The ideal candidate will have a deep understanding of language models, text-to-image, and other generative AI models. They must possess knowledge of Python, and machine learning frameworks.
Responsibilities

Develop and implement generative AI models, including LLMs, text-to-image and generative AI models.
Train and evaluate models using large datasets.
Troubleshoot and debug code to ensure high-quality results.
Keep up to date with the latest developments in the field of generative AI and apply them to our projects.
Collaborate with other engineers, stakeholders and team members to develop innovative solutions.
Deep understanding of how to scale models and their limitations
Ability to quickly identify opportunities for model improvement

Requirements

Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
2+ years of experience in developing and training AI/ML models.
Experience with data querying languages like SQL, scripting languages like Python, and/or statistical/mathematical software e.g. R
Knowledge of state-of-the-art generative AI models such as GPT-3, DALL-E, and CLIP.
Experience with Cloud infrastructure and Platforms - Azure /GCP/AWS
Experience with training and evaluating large-scale models on high-performance computing clusters.
Strong understanding of deep learning, natural language processing, and computer vision.
Excellent problem-solving skills and ability to work independently and in a team environment.

Preferred Qualifications:

Bachelor's or master's degree in computer science, Data Science, Statistics, Math, Physics, or other Science related discipline with course work in AI/ML.
Demonstrated experience in developing and training AI models
Strong knowledge of deep learning, natural language processing, and computer vision.
Experience with scaling up generative models and deploying them in production environments.
Ability to work collaboratively in a team environment and communicate complex technical concepts to non-technical stakeholders.

Job Type: Contract
Salary: $80,906.49 - $176,960.04 per year
Experience level:

7 years

Schedule:

8 hour shift

People with a criminal record are encouraged to apply
Experience:

Artificial Intelligence(AI): 3 years (Preferred)
Azure /GCP/AWS: 3 years (Preferred)
Machine Learning(ML): 3 years (Preferred)

Work Location: Remote",80906,"['python', 'machine learning', 'deep learning', 'aws', 'azure', 'gcp', 'sql']"
Data Scientist,Brik Partners,Remote,Full-time,"Key Responsibilities:

Develop and implement advanced analytics solutions to extract valuable insights from large datasets.
Design and execute complex data analysis experiments, interpreting and communicating findings to stakeholders.
Led and mentored junior data scientists, fostering a collaborative and innovative work environment.
Stay abreast of industry trends and emerging technologies, integrating them into our data science strategies.

Requirements:

8+ years of proven experience in data science roles.
Strong proficiency in Python, R, or other relevant programming languages.
Expertise in machine learning, statistical analysis, and data modeling.
Advanced knowledge of data visualization tools (e.g., Tableau, Power BI).
Excellent communication skills with the ability to present complex findings in a clear and understandable manner.

Job Type: Contract
Salary: $80,906.49 - $176,960.04 per year
Schedule:

Monday to Friday

Application Question(s):

Would you now or in future need the H1 Sponsorship?

Experience:

Python: 7 years (Preferred)
SQL: 7 years (Preferred)
Data science: 8 years (Required)

Work Location: Remote",80906,"['python', 'machine learning', 'tableau', 'sql']"
Data Scientist,Triunity Software,CA,Full-time,"
 Data Scientist (NYC, LA, SF or Seattle)
  Onsite Hybrid role - 3 days a week
 
 We are seeking a highly motivated and talented Senior Data Scientist to join our team of experts in developing and maintaining recommendation and personalization algorithms for Disney Streaming's suite of streaming video apps. As a member of our team, you will play a pivotal role in shaping the future of our streaming services by applying state-of-the-art machine learning methods to meet strategic product personalization goals.
 


Algorithm Development and Maintenance:
 o Utilize cutting-edge machine learning techniques to develop and enhance algorithms for personalization, recommendation, and predictive systems.
  o Take ownership of maintaining and optimizing algorithms deployed in production environments.
  o Serve as the point person for explaining methodologies to both technical and non-technical teams, fostering clear communication.
 

Analysis and Algorithm Optimization:
 o Conduct in-depth analysis of user interactions within our apps and user profiles to drive improvements in key personalization metrics.
  o Collaborate with data scientists and engineers to refine algorithms and enhance their performance continually.
 

MVP Development:
 o Innovate and develop machine learning products that can be used for new production features or by downstream production algorithms.
  o Work closely with cross-functional teams to prototype and operationalize personalization solutions.
 

Development Best Practices:
 o Maintain and establish best practices for algorithm development, testing, and deployment, ensuring high-quality code and efficient processes.
 

Collaboration with Product and Business Stakeholders:
 o Identify and define new personalization opportunities by collaborating with product and business stakeholders.
  o Collaborate with other data teams to improve data collection, experimentation, and analysis methods.
 
 Required Qualifications:
 

7+ years of analytical experience
5+ years of experience developing machine learning models and performing data analysis with Python and tensor-based model development frameworks (e.g. PyTorch, Tensorflow)
5+ years writing production-level, scalable code (e.g. Python, Scala)
5+ years of experience developing algorithms for deployment to production systems
In-depth understanding of modern machine learning (e.g. deep learning methods), models, and their mathematical underpinnings for recommendation engines
In-depth understanding of the latest in natural language processing techniques and contextualized word embedding models
Experience deploying and maintaining pipelines (AWS, Docker, Airflow) and in engineering big-data solutions using technologies like Databricks, S3, and Spark
Familiarity with data exploration and data visualization tools like Tableau, Looker, etc.
Understanding of statistical concepts (e.g., hypothesis testing, regression analysis)
Ability to gauge the complexity of machine learning problems and a willingness to execute simple approaches for quick, effective solutions as appropriate
Strong written and verbal communication skills
Ability to explain how models are used and algorithms behave to both technical and non-technical audiences

 Additional Preferred Qualifications:
 

MS or PhD in computer science, data science, statistics, math, or related quantitative field
Production experience with developing content recommendation algorithms at scale
Experience building and deploying full stack ML pipelines: data extraction, data mining, model training, feature development, testing, and deployment
Experience with graph-based data workflows such as Apache Airflow
Experience engineering big-data solutions using technologies like EMR, S3, Spark, Databricks
Familiar with metadata management, data lineage, and principles of data governance
Experience loading and querying cloud-hosted databases such as Snowflake
Familiarity with automated deployment, AWS infrastructure, Docker or similar containers


 Flexible work from home options available.
",140000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'tableau', 'aws', 'docker', 'airflow']"
Data Scientist,DT Professional Services,Remote,Full-time,"
Job Summary:
 DT Professional Services is seeking an accomplished and forward-thinking Data Scientist to join our team in a remote capacity! In this role, you will play a crucial part in advancing our data analysis capabilities by merging and optimizing various data sources to enhance and automate reporting processes. Working closely with our research and development team, you will pioneer innovative artificial intelligence/machine learning approaches to revolutionize how we interpret and present data. As with any position, additional expectations exist. Some of these are, but are not limited to, adhering to normal working hours, meeting deadlines, following company policies as outlined by the Employee Handbook, communicating regularly with assigned supervisor(s), and staying focused on the assigned tasks including company meetings, and completing other tasks as assigned.
 Responsibilities:

 Conduct research to identify and assess new technology solutions for automating existing reporting processes
 Collaborate with cross functional teams to design hardware and software architectures and system hosting strategies
 Lead the development of interfaces and software code to efficiently retrieve, modify, and update data
 Support the research and development of artificial intelligence/machine learning methods for advanced data analysis
 Generate new or updated system documentation, including data dictionaries, user manuals, and software designs
 Provide training sessions to personnel on newly implemented technologies and processes
 Utilize programming languages and tools such as Angular, .NET, JavaScript, C#, PL SQL, Kubernetes, XML, Python, R, and MATLAB to develop solutions
 Apply mathematical and statistical algorithms, artificial intelligence/machine learning techniques, natural language processing, and large language models for data analysis
 Collaborate with colleagues to ensure software security guides and system configurations are maintained

 Basic Qualifications:

 Ability to obtain and maintain a DoD Secret Clearance
 Proficiency in programming languages such as Angular, .NET, JavaScript, C#, PL SQL, Kubernetes, XML, Python, R, and Matlab
 Experience in developing interfaces and software code for data retrieval and manipulation
 Familiarity with mathematical and statistical algorithms, artificial intelligence/machine learning, natural language processing, and large language model approaches
 Strong problem-solving skills and the ability to innovate and implement creative solutions
 Excellent communication skills to collaborate effectively with cross-functional teams
 Attention to detail and a commitment to producing high-quality results
 Ability to provide clear and comprehensive technical documentation
 Proven experience in providing training and knowledge transfer to team members.

 Preferred Qualifications:

 3+ Years experience in research and development roles involving AI/ML technologies
 Familiarity with data visualization tools and techniques
 Experience with data mining and predictive modeling
 Proficiency in big data technologies such as Hadoop and Spark
 Strong analytical skills and a passion for exploring complex data sets
 Publications or contributions to the data science community

 The compensation range for this position: $90k - $120k annually.
 
klMtUBbu9R
",90000,"['python', 'machine learning', 'sql', 'hadoop']"
Data Scientist,Albertsons Companies,CA,Full-time,"
About the company 
Albertsons Companies is at the forefront of the revolution in retail. With a fixation on raising the bar with innovation and building belonging through our culture, our team is rallying our company around a unique purpose : to create joy around each table and inspire a healthier tomorrow for every community. 
Albertsons Companies is one of the largest food and drug retailers in the United States, with over 2,200 stores in 34 states and the District of Columbia. Our well-known banners include Albertsons, Safeway, Vons, Jewel-Osco, Shaw's, Acme, Tom Thumb, Randalls, United Supermarkets, Pavilions, Star Market, Haggen, Carrs, Kings Food Markets, and Balducci's Food Lovers Market. We support our stores with 22 distribution centers and 19 manufacturing plants. 
Placing a premium on adaptability, safety and family well-being, our work model, Presence with a Purpose, offers a hybrid work environment between remote work and office time. A one-size-fits-all approach does not apply to everyone, and teams are empowered to make decisions best for them. 
Bring your flavor 
Building the future of food and well-being starts with you. Join our team and bring your best self to the table. 
What you will be doing 
You will enjoy working with one of the richest data sets in the world, cutting edge technology, and the ability to see your insights turned into business impacts on regular basis. You'll work closely with other data scientists and business partners in identifying and defining data science projects, building machine learning algorithms and models on top of existing data platforms. The candidate will have a background in computer science or a related technical field with experiences working with large data sets and applying data-driven decision making. A successful candidate will be both technically strong and business savvy, with a passion to make an impact through creative storytelling and timely actions. You are a self-starter, smart yet humble, with a bias for action. 
This position is located in Pleasanton, California. 
Main responsibilities 

Collaborate with business teams to develop production grade machine learning models on large-scale datasets and improve customers’ overall shopping experience 
Apply machine learning to enhance recommendation engines and deliver personalized user experience on ecommerce website and loyalty mobile app 
Build models and algorithms to fuel growth initiatives for Digital, Merchandising, Marketing and Loyalty teams 
Scale up prototypes and implement reliable automated production workflow for models 
Collaborate with software development engineers to integrate models 
Apply predictive modeling techniques to optimize the forecasts for planning needs 
Detect anomaly in systems through various techniques and identify outliers in operational metrics 

The salary range is $109,600 to $142,420 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates. 
What we are searching for 

Masters or PhD degree in quantitative discipline: Computer Science, Engineering, Data Science, Math, Statistics or related fields 
2+ years of industry experience in applying data science and modeling methodologies: regression model, survival model, ensemble modeling, NLP, recommendation algorithm, clustering, deep learning algorithm, experimental design (Multivariate/A-B testing) and nonparametric Bayesian modeling etc. 
1+ years of experience and proficiency in SQL, Python and/or Spark-ML 
1+ years of SQL development skills writing queries, transforming data, mining structured and unstructured data. 
1+ years of hands-on experience in building data science solutions and production-ready systems on big data platforms such as Snowflake, Spark, Hadoop 
Strong teamwork and communication skill 
Ability to write production-level code in Python 
Experience with Snowflake, Azure Databricks is a strong plus 

What is it like at Albertsons? 
Our 290,000 associates have a passion for great service and building lasting relationships with our customers. Through a companywide focus on innovation, we are continually enhancing our digital and product offerings, making it easy for customers to get what they need, wherever they are.
",109600,"['python', 'machine learning', 'deep learning', 'azure', 'sql', 'hadoop']"
"Data Scientist, Membership Programs",Petco,CA,Full-time,"
Create a healthier, brighter future for pets, pet parents and people! 

If you want to make a real difference, create an exciting career path, feel welcome to be your whole self and nurture your wellbeing, Petco is the place for you. 

Our core values capture that spirit as we work to improve lives by doing what’s right for pets, people and our planet. 

We love all pets like our own
 We’re the future of the pet industry
 We’re here to improve lives
 We drive outstanding results together
 We’re welcome as we are


 Petco is a category-defining health and wellness company focused on improving the lives of pets, pet parents and Petco partners. We are 29,000 strong, working together across 1,500+ pet care centers, 250+ Vetco Total Care hospitals, hundreds of preventive care clinics, eight distribution centers and two support centers.
 Position Purpose:
 As a Data Scientist in the Enterprise Analytics and Data Science team at Petco, you'll work on projects to discover insights that will drive strategic decision-making and optimization for our customer membership programs. These insights will be generated through advanced customer analytics and the development of machine learning models, which will involve the following:

 Data generation: Use customer, operational and interaction data to build datasets that can be consumed by various models and reports in the company. Analytical modeling: Data modeling, exploratory data analysis, and feature selection using advanced statistical methods and techniques. Model Validation: Calibrating models to provide interpretable and repeatable outputs by using various metrics like ROC, RMSE, quantile loss, etc. Deployment: Model output will be consumed by various teams to create a customer experience that is the best in the industry. Documentation: Clear documentation of the objective, statistical model, and results.

 Scope:
 Essential Job Functions: The incumbent must be able to perform all of the following duties and responsibilities with or without a reasonable accommodation.

 Build, maintain, optimize, and productionize machine learning frameworks to quantify the impact our actions on Petco’s omni-channel business. Create new data pipelines using the latest technologies that seamlessly integrate with multiple databases at Petco. Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance. Analyze historical data to identify trends, support decision making, and identify scalable opportunities and collaborate with business stakeholders to assess impact. Utilize code (Python/R/SQL) for data analyzing and modeling algorithms. Apply statistical or machine learning knowledge and/or build decision-making models to identify and propose solutions for specific business problems. Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication. Conducts tracking and measurement of KPIs related to recommendations and socializes to the broader teams. Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters. Provide requirements to develop analytic capabilities, platforms, and pipelines. Mentor data scientists and associate data scientists on technique and process.

 Other Duties and Responsibilities

 Interact professionally and effectively through verbal and written communication with all professional contacts with emphasis on company interests.
 Independently prioritize and accomplish multiple tasks within established timeframes.
 Perform other related duties, tasks and responsibilities as required, assigned and directed.


 Education and Experience

 Advanced degree in Statistics, Math, Engineering, Economics or related field
 Ideal candidate will have experience working with Machine Learning/Deep Learning to address real world problems; related experience working in a retail organization and/or supporting subscription-based programs or services would be a strong plus
 2+ years’ experience in business analytics and data science 
Proficiency with SQL and multiple analytics tools required; Python or R strongly preferred 
Hands on experience with BI tools; Tableau /R shiny/Looker 
Must be self-driven and passionate about retail and must be customer centric. 
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment 
Ability to explain/present complicated/advanced analytical methodology and results to non-technical audiences 
Excellent communication skills as well as quantitative modeling, statistical analysis skills and problem-solving skills 


Competencies

 Demonstrate Adaptability and Desire to Learn - Works productively in the face of ambiguity or uncertainty. Demonstrates flexibility and resilience in response to obstacles, constraints, adversity, and mistakes. Constructively and resourcefully adapts to changing needs, conditions, priorities or opportunities. Seeks out opportunities to learn from new discoveries, innovations, ways of looking at things, knowledge, and ideas. Invites and incorporates feedback, without becoming defensive.



 Perform Analysis - Integrates information from a variety of sources to arrive at a broader understanding of issues (e.g., company reports plus in-store observations).Defines issues clearly despite incomplete or ambiguous information. Identifies the key issues in complex or ambiguous problems. Approaches problems or issues systematically, looking for connections, trends, and potential causes. Probes and looks past symptoms to determine the underlying causes of problems and issues.



 Plan and Execute - Develops realistic plans (e.g., action steps, timelines) to accomplish objectives. Acquires and leverages resources, processes, and tools to achieve business goals. Prioritizes and balances time, actions, and projects to ensure accomplishment of results. Holds him/herself and team accountable for outcomes (e.g., achieving goals and complying with policies and procedures). Anticipates and addresses obstacles, redirecting efforts to accelerate the work or improve quality.



 Produce Results - Initiates decisive, timely action to address important issues. Demonstrates a strong sense of ownership and a commitment to achieving meaningful results. Sets challenging, clear goals/targets and expectations for achieving business results. Drives initiatives/efforts to successful completion and closure. Takes personal responsibility to make decisions and take action.



 Good Partner - Identifies and anticipates customer requirements, expectations, and needs. Seeks feedback from customers to identify improvement opportunities. Follows up with customers to ensure problems are solved. Continually searches for ways to improve customer service (including the removal of barriers, and providing solutions).



 Use Professional Judgment - Makes logical, rational, and integrative decisions, and arrives at sound conclusions. Chooses the best alternative(s) based on a review of pros, cons, tradeoffs, timing, and probabilities. Evaluates the consequences and implications of alternatives, actions, or decisions (e.g., impact on sales, returns, customer loyalty). Makes timely decisions, balancing analysis with decisiveness.


 Work Environment
 Most tasks are performed while seated indoors at a personal computer. Limited travel to vendors, seminars and/or conferences may be required periodically throughout the year.

 Contacts
 Interaction with numerous internal departments including, but not limited to Information Systems, Analytical Services, Merchandising, Content, Creative and Marketing are a nearly daily occurrence and may range from the routine exchange of information to the analyses, evaluation and resolution of complex logistical issues. Externally, the position will work with technology & creative partners, and product/service vendors usually exchanging information, providing instruction, or resolving somewhat complex problems.

 The above description is meant to provide an overview/summary of the nature and level of work being performed; it should not be construed as an exhaustive list of all responsibilities, duties and requirements of the job. Petco reserves the right to modify the content formally or informally, either verbally or in writing, at any time without advance notice and employees are required to follow any other job-related duties/functions requested by their supervisor. Further, all employment at Petco is of an at-will nature and, as such, the company reserves its right to terminate any position or employee (with or without notice and with or without cause) within its discretion. 

Petco Animal Supplies, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or any other protected classification.

 The pay range(s) below are provided in compliance with state specific laws. Pay ranges may be different in other locations.
 $79,600.00 - $119,300.00
 
 / year

 Exact rate of pay will be based on position, location, and experience level. For a more detailed overview of Petco Total Rewards, including health and financial benefits, 401K, incentives, and PTO -see https://careers.petco.com/us/en/key-benefits 

To translate this webpage to Spanish or other languages on your internet browser click the translate button to the right of your browser address bar. Additional instruction can be found here: https://support.google.com/chrome/answer/173424?hl=en-GB&co=GENIE.Platform%3DDesktop

 Para traducir esta página web al español u otros idiomas en su navegador de Internet, haga clic en el botón de traducción a la derecha de la barra de direcciones de su navegador. Puede encontrar instrucciones adicionales aquí:
 https://support.google.com/chrome/answer/173424?hl=en-GB&co=GENIE.Platform%3DDesktop
",79600,"['python', 'machine learning', 'deep learning', 'tableau', 'sql']"
"Associate, Data Science",BlackRock,CA,Full-time,"






       Description 
        
About this role
 

Company: BlackRock Financial Management, Inc.
 Job Title: Associate, Data Science
 Location: 820 Ramona Street, Palo Alto, CA 94301
Summary of duties: Design, develop and program methods, processes, and systems to consolidate and analyze unstructured, diverse “big data” sources to generate actionable insights and solutions for client needs and/or product enhancements. Interact with stakeholder teams to identify questions and issues for data analysis, research opportunities for new uses of existing data and develop processes for data modeling, mining, and production. Utilize various techniques in machine learning, data mining, statistics, and big data infrastructures. Work with different datasets and run algorithms on large size data effectively and efficiently, staying up to date with all the latest cutting-edge technologies.
Qualifications: Bachelor's degree in Data Informatics, Computer Science, Computer Engineering, Mathematics, or a related field, and two (2) years of experience as an Associate, Aladdin Product Group; Analyst, Aladdin Product Group; Graduate Analyst Summer Intern; Programmer; Graduate Apprentice; or a related role. Two (2) years of experience with: utilizing data science principles to map applications into data science frameworks, including supervised learning, clustering, collaborated filtering, optimizations, and decision models; utilizing computer programming languages, including Python, JavaScript, SQL, Java, and Scala; applying financial market theory in capital market work, including financing models and asset valuations; applying mathematics and statistics to internal models and AI algorithms; and utilizing big data technology to distribute computing and data storage in cloud, including AWS, Azure, and Google.
Salary range: $145,000 – 152,500
To apply: please click the “Apply” button on this webpage.


 For California only the salary range for this position is $. Additionally, employees are eligible for an annual discretionary bonus, and benefits including heath care, leave benefits, and retirement benefits. BlackRock operates a pay-for-performance compensation philosophy and your total compensation may vary based on role, location, and firm, department and individual performance.
 
Our benefits
 To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
 
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.

About BlackRock
 
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being. Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
 
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.







",145000,"['python', 'machine learning', 'aws', 'azure', 'sql']"
Delivery Consultant - Sterling Data Exchange,IBM,TX,Full-time,"

Introduction
 This role has a thorough understanding of the nature of the business problems in a wide range of industries, and the products and solutions that provide value in solving those problems. Is knowledgeable in the trends and directions of the industry, the marketplace, and the players. The main focus will be to leverage their product and technical expertise with the IBM products to design, develop and customize solutions to fit each customer’s unique business and technical environments.
  

Your Role and Responsibilities
 This role has a thorough understanding of the nature of the business problems in a wide range of industries, and the products and solutions that provide value in solving those problems. Is knowledgeable in the trends and directions of the industry, the marketplace, and the players. The main focus will be to leverage their product and technical expertise with the IBM products to design, develop and customize solutions to fit each customer’s unique business and technical environments.
  

Required Technical and Professional Expertise


 Required skills include (but are not limited to) the following:
   







Direct experience in the following IBM products and technologies: IBM B2BI/SFG, IBM ITX/ITXA, IBM SSP/SEAS, ICC, PEM/PCM, Gentran, Connect Direct/Enterprise.




Strong knowledge of integration concepts and commonly used patterns, able to apply such knowledge in solution design




Experience or strong knowledge of communication and data handling protocols (AS2, PGP/GPG, S/MIME, HTTPS, FTPS/SFTP/SCP/OFTP, POP3/SMTP, Web Services/SOAP/REST, WebDAV, etc.)




Experience or strong knowledge of industry data standards (ACH, ANSI X12, EDIFACT, HIPAA, RosettaNet, SWIFT, TRADCOMS, etc.) 




Experience or strong knowledge of application programming/scripting technologies (Java/J2EE, AJX, ASP, BPEL/BPML, SQLXSLT, Linux/Unix/Windows shell scripts)




Demonstrated experience with enterprise database technologies like Oracle RAC, DB2, and MS SQL Server Enterprise




Highly skilled in complex problem solving, critical thinking, applying judgment, building consensus, and decision making




Excellent communication and interpersonal skills including the ability to work effectively with technical and non-technical staff




Strong business analysis, technical analysis, analytical thinking and decision-making ability









Preferred Technical and Professional Expertise



 Preferred skills include (but are not limited to) the following:
    







Knowledge of Cloud technologies




Knowledge of popular ERP systems, such as SAP




Strong experience working with senior IT and non-IT executives on a daily basis




Demonstrated experience in multi-shore management, teamwork and execution




B.S. in Computer Science, Software Engineering, or equivalent



Experience and strong business acumen with competing (non-IBM) integration and managed file transfer technologies.











About Business Unit
 IBM Software infuses core business operations with intelligence—from machine learning to generative AI—to help make organizations more responsive, productive, and resilient. IBM Software helps clients put AI into action now to create real value with trust, speed, and confidence across digital labor, IT automation, application modernization, security, and sustainability. Critical to this is the ability to make use of all data, because AI is only as good as the data that fuels it. In most organizations data is spread across multiple clouds, on premises, in private datacenters, and at the edge. IBM’s AI and data platform scales and accelerates the impact of AI with trusted data, and provides leading capabilities to train, tune and deploy AI across business. IBM’s hybrid cloud platform is one of the most comprehensive and consistent approach to development, security, and operations across hybrid environments—a flexible foundation for leveraging data, wherever it resides, to extend AI deep into a business.
 



 Your Life @ IBM
 In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.
   Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.
 Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.
 Are you ready to be an IBMer?



 About IBM
 IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.
  
 Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. 
  
 At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.
 



 Location Statement
 IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:
  


Healthcare benefits including medical & prescription drug coverage, dental, vision, and mental health & well being
 - Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short & long- term disability coverage, and opportunities for performance based salary incentive programs
  

Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law
Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals
Diverse and inclusive employee resource groups, giving & volunteer opportunities, and discounts on retail products, services & experiences

 The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year. 
  
 We consider qualified applicants with criminal histories, consistent with applicable law.
 



 Being You @ IBM
 IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
 
",101000,"['machine learning', 'sql']"
Data Scientist,ICF,VA,Full-time,"

  ICF International seeks an experienced Data Scientist to support the research and development of new cyber analytic capabilities that will help the US protect and defend its networks and critical information systems. The successful cleared candidate will act as a Data Scientist to support a large federal cyber security analytic program. Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate. Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large-scale.
 


 As the Data Scientist, your skillset will create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms. The ideal candidate is strong mathematically, can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. This is an opportunity to contribute to an important project from its beginning, work with the latest and emerging technologies, and all while building a great career at ICF!
 


 This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region.
 


 What You Will Be Doing:
 

 Perform knowledge elicitation from customer subject matter experts and convert that to derived algorithms
 Analyze large data sets to identify actionable insights with mathematical statistical rigor
 Rigorously critique and correct intermediate results to improve the algorithmic outcomes
 Design and deploy deep learning algorithms and predictive models
 Develop custom data models and algorithms to apply to data sets
 Assess the effectiveness and accuracy of new data sources and data gathering techniques
 Develop processes and tools to monitor and analyze model performance and data accuracy
 Interpret and communicate results to non-technical customers



 What You Must Have:
 

 3+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field. Education can be considered in lieu of experience.
 3 + years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering
 U.S. Citizenship required (required by federal government for position) SCI required.
 1 + years of experience with one or more programming languages (e.g., Python, JavaScript, R, etc.)



 Preferred Skills/Experience:
 

 Experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools
 Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
 Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables
 Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis
 Experience with statistical data analysis, experimental design, and hypotheses validation
 Experience with database querying like SQL
 Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
 Scaled Agile Framework (SAFe) experience
 CompTIA Security+ or higher certification level preferred



   Working at ICF
 
 ICF is a global advisory and technology services provider, but we’re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
 

   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our 
  
   EEO & AA policy
  .
 


   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email 
  
   icfcareercenter@icf.com
   and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: 
  
   Know Your Rights
   and 
  
   Pay Transparency Statement.
  



 Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:
  $77,890.00 - $132,413.00
  Arlington, VA (VA31)
",77890,"['python', 'machine learning', 'deep learning', 'sql']"
"Data Scientist, DentaQuest",DentaQuest,MA,Full-time,"
You are as unique as your background, experience and point of view. Here, you’ll be encouraged, empowered and challenged to be your best self. You'll work with dynamic colleagues - experts in their fields - who are eager to share their knowledge with you. Your leaders will inspire and help you reach your potential and soar to new heights. Every day, you'll have new and exciting opportunities to make life brighter for our Clients - who are at the heart of everything we do. Discover how you can make a difference in the lives of individuals, families and communities around the world.

 DentaQuest manages dental and vision benefits for more than 33 million Americans. Our outcomes-based, cost-effective solutions are designed for Medicaid and CHIP, Medicare Advantage, small and large businesses, and individuals. With a focus on prevention and value, we aim to make quality care accessible to improve the oral health of all.








 Job Description: 







Location: We welcome applicants from anywhere in the U.S.

 At Sun Life, we look for optimistic people who want to make life brighter for our Clients. We understand the value of diverse cultures, perspectives, and identities, and want you to bring your full and authentic self to work. Every day, you’ll be empowered and challenged by working with dynamic colleagues to find new and innovative ways to make Sun Life the best benefits company in America.

 The opportunity:

 Collaborating with operational leads and subject matter experts to develop and implement tactics and strategy for optimizing profitability, clinical performance, member and provider satisfaction and client satisfaction by developing and leveraging analytic tools, financial models and reports, marketing and outreach.
 Is an expert SAS/Python, SQL, Tableau and Excel developer, responsible for presenting recommendations, strategies and findings. Will organize, lead and support efforts to measure, analyze and report on trends enterprise-wide related to provider utilization, reimbursements, access to care, cost management, etc. and identify and promote strategies to positively influence access to quality, cost effective care and improved program performance.
 Works with other areas of the company, including Underwriting, Provider Services, Clinical Management and Client Services to assist in the understanding of provider cost and network trends impacting program costs and profitability and to recommend strategies for improvement wherever possible.


 How you will contribute:

 Working with DentaQuest data to manipulate and analyze data to extract insight, and to develop data science methodologies, and the implementation of actionable finding.
 Use SAS/Python, SQL and other tools to analyze complex business situations and support effort to optimize outcomes measurement, provider optimization, fraud detection, member behavior management.
 Present technical findings and methodologies and present recommendations to senior clients in written and visual presentations.
 Provide mentoring and support to analysts to assist in their development and ability to meet department needs.
 Monitor and track provider reimbursements to identify strategies to ensure access and profitability targets are met in a manner that is consistent with quality, cost effective value-based care.
 Work with other internal departments as necessary to develop strategies and programs to manage dental costs within each market to assure profitability and budgetary goals are met.
 Provide recommendations on department policies, objectives and initiatives. Evaluate and suggest changes as necessary to optimize processes and efficiencies.
 Participate in special projects as needed or requested.
 Adhere to DentaQuest and Business Analytics business processes, SOPs and quality control standards.


 What you will bring with you:

 Bachelor’s degree in Statistics, Computer Science, Math, Finance, Economics or business-related field or equivalent experience.
 5+ years’ experience in data management, analysis and reporting to include experience with combining clinical and financial data.
 Advanced experience with database and business intelligence tools such as SAS, Python, Tableau, MS Report Manager and Report Builder.
 Experience designing and implementing complex algorithms and/or quality metrics.
 Strong foundation in statistical theory and practice required.


 Preferred skills 

Knowledge of health care industry is preferred.
 Strong time management and business process skills.
 Ability work well with others.
 Ability to meet multiple deadlines in a fast-paced environment.

 Do you see yourself in this role even if you haven’t checked all the boxes above? We welcome all talented candidates and are committed to a culture that represents diversity in all forms. If you think you might thrive in this setting, we would love to hear from you.

 Not ready to apply yet but want to stay in touch? Join our talent community to stay connected until the time is right for you!

 Life is brighter when you work at Sun Life

 Excellent benefits and wellness programs to support the three pillars of your well-being – mental, physical and financial – including generous vacation and sick time, market-leading paid family, parental and adoption leave, a partially-paid sabbatical program, medical plans, company paid life and AD&D insurance as well as disability programs and more
 Retirement and Stock Purchase programs to help build and enhance your future financial security including a 401(k) plan with an employer-paid match as well as an employer-funded retirement account
 A flexible work environment with a friendly, caring, collaborative and inclusive culture
 Great Place to Work® Certified in Canada and the U.S.
 Named as a “Top 10” employer by the Boston Globe's “Top Places to Work” two years running


 All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

 If you are a California resident, the salary range for this position is:

 Southern region: $95,200-$142,800 annually 
Central region: $100,400-$150,600 annually 
Northern region: $107,400-$161,100 annually 


If you are a Colorado resident, the salary range for this position is $90,900- $13,400 annually.

 If you are a New York resident, the salary range for this position is $107,400-$161,100 annually.

 If you are Washington resident, the salary range for this position is $100,400-$150,600 annually.

 We consider various factors in determining actual pay including your skills, qualifications, and experience. In addition to salary, this position is eligible for incentive awards based on individual and business performance as well as a broad range of competitive benefits.

 Sun Life Financial is a leading provider of group insurance benefits in the U.S., helping people protect what they love about their lives. More than just a name, Sun Life symbolizes our brand promise of making life brighter -for our customers, partners, and communities. Join our talented, diverse workforce and launch a rewarding career. Visit us at www.sunlife.com/us to learn more.

 At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.

 #LI-remote 

Our Affirmative Action Program affirms our commitment to make reasonable accommodation to the known physical or mental limitation of otherwise-qualified individuals with disabilities or special disabled veterans, unless the accommodation would impose an undue hardship on the operation of our business. Please email recruitingUS@sunlife.com to request an accommodation.

 At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.








 For applicants residing in California, please read our employee California Privacy Policy and Notice.






















 Job Category: 













Advanced Analytics
 







 Posting End Date: 






28/01/2024
 
 All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran
",100400,"['python', 'tableau', 'sql']"
Data Scientist or Senior Data Scientist,Metropolitan Council,MN,Full-time,"


WHO WE ARE


We are the Metropolitan Council, the regional government for the seven-county Twin Cities metropolitan area. We plan 30 years ahead for the future of the metropolitan area and provide regional transportation, wastewater, and housing services. More information about us is on our website.  The Metropolitan Transportation Services (MTS) Division has one (1) vacancy for a Data Scientist. This vacancy may be filled as a Data Scientist or Senior Data Scientist based on the candidates' qualifications and the needs of the business.  We are committed to supporting a diverse workforce that reflects the communities we serve.  Metropolitan Transportation Services conducts planning for the regional transportation system that includes highways, transit, aviation, freight, and bicycle and pedestrian connections. The Metropolitan Council is the region’s federally designated Metropolitan Planning Organization. MTS also provides direct transit service through contracts or partnerships with counties to deliver four major programs: Metro Mobility/ADA, Transit Link dial-a-ride, contracted regular-route bus service, and Metro Vanpool.  How your work would contribute to our organization and the Twin Cities region:  The Data Scientist will support multi-modal transportation planning in the Minneapolis and St. Paul region through innovative approaches to collecting and analyzing transportation data and through the development and application of cutting-edge travel forecasting models and tools. The Data Scientist will join a vibrant travel research and modeling team working on travel demand forecasting, travel behavior surveys, and creative analysis of all kinds of transportation data to drive planning and policy analysis. A Data Scientist will perform work with less supervision, will work on projects with more complexity, and will be involved in project management of small projects or project components. A Senior Data Scientist will perform work independently and will lead projects.  This position is eligible for a hybrid (both remote and onsite) telework arrangement. The candidate's permanent residence must be in Minnesota or Wisconsin.



What you would do in this job




Perform technical, statistical, and analytic tasks that support long-range transportation planning and research on regional transportation issues (for example: emerging transportation modes and technologies, generational changes in travel behavior, and disparities in transportation access).
 Develop visualizations of transportation data and performance measures.
 Develop and apply cutting-edge transportation models that assess the region's future.
 Develop transportation forecasts at the regional, corridor, and project levels.
 Process, clean, and code transportation data.
 Analyze, examine, and visualize spatial information in static and interactive maps.
 Perform geocoding, spatial data manipulation, and spatial data analysis.
 Collaborate with planners, researchers, and policymakers.
 Develop public-facing reports and web-based, interactive data visualization, analysis, and dissemination tools in partnership with internal and external partners.
 Respond to requests for data and information, including requests from the media, other Council staff, or local partners, by summarizing data in a clear, coherent manner.
 Be a contributory team member in a multi-disciplinary team.
 Make presentations to the Transportation Committee, and other Council advisory and technical committees as needed.
 Review scholarly articles and technical papers in academic and industry databases/journals.
 Promote a culture of creativity, life-long learning, and continuous improvement.
 Promote a culturally diverse and inclusive work environment that advances racial equity.




What education and experience are required for this job (minimum qualifications)


Data Scientist Any of the following combinations of experience (with statistical modeling and/or developing web-based interactive data visualization tools) and completed education (degree field of study in Mathematics, Analytics, Data Science, or related field):


 High School Diploma or GED and seven (7) years of experience
 Associate's degree and five (5) years of experience
 Bachelor's degree and three (3) years of experience.


 Senior Data Scientist
 Any of the following combinations of experience (with statistical modeling and/or developing web-based interactive data visualization tools) and completed education (degree field of study in Mathematics, Analytics, Data Science, or related field):
   

 High School Diploma or GED and eight (8) years of experience
 Associate degree and six (6) years of experience
 Bachelor's degree and four (4) years of experience


 What additional skills and experience would be helpful in this job (desired qualifications
):


Data Scientist level

 Demonstrated ability in performing and communicating data analysis and statistical modeling of transportation data.
 Experience working with travel demand models.
 Experience in programming and modeling languages (R or Python preferred)
 Experience in data mining, passive and or 'big' data, structured, unstructured, and semi-structured data.
 Experience working and collaborating in diverse, multicultural, and inclusive environments.

 Senior Data Scientist Level

 Project Management Skills
 Ability to Present Work to peers, and to technical and policy committees.
 Knowledge of regional transportation planning and how to apply data science principles to support this work.
 Skill in applying knowledge of institutional racism and the historic and continuing disparities in communities of color to one’s work in the data science field.

 What knowledge, skills, and abilities you should have within the first six months on the job
:

 Knowledge of statistical analysis techniques (regression analysis, survival analysis, time-series modeling, etc.)
 Knowledge of database systems design and maintenance
 Knowledge of web-based interactive tool development
 Knowledge of computer programming (i.e. R, Python)
 Knowledge of passive transportation (i.e. Streetlight Data) and transportation survey data
 Skills in applied mathematics and statistics
 Skills in Data visualization (i.e. 'ggplot2' package in R, Shiny, Tableau, Dash/Plotly in Python)
 Skills in version control and collaboration in Git
 Skills in data mining with structures, unstructured, and semi-structured data
 Skills in GIS/Spatial analysis (i.e. ArcGIS, QGIS, ArcPy, Geopandas)
 Ability to read and understand complex academic and technical papers.
 Ability to write summary reports, technical papers, and literature reviews.
 Ability to synthesize technical information in a useable way that facilitates good policy and planning decisions.
 Ability to plan workflow and prioritize work tasks.
 Ability to establish and maintain effective working relationships with internal and external stakeholders.
 Ability to exercise sound professional judgment and to promote an equitable, positive, and respectful professional environment.

 What you can expect from us:

 We offer the opportunity to make a difference and positively influence the Twin Cities metropolitan area.
 We encourage our employees to develop their skills through on-site training and tuition reimbursement.
 We provide a competitive salary, excellent benefits, and a good work/life balance.
 More about why you should join us!
  


Additional information


Data Scientist Union/Grade: AFSCME/Grade G FLSA Status: Exempt Safety Sensitive: No Full Salary Range: $34.70 - $52.36 hourly / $72,176 - $108,909 annually  Senior Data Scientist Union/Grade: AFSCME/Grade H FLSA Status: Exempt Safety Sensitive: No Full Salary Range: $37.50 - $56.60 hourly / $78,000 - $117,728 annually  Work environment: Work is performed in a standard office setting.  What steps the recruitment process involve:


 We review your minimum qualifications.
 We rate your education and experience.
 We conduct a structured panel interview.
 We conduct a selection interview.
 Once you have successfully completed the steps above, then:
   

If you are new to the Metropolitan Council, you must pass a background check that verifies education, employment, and criminal history. A driving record check and/or physical may be conducted if applicable to the job. If you have a criminal conviction, you do not automatically fail. The Metropolitan Council considers felony, gross misdemeanor, and misdemeanor convictions on a case-by-case basis, based on whether they are related to the job and whether the candidate has demonstrated adequate rehabilitation.
   

If you are already an employee of the Metropolitan Council, you must pass a criminal background check if the job you're applying for is safety-sensitive, is a supervisory or management job, is in the Finance, Information Services, Audit, or Human Resources departments, or has access to financial records, files/databases, cash, vouchers or transit fare cards. A driving record check and/or physical may be conducted if applicable to the position.
   
 IMPORTANT: If you make a false statement or withhold information, you may be barred from job consideration.
   

The 
Metropolitan Council is an Equal Opportunity
, Affirmative Action, and veteran-friendly employer. The Council is committed to a workforce that reflects the diversity of the region and strongly encourages persons of color, members of the LGBTQ community, individuals with disabilities, women, and veterans to apply. If you have a disability that requires accommodation during the selection process, please email HR-OCCHealth@metc.state.mn.us.








We believe our employees are a key to our agency's success! In order to attract and retain high quality employees, the Council provides a highly competitive benefits package both in choice and coverage levels. Some highlights about our benefits are listed below: 

Guaranteed monthly retirement income through Minnesota State Retirement System pension fund
Opportunity to save additional funds for retirement on a tax-deferred basis through a voluntary deferred compensation (457) plan
Two or more medical plans from which to choose, with employer contribution towards premiums over 80%
Dental insurance, life insurance and vision insurance
The following benefits are provided to all employees as part of working for the Council. You will have access to free:
   
Well@Work clinic
bus/rail pass valued at over $1200 per year
parking at many job locations
fitness centers at many job locations
Employee Assistance Program
extensive health and wellness programs and resources




",78000,"['python', 'tableau', 'git']"
Data and Quality Supervisor - Research Scientist Supervisor 2,State of Minnesota,MN,Full-time,"



Job Details





Working Title: Data and Quality Supervisor Job Class: Research Scientist Supervisor 2 Agency: Health Department

Who May Apply: Open to all qualified job seekers
Date Posted: 11/15/2023
Closing Date: 12/06/2023
Hiring Agency/Seniority Unit: Health Department / Health-MMA
Division/Unit: Public Health Laboratory / PHL NBS Qual/Data Staff
Work Shift/Work Hours: Day Shift / 8:00 am - 4:30 pm
Days of Work: Monday - Friday
Travel Required: No
Salary Range: $36.72 - $52.79 / hourly; $76,671 - $110,225 / annually
Classified Status: Classified
Bargaining Unit/Union: 216 - Middle Management Association/MMA
FLSA Status: Exempt - Executive
Telework Eligible: No
Designated in Connect 700 Program for Applicants with Disabilities: Yes

 Make a difference in the lives of Minnesotans.
 The work you’ll do is more than just a job. Join the talented, engaged and inclusive workforce dedicated to creating a better Minnesota.






 Job Summary





Join the mission-driven team at the Public Health Laboratory and promote and protect the health of all Minnesotans! The purpose of the Data and Quality Supervisor is to provide management, direction, and leadership for the Data and Quality unit in the Newborn Screening Section at the Public Health Laboratory. The incumbent will represent MDH in public forums, including presentations at conferences and, when necessary, engagement with local and national media.
 The position leads all activities in the collection, analysis, and transmission of data; retention and management of records; as well as regulatory and quality system compliance. 
These leadership activities include:

Directs and prioritizes all staff activities. 
Investigates, evaluates, and implements processes to continually improve newborn screening data use and quality system. 
Incorporates continuous quality control/quality assurance measures.
Researches and applies statistics and data analytics in the determination of program performance.
Collaborates with key newborn screening stakeholders. 

All positions within the MDH Public Health Lab will work to cultivate an inclusive work environment for all, with respect to diversity and equity.






 Qualifications



Minimum Qualifications
 Experience in these areas must be clearly stated on your resume to be considered.

Supervisory or other leadership experience OR completion of a leadership development program (such as Emerging Leaders Institute, etc.)
3 years of experience with data management, analytic methods, or records management systems.
Experience in Newborn Screening

 Previous experience and understanding below is required to be considered a candidate and will be assessed during the interview process:

Knowledge of best practices for data visualizations
Experience working with a LIMS (laboratory information management system)
Knowledge of health information technology trends, requirements, and standards
An understanding of national privacy standards (i.e., HIPAA) as they pertain to conduction of Newborn Screening in the State of Minnesota to confirm program compliance
Understand diversity, equity, and inclusion principles, and how they can be applied in the workplace to promote an inclusive work environment for all

 Preferred Qualifications

An understanding of Minnesota Statutes 144.125-128 and 13.3805, Minnesota Rules 4615.0300-4615.0700
Knowledge of MDH record retention schedule and applicable statutes
Experience with newborn hearing screening, heart screening, and bloodspot testing for diseases in newborns
Experience working with quality for a laboratory and knowledge of CMS and CLIA regulations
Experience working with Tableau and creating data visualizations and dashboards
Experience performing internal audits for a laboratory

 Additional Requirements
 This position requires successful completion of a background check.






 Application Details



How to Apply 
Select “Apply for Job” at the top of this page. If you have questions about applying for jobs, contact the job information line at 651-259-3637 or email careers@state.mn.us. For additional information about the application process, go to http://www.mn.gov/careers. 
If you have questions about the position, contact Elizabeth Huckins at elizabeth.huckins@state.mn.us or 651-201-5609. 
To receive consideration as a Connect 700 Program applicant, apply online, email the Job ID#, the Working Title and your valid Proof of Eligibility Certificate by the closing date to Elizabeth Huckins at elizabeth.huckins@state.mn.us. 
About Health Department 
Come work for one of the best public health systems in the nation and you will contribute to our mission to protect, maintain and improve the health of all Minnesotans. We are working hard to achieve our vision for health equity in Minnesota, where all communities are thriving and all people have what they need to be healthy. 
Why Work for Us 
Diverse Workforce 
We are committed to continually developing a workforce that reflects the diversity of our state and the populations we serve. The varied experiences and perspectives of employees strengthen the work we do together and our ability to best serve the people of Minnesota. 
A recent engagement survey of State of Minnesota employees found: 

95% of employees understand how their work helps achieve their agency’s mission 
91% of employees feel trusted to do their jobs 
88% of employees feel equipped to look at situations from other cultural perspectives when doing their job 
87% of employees report flexibility in their work schedule 

Comprehensive Benefits 
Our benefits aim to balance four key elements that make life and work meaningful: health and wellness, financial well-being, professional development, and work/life harmony. As an employee, your benefits may include: 

Public pension plan 
Training and professional development 
Paid vacation and sick leave 
11 paid holidays each year 
Paid parental leave 
Low-cost medical and dental coverage 
Prescription drug coverage 
Vision coverage 
Wellness programs and resources 
Employer paid life insurance 
Short-term and long-term disability 
Health care spending and savings accounts 
Dependent care spending account 
Tax-deferred compensation 
Employee Assistance Program (EAP) 
Tuition reimbursement 
Federal Public Service Student Loan Forgiveness Program 

Programs, resources and benefits eligibility varies based on type of employment, agency, funding availability, union/collective bargaining agreement, location, and length of service with the State of Minnesota. 

AN EQUAL OPPORTUNITY EMPLOYER 
Minnesota state agencies are equal opportunity, affirmative action, and veteran-friendly employers. The State of Minnesota recognizes that a diverse workforce is essential and strongly encourages qualified women, minorities, individuals with disabilities, and veterans to apply. 
We will make reasonable accommodations to all qualified applicants with disabilities. If you are an individual with a disability who needs assistance or cannot access the online job application system, please contact the job information line at 651-259-3637 or email careers@state.mn.us and indicate what assistance is needed.




",73440,['tableau']
Data Manager II,DLH Corp,US,Full-time,"
 About Us: 
 
   DLH delivers improved health and national security readiness solutions for federal programs through science research and development, systems engineering and integration, and digital transformation. Our experts in public health, performance evaluation, and health operations solve the complex problems faced by civilian and military customers alike by leveraging advanced tools – including digital transformation, artificial intelligence, data analytics, cloud enablement, modeling, and simulation, and more. With over 3,200 employees dedicated to the idea that “Your Mission is Our Passion,” DLH brings a unique combination of government sector experience, proven methodology, and unwavering commitment to innovation to improve the lives of millions.
  Overview: 
 
   The project is a comprehensive, nationally representative health survey designed to assess the health and wellness of individuals across the country. Beyond traditional questionnaires and interviews, this survey incorporates biospecimen collection, allowing for a more in-depth analysis of participants' health. Participants will provide biological samples, such as blood, saliva, or urine, which will be meticulously analyzed to understand various physiological, genetic, and biochemical markers. This combination of survey data and biospecimen analysis aims to offer a holistic view of the nation's health, identifying trends, risk factors, and areas of concern.
 


 The Data Manager II: Performs requirements gathering, design, coordination, and testing for reporting and analytic projects/tasks. Assists Project Manager in the development of project plans. Collaborates with business process owners, technical staff and project manager to leverage the use of data and data strategies across business/operational needs. May participate in feasibility studies to assess cost/benefit, efficiency and technical viability of solutions to business problems. Provides necessary data elements and business knowledge to support the design and development of data models. Employs data warehouse analysis and design experience, with knowledge of data warehouse methodologies and data modeling.
  Responsibilities: 
 
Develop, revise, test and perform quality control of programs for a variety of analytic and operational projects.
 Apply data analysis or data modeling techniques to establish, modify or maintain complex data structures.
 Test and validate databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
 Interpret data, analyze results using statistical techniques and provide ongoing reports.
 Acquire data from primary or secondary data sources and maintain databases/data systems.
 Perform complex database analysis to help answer business questions and drive organizational performance.
 Identify, analyze, and interpret trends or patterns in complex datasets.
 Filter and clean data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems.
 Construct codebooks and format files.
 Format tables and compiling reports.
 Produce graphical output.
 Assist with the design and implementation of high impact analytical and predictive modeling initiatives.
 Contribute to the development and implementation of data management plans.
 Comply with federal regulations, client guidelines, corporate SOPs, and project work instructions related to data management.
 Performs other duties as assigned.
 Complies with all policies and standards.


 Basic Compensation: $74,000.00- $78,000.00/yr
 

   The salary offered within this range will be based on the selected candidates skills, experience, education, market data, and internal parity. DLH may offer other rewards that may include performance incentives and program-specific awards. An applicant’s salary history will not be used to determine compensation.
 


 #LI-REMOTE
 

 Qualifications: 
 
 Education:


  Bachelor Degree in Computer Sciences or related technicial field of study (or equivalent).
 


 Experience:


  Two (2) years SAS or R for data management, which includes writing programs for cleaning and reporting of study data as well as generating analytical datasets. (Preferred)
 



 Knowledge of other software such as STATA, REDCap, Qualtrics, or Python.
 Strong knowledge of relational databases and electronic data capture systems is highly desirable.
 Strong verbal and written communication skills.
 Problem solving skills that demonstrate an ability to apply a data driven approach.
 Attention to detail to ensure data accuracy and to identify anomalies.
 Good teamwork and collaboration skills.
 Benefits: 
 
   DLH Corp offers our employees an excellent benefits package including - Personal Time Off (PTO), medical, dental, vision, supplemental life with AD&D, short and long-term disability, flexible spending accounts, parental leave, legal services and more. We want our employees to save for their future, therefore we offer a 401(k) Retirement Plan, which includes a matching component. DLH is dedicated to your career development, providing training to help drive success, with access to our best-in-class e-Learning suite for formal and informal learning, professional and technical certification preparation, and education assistance at accredited institutions.
  EEO: 
 
   DLH Corporation is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
 
",74000,['python']
Artificial Intelligence Engineer,DJ0 - TheCRM,CA,Full-time,"Responsibilities:- Develop and maintain business intelligence solutions using various tools and technologies- Collaborate with stakeholders to gather requirements and understand business needs- Design, develop, and implement data models, data warehouses, and ETL processes- Create and optimize SQL queries for data extraction and analysis- Develop reports, dashboards, and visualizations to present data insights- Perform data analysis to identify trends, patterns, and anomalies- Implement data quality measures to ensure accuracy and reliability of data- Stay up-to-date with the latest trends and advancements in business intelligence technologies
Skills:- Proficiency in TensorFlow, SAS, VBA, AI, AWS, Big Data, Natural Language Processing, and Machine Learning- Strong analytical and problem-solving skills- Experience with data modeling and database design concepts- Proficiency in SQL for data extraction and manipulation- Familiarity with ETL processes and tools- Knowledge of data visualization tools such as Tableau or Power BI- Understanding of statistical analysis techniques- Excellent communication skills to effectively collaborate with stakeholders
Note: This job description is not intended to be all-inclusive. The employee may perform other related duties as negotiated to meet the ongoing needs of the organization.
Job Type: Full-time
Pay: $117,295.00 - $125,197.00 per year
Benefits:

Dental insurance
Health insurance
Paid time off

Experience level:

2 years

Schedule:

Monday to Friday

Work Location: In person",117295,"['tensorflow', 'machine learning', 'tableau', 'aws', 'etl', 'sql']"
ML Engineer (Entry Level),Grindr,CA,Full-time,"
This is a hybrid role based in our Chicago or SF offices and will require you to be in office Tuesdays and Thursdays.
 What's so interesting about this role?
 We at Grindr believe that AI can revolutionize the dating industry. Our Machine Learning Engineer is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this role, you will be working directly with the Director of AI to build an end to end pipeline of ML model development including data exploration, transformation, feature engineering, model development, experimentation and deployment.
 What's the job?
 We're looking for an exceptional Machine Learning engineer who is passionate about data for AI and values it can bring to Grindr, Who loves working with data at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines, data transformation and model development.
 Responsibilities:

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling
Be self-motivated in seeking solutions when the correct path isn't always known
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders
Research and evaluate new technologies in the big data space to guide our continuous improvement
Be a fast learner and courageous to go out of your comfort zone.
Help our ML team with data analysis, data engineering, ML model development and deployment.
Collaborate with multi-functional teams to help tune the performance of large data applications

What we'll love about you

Masters in Computer Science, Mathematics, Economics, Physics, or a related fields
Experience in statistical analysis & visualization on datasets using Pandas or R
Excellent coding skills in Python, SQL, Pandas/R
Very good understanding of Probability & Statistics
Good foundation in linear algebra
Good understanding of classical machine learning concepts

We'll really swoon if you have

Understanding of Deep Learning concepts
Experience in working with Deep Learning frameworks (ie., Pytorch, Tensorflow, Keras)
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark)
Experience with any public cloud environment - AWS, GCP or Azure
SiExperience with distributed systems and microservices
Experience with Kubernetes and building Docker images
Strong understanding of applied machine learning topics

What you'll love about us


Mission and Impact: Grindr is the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world
We are hiring someone for this role to be based ideally in San Francisco or Chicago
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events

About Grindr
 Grindr is the world's largest dating app for gay, bi, trans, and queer people. With around 13 million monthly active users, Grindr has become a fundamental part of the global LGBTQ community, and we take pride in empowering our users to connect, express themselves, and discover the queer world around them.
 Our next evolution is underway as a newly public company looking to expand and continue to build meaningful experiences for our users. From social issues to original content, we're blazing innovative paths with impact for our community, all while leveraging the latest tech stacks and striving for engineering excellence. At the heart of our work in this new chapter is a shared set of core values: openness and exploration, a bias for action, and strong support of the LGBTQ community.
 With a track record of strong financial performance and plans for continued headcount growth, we're looking to build a team of talented, passionate, and open-minded people who believe in our mission, align with our values, and are excited to work at the intersection of innovative technology and social impact. Come be a part of this exciting journey with us. 
Grindr is an equal-opportunity employer
 To learn more about how we handle the personal data of applicants, visit our Employee and Candidate Privacy Policy.


 #LI-Hybrid



 Grindr is committed to fair and equitable compensation practices. This base pay range is for the U.S. and is not applicable to locations outside of the U.S. The actual base pay is dependent upon many factors, such as training, transferable skills, work experience, business needs, location, and market demands. The base pay range is subject to change and may be modified in the future. This role will also be eligible for equity, benefits, and a company bonus program.

 Base Pay Range

    $130,000—$220,000 USD
  

",130000,"['tensorflow', 'pytorch', 'python', 'pandas', 'machine learning', 'deep learning', 'aws', 'azure', 'docker', 'gcp', 'sql', 'airflow', 'pyspark']"
Head Data Scientist,Resource Innovations,CO,Full-time,"
Resource Innovations is seeking a Head Data Scientist to join our growing team preferably in Louisville, Colorado (USA), or Toronto, Ontario (Canada), however, other locations within the United States or Canada will be considered. As the Head Data Scientist with Resource Innovations, you will be responsible for providing technical oversight and project management, while driving team growth, and team development for the Advisory Services business unit. 
This position is responsible for identifying, architecting, and deploying analytical solutions for our utility, software, and energy efficiency delivery teams. As a result, the ideal candidate will have significant experience at the intersection of programming, statistical modeling, and software development. This is a highly collaborative position and the candidate must be self-directed and comfortable supporting the analytical needs of multiple teams, systems, and products.
 Specific responsibilities will include supporting: hiring/team growth, team development, processes, and resource planning, as well as project management and delivery of on-time and under budget services. 
Candidates with more than 7 years of related work experience are encouraged to apply. 
Resource Innovations (RI) is a women-led energy transformation firm focused on impact. Building on our expertise in energy efficiency, we’re constantly expanding our portfolio of clean energy solutions to guide utilities through increasingly complex, connected challenges. Load flexibility. Electrification. Carbon reduction. With every step, we’re leading the charge to power change.
 Duties and Responsibilities

Use knowledge of utility data, organizations and priorities to advise clients on data-driven solutions to operational needs, regulatory mandates, and customer outreach.
Leverage knowledge of the electricity and gas sector to select appropriate statistical and technical approaches to client challenges.
Prepare reports, presentations, tools, and proposals explaining technical analytical methods and results to both technical and non-technical audiences.
Familiarity with the full data science stack, with a focus on machine learning, data visualization and communication of complex results to a variety of audiences
Write production-level machine learning pipeline code
Create and provide guidance on solution architectures including integration with Amazon Web Services (AWS) and /or Azure.
Project manage and/or support teams to deliver high quality analysis while remaining on time and on budget.
Take initiative to validate and troubleshoot data and statistical models.
Coach junior staff to develop their data science skills.
Define hiring needs, and support recruiting, hiring, and onboarding of new team members.
Lead meetings, conference calls, and email exchanges with clients
Track energy industry trends and emerging issues
Other duties as assigned.

Requirements

A Bachelors degree in a quantitative field is required; a Master’s Degree is strongly preferred.
A minimum of 7+ years of work experience in one or more of the following disciplines: data science, economics, statistics, public policy with a quantitative focus, or computer science
Experience performing advanced customer data analytics, including propensity modeling and high frequency consumption data analysis
Substantial work experience in the energy and utilities sector
Practical experience in machine learning, applied econometrics and/or statistical program evaluation
Real world experience scraping and/or munging large data sets
Significant programming experience using R, Python and SQL to build and deploy regression, classification, and other statistical models.
Experience building machine learning pipelines.
Strong written and oral communication skills
Experience with model selection and validation methods
Strong data visualization skills
Understanding of relational databases and basic architectural principles
Preferred Qualifications
Experience with AWS and/or Azure to deliver data-driven solutions.
AWS certifications are highly preferred.
Experience using Tableau or other data visualization software
Familiar with the use of version control (e.g. git/GitHub)
Project management experience, including supervising junior staff and tracking budgets and deliverables, preferably in a consulting or client-facing environment.

Benefits
 Resource Innovations offers competitive salaries based on candidate's qualifications. Resource Innovations also offers three weeks paid vacation per year, paid holidays, a 401(k) plan with employee matching funds, a discretionary bonus and an overall comprehensive benefits package.
 About Resource Innovations Resource Innovations (RI) is a women-led energy transformation firm focused on impact. Building on our expertise in energy efficiency, we’re constantly expanding our portfolio of clean energy solutions to guide utilities through increasingly complex, connected challenges. Load flexibility. Electrification. Carbon reduction. With every step, we’re leading the charge to power change.
 Resource Innovations is an Equal Opportunity Employer, committed to ensuring equal employment opportunities for all job applicants and employees without regard to race, color, religion, national origin, gender, age, disability, marital status, genetics, protected veteran status, sexual orientation, or any other protected status. In addition to federal law requirements, Resource Innovations complies with applicable state and local laws governing non-discrimination in employment in every location in which the company does work.
 The above job description and job requirements are not intended to be all inclusive. Resource Innovations retains the right to make changes or adjustments to job descriptions and/or job requirements at any time without notice.
 The compensation range for this exempt position is $120000- $220000. The stated range is based on a good faith estimate of the compensation range for the duties, responsibilities and skills / experience required for the position. Starting pay will be dependent on experience and internal equity. This provided range may exceed this range for well-qualified candidates, especially with industry experience.
",170000,"['python', 'machine learning', 'tableau', 'aws', 'azure', 'sql', 'git']"
Senior Data Analyst (Business Intelligence Analyst),TRILLIUM HEALTH RESOURCES,NC,Full-time,"

Pay Plan Title: Senior Data Analyst
 

 Working Title: Business Intelligence Analyst
 

 FLSA Status: Exempt
 

 Posting Salary Range: $51,500 - $73,166
 

 Office Location: Remote with offices available in Greenville, NC and Wilmington, NC
 

 POSTING DETAILS:
 Make an Impact
 Trillium Health Resources is a local governmental agency (LME/MCO) in North Carolina that manages serious mental health, substance use, and intellectual/developmental disability services. Serving in 28 counties, we help individuals and their families strengthen well-being and build foundations for a healthy life.
 Join our team as we empower others to live their best lives by providing access to quality healthcare. We offer a challenging, engaging work environment where staff take home more than a paycheck. Every day, we see the results of our dedication – in the smiles of children on our accessible playgrounds and in the pride on the face of an adult cooking a meal for the first time. Working at Trillium Health Resources is more than just a job; it is an opportunity to make a direct impact on the communities we serve.
 At Trillium, we know that empowering others begins with supporting and developing our team. That’s why we offer competitive benefits and work-from-home flexibility so that our employees thrive outside of the office. We’re also committed to building a diverse, inclusive culture where all employees have the potential to grow professionally and personally.
 What We’re Looking For
 We’re seeking a Business Intelligence Analyst who wants to grow their IT career by helping us conduct data analysis activities for Trillium. You’ll work directly with team members from all parts of our organization to assure compliance with the DMH and DMA contract requirements as well as other external and internal reporting needs. The Business Intelligence Analyst is responsible for the validation of data collected and ensuring data integrity. You’ll be a valued member of the Informatics Data Report
 On a typical day, you might:

 Ensure that data from reports are presented in a user-friendly format and made accessible to staff, consumers and community members.
 Analyze and report statistical data on populations, disabilities and cultural factors.
 Provide technical assistance to other Trillium department staff or provider agencies regarding data collection, analysis, and reporting.
 Use SQL and various analytical programs such as R, SPSS, or Python for analysis of data.
 Uses KACE and Team Foundation Server (TFS) to respond to organizational requests, document and track progress, and maintain version control of reports and code

 Employee Benefits:
 Trillium knows that work/life balance is important. That’s why we offer our employees competitive benefits and flexibility that is second to none. Take a look at what we have to offer:

 Flexible Work Schedules. Remote work was a strong part of our culture prior to COVID-19, and currently, employees may work remotely 100% of the time, with an in-office option available for those who prefer that.
 Paid Time Off (PTO) of 23 days per year, plus 10 paid holidays both in first year of employment
 Health Insurance - no premium for employee coverage
 NC Local Government retirement pension. This is a defined-benefit retirement plan that will pay you a monthly amount upon retirement, for the rest of your life, with as little as five years of service. For more information, go to:

 https://files.nc.gov/retire/documents/files/Actives/LGERSHandbook.pdf

 401k with 5% employer match & immediate vesting
 Public Service Loan Forgiveness Qualifying Employer
 Flexible Spending Accounts

 Qualifications:
 Education: Associate’s Degree OR, Based on required experience / Bachelor’s Degree

 Required Experience: Associate’s degree in Information Technology, Actuarial/ Statistics, Data Analytics, Business, or Human Service field (such as Psychology, Social Work, etc.) and four (4) years’ experience in Information Technology, Actuarial/ Statistics, Data Analytics, Business, Human Service field (such as Psychology, Social Work, etc.).
 

   OR
 

   Bachelor’s degree in Information Technology, Actuarial/ Statistics, Data Analytics, Business, or Human Service field (such as Psychology, Social Work, etc.) and a minimum two (2) years’ experience in Information Technology, Actuarial/ Statistics, Data Analytics, Business, Human Service field (such as Psychology, Social Work, etc.).
 

   OR
 
 Equivalent combination of education/experience
 License/Certification: None Identified
 Preferred License/Certification (if applicable): CSPA, Certified Machine Learning – Specialty (AWS), Predictive Analytics Certificate (SOA), and/or CAHIMS, ITIL v3 or equivalent certifications preferred
 Must have a valid driver’s license
 Remote with office locations available in Greenville or Wilmington, NC
 Deadline for application: Posting closed on Wednesday, November 22, 2023 at 11:59 p.m.
 To be considered for employment, all candidates are required to submit an application through ADP and upload a current resume. Your resume must provide your level of education and detailed work experience, including:

 Employer Name
   
 Dates of service (month & year)
 Average number of hours worked per week
 Essential duties of the job as related to the position you’re applying for

 Education
   
 Degree type
 Date degree was awarded
 Institution

 Licensure/certification, if applicable

 After submitting your application through our career center in ADP, your resume will be reviewed to ensure that your skills and experience meet the essential criteria for the role you have applied for.
 Join our Talent Community through our ADP career center to stay informed about positions you may qualify for. Remember to keep an update resume in the Talent Community profile.
 The diversity of the communities we serve is reflected in our employees. Trillium Health Resources is an Equal Employment Opportunity (EEO) employer.
 Trillium Health Resources is a drug-free workplace. Candidates are required to pass a drug test as a condition of employment.
 #Innovation #Technology #Careers #NorthCarolina #BehavioralHealth
",51500,"['python', 'machine learning', 'aws', 'sql']"
Senior Staff AI Data Engineer,Recruiting From Scratch,FL,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
AI Engineer,Mach Industries,TX,Full-time,"
Mach Industries is a defense technology company with a mission to create better defense systems for the US and its allies, fueled by hydrogen. With a vertically integrated energy chain, we offer capabilities impossible with conventional methods. Our innovative approach and commitment to advanced technology are transforming military capabilities.

 Role Summary:
 The AI Engineer will be instrumental in the research, development, and deployment of cutting-edge artificial intelligence algorithms to enhance the performance, safety, and reliability of our hydrogen-powered weapons systems, including drones, guns, and balloons. This role demands a profound understanding of AI and machine learning technologies, coupled with a deep interest in the defense sector, to propel our company into new frontiers of innovation.
 Key Responsibilities:

 AI Research and Development: Conduct research to develop state-of-the-art AI and machine learning algorithms tailored for hydrogen-powered defense systems.
 Model Training and Validation: Build, train, and validate machine learning models to ensure they meet the specific requirements of our unique weapons systems.
 Optimization and Scalability: Work to optimize AI algorithms for real-time decision-making and scalability across diverse hardware platforms.
 Security Compliance: Ensure AI technologies are developed and deployed in accordance with military and industry-specific cybersecurity standards.
 System Integration: Collaborate with Hardware and Software Engineering teams to seamlessly integrate AI capabilities into existing and future products.
 Data Management: Develop robust data pipelines for training and evaluating machine learning models, including data collection, cleaning, and preprocessing.
 Algorithm Auditing: Conduct thorough audits of machine learning models to verify performance metrics, ethical considerations, and safety protocols.
 Cross-Functional Communication: Effectively communicate the impact and benefits of AI technologies to non-technical stakeholders within and outside the company.
 Documentation and IP: Maintain rigorous documentation for developed algorithms and contribute to the intellectual property portfolio of the company.
 Quality Assurance: Establish best practices for AI development to ensure high-quality, reliable, and safe deployment of algorithms.

 Qualifications:

 Minimum of 5 years experience in AI engineering, machine learning, or a closely related field.
 Expertise in programming languages such as Python, C++, or Java.
 Strong proficiency in machine learning libraries and frameworks like TensorFlow, PyTorch, or scikit-learn.
 Experience with big data technologies like Hadoop, Spark, or similar.
 Familiarity with military and industry-specific cybersecurity standards.
 Bachelor's or Master's degree in Computer Science, Artificial Intelligence, or a related field.

 Ideal Candidate:
 An innovative thinker possessing both a deep technical expertise in AI and a passion for defense technology. The ideal candidate is highly collaborative and comfortable working in a fast-paced, Skunkworks-inspired environment, and has a track record of developing and deploying AI solutions that are both pioneering and practical.

 Disclosures
 This position may require access to information protected under U.S. export control laws and regulations, including the Export Administration Regulations (EAR) and the International Traffic in Arms Regulations (ITAR). Please note that any offer for employment may be conditioned on authorization to receive software or technology controlled under these U.S. export control laws and regulations without sponsorship for an export license.
 The salary range for this role is an estimate based on a wide range of compensation factors, inclusive of base salary only. Actual salary offers may vary based on (but not limited to) work experience, education and training, critical skills, and business considerations. Highly competitive equity grants are included in most offers and are considered part of Mach’s total compensation package. Mach offers benefits such as health insurance, retirement plans, and opportunities for professional development.
 Mach is an equal opportunity employer committed to creating a diverse and inclusive workplace. All qualified applicants will be treated with respect and receive equal consideration for employment without regard to race, color, creed, religion, sex, gender identity, sexual orientation, national origin, disability, uniform service, Veteran status, age, or any other protected characteristic per federal, state, or local law, including those with a criminal history, in a manner consistent with the requirements of applicable state and local laws. If you’d like to defend the American way of life, please reach out!
 Compensation Range: $80K - $180K
",80000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'hadoop']"
Data Scientist (W2 role),Techsara solutions,TX,Full-time,"Job Title: Data Scientist
Client: Citi
Location: Tampa, FL or Irving, TX (Hybrid)
W2 role (USC & GC)
Overview:The Data Scientist must be able to work with large and complex data sets to evaluate, recommend, and support the implementation of business strategies. The ideal candidate has experience in solving analytical problems using quantitative approaches with a passion for data & statistics.
Responsibilities:

Mine and analyze large sets of data
Identify gaps and opportunities for improvement
Leverage this data to develop strategic roadmaps
Define and deploy metrics for measuring process improvement
Institute feedback models to enable continuous process improvement
Conduct research and publish artifacts to drive simplification
Review / Author operational procedures
Distill information provided by subject matter experts and other partners into executive-level narratives
Establish foundational and execution work streams for process improvement and automation initiatives
Partner with Domain and Technical architecture teams to drive efficiency

To be effective in this role, the candidate should possess the following:5-8 years of Data Analysis, or relevant experience with at least 2 years as a Data Scientist.Knowledge and experience of a variety of exploratory data analysis, predictive modelling, anomaly detection and their real-world advantages/drawbacks.

Experience using statistical computer languages like Python, R, etc.
Working to deep knowledge of financial products and automation solutions
Machine learning experience is a plus
Experience in predictive model a/b testing and training models
Experience in complex data extraction techniques and data cleansing methodologies
Ability to deconstruct descriptive data into meaningful categories for predictive modeling and visual analysis.
Responsible for documenting data requirements, data collection / processing / cleaning, and exploratory data analysis; which may include utilizing statistical models / algorithms and data visualization techniques
Identifies and compiles data sets using a variety of tools (e.g. SQL, Access) to help predict, improve, and measure the success of key business to business outcomes
Experience in all the phases of a software development lifecycle project including requirements gathering, analysis, design, and implementation through agile and/or waterfall and/or hybrid methodologies
Excellent problem-solving skills, including the ability to grasp new concepts quickly, lead diverse partners toward reasonable recommendations, and prepare decisions in a logical fashion with supporting impact, to aid in timely decision making
Ability to develop and manage a comprehensive program plan and dependencies
Intellectually curious, consistently seeking and developing new opportunities
Self-starter, with an ability to lead and execute work with limited to no supervision
Ability in strategic thinking and the ability to frame business problems
Excellent written and verbal communication skills; must be able to understand detailed problem resolution discussions and condense pertinent facts for senior leadership
Experienced with data visualization tools a plus

Job Type: Contract
Pay: $60.00 - $74.00 per hour
Work Location: In person",120000,"['python', 'machine learning', 'sql']"
Director of Data Science,National Funding,CA,Full-time,"
Director of Data Science - San Diego, CA
Hybrid 3 days/week, Full time M-F 8am-5pm PST
Being authorized to work in the U.S. is a precondition of employment.
National Funding does not consider candidates requiring 1099 or C2C.
Exempt/Salary: $130,000-$230,000 + Bonus
National Funding is is seeking an experienced and dynamic professional to join us as the Director of Data Science. This leadership role will drive the strategic utilization of statistical and machine learning techniques, leading model development initiatives for our Small Lending business. The successful candidate will manage a team of 4-6 model developers, overseeing the entire modeling life cycle, including development, implementation, use, and monitoring.
Responsibilities:
Model Development and Performance:

Spearhead the creation and optimization of Marketing, Credit, and custom score models, along with associated processes, systems, and ML Ops.
 Formulate and execute Generative AI and LLM strategies across all facets of the company, from Data Science to Operations.

Collaboration and Communication:

Foster effective communication and collaboration with cross-functional teams, including Marketing, Credit, Sales, Finance, Tech, and Product, ensuring alignment in strategy, model governance, risk, and technology.

Team Leadership and Management:

Lead day-to-day operations of the Data Science team, providing guidance, coaching, and project management.
 Drive the creation and execution of custom models, processes, and systems.
 Manage projects of varying complexity, from conceptualization to business requirements, project plans, and successful execution.

Special Projects and Documentation:

Oversee special requests and projects, meticulously documenting processes, and procedures.

Experience:

Minimum 5-7 years of work experience, including 3-5 years in a managerial capacity.
 Proven expertise in designing, building, and deploying production-quality models using statistical/ML techniques.
 Deep experience in creating, monitoring, and improving custom ML scorecards.
 Proficiency in SQL, Python, programming, database management, and ML Ops implementation.
 Background in management, strategic leadership, and/or leadership roles.


Strong project management experience.

Requirements:

Exceptional leadership skills with a demonstrated ability to guide, coach, and build high-value teams.
 Track record of creating and fine-tuning custom scorecards, incorporating continuous improvement processes.
 In-depth working knowledge of Generative AI, LLM, deep neural networks, and deep learning modeling.
 Ability to thrive in a fast-paced and dynamic business environment.
 Keen sense of responsibility and ownership, detail-oriented, with project management and implementation experience.
 Master's Degree in statistics or other quantitative areas of study.
 Excellent interpersonal, written, and verbal communication skills, including influencing and presentation skills.
 Demonstrated business and financial acumen.
 Critical thinker with an analytical mindset and a process-oriented approach.


Physical Demands:


Working in a temperature-controlled office environment
Sitting at a desk for prolonged periods of time while viewing multiple computer screen monitors
Potential lifting of boxes around 5-10lbs


Why National Funding?

Positive, energetic, passionate, business casual environment with management who commits to your success


Fantastic benefits package: Our current benefit package includes medical, dental, vision, life, LTD and AD&D insurance as well as a 401(k) Retirement Savings plan with an employer match. Eligibility for all benefits will start at the first of the month following 60 days of employment.
 Numerous employee events throughout the year, including our annual traditions such as a Day at the Del Mar Racetrack, Del Mar Mud Run, Bring Your Kid to Work Day, Holiday Party, Employee and Family Picnic, sporting events and more.

National Funding is one of the leading providers of short-term loans and equipment leasing for small businesses across the United States. In both 2013 and 2014, we were ranked by the San Diego Business Journal as one of the 100 Fastest Growing Private Companies in San Diego and listed on the Inc. 5000 List of America's Fastest Growing Private Companies. We serve the small business community nationwide by offering a range of financial services and products. Since 1999, we have been in the forefront of the equipment leasing business, working with businesses in hundreds of communities and industries to expand and upgrade their business equipment. As we have grown, so too has our product line, and now we are one of the country's largest private lenders of small business loans. Our customers call on us to get working capital, merchant cash advances, credit card processing, and of course, equipment leasing.
National Funding is an Equal Opportunity Employer.
",130000,"['python', 'machine learning', 'deep learning', 'sql']"
Machine Learning Engineer,Dezign Concepts LLC,VA,Full-time,"


20231112-2219-01
 Active Top Secret Clearance with Poly Required
 Salary Range: Up to $225K **salary is commensurate with education and experience**
 Job Summary
 The Sponsor seeks to develop and adapt Large Language Models (LLM) and Natural Language Processing (NLP) methodologies using artificial intelligence and machine learning (AI/ML) frameworks and programming languages to create new capabilities to improve analytic workflows and address key intelligence questions. The Sponsor needs experienced AI/ML engineering skills to build tools and analytics that use the Sponsor’s structured and unstructured data to yield novel analytic insights, accelerate workflows, enable analysts to surface relevant information from massive data stores. The work will be performed within a team environment.

 **Please note: This job requires an existing Top Secret Clearance and Polygraph**
 Responsibilities and Duties

 Leverage open source best-in-class models to create new models—through fine tuning, transfer learning, and more— and ensembles that can be re-purposed and reused, covering the following domains:
   
 Classification
 Supervised (CNN, Unet, YOLO, or similar)
 Unsupervised (DBSCAN, K-Nearest, Adaboost, or similar)
 Prediction
 Predictors (LSTM, UConv, or similar)
 Regressors (Bayesian, linear, or similar)
 Fusion (sensor level and entity level)
 Decision making (Task assignments, combinational and parametric optimizations, Reinforcement Learning, Path Planning, or similar)
 Generative (LLMs, Stackable LLMs, or similar)
 Machine Learning, AI, Deep Learning (TensorFlow, PyTorch), Text, (Classification, NLP, Topic and Language Modeling, Sentiment Analysis, Information Retrieval), Recommender Systems and Personalization, Threat Detection, Computer Vision, Data Mining, Statistics, or similar.

 Analyze large amounts of raw data, including text data, to determine utility for training or testing AI models.
 Preprocess or clean structured and unstructured Sponsor data, including text data.
 Design and implement advanced ETL code and table configurations for complex data sets.
 Use Structured Query Language (SQL) to develop and organize relevant information.
 Cooperation with a team, author analytic publications and produce ad-hoc reports to include data visualizations using the Sponsor’s templates, and document methods in Github.
 Implement the Sponsor’s existing coordination process.
 Provide technical education to staff on an ad-hoc basis.
 Provide subject matter expertise in AI/ML to support Sponsor’s initiatives.


 Experience Needed:

 Citizenship: Must Be a US Citizen
 Existing Clearance Required: Active Top Secret SCI with Poly
 Demonstrated experience tuning neural networks, such as LLMs, on custom data sets and applying results to specific use cases.
 Demonstrated professional or academic experience developing models and ensembles in the AI/ML space, including selecting the best Python libraries for a given task, choosing appropriate pre-processing actions, performing analysis, and assessing model performance.
 Demonstrated professional or academic experience using Python or R.
 Demonstrated professional or academic experience with deep learning frameworks such as PyTorch, Tensorflow, or Keras.
 Demonstrated professional or academic experience and proficiency with SQL to include using common table expressions, set operations, aggregated functions and nested subqueries.
 Demonstrated professional or academic experience with version control systems such as Github and Jenkins.
 Demonstrated experience leveraging GPUs for accelerated computing.

 Other skills and demonstrated experiences that are highly desired but not required to perform the work include:

 Demonstrated professional or academic experience with the HuggingFace Transformers library and hub.
 Demonstrated experience with cloud computing development and architecture.
 Demonstrated experience with front-end web development frameworks such as Flask.
 Demonstrated experience creating machine learning models that conduct text classification and topic modeling in Python using standard machine learning (SciKit Learn-) or deep learning models.
 Demonstrated experience developing applications for semantic search.
 Demonstrated professional or academic experience and proficiency with Tableau to produce visualizations and dashboards.
 Demonstrated academic or professional experience communicating methodological choices and model results.
 Demonstrated experience with verification and validation test benches.
 Demonstrated experience with Explainable AI (XAI) techniques.
 Demonstrated experience with ONNX (Open Neural Net Exchange).

 Travel is anticipated for this position:

 Local travel/POV will be on an as needed basis, within the local place of performance.




 Health Benefits
 Work/Life Balance
 Financial Opportunities


 Medical, Dental, Vision, Health Savings Account and more.
 Paid Time Off, Holidays, Social Events, Employee Assistance Program and Team Building
 401K, Tuition Assistance, Annual and Referral Bonuses



 Main Number: 1-888-663-2690 | info@Dezign-Concepts.com | www.dezign-concepts.com
 Dezign Concepts provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
 
diPoSw0pO2
",225000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'tableau', 'etl', 'sql']"
Data Scientist - Level 3,Applied Network Solutions Inc,CO,Full-time,"
 Description: 
  Who we are:
 At Applied Network Solutions (ANS), we bring together some of the most curious minds in networking and cybersecurity. ANS was founded to disrupt the status quo. For over 20 years, our team provides expertise in network, system engineering and both offensive and defensive cybersecurity operations.
 What we do:
 Our vision is for a future in which talent and customers alike come to ANS because of our reputation for delivering technical excellence, solving our nation’s toughest challenges and our ability to exceed expectations.
 Why ANS:
 At ANS we value the integrity of your work. We are looking for the right person to plan, analyze, design, develop, test, secure, integrate, implement, operate, and maintain the custom solutions that ANS delivers. Together, let’s ensure today is safe and tomorrow is smarter.
 As a Data Scientist on our team, you will: Be trusted to design and execute machine learning models and applications, document analytic results and create visualizations for client stakeholders.
 Requirements:

 Active TS/SCI clearance with Polygraph
 A Bachelor's degree and 10 years of relevant experience. A Master's degree and 8 years of relevant experience. A Doctorate's degree and 6 years of relevant experience. An Associate's degree plus 12 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position.
 Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science
 A broader range of degrees will be considered if accompanied by a Certificate in Data Science from an accredited college/university
 Experience in designing/implementing machine learning, data science, advanced analytical algorithms, programming (skill in at least one high-level language (e.g., Python) and skill in at least one mid-level language (e.g., C)), data mining, advanced statistical analysis (e.g., statistical foundations of machine learning, statistical approaches to missing data, time series), advanced mathematical foundations, artificial intelligence, workflow and reproducibility, data management and curation, data modeling and assessment (e.g., model selection, evaluation, and sensitivity analysis), experience as a data scientist working to support a single or multiple domain area, and/or software engineering.

 Desired Qualifications:

 Working knowledge of Big Data, dataflows, and ML/AI familiarity
 Working knowledge of Jupyter notebooks
 Working knowledge of Spark

 Responsibilities include, but are not limited to:

 Working knowledge of statistics, programing and predictive modeling
 Use programming languages (e.g., Python, R) to manipulate and analyze large data sets
 Design and implement machine learning, data science and advanced analytical algorithms
 Provide statistical analysis as well as (e.g. variability, sampling error, inference, hypothesis testing, EDA, applications of linear models), data management, data mining, data modeling and assessment
 Requirements: 
  Benefits:
 ANS offers excellent compensation along with a generous benefits package to include:

 Family Medical, Dental (w/ adult orthodontia) and Vision coverage
 Pet Insurance
 PTO (Paid Time Off)
 Maternity/ Paternity Leave
 Supplemental Military Leave Pay
 11 Paid Holidays
 401(k) plan with 6% Company Contribution
 Generous Professional Development Program
 100% Employer paid Short- and Long-Term Disability
 100% Employer paid Life Insurance
 Supplemental Whole Life Insurance
 Lucrative Referral Bonus Program
 Annual Allowance for ANS Swag
 Potential for Paid Overtime
 Flexible Work Schedules

 Applied Network Solutions, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age or protected veteran status and will not be discriminated against on the basis of disability.
 *Disclaimer: Salary is an open band for Indeed purposes and may not accurately represent the salary band for this position*
",100000,"['python', 'machine learning']"
Generative AI Practice Leader,ehub global,NJ,Full-time,"Title: Generative AI Practice Leader
Location: New Jersey
Fulltime Role
Job Description:
Expectations

Experience in Banking, Insurance and / or Capital Market (BFSI) domain
Create differentiated solution & Services offerings and translate into revenue growth.
Drive strategic account growth and be responsible for the delivery of consulting services to our customers.
Actively search for opportunities to expand business within existing accounts and help win new clients.
Building new technology capabilities, and building team competencies
Marketing of technology & domain solutions / service offerings to internal/external stakeholders
Manage business relationship with the technology partners & start-up eco systems and demonstrate edge over competition.
Passionate about technology and customer success with excellent communication and articulation skills
Ability to communicate technical concepts and solutions at a level appropriate for technical and non-technical audiences.
Research, curate, and record tutorials on various applications of data science and machine learning
Ability to work effectively in a dynamic, research-oriented group that has several concurrent projects.

Behavior Competencies

Excellent Communication
Consulting and Advisory
Conflict Resolution
Solutioning
Customer Service
Accountability
Judgement and decision making

Technical Skills

At least 5+ years of hands-on experience with building language models, machine learning and AI models leveraging industry tools, products, and / or Azure cognitive services.
Deep and hands-on expertise in (as an individual contributor) Undertaking data collection, Data mining, preprocessing and analysis of structured and unstructured data.

Hands-on expertise in large language models (LLMs/LSTMs/BERT) that can perform complex reasoning in few- and zero-shot settings by generating intermediate chain of thought (CoT) reasoning steps
Experience of building / customizing and fine-tuning AI models including LLM models via OpenAI (Azure), Bert (AWS) for rapid PoCs
Experience on LLM Model Governance, LLMSecOps, Hallucination and bias handling
Deep and hands-on experience in applying machine learning algorithms.
Strong data science and data engineering background both with open source and cloud distributed machines learning and AI tools especially Azure Cognitive Services, Azure Machine Learning and AWS Sagemaker and Bedrocks

Strong understanding of Azure cloud technology including Cognitive Services viz. Vision, Speech, Language, Decision, Search and GenAI and its implementation
Proven experience with, and applied knowledge of, at least one scripting language, such as Python, or R

Job Type: Full-time
Salary: $140,000.00 - $170,000.00 per year
Benefits:

401(k)
Dental insurance
Health insurance
Vision insurance

Schedule:

8 hour shift

Work Location: In person",140000,"['python', 'machine learning', 'aws', 'azure']"
Data Analyst/ Statistical,Neotech solutions,IL,Full-time,"Role:Data Analyst/ Statistical
Location: Peoria, IL (Onsite)
Duration: Full Time
Must have:
Correlation Analysis experience Engineering Background, hypothesis test, Interval estimation, Python, reliability/performance
-Candidate must worked for Engineering companies
Details and Requirement:
Statistical Analysis/Uncertainty Quantification.
Capable of designing hypothesis test
Deep understanding of the confidence interval estimation
M.S. degree with 4 to 5 years of experience in statistical analysis is acceptable.
Applied Math major with a good amount of engineering experience is acceptable.
Strong Knowledge in Python.
Automotive industries experience is preferred.
Job Type: Full-time
Salary: $60,000.00 - $65,000.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Life insurance
Paid time off
Parental leave
Relocation assistance
Vision insurance

Experience level:

4 years
5 years
6 years
7 years
8 years
9 years

Schedule:

8 hour shift

Work Location: In person",60000,['python']
Senior Data Analyst (Business Intelligence Analyst),TRILLIUM HEALTH RESOURCES,Remote,Full-time,"

Pay Plan Title: Senior Data Analyst
 

 Working Title: Business Intelligence Analyst
 

 FLSA Status: Exempt
 

 Posting Salary Range: $51,500 - $73,166
 

 Office Location: Remote with offices available in Greenville, NC and Wilmington, NC
 

 POSTING DETAILS:
 Make an Impact
 Trillium Health Resources is a local governmental agency (LME/MCO) in North Carolina that manages serious mental health, substance use, and intellectual/developmental disability services. Serving in 28 counties, we help individuals and their families strengthen well-being and build foundations for a healthy life.
 Join our team as we empower others to live their best lives by providing access to quality healthcare. We offer a challenging, engaging work environment where staff take home more than a paycheck. Every day, we see the results of our dedication – in the smiles of children on our accessible playgrounds and in the pride on the face of an adult cooking a meal for the first time. Working at Trillium Health Resources is more than just a job; it is an opportunity to make a direct impact on the communities we serve.
 At Trillium, we know that empowering others begins with supporting and developing our team. That’s why we offer competitive benefits and work-from-home flexibility so that our employees thrive outside of the office. We’re also committed to building a diverse, inclusive culture where all employees have the potential to grow professionally and personally.
 What We’re Looking For
 We’re seeking a Business Intelligence Analyst who wants to grow their IT career by helping us conduct data analysis activities for Trillium. You’ll work directly with team members from all parts of our organization to assure compliance with the DMH and DMA contract requirements as well as other external and internal reporting needs. The Business Intelligence Analyst is responsible for the validation of data collected and ensuring data integrity. You’ll be a valued member of the Informatics Data Report
 On a typical day, you might:

 Ensure that data from reports are presented in a user-friendly format and made accessible to staff, consumers and community members.
 Analyze and report statistical data on populations, disabilities and cultural factors.
 Provide technical assistance to other Trillium department staff or provider agencies regarding data collection, analysis, and reporting.
 Use SQL and various analytical programs such as R, SPSS, or Python for analysis of data.
 Uses KACE and Team Foundation Server (TFS) to respond to organizational requests, document and track progress, and maintain version control of reports and code

 Employee Benefits:
 Trillium knows that work/life balance is important. That’s why we offer our employees competitive benefits and flexibility that is second to none. Take a look at what we have to offer:

 Flexible Work Schedules. Remote work was a strong part of our culture prior to COVID-19, and currently, employees may work remotely 100% of the time, with an in-office option available for those who prefer that.
 Paid Time Off (PTO) of 23 days per year, plus 10 paid holidays both in first year of employment
 Health Insurance - no premium for employee coverage
 NC Local Government retirement pension. This is a defined-benefit retirement plan that will pay you a monthly amount upon retirement, for the rest of your life, with as little as five years of service. For more information, go to:

 https://files.nc.gov/retire/documents/files/Actives/LGERSHandbook.pdf

 401k with 5% employer match & immediate vesting
 Public Service Loan Forgiveness Qualifying Employer
 Flexible Spending Accounts

 Qualifications:
 Education: Associate’s Degree OR, Based on required experience / Bachelor’s Degree

 Required Experience: Associate’s degree in Information Technology, Actuarial/ Statistics, Data Analytics, Business, or Human Service field (such as Psychology, Social Work, etc.) and four (4) years’ experience in Information Technology, Actuarial/ Statistics, Data Analytics, Business, Human Service field (such as Psychology, Social Work, etc.).
 

   OR
 

   Bachelor’s degree in Information Technology, Actuarial/ Statistics, Data Analytics, Business, or Human Service field (such as Psychology, Social Work, etc.) and a minimum two (2) years’ experience in Information Technology, Actuarial/ Statistics, Data Analytics, Business, Human Service field (such as Psychology, Social Work, etc.).
 

   OR
 
 Equivalent combination of education/experience
 License/Certification: None Identified
 Preferred License/Certification (if applicable): CSPA, Certified Machine Learning – Specialty (AWS), Predictive Analytics Certificate (SOA), and/or CAHIMS, ITIL v3 or equivalent certifications preferred
 Must have a valid driver’s license
 Remote with office locations available in Greenville or Wilmington, NC
 Deadline for application: Posting closed on Wednesday, November 22, 2023 at 11:59 p.m.
 To be considered for employment, all candidates are required to submit an application through ADP and upload a current resume. Your resume must provide your level of education and detailed work experience, including:

 Employer Name
   
 Dates of service (month & year)
 Average number of hours worked per week
 Essential duties of the job as related to the position you’re applying for

 Education
   
 Degree type
 Date degree was awarded
 Institution

 Licensure/certification, if applicable

 After submitting your application through our career center in ADP, your resume will be reviewed to ensure that your skills and experience meet the essential criteria for the role you have applied for.
 Join our Talent Community through our ADP career center to stay informed about positions you may qualify for. Remember to keep an update resume in the Talent Community profile.
 The diversity of the communities we serve is reflected in our employees. Trillium Health Resources is an Equal Employment Opportunity (EEO) employer.
 Trillium Health Resources is a drug-free workplace. Candidates are required to pass a drug test as a condition of employment.
 #Innovation #Technology #Careers #NorthCarolina #BehavioralHealth
",51500,"['python', 'machine learning', 'aws', 'sql']"
Senior Data Analyst (Business Intelligence Analyst),TRILLIUM HEALTH RESOURCES,NC,Full-time,"

Pay Plan Title: Senior Data Analyst
 

 Working Title: Business Intelligence Analyst
 

 FLSA Status: Exempt
 

 Posting Salary Range: $51,500 - $73,166
 

 Office Location: Remote with offices available in Greenville, NC and Wilmington, NC
 

 POSTING DETAILS:
 Make an Impact
 Trillium Health Resources is a local governmental agency (LME/MCO) in North Carolina that manages serious mental health, substance use, and intellectual/developmental disability services. Serving in 28 counties, we help individuals and their families strengthen well-being and build foundations for a healthy life.
 Join our team as we empower others to live their best lives by providing access to quality healthcare. We offer a challenging, engaging work environment where staff take home more than a paycheck. Every day, we see the results of our dedication – in the smiles of children on our accessible playgrounds and in the pride on the face of an adult cooking a meal for the first time. Working at Trillium Health Resources is more than just a job; it is an opportunity to make a direct impact on the communities we serve.
 At Trillium, we know that empowering others begins with supporting and developing our team. That’s why we offer competitive benefits and work-from-home flexibility so that our employees thrive outside of the office. We’re also committed to building a diverse, inclusive culture where all employees have the potential to grow professionally and personally.
 What We’re Looking For
 We’re seeking a Business Intelligence Analyst who wants to grow their IT career by helping us conduct data analysis activities for Trillium. You’ll work directly with team members from all parts of our organization to assure compliance with the DMH and DMA contract requirements as well as other external and internal reporting needs. The Business Intelligence Analyst is responsible for the validation of data collected and ensuring data integrity. You’ll be a valued member of the Informatics Data Report
 On a typical day, you might:

 Ensure that data from reports are presented in a user-friendly format and made accessible to staff, consumers and community members.
 Analyze and report statistical data on populations, disabilities and cultural factors.
 Provide technical assistance to other Trillium department staff or provider agencies regarding data collection, analysis, and reporting.
 Use SQL and various analytical programs such as R, SPSS, or Python for analysis of data.
 Uses KACE and Team Foundation Server (TFS) to respond to organizational requests, document and track progress, and maintain version control of reports and code

 Employee Benefits:
 Trillium knows that work/life balance is important. That’s why we offer our employees competitive benefits and flexibility that is second to none. Take a look at what we have to offer:

 Flexible Work Schedules. Remote work was a strong part of our culture prior to COVID-19, and currently, employees may work remotely 100% of the time, with an in-office option available for those who prefer that.
 Paid Time Off (PTO) of 23 days per year, plus 10 paid holidays both in first year of employment
 Health Insurance - no premium for employee coverage
 NC Local Government retirement pension. This is a defined-benefit retirement plan that will pay you a monthly amount upon retirement, for the rest of your life, with as little as five years of service. For more information, go to:

 https://files.nc.gov/retire/documents/files/Actives/LGERSHandbook.pdf

 401k with 5% employer match & immediate vesting
 Public Service Loan Forgiveness Qualifying Employer
 Flexible Spending Accounts

 Qualifications:
 Education: Associate’s Degree OR, Based on required experience / Bachelor’s Degree

 Required Experience: Associate’s degree in Information Technology, Actuarial/ Statistics, Data Analytics, Business, or Human Service field (such as Psychology, Social Work, etc.) and four (4) years’ experience in Information Technology, Actuarial/ Statistics, Data Analytics, Business, Human Service field (such as Psychology, Social Work, etc.).
 

   OR
 

   Bachelor’s degree in Information Technology, Actuarial/ Statistics, Data Analytics, Business, or Human Service field (such as Psychology, Social Work, etc.) and a minimum two (2) years’ experience in Information Technology, Actuarial/ Statistics, Data Analytics, Business, Human Service field (such as Psychology, Social Work, etc.).
 

   OR
 
 Equivalent combination of education/experience
 License/Certification: None Identified
 Preferred License/Certification (if applicable): CSPA, Certified Machine Learning – Specialty (AWS), Predictive Analytics Certificate (SOA), and/or CAHIMS, ITIL v3 or equivalent certifications preferred
 Must have a valid driver’s license
 Remote with office locations available in Greenville or Wilmington, NC
 Deadline for application: Posting closed on Wednesday, November 22, 2023 at 11:59 p.m.
 To be considered for employment, all candidates are required to submit an application through ADP and upload a current resume. Your resume must provide your level of education and detailed work experience, including:

 Employer Name
   
 Dates of service (month & year)
 Average number of hours worked per week
 Essential duties of the job as related to the position you’re applying for

 Education
   
 Degree type
 Date degree was awarded
 Institution

 Licensure/certification, if applicable

 After submitting your application through our career center in ADP, your resume will be reviewed to ensure that your skills and experience meet the essential criteria for the role you have applied for.
 Join our Talent Community through our ADP career center to stay informed about positions you may qualify for. Remember to keep an update resume in the Talent Community profile.
 The diversity of the communities we serve is reflected in our employees. Trillium Health Resources is an Equal Employment Opportunity (EEO) employer.
 Trillium Health Resources is a drug-free workplace. Candidates are required to pass a drug test as a condition of employment.
 #Innovation #Technology #Careers #NorthCarolina #BehavioralHealth
",51500,"['python', 'machine learning', 'aws', 'sql']"
Data Scientist,Albertsons Companies,CA,Full-time,"
About the company 
Albertsons Companies is at the forefront of the revolution in retail. With a fixation on raising the bar with innovation and building belonging through our culture, our team is rallying our company around a unique purpose : to create joy around each table and inspire a healthier tomorrow for every community. 
Albertsons Companies is one of the largest food and drug retailers in the United States, with over 2,200 stores in 34 states and the District of Columbia. Our well-known banners include Albertsons, Safeway, Vons, Jewel-Osco, Shaw's, Acme, Tom Thumb, Randalls, United Supermarkets, Pavilions, Star Market, Haggen, Carrs, Kings Food Markets, and Balducci's Food Lovers Market. We support our stores with 22 distribution centers and 19 manufacturing plants. 
Placing a premium on adaptability, safety and family well-being, our work model, Presence with a Purpose, offers a hybrid work environment between remote work and office time. A one-size-fits-all approach does not apply to everyone, and teams are empowered to make decisions best for them. 
Bring your flavor 
Building the future of food and well-being starts with you. Join our team and bring your best self to the table. 
What you will be doing 
You will enjoy working with one of the richest data sets in the world, cutting edge technology, and the ability to see your insights turned into business impacts on regular basis. You'll work closely with other data scientists and business partners in identifying and defining data science projects, building machine learning algorithms and models on top of existing data platforms. The candidate will have a background in computer science or a related technical field with experiences working with large data sets and applying data-driven decision making. A successful candidate will be both technically strong and business savvy, with a passion to make an impact through creative storytelling and timely actions. You are a self-starter, smart yet humble, with a bias for action. 
This position is located in Pleasanton, California. 
Main responsibilities 

Collaborate with business teams to develop production grade machine learning models on large-scale datasets and improve customers’ overall shopping experience 
Apply machine learning to enhance recommendation engines and deliver personalized user experience on ecommerce website and loyalty mobile app 
Build models and algorithms to fuel growth initiatives for Digital, Merchandising, Marketing and Loyalty teams 
Scale up prototypes and implement reliable automated production workflow for models 
Collaborate with software development engineers to integrate models 
Apply predictive modeling techniques to optimize the forecasts for planning needs 
Detect anomaly in systems through various techniques and identify outliers in operational metrics 

The salary range is $109,600 to $142,420 annually. Starting salary will vary based on criteria such as location, experience, and qualifications. There may be flexibility for exceptional candidates. 
What we are searching for 

Masters or PhD degree in quantitative discipline: Computer Science, Engineering, Data Science, Math, Statistics or related fields 
2+ years of industry experience in applying data science and modeling methodologies: regression model, survival model, ensemble modeling, NLP, recommendation algorithm, clustering, deep learning algorithm, experimental design (Multivariate/A-B testing) and nonparametric Bayesian modeling etc. 
1+ years of experience and proficiency in SQL, Python and/or Spark-ML 
1+ years of SQL development skills writing queries, transforming data, mining structured and unstructured data. 
1+ years of hands-on experience in building data science solutions and production-ready systems on big data platforms such as Snowflake, Spark, Hadoop 
Strong teamwork and communication skill 
Ability to write production-level code in Python 
Experience with Snowflake, Azure Databricks is a strong plus 

What is it like at Albertsons? 
Our 290,000 associates have a passion for great service and building lasting relationships with our customers. Through a companywide focus on innovation, we are continually enhancing our digital and product offerings, making it easy for customers to get what they need, wherever they are.
",109600,"['python', 'machine learning', 'deep learning', 'azure', 'sql', 'hadoop']"
Data Scientist,NORC at the University of Chicago,IL,Full-time,"




JOB DESCRIPTION:


At NORC, Data Scientists play a key role in working with our research teams to produce valuable insights for our clients. This position supports the development of the strategy and vision for data analysis projects and performs tasks such as importing, cleaning, transforming, validating, or modeling data. Data Scientists may also support the presentation of data by developing charts, graphs, and tables. In addition, the Data Scientist may assist in data collection from primary or secondary data sources (e.g., administrative records, commercial data, social media data), identify, analyze, and interpret trends or patterns in data sets and maintain databases/data systems, dictionaries, etc. The Data Scientist is expected to work collaboratively in a team environment.






DEPARTMENT: Statistics and Data Science


The Statistics and Data Science department conducts a wide range of statistical and data science projects, engaging in statistical analysis, modeling, data linkage, statistical matching, disclosure control, small area estimation, and Bayesian analysis, to support all aspects of social science research. NORC statisticians and data scientists design and implement rigorous, efficient methods for sampling, weighting, and imputation for sample surveys and evaluation research. They also employ statistical modelling, machine learning methods, and data visualization for analyzing and interpreting data. The department collaborates with the Methodology and Quantitative Social Sciences department, all NORC research departments, and the Academic Research Centers in addition to conducting research in its own field.






RESPONSIBILITIES:



Gather and interpret results using a variety of techniques, ranging from simple data aggregation via statistical analysis to moderate to complex analytical/predictive modeling and/or intermediate machine learning.
Prepares reports, develops charts, graphs, tables and interactive data tools, primarily in R.
Create, manage, and maintain databases/data systems, data dictionaries, etc.
Conduct data management, including merging, cleaning, transforming and harmonizing data.
Work directly with clients and/or project and business leaders to assist in identifying analytical requirements.
May assist in proposal development by drafting subsections.






REQUIRED SKILLS:



Master’s or Bachelor’s degree in Math, Statistics, Computer Science, Data Science, or related field
Strong foundation in areas of statistics, mathematics, machine learning, scientific methods of inquiry.
Working knowledge of different types of data that can be sourced whether from social media, administrative or sensor data.
Strong problem-solving skills.
Ability to organize and prioritize work assignments to meet project needs.
At least 2 years’ experience (at least 4 years’ experience if Bachelor's degree) in positions of increasing responsibility, conducting statistical and quantitative modeling, melding analytics with strong R programming.
Strong written and verbal communication including strong technical writing skills.
Strong data visualization/presentation skills, especially interactive data visualization.
Able to explain technology, techniques, and approaches to others.
Experience with interactive data visualization tools in R, including (but not limited to) Shiny, ggiraph, r2d3, and plotly.
Experience with literate programming tools in R, such as R Markdown or Quarto.






SALARY AND BENEFITS:



The pay range for this position is $86,000 – $153,000. The budgeted range for this role is: $86,000 - $100,000.


This position is classified as regular. Regular staff are eligible for NORC’s comprehensive benefits program. Benefits include, but are not limited to:




Generously subsidized health insurance, effective on the first day of employment 
Dental and vision insurance 
A defined contribution retirement program, along with a separate voluntary 403(b) retirement program 
Group life insurance, long-term and short-term disability insurance 
Benefits that promote work/life balance, including generous paid time off, holidays; paid parental leave, tuition assistance, and an Employee Assistance Program (EAP). 




NORC’s Approach to Equity and Transparency


Pay and benefits transparency helps to reduce wage gaps. As part of our commitment to pay equity and salary transparency, NORC includes a salary range for each job opening along with information about eligible benefit offerings. At NORC, we take a comprehensive approach to setting salary ranges and reviewing raises and promotions, which is overseen by a formal Salary Review Committee (SRC).







WHAT WE DO:


NORC at the University of Chicago is an objective, non-partisan research institution that delivers reliable data and rigorous analysis to guide critical programmatic, business, and policy decisions. Since 1941, our teams have conducted groundbreaking studies, created and applied innovative methods and tools, and advanced principles of scientific integrity and collaboration. Today, government, corporate, and nonprofit clients around the world partner with us to transform increasingly complex information into useful knowledge.






WHO WE ARE:


For over 75 years, NORC has evolved in many ways, moving the needle with research methods, technical applications and groundbreaking research findings. But our tradition of excellence, passion for innovation, and commitment to collegiality have remained constant components of who we are as a brand, and who each of us is as a member of the NORC team. With world-class benefits, a business casual environment, and an emphasis on continuous learning, NORC is a place where people join for the stellar research and analysis work for which we’re known, and stay for the relationships they form with their colleagues who take pride in the impact their work is making on a global scale.






EEO STATEMENT:


NORC is an affirmative action, equal opportunity employer that values and actively seeks diversity in the workforce. NORC evaluates qualified applicants without regard to race, color, religion, sex, national origin, disability, veteran status, sexual orientation, gender identity, and other legally- protected characteristics.





",86000,['machine learning']
"Associate, Data Science",BlackRock,CA,Full-time,"






       Description 
        
About this role
 

Company: BlackRock Financial Management, Inc.
 Job Title: Associate, Data Science
 Location: 820 Ramona Street, Palo Alto, CA 94301
Summary of duties: Design, develop and program methods, processes, and systems to consolidate and analyze unstructured, diverse “big data” sources to generate actionable insights and solutions for client needs and/or product enhancements. Interact with stakeholder teams to identify questions and issues for data analysis, research opportunities for new uses of existing data and develop processes for data modeling, mining, and production. Utilize various techniques in machine learning, data mining, statistics, and big data infrastructures. Work with different datasets and run algorithms on large size data effectively and efficiently, staying up to date with all the latest cutting-edge technologies.
Qualifications: Bachelor's degree in Data Informatics, Computer Science, Computer Engineering, Mathematics, or a related field, and two (2) years of experience as an Associate, Aladdin Product Group; Analyst, Aladdin Product Group; Graduate Analyst Summer Intern; Programmer; Graduate Apprentice; or a related role. Two (2) years of experience with: utilizing data science principles to map applications into data science frameworks, including supervised learning, clustering, collaborated filtering, optimizations, and decision models; utilizing computer programming languages, including Python, JavaScript, SQL, Java, and Scala; applying financial market theory in capital market work, including financing models and asset valuations; applying mathematics and statistics to internal models and AI algorithms; and utilizing big data technology to distribute computing and data storage in cloud, including AWS, Azure, and Google.
Salary range: $145,000 – 152,500
To apply: please click the “Apply” button on this webpage.


 For California only the salary range for this position is $. Additionally, employees are eligible for an annual discretionary bonus, and benefits including heath care, leave benefits, and retirement benefits. BlackRock operates a pay-for-performance compensation philosophy and your total compensation may vary based on role, location, and firm, department and individual performance.
 
Our benefits
 To help you stay energized, engaged and inspired, we offer a wide range of benefits including a strong retirement plan, tuition reimbursement, comprehensive healthcare, support for working parents and Flexible Time Off (FTO) so you can relax, recharge and be there for the people you care about.
 
Our hybrid work model
BlackRock’s hybrid work model is designed to enable a culture of collaboration and apprenticeship that enriches the experience of our employees, while supporting flexibility for all. Employees are currently required to work at least 4 days in the office per week, with the flexibility to work from home 1 day a week. Some business groups may require more time in the office due to their roles and responsibilities. We remain focused on increasing the impactful moments that arise when we work together in person – aligned with our commitment to performance and innovation. As a new joiner, you can count on this hybrid model to accelerate your learning and onboarding experience here at BlackRock.

About BlackRock
 
At BlackRock, we are all connected by one mission: to help more and more people experience financial well-being. Our clients, and the people they serve, are saving for retirement, paying for their children’s educations, buying homes and starting businesses. Their investments also help to strengthen the global economy: support businesses small and large; finance infrastructure projects that connect and power cities; and facilitate innovations that drive progress.
 
This mission would not be possible without our smartest investment – the one we make in our employees. It’s why we’re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.







",145000,"['python', 'machine learning', 'aws', 'azure', 'sql']"
Data Scientist,Booz Allen Hamilton,SC,Full-time,"


Job Description










         Location: 
        

         Shaw AFB,SC,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184709
        


















         Data Scientist
          The Opportunity:
 As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by big data, streaming analytics, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can turn these complex data sets into useful information to solve global challenges with direct impact on Department of Defense national security missions. We need a seasoned data scientist like you to help our clients pursue a data-driven future.

 On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide and mentor your team as you oversee the development of algorithms and data-driven solutions. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. As a technical leader, you’ll identify new opportunities to use data science solutions to help your clients meet their toughest challenges. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used.

 Work with us as we use data science for good.

 Join us. The world can’t wait.

 You Have:

 3+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining
 3+ years of experience with statistical and general-purpose programming languages for data analysis
 3+ years of experience analyzing structured and unstructured data sources
 Experience developing predictive data models, quantitative analyses, and visualization of targeted data sources
 Experience leading the development of algorithms leveraging R, Python, or SQL and NoSQL 
Experience with natural language processing, text mining, or machine learning techniques
 Experience leading a team, including project milestones and deliverables
 Ability to obtain a security clearance
 Bachelor’s degree


 Nice If You Have:

 Experience with applying machine learning and AI methods, including LLM and NLP
 Experience with Distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL
 Experience with visualization packages, including Plotly, Seaborn, or ggplot2
 Secret clearance


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.
 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,000.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73000,"['python', 'machine learning', 'mysql', 'nosql', 'sql', 'kafka', 'hadoop']"
Data Scientist,ICF,VA,Full-time,"

  ICF International seeks an experienced Data Scientist to support the research and development of new cyber analytic capabilities that will help the US protect and defend its networks and critical information systems. The successful cleared candidate will act as a Data Scientist to support a large federal cyber security analytic program. Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate. Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large-scale.
 


 As the Data Scientist, your skillset will create useful and actionable insight for the customer through the development of machine learning, deep learning models, and related algorithms. The ideal candidate is strong mathematically, can automate scoring using machine learning techniques, build recommendation systems, and select the correct data points for analysis from large data sets. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. This is an opportunity to contribute to an important project from its beginning, work with the latest and emerging technologies, and all while building a great career at ICF!
 


 This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region.
 


 What You Will Be Doing:
 

 Perform knowledge elicitation from customer subject matter experts and convert that to derived algorithms
 Analyze large data sets to identify actionable insights with mathematical statistical rigor
 Rigorously critique and correct intermediate results to improve the algorithmic outcomes
 Design and deploy deep learning algorithms and predictive models
 Develop custom data models and algorithms to apply to data sets
 Assess the effectiveness and accuracy of new data sources and data gathering techniques
 Develop processes and tools to monitor and analyze model performance and data accuracy
 Interpret and communicate results to non-technical customers



 What You Must Have:
 

 3+ years of experience in Computer Science, Statistics, Applied Mathematics, Computational Linguistics, Artificial Intelligence or related field. Education can be considered in lieu of experience.
 3 + years of practical working experience in one or more of the following areas: Natural Language Processing, Machine Learning Models, Question Answering, Text Mining, Information Retrieval, Distributional Semantics, Data Science, Knowledge Engineering
 U.S. Citizenship required (required by federal government for position) SCI required.
 1 + years of experience with one or more programming languages (e.g., Python, JavaScript, R, etc.)



 Preferred Skills/Experience:
 

 Experience using a variety of mathematical, statistical, data mining, and data analysis methods/tools
 Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
 Experience in productization of machine learning algorithms and the ability to deliver data science components that are part of successful deliverables
 Working knowledge of general machine learning algorithms and NLP, Graph Theory, and Network Analysis
 Experience with statistical data analysis, experimental design, and hypotheses validation
 Experience with database querying like SQL
 Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
 Scaled Agile Framework (SAFe) experience
 CompTIA Security+ or higher certification level preferred



   Working at ICF
 
 ICF is a global advisory and technology services provider, but we’re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
 

   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our 
  
   EEO & AA policy
  .
 


   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email 
  
   icfcareercenter@icf.com
   and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: 
  
   Know Your Rights
   and 
  
   Pay Transparency Statement.
  



 Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:
  $77,890.00 - $132,413.00
  Arlington, VA (VA31)
",77890,"['python', 'machine learning', 'deep learning', 'sql']"
"Data Scientist, DentaQuest",DentaQuest,MA,Full-time,"
You are as unique as your background, experience and point of view. Here, you’ll be encouraged, empowered and challenged to be your best self. You'll work with dynamic colleagues - experts in their fields - who are eager to share their knowledge with you. Your leaders will inspire and help you reach your potential and soar to new heights. Every day, you'll have new and exciting opportunities to make life brighter for our Clients - who are at the heart of everything we do. Discover how you can make a difference in the lives of individuals, families and communities around the world.

 DentaQuest manages dental and vision benefits for more than 33 million Americans. Our outcomes-based, cost-effective solutions are designed for Medicaid and CHIP, Medicare Advantage, small and large businesses, and individuals. With a focus on prevention and value, we aim to make quality care accessible to improve the oral health of all.








 Job Description: 







Location: We welcome applicants from anywhere in the U.S.

 At Sun Life, we look for optimistic people who want to make life brighter for our Clients. We understand the value of diverse cultures, perspectives, and identities, and want you to bring your full and authentic self to work. Every day, you’ll be empowered and challenged by working with dynamic colleagues to find new and innovative ways to make Sun Life the best benefits company in America.

 The opportunity:

 Collaborating with operational leads and subject matter experts to develop and implement tactics and strategy for optimizing profitability, clinical performance, member and provider satisfaction and client satisfaction by developing and leveraging analytic tools, financial models and reports, marketing and outreach.
 Is an expert SAS/Python, SQL, Tableau and Excel developer, responsible for presenting recommendations, strategies and findings. Will organize, lead and support efforts to measure, analyze and report on trends enterprise-wide related to provider utilization, reimbursements, access to care, cost management, etc. and identify and promote strategies to positively influence access to quality, cost effective care and improved program performance.
 Works with other areas of the company, including Underwriting, Provider Services, Clinical Management and Client Services to assist in the understanding of provider cost and network trends impacting program costs and profitability and to recommend strategies for improvement wherever possible.


 How you will contribute:

 Working with DentaQuest data to manipulate and analyze data to extract insight, and to develop data science methodologies, and the implementation of actionable finding.
 Use SAS/Python, SQL and other tools to analyze complex business situations and support effort to optimize outcomes measurement, provider optimization, fraud detection, member behavior management.
 Present technical findings and methodologies and present recommendations to senior clients in written and visual presentations.
 Provide mentoring and support to analysts to assist in their development and ability to meet department needs.
 Monitor and track provider reimbursements to identify strategies to ensure access and profitability targets are met in a manner that is consistent with quality, cost effective value-based care.
 Work with other internal departments as necessary to develop strategies and programs to manage dental costs within each market to assure profitability and budgetary goals are met.
 Provide recommendations on department policies, objectives and initiatives. Evaluate and suggest changes as necessary to optimize processes and efficiencies.
 Participate in special projects as needed or requested.
 Adhere to DentaQuest and Business Analytics business processes, SOPs and quality control standards.


 What you will bring with you:

 Bachelor’s degree in Statistics, Computer Science, Math, Finance, Economics or business-related field or equivalent experience.
 5+ years’ experience in data management, analysis and reporting to include experience with combining clinical and financial data.
 Advanced experience with database and business intelligence tools such as SAS, Python, Tableau, MS Report Manager and Report Builder.
 Experience designing and implementing complex algorithms and/or quality metrics.
 Strong foundation in statistical theory and practice required.


 Preferred skills 

Knowledge of health care industry is preferred.
 Strong time management and business process skills.
 Ability work well with others.
 Ability to meet multiple deadlines in a fast-paced environment.

 Do you see yourself in this role even if you haven’t checked all the boxes above? We welcome all talented candidates and are committed to a culture that represents diversity in all forms. If you think you might thrive in this setting, we would love to hear from you.

 Not ready to apply yet but want to stay in touch? Join our talent community to stay connected until the time is right for you!

 Life is brighter when you work at Sun Life

 Excellent benefits and wellness programs to support the three pillars of your well-being – mental, physical and financial – including generous vacation and sick time, market-leading paid family, parental and adoption leave, a partially-paid sabbatical program, medical plans, company paid life and AD&D insurance as well as disability programs and more
 Retirement and Stock Purchase programs to help build and enhance your future financial security including a 401(k) plan with an employer-paid match as well as an employer-funded retirement account
 A flexible work environment with a friendly, caring, collaborative and inclusive culture
 Great Place to Work® Certified in Canada and the U.S.
 Named as a “Top 10” employer by the Boston Globe's “Top Places to Work” two years running


 All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

 If you are a California resident, the salary range for this position is:

 Southern region: $95,200-$142,800 annually 
Central region: $100,400-$150,600 annually 
Northern region: $107,400-$161,100 annually 


If you are a Colorado resident, the salary range for this position is $90,900- $13,400 annually.

 If you are a New York resident, the salary range for this position is $107,400-$161,100 annually.

 If you are Washington resident, the salary range for this position is $100,400-$150,600 annually.

 We consider various factors in determining actual pay including your skills, qualifications, and experience. In addition to salary, this position is eligible for incentive awards based on individual and business performance as well as a broad range of competitive benefits.

 Sun Life Financial is a leading provider of group insurance benefits in the U.S., helping people protect what they love about their lives. More than just a name, Sun Life symbolizes our brand promise of making life brighter -for our customers, partners, and communities. Join our talented, diverse workforce and launch a rewarding career. Visit us at www.sunlife.com/us to learn more.

 At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.

 #LI-remote 

Our Affirmative Action Program affirms our commitment to make reasonable accommodation to the known physical or mental limitation of otherwise-qualified individuals with disabilities or special disabled veterans, unless the accommodation would impose an undue hardship on the operation of our business. Please email recruitingUS@sunlife.com to request an accommodation.

 At Sun Life we strive to create a flexible work environment where our employees are empowered to do their best work. Several flexible work options are available and can be discussed throughout the selection process depending on the role requirements and individual needs.








 For applicants residing in California, please read our employee California Privacy Policy and Notice.






















 Job Category: 













Advanced Analytics
 







 Posting End Date: 






28/01/2024
 
 All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran
",100400,"['python', 'tableau', 'sql']"
Data Scientist or Senior Data Scientist,Metropolitan Council,MN,Full-time,"


WHO WE ARE


We are the Metropolitan Council, the regional government for the seven-county Twin Cities metropolitan area. We plan 30 years ahead for the future of the metropolitan area and provide regional transportation, wastewater, and housing services. More information about us is on our website.  The Metropolitan Transportation Services (MTS) Division has one (1) vacancy for a Data Scientist. This vacancy may be filled as a Data Scientist or Senior Data Scientist based on the candidates' qualifications and the needs of the business.  We are committed to supporting a diverse workforce that reflects the communities we serve.  Metropolitan Transportation Services conducts planning for the regional transportation system that includes highways, transit, aviation, freight, and bicycle and pedestrian connections. The Metropolitan Council is the region’s federally designated Metropolitan Planning Organization. MTS also provides direct transit service through contracts or partnerships with counties to deliver four major programs: Metro Mobility/ADA, Transit Link dial-a-ride, contracted regular-route bus service, and Metro Vanpool.  How your work would contribute to our organization and the Twin Cities region:  The Data Scientist will support multi-modal transportation planning in the Minneapolis and St. Paul region through innovative approaches to collecting and analyzing transportation data and through the development and application of cutting-edge travel forecasting models and tools. The Data Scientist will join a vibrant travel research and modeling team working on travel demand forecasting, travel behavior surveys, and creative analysis of all kinds of transportation data to drive planning and policy analysis. A Data Scientist will perform work with less supervision, will work on projects with more complexity, and will be involved in project management of small projects or project components. A Senior Data Scientist will perform work independently and will lead projects.  This position is eligible for a hybrid (both remote and onsite) telework arrangement. The candidate's permanent residence must be in Minnesota or Wisconsin.



What you would do in this job




Perform technical, statistical, and analytic tasks that support long-range transportation planning and research on regional transportation issues (for example: emerging transportation modes and technologies, generational changes in travel behavior, and disparities in transportation access).
 Develop visualizations of transportation data and performance measures.
 Develop and apply cutting-edge transportation models that assess the region's future.
 Develop transportation forecasts at the regional, corridor, and project levels.
 Process, clean, and code transportation data.
 Analyze, examine, and visualize spatial information in static and interactive maps.
 Perform geocoding, spatial data manipulation, and spatial data analysis.
 Collaborate with planners, researchers, and policymakers.
 Develop public-facing reports and web-based, interactive data visualization, analysis, and dissemination tools in partnership with internal and external partners.
 Respond to requests for data and information, including requests from the media, other Council staff, or local partners, by summarizing data in a clear, coherent manner.
 Be a contributory team member in a multi-disciplinary team.
 Make presentations to the Transportation Committee, and other Council advisory and technical committees as needed.
 Review scholarly articles and technical papers in academic and industry databases/journals.
 Promote a culture of creativity, life-long learning, and continuous improvement.
 Promote a culturally diverse and inclusive work environment that advances racial equity.




What education and experience are required for this job (minimum qualifications)


Data Scientist Any of the following combinations of experience (with statistical modeling and/or developing web-based interactive data visualization tools) and completed education (degree field of study in Mathematics, Analytics, Data Science, or related field):


 High School Diploma or GED and seven (7) years of experience
 Associate's degree and five (5) years of experience
 Bachelor's degree and three (3) years of experience.


 Senior Data Scientist
 Any of the following combinations of experience (with statistical modeling and/or developing web-based interactive data visualization tools) and completed education (degree field of study in Mathematics, Analytics, Data Science, or related field):
   

 High School Diploma or GED and eight (8) years of experience
 Associate degree and six (6) years of experience
 Bachelor's degree and four (4) years of experience


 What additional skills and experience would be helpful in this job (desired qualifications
):


Data Scientist level

 Demonstrated ability in performing and communicating data analysis and statistical modeling of transportation data.
 Experience working with travel demand models.
 Experience in programming and modeling languages (R or Python preferred)
 Experience in data mining, passive and or 'big' data, structured, unstructured, and semi-structured data.
 Experience working and collaborating in diverse, multicultural, and inclusive environments.

 Senior Data Scientist Level

 Project Management Skills
 Ability to Present Work to peers, and to technical and policy committees.
 Knowledge of regional transportation planning and how to apply data science principles to support this work.
 Skill in applying knowledge of institutional racism and the historic and continuing disparities in communities of color to one’s work in the data science field.

 What knowledge, skills, and abilities you should have within the first six months on the job
:

 Knowledge of statistical analysis techniques (regression analysis, survival analysis, time-series modeling, etc.)
 Knowledge of database systems design and maintenance
 Knowledge of web-based interactive tool development
 Knowledge of computer programming (i.e. R, Python)
 Knowledge of passive transportation (i.e. Streetlight Data) and transportation survey data
 Skills in applied mathematics and statistics
 Skills in Data visualization (i.e. 'ggplot2' package in R, Shiny, Tableau, Dash/Plotly in Python)
 Skills in version control and collaboration in Git
 Skills in data mining with structures, unstructured, and semi-structured data
 Skills in GIS/Spatial analysis (i.e. ArcGIS, QGIS, ArcPy, Geopandas)
 Ability to read and understand complex academic and technical papers.
 Ability to write summary reports, technical papers, and literature reviews.
 Ability to synthesize technical information in a useable way that facilitates good policy and planning decisions.
 Ability to plan workflow and prioritize work tasks.
 Ability to establish and maintain effective working relationships with internal and external stakeholders.
 Ability to exercise sound professional judgment and to promote an equitable, positive, and respectful professional environment.

 What you can expect from us:

 We offer the opportunity to make a difference and positively influence the Twin Cities metropolitan area.
 We encourage our employees to develop their skills through on-site training and tuition reimbursement.
 We provide a competitive salary, excellent benefits, and a good work/life balance.
 More about why you should join us!
  


Additional information


Data Scientist Union/Grade: AFSCME/Grade G FLSA Status: Exempt Safety Sensitive: No Full Salary Range: $34.70 - $52.36 hourly / $72,176 - $108,909 annually  Senior Data Scientist Union/Grade: AFSCME/Grade H FLSA Status: Exempt Safety Sensitive: No Full Salary Range: $37.50 - $56.60 hourly / $78,000 - $117,728 annually  Work environment: Work is performed in a standard office setting.  What steps the recruitment process involve:


 We review your minimum qualifications.
 We rate your education and experience.
 We conduct a structured panel interview.
 We conduct a selection interview.
 Once you have successfully completed the steps above, then:
   

If you are new to the Metropolitan Council, you must pass a background check that verifies education, employment, and criminal history. A driving record check and/or physical may be conducted if applicable to the job. If you have a criminal conviction, you do not automatically fail. The Metropolitan Council considers felony, gross misdemeanor, and misdemeanor convictions on a case-by-case basis, based on whether they are related to the job and whether the candidate has demonstrated adequate rehabilitation.
   

If you are already an employee of the Metropolitan Council, you must pass a criminal background check if the job you're applying for is safety-sensitive, is a supervisory or management job, is in the Finance, Information Services, Audit, or Human Resources departments, or has access to financial records, files/databases, cash, vouchers or transit fare cards. A driving record check and/or physical may be conducted if applicable to the position.
   
 IMPORTANT: If you make a false statement or withhold information, you may be barred from job consideration.
   

The 
Metropolitan Council is an Equal Opportunity
, Affirmative Action, and veteran-friendly employer. The Council is committed to a workforce that reflects the diversity of the region and strongly encourages persons of color, members of the LGBTQ community, individuals with disabilities, women, and veterans to apply. If you have a disability that requires accommodation during the selection process, please email HR-OCCHealth@metc.state.mn.us.








We believe our employees are a key to our agency's success! In order to attract and retain high quality employees, the Council provides a highly competitive benefits package both in choice and coverage levels. Some highlights about our benefits are listed below: 

Guaranteed monthly retirement income through Minnesota State Retirement System pension fund
Opportunity to save additional funds for retirement on a tax-deferred basis through a voluntary deferred compensation (457) plan
Two or more medical plans from which to choose, with employer contribution towards premiums over 80%
Dental insurance, life insurance and vision insurance
The following benefits are provided to all employees as part of working for the Council. You will have access to free:
   
Well@Work clinic
bus/rail pass valued at over $1200 per year
parking at many job locations
fitness centers at many job locations
Employee Assistance Program
extensive health and wellness programs and resources




",78000,"['python', 'tableau', 'git']"
Health Data Scientist,Booz Allen Hamilton,MD,Full-time,"


Job Description










         Location: 
        

         Bethesda,MD,US 
        



         Remote Work: 
        

         Yes 
        



         Job Number: 
        

         R0184682
        


















         Health Data Scientist
          The Opportunity:
 As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors—from fraud detection to cancer research to national intelligence—we need you to help find the answers in the data. This role is open to remote delivery.

 On our team, you’ll use your analytical skills and data science knowledge to create real-world impact. You’ll work closely with your clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll develop algorithms and systems and use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to help clients make informed decisions. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used.

 Work with us as we use data science for good.

 Join us. The world can’t wait.

 You Have:

 2+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining
 2+ years of experience with statistical and general-purpose programming languages for data analysis
 Experience analyzing structured and unstructured data sources
 Experience developing predictive data models, quantitative analyses and visualization of targeted data sources
 Knowledge of Machine Learning, Artificial Intelligence, or Natural Language Processing
 Knowledge of text mining or machine learning techniques
 Bachelor’s degree


 Nice If You Have:

 2+ years of experience with Distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL
 2+ years of experience with Machine Learning, AI or NLP
 Experience with generative AI models and techniques
 Experience with visualization packages, including Plotly, Seaborn, or ggplot2
 Experience with MLOps including model testing and evaluation, model deployment and CI/CD pipelines
 Master’s degree


 Create Your Career:
 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['machine learning', 'mysql', 'kafka', 'hadoop']"
Data Mining and Analytics Engineer (Junior),ICF,VA,Full-time,"

  ICF International seeks a Junior Data Mining and Analytics Engineer to support the research and development of new cyber analytic capabilities that will help the US protect and defend its networks and critical information systems. The successful cleared candidate will act as a Data Mining and Analytics Engineer to support a large federal cyber security analytic program. Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate. Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large-scale.
 


 As the Junior Data Mining and Analytics Engineer, your skillset will create useful and actionable insight for the customer through the development of analytic solutions (hardware, analytics, tools, techniques, practices, deployment, standards, performance specifications, etc.) for analytic use cases developed during the performance of this project. You will work closely with the Analytics Research team to identify platform enhancements that support the forward-looking analytics under consideration.
 


 The ideal candidate has extensive knowledge of a wide variety of systems and networks to include high-volume/high-availability systems. You are focused on results, a self-starter, and have demonstrated success for using analytics to drive the understanding, growth, and success of the analysis. This is an opportunity to contribute to an important project from its beginning, work with the latest and emerging technologies, and all while building a great career at ICF!
 


 This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region.
 


 What You Will Be Doing:
 

 Perform knowledge elicitation from customer subject matter experts and convert that to build analytic solutions
 Design, engineer, and optimize sustainment of large-scale distributed computation platforms and supporting environment (ecosystems) for various stakeholders, business owners, and industry partners
 Oversee the transition of services from third-party vendors to the analytic environment and be responsible for ad hoc and formal end-user training
 Identify applicable data to perform analytics and create solutions to acquire, transform, and load or correlate data components to and from the analytic environment
 Develop custom data modeling procedures to assist with data mining, modeling, and production
 Assess the effectiveness and accuracy of new data sources and data gathering techniques
 Develop processes and tools to monitor and analyze model performance and data accuracy
 Interpret and communicate results to non-technical customers



 What You Must Have:
 

 Active high-level security clearance required as part of client contract requirements
 Bachelor’s degree in Computer Science, Mathematics, Engineering, or related field
 US Citizenship required as part of client contract requirements
 Practical working experience and advanced knowledge of cyber threats, tools, techniques, and processes.
 Experience in data modeling and working with datasets of all sizes using a variety of data mining and data analysis methods/tools



 Preferred Skills/Experience:
 

 Master’s degree in Computer Science, Mathematics, Engineering, or related field
 Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
 Experience in developing analytic tools, processes, and governance for storing, modeling, capturing, and delivering data to the client’s enterprise
 Experience with computational notebook software such as Zeppelin or Jupyter
 Experience with the application of visual analytics to computational analytic results
 Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)
 Experience with database querying like SQL
 Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
 Scaled Agile Framework (SAFe) experience
 Amazon Web Services (AWS) Certified Cloud Practitioner or higher desired
 CompTIA Security+ or higher cybersecurity certification preferred


   #cybsr1
 


   Working at ICF
 
 ICF is a global advisory and technology services provider, but we’re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
 

   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our 
  
   EEO & AA policy
  .
 


   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email 
  
   icfcareercenter@icf.com
   and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: 
  
   Know Your Rights
   and 
  
   Pay Transparency Statement.
  



 Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:
  $64,372.00 - $109,432.00
  Arlington, VA (VA31)
",64372,"['python', 'aws', 'sql']"
"Data Scientist 2 - Price Optimization - Hybrid - Seattle, WA, Los Angeles, CA, Denver, CO, or Chicago, IL",Nordstrom Inc,CO,Full-time,"
Job Description
 Nordstrom is a specialty retailer offering the very best in fashion and customer service since 1901. We live by five simple values that guide how we work together day-to-day and how we deliver data science & analytics products. We are customer-obsessed, owners at heart, curious and ever-changing, we extend ourselves to our peers and our customers, and we’re here to win!

 Our Pricing Data Science & Analytics team is re-imagining Nordstrom’s core pricing capabilities & developing innovative data products to drive value for our customers. As an integral part of the team, the Data Scientist 2 – Price Optimization will research and implement machine learning & optimization techniques across all areas of our pricing strategy. The ideal candidate is a relentless problem solver with strong technical skills and the ability to create robust data solutions end-to-end. They should be energized by the chance to solve open-ended, high-impact research questions and thrive when collaborating with both technical and non-technical partners.

 If you are passionate about problem solving and want to work on a team dedicated to a culture of inclusion, growth mindset and collaboration, we need you!

 A day in the life…

 Partner with key stakeholders to understand the challenges in the pricing landscape and their current processes and workflows
 Dive deep into complex business problems and immerse yourself in Nordstrom data & outcomes
 Research analytical approaches within the pricing domain and bring forth ideas
 Work on complex and highly ambiguous projects that may connect multiple domains (e.g. pricing, financial planning, demand forecasting)
 Develop, assess, and deploy statistical and machine learning and/or optimization models that make large scale pricing recommendations
 Present findings to business senior management team to inform business strategy and decisions
 Collaborate with cross-functional teams across discipline such as business, product, engineering partners to drive high quality end-to-end solutions from ideation to productionization
 Design experiments to measure success of pricing data products & interpret findings to share with audiences of all technical abilities


 You own this if you have…

 Ph.D. or MS degree in, Statistics, Economics, Machine Learning, Operations Research, Computer Science or other quantitative fields
 3+ years of professional experience analyzing complex data, drawing conclusions, and making recommendations, with direct experience in pricing a plus
 2+ years of experience in extracting & manipulating large data sets from relational databases using SQL
 Experience developing and implementing statistical and machine learning algorithms (e.g. regression, classification and/or clustering) from inception to deployment
 Familiarity with experimental design and the ability to identify, compute and validate the appropriate metrics to measure success
 Demonstrated success working in a highly collaborative technical environment (e.g., code sharing, using revision control, contributing to team discussions/workshops, and collaborative documentation)
 Passion and aptitude for turning complex business problems into concrete hypotheses that can be answered through rigorous data analysis and experimentation
 Proficient coding skills in Python or R
 Expertise in analytical storytelling and stellar communications skills


 #LI-EB1

 We’ve got you covered…

 Our employees are our most important asset and that’s reflected in our benefits. Nordstrom is proud to offer a variety of benefits to support employees and their families, including:

 Medical/Vision, Dental, Retirement and Paid Time Away
 Life Insurance and Disability
 Merchandise Discount and EAP Resources


 A few more important points...

 The job posting highlights the most critical responsibilities and requirements of the job. It’s not all-inclusive. There may be additional duties, responsibilities and qualifications for this job.

 Nordstrom will consider qualified applicants with criminal histories in a manner consistent with all legal requirements.

 Applicants with disabilities who require assistance or accommodation should contact the nearest Nordstrom location, which can be identified at www.nordstrom.com.

 © 2022 Nordstrom, Inc

 Current Nordstrom employees: To apply, log into Workday, click the Careers button and then click Find Jobs.

 Pay Range Details

 The pay range(s) below are provided in compliance with state specific laws. Pay ranges may be different in other locations.
 California: $130,000-$201,500 Annually, Colorado: $114,000-$176,500 Annually, Washington: $130,000-$201,500 Annually
  This position may be eligible for performance-based incentives/bonuses. Benefits include 401k, medical/vision/dental/life/disability insurance options, PTO accruals, Holidays, and more. Eligibility requirements may apply based on location, job level, classification, and length of employment. Learn more in the Nordstrom Benefits Overview by copying and pasting the following URL into your browser: https://careers.nordstrom.com/pdfs/Ben_Overview_17-19.pdf

",114000,"['python', 'machine learning', 'sql']"
SME Data Scientist,ManTech International Corporation,Remote,Full-time,"
Secure our Nation, Ignite your Future 

Each day U.S. Customs and Border Protection (CBP) oversees the massive flow of people, capital, and products that enter and depart the United States via air, land, sea, and cyberspace. The volume and complexity of both physical and virtual border crossings require the application of solutions to promote efficient trade and travel. Further, effective solutions help CBP ensure the movement of people, capital, and products is legal, safe, and secure. 

In response to this challenge, ManTech, as a trusted mission partner of CBP, seeks capable, qualified, and versatile data scientists to help lead the development and delivery of high-quality predictive modelling solutions. Successful applicants will serve as recognized subject matter experts in the application of quantitative methods, machine learning algorithms, and predictive models to address complex national and homeland security challenges. They will help our team to leverage large structured and unstructured datasets to develop and operationalize models, tools, and applications that drive optimized decision making. Project tasks include data collection, mining, data and text analytics, clustering analysis, pattern recognition and extraction, automated classification and categorization, and entity resolution to implement and enhance automated risk assessment. The products we develop provide actionable insight with real and immediate impact on the safety and security of the United States, its citizens, visitors, and economy. 

The strongest applicants will offer multiple years of experience in highly dynamic, threat/risk driven operating environments. They will also have a proven track record of delivering production ready decision support tools and applications employed in the field and by mission-support entities. Further, highly competitive applicants will have a demonstrated capacity to: work closely and collaboratively with mission stakeholders; respond to emergent, mission-driven changes in priorities and expected outcomes; and, apply new and emerging tools and techniques. Within three - six months of joining the project, data scientists will be expected to: 

Perform hands-on analysis and modeling involving the creation of intervention hypotheses and experiments, assessment of data needs and available sources, determination of optimal analytical approaches, performance of exploratory data analysis, and feature generation (e.g., identification, derivation, aggregation). 
Collaborate with mission stakeholders to define, frame, and scope mission challenges where big data interventions may offer important mitigations and develop robust project plans with key milestones, detailed deliverables, robust work tracking protocols, and risk mitigation strategies. 
Demonstrate proficiency in extracting, cleaning, and transforming CBP transactional and mission data associated within an identified problem space to build predictive models as well as develop appropriate supporting documentation. 
Leverage knowledge of a variety of statistical and machine learning techniques and methods to define and develop programming algorithms; train, evaluate, and deploy predictive analytics models that directly inform mission decisions. 
Execute projects including those intended to identify patterns and/or anomalies in large datasets; perform automated text/data classification and categorization as well as entity recognition, resolution and extraction; and named entity matching. 
Brief project management, technical design, and outcomes to both technical and non-technical audiences including senior government stakeholders throughout the model development/ project lifecycle through written as well as in-person reporting. 

Education: 

Bachelor’s Degree (required), Master’s or Ph.D. degree (preferred) in operations research, industrial engineering, mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience. 
Qualifications (Degree/years):  HS Diploma/GED and 15+ years  AS/AA and 13-18 years  BS/BA and 7-12 years  MS/MA/MBA and 5-9 years  PhD/Doctorate and 3-7 years  

Required Qualifications 

5+ years of related experience 
Experience in developing machine learning models and applying advanced analytics solutions to solve complex business problems 
Experience with programming languages including: R, Python, Scala, Java. 
Proficiency with SQL programming 
Experience constructing and executing queries to extract data in support of EDA and model development 
Proficiency with statistical software packages including: SAS, SPSS Modeler, R, WEKA, or equivalent 
Experience with pattern recognition and extraction, automated classification, and categorization 
Experience with entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation) 
Experience with unsupervised and supervised machine learning techniques and methods 
Experience performing data mining, analysis, and training set construction 


Desired Qualifications 

Proficiency with Unsupervised Machine Learning methods including Cluster Analysis (e.g., K-means, K-nearest Neighbor, Hierarchical, Deep Belief Networks, Principal Component Analysis), Segmentation, etc. 
Proficiency with Supervised Machine Learning methods including Decision Trees, Support Vector Machines, Logistic Regression, Random/Rotation Forests, Categorization/Classification, Neural Nets, Bayesian Networks, etc. 
Experience with pattern recognition and extraction, automated classification, and categorization 
Experience with entity resolution (e.g., record linking, named-entity matching, deduplication/ disambiguation) 
Experience with visualization tools and techniques (e.g., Periscope, Business Objects, D3, ggplot, Tableau, SAS Visual Analytics, PowerBI) 
Experience with big data technologies (e.g., Hadoop, HIVE, HDFS, HBase, MapReduce, Spark, Kafka, Sqoop) 
Master’s Degree in mathematics, statistics, computer science/engineering, or other related technical fields with equivalent practical experience 

Clearance: 
Selected applicants must be a US Citizen and able to obtain and maintain a U.S. Customs and Border Protection (CBP) suitability. 
The projected compensation range for this position is $105,900-$175,800. There are differentiating factors that can impact a final salary/hourly rate, including, but not limited to, Contract Wage Determination, relevant work experience, skills and competencies that align to the specified role, geographic location (For Remote Opportunities), education and certifications as well as Federal Government Contract Labor categories. In addition, ManTech invests in it’s employees beyond just compensation. ManTech’s benefits offerings include, dependent upon position, Health Insurance, Life Insurance, Paid Time Off, Holiday Pay, Short Term and Long Term Disability, Retirement and Savings, Learning and Development opportunities, wellness programs as well as other optional benefit elections. 
 
For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone. 























ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law. 

If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services. 

If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access






















",105900,"['python', 'machine learning', 'tableau', 'sql', 'kafka', 'hadoop']"
Data and Quality Supervisor - Research Scientist Supervisor 2,State of Minnesota,MN,Full-time,"



Job Details





Working Title: Data and Quality Supervisor Job Class: Research Scientist Supervisor 2 Agency: Health Department

Who May Apply: Open to all qualified job seekers
Date Posted: 11/15/2023
Closing Date: 12/06/2023
Hiring Agency/Seniority Unit: Health Department / Health-MMA
Division/Unit: Public Health Laboratory / PHL NBS Qual/Data Staff
Work Shift/Work Hours: Day Shift / 8:00 am - 4:30 pm
Days of Work: Monday - Friday
Travel Required: No
Salary Range: $36.72 - $52.79 / hourly; $76,671 - $110,225 / annually
Classified Status: Classified
Bargaining Unit/Union: 216 - Middle Management Association/MMA
FLSA Status: Exempt - Executive
Telework Eligible: No
Designated in Connect 700 Program for Applicants with Disabilities: Yes

 Make a difference in the lives of Minnesotans.
 The work you’ll do is more than just a job. Join the talented, engaged and inclusive workforce dedicated to creating a better Minnesota.






 Job Summary





Join the mission-driven team at the Public Health Laboratory and promote and protect the health of all Minnesotans! The purpose of the Data and Quality Supervisor is to provide management, direction, and leadership for the Data and Quality unit in the Newborn Screening Section at the Public Health Laboratory. The incumbent will represent MDH in public forums, including presentations at conferences and, when necessary, engagement with local and national media.
 The position leads all activities in the collection, analysis, and transmission of data; retention and management of records; as well as regulatory and quality system compliance. 
These leadership activities include:

Directs and prioritizes all staff activities. 
Investigates, evaluates, and implements processes to continually improve newborn screening data use and quality system. 
Incorporates continuous quality control/quality assurance measures.
Researches and applies statistics and data analytics in the determination of program performance.
Collaborates with key newborn screening stakeholders. 

All positions within the MDH Public Health Lab will work to cultivate an inclusive work environment for all, with respect to diversity and equity.






 Qualifications



Minimum Qualifications
 Experience in these areas must be clearly stated on your resume to be considered.

Supervisory or other leadership experience OR completion of a leadership development program (such as Emerging Leaders Institute, etc.)
3 years of experience with data management, analytic methods, or records management systems.
Experience in Newborn Screening

 Previous experience and understanding below is required to be considered a candidate and will be assessed during the interview process:

Knowledge of best practices for data visualizations
Experience working with a LIMS (laboratory information management system)
Knowledge of health information technology trends, requirements, and standards
An understanding of national privacy standards (i.e., HIPAA) as they pertain to conduction of Newborn Screening in the State of Minnesota to confirm program compliance
Understand diversity, equity, and inclusion principles, and how they can be applied in the workplace to promote an inclusive work environment for all

 Preferred Qualifications

An understanding of Minnesota Statutes 144.125-128 and 13.3805, Minnesota Rules 4615.0300-4615.0700
Knowledge of MDH record retention schedule and applicable statutes
Experience with newborn hearing screening, heart screening, and bloodspot testing for diseases in newborns
Experience working with quality for a laboratory and knowledge of CMS and CLIA regulations
Experience working with Tableau and creating data visualizations and dashboards
Experience performing internal audits for a laboratory

 Additional Requirements
 This position requires successful completion of a background check.






 Application Details



How to Apply 
Select “Apply for Job” at the top of this page. If you have questions about applying for jobs, contact the job information line at 651-259-3637 or email careers@state.mn.us. For additional information about the application process, go to http://www.mn.gov/careers. 
If you have questions about the position, contact Elizabeth Huckins at elizabeth.huckins@state.mn.us or 651-201-5609. 
To receive consideration as a Connect 700 Program applicant, apply online, email the Job ID#, the Working Title and your valid Proof of Eligibility Certificate by the closing date to Elizabeth Huckins at elizabeth.huckins@state.mn.us. 
About Health Department 
Come work for one of the best public health systems in the nation and you will contribute to our mission to protect, maintain and improve the health of all Minnesotans. We are working hard to achieve our vision for health equity in Minnesota, where all communities are thriving and all people have what they need to be healthy. 
Why Work for Us 
Diverse Workforce 
We are committed to continually developing a workforce that reflects the diversity of our state and the populations we serve. The varied experiences and perspectives of employees strengthen the work we do together and our ability to best serve the people of Minnesota. 
A recent engagement survey of State of Minnesota employees found: 

95% of employees understand how their work helps achieve their agency’s mission 
91% of employees feel trusted to do their jobs 
88% of employees feel equipped to look at situations from other cultural perspectives when doing their job 
87% of employees report flexibility in their work schedule 

Comprehensive Benefits 
Our benefits aim to balance four key elements that make life and work meaningful: health and wellness, financial well-being, professional development, and work/life harmony. As an employee, your benefits may include: 

Public pension plan 
Training and professional development 
Paid vacation and sick leave 
11 paid holidays each year 
Paid parental leave 
Low-cost medical and dental coverage 
Prescription drug coverage 
Vision coverage 
Wellness programs and resources 
Employer paid life insurance 
Short-term and long-term disability 
Health care spending and savings accounts 
Dependent care spending account 
Tax-deferred compensation 
Employee Assistance Program (EAP) 
Tuition reimbursement 
Federal Public Service Student Loan Forgiveness Program 

Programs, resources and benefits eligibility varies based on type of employment, agency, funding availability, union/collective bargaining agreement, location, and length of service with the State of Minnesota. 

AN EQUAL OPPORTUNITY EMPLOYER 
Minnesota state agencies are equal opportunity, affirmative action, and veteran-friendly employers. The State of Minnesota recognizes that a diverse workforce is essential and strongly encourages qualified women, minorities, individuals with disabilities, and veterans to apply. 
We will make reasonable accommodations to all qualified applicants with disabilities. If you are an individual with a disability who needs assistance or cannot access the online job application system, please contact the job information line at 651-259-3637 or email careers@state.mn.us and indicate what assistance is needed.




",73440,['tableau']
Sr. Data Scientist,Saks,NY,Full-time,"Who We Are:
 Saks is a world-renowned luxury ecommerce destination. The company’s unique approach combines a focus on the digital customer experience with a strong connection to a network of extraordinary stores that extends that seamless experience into the real world.On its website and app, Saks offers an unparalleled selection of curated merchandise across fashion for women and men, beauty, jewelry, home décor and more. In addition to the shopping experience, customers come to Saks for inspiring editorial content, access to digital stylists, lifestyle experiences and other world-class services. The company is currently in the midst of a dramatic expansion, driven by significant enhancements to its platforms and offerings, with the goal of becoming the preeminent destination for luxury internationally. 


Role Summary:
 Saks.com LLC seeks Data Scientist in New York, NY, to analyze large amounts of information to discover trends and patterns to help Saks’ leadership team make data-driven decisions. Requirements: Master’s degree or foreign equivalent in Mathematics, Statistics or a related field and three (3) years of experience in the job offered or related occupation utilizing Structured Query Language (SQL), Python, R, and other programming languages to conduct business analytics tasks such as data processing, EDA (exploratory data analysis) and reporting. One (1) full year of experience designing and conducting Hypothesis Experiments for marketing campaign pilots and provide insights to improve business performance; utilizing machine learning technologies such as Tensorflow, Keras, and PyTorch to build algorithms for site personalization and advanced marketing strategies; utilizing cloud based tools such as Airflow, Docker, Kubernetes, and Snowflake to build MLops pipelines and for model production and integration with other applications; and applying algorithms including K Nearest Neighbors, Random Forest, GBM, Neural Networks, boosted trees, LDA, collaborative filtering, Bayesian to resolve business problems. Telecommuting and/or working from home may be permissible pursuant to company policies. When not telecommuting, must report to work site. Offered salary is between $135,782.00 and $140,000.00. Submit resume to jobs@saks.com. Please indicate job code KZ10302023EW. 


Your Life and Career at Saks:
 Exposure to rewarding career advancement opportunities 
A culture that promotes a healthy, fulfilling work/life balance 
Benefits package for all eligible full-time employees (including medical, vision and dental). 
An amazing employee discount 

 Thank you for your interest in Saks. We look forward to reviewing your application. 

 Saks provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Saks complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. 

 Saks welcomes all applicants for this position. Should you be individually selected to participate in an assessment or selection process, accommodations are available upon request in relation to the materials or processes to be used. 

 Saks.com is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. 



The above expected salary range may have some variability based upon factors including, but not limited to, a candidate’s overall experience, qualifications, and geographic location. If you are interested in the role, we encourage you to apply and, if selected to move forward in the interview process, you will have a chance to speak with our recruitment team regarding your specific salary expectations.
",135782,"['tensorflow', 'pytorch', 'python', 'machine learning', 'docker', 'sql', 'airflow']"
AI/ML Engineer II,kraken,Remote,Full-time,"


Location

     United States - Remote, Europe - Remote, Canada - Remote
   


 Type

     Full time
   


 Department


      Engineering
    
 AI & Machine Learning



 Compensation


 $135K – $203K




      This is the target annual salary range for this role. This range is not inclusive of other additional compensation elements, such as our Bonus program, Equity program, Wellness allowance, and other benefits [US Only] (including medical, dental, vision and 401(k)).
    


      The compensation range provided is influenced by various factors and represents the initial target range. Our salary offerings are dynamic and we strive to ensure that our base salary and total compensation package aligns and recognizes the top talent we aim to attract and retain. The compensation package of the successful candidate is based on various factors such as their skillset, experience, and job scope.
    





 





 Building the Future of Crypto

 Our Krakenites are a world-class team with crypto conviction, united by our desire to discover and unlock the potential of crypto and blockchain technology.

 What makes us different? 
Kraken is a mission-focused company rooted in crypto values. As a Krakenite, you’ll join us on our mission to accelerate the global adoption of crypto, so that everyone can achieve financial freedom and inclusion. For over a decade, Kraken’s focus on our mission and crypto ethos has attracted many of the most talented crypto experts in the world.

 Before you apply, please read the Kraken Culture page to learn more about our internal culture, values, and mission. 

As a fully remote company, we have Krakenites in 60+ countries who speak over 50 languages. Krakenites are industry pioneers who develop premium crypto products for experienced traders, institutions, and newcomers to the space. Kraken is committed to industry-leading security, crypto education, and world-class client support through our products like Kraken Pro, Kraken NFT, and Kraken Futures.

 Become a Krakenite and build the future of crypto!
 Proof of work

 The team

 Kraken is looking for an experienced Machine Learning engineer to join our AI/ML Team in the centralized Data organization. In this role you will be applying cutting edge AI/ML technology to solving the most complex and exciting problems in the quickly growing and evolving crypto industry. We are looking for an extremely strong communicator and team-player, who is able to break down large complex problems into smaller more manageable problems-to-solve. You will take initiative to identify business problems, explore different ways to resolve issues, and systematically find the most efficient and effective way to deliver business impact.

 The Opportunity



        Assist in designing, implementing, and deploying Machine Learning solutions to solve complex problems and deliver real business value ie. revenue, engagement and customer satisfaction.
      


        Collaborate with data scientists, software engineers, and business partners to identify AI/ML opportunities for improving operation scalability and efficiency.
      


        Assist in developing production-grade ML models to power personalized customer experience, content recommendation, fraud detection/prevention and more.
      


        Support the monitoring and improvement of model performance via data enhancement, feature engineering, experimentation and online/offline evaluation.
      


        Stay up-to-date in machine learning, and artificial intelligence trends and technologies, all while contributing to the growth of AI/ML in the Crypto industry.
      


 Skills you should HODL



        Experience in building, deploying, measuring, and maintaining machine learning models.
      


        Familiarity with the software development lifecycle, DevOps (build, continuous integration, deployment tools) and best practices.
      


        Programming skills in Python, Scala, Go or other languages.
      


        Good written and verbal communication skills and interpersonal skills.
      


        Experience or familiarity with ML frameworks, such as scikit-learn, Tensorflow, PyTorch.
      


        Experience or familiarity with Big Data tools – Spark, S3, Hadoop.
      


        Experience or familiarity with MLOps platforms, such as Kubeflow or MLFlow, is a plus.
      


        Knowledge of GenAI tools, such as Langchain, LlamaIndex, and open source Vector DBs, is a plus.
      


        Bachelor's degree in Computer Science, Machine Learning or related field.
      


        A minimum of 2 years of experience in AI/ML engineering, with a focus on learning and skill development.
      

 Location Tagging: #US #EU #LI-Remote

 Kraken is powered by people from around the world and we celebrate all Krakenites for their diverse talents, backgrounds, contributions and unique perspectives. We hire strictly based on merit, meaning we seek out the candidates with the right abilities, knowledge, and skills considered the most suitable for the job. We encourage you to apply for roles where you don't fully meet the listed requirements, especially if you're passionate or knowledgable about crypto!

 As an equal opportunity employer, we don’t tolerate discrimination or harassment of any kind. Whether that’s based on race, ethnicity, age, gender identity, citizenship, religion, sexual orientation, disability, pregnancy, veteran status or any other protected characteristic as outlined by federal, state or local laws.




",135000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'hadoop']"
Senior Data Analyst,Integral Ad Science,IL,Full-time,"
Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for Senior Data Analyst. You will be responsible for ongoing monitoring and surfacing of new threats in the digital advertising ecosystem. This role and team will have extensive interaction with large data sets (we monitor hundreds of thousands of transactions per second and collect tens of billions of events each day)
 Integral Ad Science (IAS) is a global technology and data company that builds verification, optimization, and analytics solutions for the advertising industry and we're looking for Data Analysts. You will be responsible for ongoing monitoring and surfacing of new threats in the digital advertising ecosystem. This role and team will have extensive interaction with large data sets (we monitor hundreds of thousands of transactions per second and collect tens of billions of events each day) What you'll get to do:

Analyze and investigate impression level data in order to conceptualize stories, and write research reports, articles, blogs and bulletins
Partner with Marketing to drive publication and distribution of noteworthy stories coming from internal investigations
Apply business insight to research for C-Level thought leadership stories that define high level trends by industry, vertical or geographic area
Stay on top of emerging threats that could be first to market blogs
Assist product management, data science, and development in product/solution planning and prioritization

Qualifications/Requirements:

Bachelors or Master's degree in data science, computer science, computer engineering, digital forensics, cyber security, telecommunications, information assurance or security studies
At least 7+ years data analysis / data mining experience
Experience with ad tech strong preferred
Experience with the Threat Landscape and familiarity with threat tracking, attribution, and reporting
Ability to read/write Regex and Yara
Familiarity with ESX/VMware virtualization environments
Excellent analytical abilities and a strong ability to think creatively when approaching issues
Strong SQL skills including building functions & procedures, writing complex queries, and using SQL as an investigative tool
Familiarity with Python (Pandas/Numpy)
Ability to synthesize technical information about large datasets to communicate both qualitatively and quantitatively
Strong data mining skills
Strong interpersonal and presentation skills required – both oral and written, with the ability to educate others about complex technology/methodologies and clearly articulate business level benefits/impacts.
Strong verbal presentation and writing skills, including the demonstrated ability to write clear and concise text

New York Applicants: The salary range for this position is $100,000 - $172,000, actual pay may vary based on experience or geographic location.
 About Integral Ad Science

Integral Ad Science (IAS) is a leading global media measurement and optimization platform that delivers the industry's most actionable data to drive superior results for the world's largest advertisers, publishers, and media platforms. IAS's software provides comprehensive and enriched data that ensures ads are seen by real people in safe and suitable environments, while improving return on ad spend for advertisers and yield for publishers. Our mission is to be the global benchmark for trust and transparency in digital media quality. For more information, visit integralads.com.

Equal Opportunity Employer:
 IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.
 California Applicant Pre-Collection Notice:
 We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.
 To learn more about us, please visit http://integralads.com/ and https://muse.cm/2t8eGlN
 Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership.
 #LI-Hybrid
",100000,"['python', 'numpy', 'pandas', 'sql']"
Delivery Consultant - Sterling Data Exchange,IBM,TX,Full-time,"

Introduction
 This role has a thorough understanding of the nature of the business problems in a wide range of industries, and the products and solutions that provide value in solving those problems. Is knowledgeable in the trends and directions of the industry, the marketplace, and the players. The main focus will be to leverage their product and technical expertise with the IBM products to design, develop and customize solutions to fit each customer’s unique business and technical environments.
  

Your Role and Responsibilities
 This role has a thorough understanding of the nature of the business problems in a wide range of industries, and the products and solutions that provide value in solving those problems. Is knowledgeable in the trends and directions of the industry, the marketplace, and the players. The main focus will be to leverage their product and technical expertise with the IBM products to design, develop and customize solutions to fit each customer’s unique business and technical environments.
  

Required Technical and Professional Expertise


 Required skills include (but are not limited to) the following:
   







Direct experience in the following IBM products and technologies: IBM B2BI/SFG, IBM ITX/ITXA, IBM SSP/SEAS, ICC, PEM/PCM, Gentran, Connect Direct/Enterprise.




Strong knowledge of integration concepts and commonly used patterns, able to apply such knowledge in solution design




Experience or strong knowledge of communication and data handling protocols (AS2, PGP/GPG, S/MIME, HTTPS, FTPS/SFTP/SCP/OFTP, POP3/SMTP, Web Services/SOAP/REST, WebDAV, etc.)




Experience or strong knowledge of industry data standards (ACH, ANSI X12, EDIFACT, HIPAA, RosettaNet, SWIFT, TRADCOMS, etc.) 




Experience or strong knowledge of application programming/scripting technologies (Java/J2EE, AJX, ASP, BPEL/BPML, SQLXSLT, Linux/Unix/Windows shell scripts)




Demonstrated experience with enterprise database technologies like Oracle RAC, DB2, and MS SQL Server Enterprise




Highly skilled in complex problem solving, critical thinking, applying judgment, building consensus, and decision making




Excellent communication and interpersonal skills including the ability to work effectively with technical and non-technical staff




Strong business analysis, technical analysis, analytical thinking and decision-making ability









Preferred Technical and Professional Expertise



 Preferred skills include (but are not limited to) the following:
    







Knowledge of Cloud technologies




Knowledge of popular ERP systems, such as SAP




Strong experience working with senior IT and non-IT executives on a daily basis




Demonstrated experience in multi-shore management, teamwork and execution




B.S. in Computer Science, Software Engineering, or equivalent



Experience and strong business acumen with competing (non-IBM) integration and managed file transfer technologies.











About Business Unit
 IBM Software infuses core business operations with intelligence—from machine learning to generative AI—to help make organizations more responsive, productive, and resilient. IBM Software helps clients put AI into action now to create real value with trust, speed, and confidence across digital labor, IT automation, application modernization, security, and sustainability. Critical to this is the ability to make use of all data, because AI is only as good as the data that fuels it. In most organizations data is spread across multiple clouds, on premises, in private datacenters, and at the edge. IBM’s AI and data platform scales and accelerates the impact of AI with trusted data, and provides leading capabilities to train, tune and deploy AI across business. IBM’s hybrid cloud platform is one of the most comprehensive and consistent approach to development, security, and operations across hybrid environments—a flexible foundation for leveraging data, wherever it resides, to extend AI deep into a business.
 



 Your Life @ IBM
 In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.
   Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.
 Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.
 Are you ready to be an IBMer?



 About IBM
 IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.
  
 Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. 
  
 At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.
 



 Location Statement
 IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:
  


Healthcare benefits including medical & prescription drug coverage, dental, vision, and mental health & well being
 - Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short & long- term disability coverage, and opportunities for performance based salary incentive programs
  

Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law
Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals
Diverse and inclusive employee resource groups, giving & volunteer opportunities, and discounts on retail products, services & experiences

 The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year. 
  
 We consider qualified applicants with criminal histories, consistent with applicable law.
 



 Being You @ IBM
 IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
 
",101000,"['machine learning', 'sql']"
Data Science Engineer,GE Renewable Energy,NY,Full-time,"
Job Description Summary The Lead Fleet Analytics Developer will be responsible for developing analytics and data visualizations for GE Renewable Energy’s in-service wind fleet, as well as supporting contractual customer reporting. You will lead automation efforts, streamline current processes, and troubleshoot issues arising from analysis of data generated by GE’s global fleet of wind turbines.
 
 Job Description
 About us: GE’s Onshore Wind business has a total installed base of more than 50,000 wind turbines in more than 35 counties, with 100+ GW of global installed capacity. We harness increased onshore wind energy potential through a broad family of turbines that are uniquely suited for a variety of wind environments, including Cypress, GE’s most powerful onshore wind turbine, and GE’s 2MW platform, which has more than 20GW installed and in operation today. We are committed to our customers’ success in wind, offering a broad portfolio of products and services that make renewables the energy of choice for a cleaner future.

 Essential Responsibilities:
 In this role, you will:

 Develop essential tools that will support improvement of key fleet metrics (i.e. availability, down time, fault rates, production, etc.)
 Develop SQL queries against a data warehouse, Amazon Redshift and MS SQL database
 Streamline and automate processes and reports, including improvements to proprietary message handling logic, monthly and weekly customer reporting, and efficiency metrics
 Provide engineering and services support teams with actionable data and analysis to enable quick response and effective technical troubleshooting
 Produce customer-facing analytics and applications using a variety of programming languages
 Maintain and expand on existing tools and software
 Manage local databases and assist in management of data infrastructure
 Interact with key stakeholders in the business (Sales, Commercial, Services) to develop data standardization practices


 Required Qualifications:

 Bachelor’s Degree in Computer Science, Mathematics, Statistics, Mechanical Engineering, Electrical Engineering, or related technical field from an accredited college or university
 Minimum of 2 years experience in development with SQL, Python, Java, Matlab, R, or other comparable tools


 Desired Characteristics:

 Strong analytical skills, with the ability to improve / automate existing processes
 Familiarity with wind turbine performance metrics, including availability, fault rate, production ratio, etc.
 Working knowledge of Java and Python and ability to contribute to existing environment
 Ability to scrutinize data for quality and consistency
 Background in statistical analysis and significance testing
 Strong communication skills
 Demonstrated ability to deliver on commitments, on time and with high quality
 Ability to work independently and anticipate customer needs
 High flexibility and motivation to succeed


 The salary range for this position is $102,200 - $170,300 USD Annual. The specific salary offered to a candidate may be influenced by a variety of factors including the candidate’s experience, their education, and the work location. In addition, this position is eligible for a 10% variable incentive bonus. Available health and welfare benefits include healthcare, prescription drug, dental, and vision coverage; savings account options (such as a Health Care Flexible Savings Account, Health Reimbursement Account, Limited Purpose Flexible Spending Account, and Dependent Care Flexible Spending Account); and an employee assistance program. Additional benefits include a defined contribution 401(k) plan, employee life insurance, optional dependent life insurance, employee accidental death or dismemberment insurance coverage, short-term disability, optional long-term disability, pre-tax transportation/commuter program, paid holidays, paid time off, parental leave, a layoff plan for salaried employees, tuition refund program, use of CariLoop, adoption assistance, optional identity theft prevention insurance, optional personal legal assistance, and optional personal excess liability insurance.

 Additional Information







 GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.















 GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable). 















Relocation Assistance Provided: No







",102200,"['python', 'sql']"
Sr. Data Analyst,BAXTER,IL,Full-time,"
This is where you save and sustain lives 

At Baxter, we are deeply connected by our mission. No matter your role at Baxter, your work makes a positive impact on people around the world. You’ll feel a sense of purpose throughout the organization, as we know our work improves outcomes for millions of patients.

 Baxter’s products and therapies are found in almost every hospital worldwide, in clinics and in the home. For over 85 years, we have pioneered significant medical innovations that transform healthcare.

 Together, we create a place where we are happy, successful and inspire each other. This is where you can do your best work.

 Join us at the intersection of saving and sustaining lives— where your purpose accelerates our mission.

 Your Role at Baxter:

 The Sr. Data Analyst is responsible for partnering across regions and functions to perform detailed analysis on various datasets. This role will collaborate with the global service commercial and marketing team, field service personnel, project management and all levels of service leadership to provide data and metrics that help guide business decisions.

 Your Team:

 Baxter offers dental, medical, and vision insurance, paid time off, parental leave, and more.

 What you'll be doing:

 Designs, develops, and maintains ongoing metrics, reports, analyses, dashboards applying Tableau, Power BI, SQL and other tools as needed.
 Performs detailed data analysis using SQL language and various datasets.
 Analyzes and manipulates data in Excel and handles and merges multiple Excel data files without error or data corruption.
 Partners and collaborates with the global service commercial and marketing team, field service personnel, project management and all levels of service leadership to provide data and metrics that help guide business decisions.
 Analyzes data sets, highlights anomalies in the data that could lead to business efficiency.
 Understands business partners data needs, captures, analyzes, and reports accurate business and financial data per user requirements, utilizes critical thinking skills to interpret the data and provides end user training on how to interpret and use data workbooks.
 Assists in continuous improvement projects, training, and initiatives that drive business and financial results.
 Travel up to 10% of the time for team meetings.


 What you'll bring:

 Bachelor’s degree in Business Administration, Information Management, Computer Science, Statistics, or Finance, required.
 3-5 years of experience within data analytics or related field, required.
 3+ years of experience with PowerBI, Microsoft SQL Server, T-SQL, Tableau, or similar report visualization tools and general report generation and relevant analytics experience, preferred.
 Experience with Power Automate, Python programming language, or R-programming language, preferred.
 Proficiency with MS Office (Word, Excel, PowerPoint).
 Excellent communication and strong interpersonal skills.
 Ability to work in a team-oriented environment, often cross-functionally, and handle tasks concurrently, with a high attention to detail.
 Ability to define problems, determine solutions and follow through to completion.
 Analytical background with ability to understand statistical concepts.


 We understand compensation is an important factor as you consider the next step in your career. At Baxter, we are committed to equitable pay for all employees, and we strive to be more transparent with our pay practices. The estimated base salary for this position is $80,000 - $110,000 annually. The estimated range is meant to reflect an anticipated salary range for the position. We may pay more or less than of the anticipated range based upon market data and other factors, all of which are subject to change. Individual pay is based on upon location, skills and expertise, experience, and other relevant factors. This position may also be eligible for discretionary bonuses. For questions about this, our pay philosophy, and available benefits, please speak to the recruiter if you decide to apply and are selected for an interview.

 #LI-JE1

 The successful candidate for this job may be required to verify that he or she has been vaccinated against COVID-19, subject to reasonable accommodations for individuals with medical conditions or religious beliefs that prevent vaccination, and in accordance with applicable law.

 Equal Employment Opportunity

 Baxter is an equal opportunity employer. Baxter evaluates qualified applicants without regard to race, color, religion, gender, national origin, age, sexual orientation, gender identity or expression, protected veteran status, disability/handicap status or any other legally protected characteristic.  EEO is the Law EEO is the law - Poster Supplement Pay Transparency Policy

 Reasonable Accommodations  Baxter is committed to working with and providing reasonable accommodations to individuals with disabilities globally. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please click on the link here and let us know the nature of your request along with your contact information.

 Recruitment Fraud Notice  Baxter has discovered incidents of employment scams, where fraudulent parties pose as Baxter employees, recruiters, or other agents, and engage with online job seekers in an attempt to steal personal and/or financial information. To learn how you can protect yourself, review our Recruitment Fraud Notice. 118048
  #LI-Remote
",80000,"['python', 'tableau', 'sql']"
"Sr. Data Scientist, CRM & Loyalty",Yum! Brands,TX,Full-time,"
As a CRM / Customer Engagement and Retention (CER) Data Analyst, you’ll closely support the CER team in making data-driven decisions about marketing campaign execution. This position will own critical analyses and integration projects from beginning to end, including opportunity identification, problem scoping, analysis framing / execution, and synthesizing results to project stakeholders as well as internal leadership.

Analyze CRM & Loyalty campaigns to provide actionable recommendations to the CER team
Identify areas of opportunity based on Loyalty/CRM analytics, customer segmentations, deployment tactics and audience targeting
Assist in creating test and learn plans to facilitate tactical optimization and strategic changes to our programs to increase customer annual value (CAV)
Partner closely with data science and loyalty vendor partners to monitor critical KPI’s

EDUCATION
 Bachelor’s degree in computer science, marketing, databases, or a related field with 4+ years of experience working in analytics positions in performance-driven marketing, e-commerce, or consulting organizations.
 MINIMUM REQUIREMENTS AND EXPERIENCE

Master Level of Experience using SQL; able to easily query complex data and construct data models as needed and experience working with relational databases (Snowflake), query authoring (SQL) as well as working familiarity with a variety of databases
Comfortable with multi-faceted analytics projects, integrating data from multiple sources, and synthesizing & presenting actionable insights from a variety of data-points
Working knowledge of a CDP (Treasure Data, Twilio, Bloomreach, Convertlab, Salesforce Data Cloud, etc.)
Working knowledge of at least one commonly applied BI tool (Tableau, Power BI, Domo, etc.) Digital Marketing -tools (e.g. Braze, Punchh, etc.) and Project Management tools (e.g. Atlassian, Jira, etc.)
Experience with data management and manipulation tools (Python, Scala, or R) and a desire to learn more
Excellent communication skills with a record of successfully advocating to turn insights into action, as well as the ability to synthesize quantitative results to determine implications and make actionable strategic recommendations

Salary Range: $108,700 to $136,300 annually + bonus eligibility. This is the expected salary range for this position. Ultimately, in determining pay, we'll consider the successful candidate’s location, experience, and other job-related factors.
 Benefits: Employees (and their eligible family members) may enroll in the following types of insurance coverage: medical, dental, vision, legal, and accidental death and dismemberment, as well as FSA/HSA (depending on enrolled medical plan). Yum! also provides short-term disability, long-term disability, and life insurance. Employees may enroll in our 401(k) plan. Yum! provides 4 weeks of vacation, paid sick leave, 10 paid holidays, a floating day off and 2 paid days for volunteer time each calendar year. To learn more about working at Yum! -Click here.  At Yum!, one of our core values is to Believe in ALL People. This means seeing the value in everyone and unlocking their full potential to be their best self. YUM! Brands, Inc. (including its subsidiaries Yum Restaurant Services Group, LLC (“YRSG”) and Yum Connect, LLC (“Yum Digital and Technology”)(collectively, “Yum”) is proud to be an equal opportunity employer and is committed to equity, inclusion, and belonging for all dimensions of diversity. We do not discriminate based on race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other protected characteristic. Yum! is committed to working with and providing reasonable accommodation to applicants with disabilities or special needs.
 US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and supplement and the Pay Transparency Policy Statement.


Who We Are  Founded in 1958, Pizza Hut - a subsidiary of Yum! Brands, Inc. - now operates more than 18,000 restaurants in more than 100 countries. Pizza Hut is leading the way in providing customers with great experiences, innovating with technology and new products, as well as delivering exceptional service.


Our People & Culture
We're looking for people who LOVE pizza and thrive in a fun, past paced, and customer-centric environment. At our corporate campuses, Pizza Hut has created the perfect place for you to grow your career. Every day, you’ll work to support our franchisees and teams across the U.S., continuously challenging yourself to feed more possibilities. In return, we’ll provide professional development and career growth opportunities so that you can become your best and achieve your goals. And we’ll sweeten the deal by immersing you in our world-class recognition culture and providing a robust array of benefits, some highlights include:

 4 weeks PTO, plus standard holidays and time off to volunteer 


 Generous parental leave (16 weeks for moms, 6 weeks for dads)


 401(k) with 6% match, vested immediately


 On-site daycare


 24/7 fitness center with laundry services


 Half-day Fridays, year round


 
Giving Back
As a global company, Pizza Hut aims to make the world better by acting responsibly with respect to food, planet and people. Whether it’s donating food through the Harvest Program or supporting literacy with the Pizza Hut BOOK IT! Program – the company, our franchisees and our team members are committed to improving the communities we serve.



Pizza Hut is an equal opportunity workplace and committed to fostering an inclusive, diverse culture. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age, disability and genetic information (including family medical history).

",108700,"['python', 'tableau', 'sql']"
"Director, Data Science - Operational Research",Best Buy,GA,Full-time,"



    As a 
    Director of Data Science and Optimization, you’ll play a pivotal role in steering our organization's strategic use of data to drive innovation and efficiency. In this dynamic position, you will be responsible for leading a talented team of data scientists, guiding them in developing and implementing advanced analytics, machine learning models, and optimization algorithms. Your primary focus will be on leveraging organizational data to uncover actionable insights, improve decision-making processes and enhance operational effectiveness across various business units.
    

What you'll do

 Direct multiple teams that perform data analytics, data modeling, optimization, simulation and machine learning based on the requirements for cross-functional business clients
 Interpret data model results to provide recommendations that feed into interconnecting products and business solutions
 Integrate and finalize improvements for varying algorithmic approaches, as well as standardize methodologies within a department
 Communicate assumptions, results and implications of statistical and machine learning models that solve business problems
 Educate business clients and leaders on how recommended solutions impact other business clients by identifying interactions between components or linkages of an entire system
 Participate in business strategy creation and translate long-term business strategy into short-/mid-term business objectives. Delegate work to team members and ensure appropriate resources are allocated, may review for quality and completion.


 Basic qualifications

 Bachelor's degree in a quantitative field (e.g., mathematics, statistics, operations research, physics, economics, computer science, engineering)
 10 years of experience in data science, data analysis, data mining or other similar business functions
 4 years of experience leading data science technical efforts/teams


 Preferred qualifications

 Master’s or PhD in a quantitative field (e.g., mathematics, statistics, operations research, physics, economics, computer science, engineering)
 Foundational in software programming and data mining.
 Intermediate in data wrangling, business acumen, planning and organizing, AI and ML frameworks, deep learning and relationship management skills
 Advanced in collaborating cross functionally, validating data and solutions, applied mathematics, statistics, statistical methods and modeling, designing complex algorithms and statistical models, validating data and solutions, supervised and unsupervised learning and researching
 Experience in retail industry, or any relevant industry that handles large datasets


 What’s in it for you
 We’re committed to helping our people thrive at work and at home. We offer generous benefits that address your total well-being and provide support as you need it, especially key moments in your life.
    
 Our benefits include:
    

Competitive pay
Generous employee discount
Financial savings and retirement resources
Support for your physical and mental well-being


About us
 As part of the Best Buy team, you’ll help us fulfill our purpose to enrich lives through technology. We bring that to life every day by humanizing and personalizing tech solutions for every stage of life — in our stores, online and in customers’ homes.
    
 Our culture is built on deeply supporting and valuing our amazing employees who make it all possible. We’re committed to being a great place to work, where you can unlock unique career possibilities. Above all, we aim to provide a place where you can bring your full, authentic self to work now and into the future. Tomorrow works here.™
   



",148250,"['machine learning', 'deep learning']"
Campus Graduate 2024 - Credit & Fraud Risk Decision Science Manager Full Time,Amex,NY,Full-time,"
You Lead the Way. We’ve Got Your Back.


 With the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, you’ll learn and grow as we help you create a career journey that’s unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.


 At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.


 Join Team Amex and let's lead the way together.


 As a Data Science colleague, you have the opportunity to make your mark on technology and life at American Express. You’ll be challenged everyday as we work together to create digital products and develop actionable data-driven insights to meet the customers of tomorrow. It is an exciting opportunity for someone who wants to help shape digital experiences for one of the world’s top brands.


 Business Unit/Role Specific Info


 Where are these roles located within American Express?


 Global Decision Science : Data Science colleagues will serve as a key member of the Credit and Fraud Risk organization. We seek a thought-leader and a problem-solver who can blend business, technical, and industry standard processes when it comes to developing the analyses, models, and algorithms that power our customers’ digital experiences.


 This vital team is responsible for leading enterprise risks throughout the customer lifecycle, across our consumer and commercial businesses, and across all our global products. We develop industry-first data capabilities, build profitable decision-making frameworks, create machine learning-powered predictive models, and improve customer servicing strategies.


 Data Science roles in these teams:


 Our Decision Science teams use industry leading modeling and AI practices to predict customer behavior. We develop, deploy and validate predictive models and support the use of models in economic logic to enable profitable decisions across credit, fraud, marketing and servicing optimization engines.


 What type of work can you expect to do in Data Science at American Express?


 The specific job responsibilities would depend on the team you are selected in for a summer internship role. Broadly the role could entail some of the below listed responsibilities:

Work with extensive amounts of digital data (Web, App, API) and sophisticated tools in an industry leading Big Data environment. 
Build everything from basic reports to advanced machine learning models and algos to drive improvements to our customer’s online and mobile app experiences. 


Develop insights into customer behavior and introduce new directions to transform complex behavioral data into useful information 
Bring to bear the power of closed loop through Amex network to make decisions more intelligent and relevant 
Innovate with a focus on developing newer and better approaches using big data & machine learning solutions


 
Skills/Experience

Passion for improving end-to-end customer experience, innovation and customer first thinking 
Proven track record to frame business problems into mathematical programming problems to engineer a solution and deliver business insights 
Expertise in an analytical language (Python, R or the equivalent), and experience with databases (Hive, SQL, or the equivalent) 
Ambitious thinker who’s organized, has excellent attention to detail, and can multi-task 
Ability to blend big picture thinking with fine details and lead many stakeholders 


Willing to try new things, experiment, and share fresh perspectives 
Proficient in presentation tools, including Excel and PowerPoint 
Excellent written and verbal communication skills


 
Requirements/Qualifications

Currently enrolled in a full-time Masters/PhD degree program in a quantitative field (Computer Science, Statistics, Mathematics, Physics, Operation Research and etc.) with hands-on experience using sophisticated analytical and machine learning techniques. PhD degree with practical experiences NLP is a significant plus. 


Students must have a graduation date between December 2024 and June 2025


 
Salary Range: $80,000.00 to $155,000.00 annually + bonus + benefits


 The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.


 We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:

Competitive base salaries
Bonus incentives
6% Company Match on retirement savings plan
Free financial coaching and financial well-being support
Comprehensive medical, dental, vision, life insurance, and disability benefits
Flexible working model with hybrid, onsite or virtual arrangements depending on role and business need
20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
Free and confidential counseling support through our Healthy Minds program
Career development and training opportunities



 For a full list of Team Amex benefits, visit our Colleague Benefits Site.


 American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.


 Employment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.


 We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.


 US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and the Pay Transparency Policy Statement.


 If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.
",80000,"['python', 'machine learning', 'sql']"
Data Science Analyst,The American College of Radiology,VA,Full-time,"



Founded in 1923, the American College of Radiology® is at the forefront of radiology evolution, representing nearly 40,000 radiologists, radiation oncologists, nuclear medicine physicians and medical physicists. We are seeking energetic and innovative individuals to further reinforce our core purpose of serving patients and society by empowering members to advance the practice, science and professions of radiological care.
 If you share our core values of: Leadership • Integrity • Quality • Innovation, we want you on our team!
 ACR's Data Science Institute (DSI) was created to make patient care safer, faster, cheaper, and more precise. We do this by working with clinicians, industry and government to create the infrastructure and services that facilitate the integration of Artificial Intelligence (AI) into the clinical workflow. As AI in medical imaging moves from early adopter to general use in practice, clinicians, industry, and patients are looking to the DSI to be the honest broker to ensure a high level of quality and trust in technologies applied in healthcare.
 ACR's data science analysts work at the nexus between clinicians, industry, patient advocates, and government bodies to create, manage, and apply standards for AI in medical imaging. At the core of this work is the development and execution of the clinical AI lifecycle. The AI lifecycle encompasses a series of services and projects such as use cases for industry guidance, technical standards creation, industry analysis and research, multi-center clinical trials, and post-market monitoring of deployed AI.
 To effectively advance AI in medical imaging, the data analyst role is involved in every aspect of the DSI, from discussion with clinicians and industry to executions of studies and services.
 The new hire will:

Collaborate with scientists, ACR leadership, government regulatory bodies, vendors, and clinicians to develop standards, guidelines, and research for applying AI in healthcare.


Apply technical knowledge to guide and support the development of AI standards and requirements.


Work directly with healthcare organizations, clinicians, and industry to execute the service line the DSI performs such as Define-AI, AI Central, Assess-AI, and Certify-AI.


Work with internal teams to develop and expand services lines and programs.



 The qualified candidate will possess the following:

Bachelor’s degree in a STEM field


3+ years of directly relevant experience in developing requirements and performing system analysis


Experience with statistical methods, information classification and/or machine learning


Organizational and analytical skills


Ability to take lead on cutting edge and ever evolving domain spaces


Ability to clearly communicate ideas and solution


Strong verbal and written communication skills, including presentation skills


Ability to manage ambiguity


Ability to work as a part of a team and individually



 Preferred experience includes:

Statistical analysis


Web content management


Medical terminology


Project Management


AWS (Amazon Web Services)


Algorithm development


AI (Artificial Intelligence)


SQL


Tableau


R or Python

 ******************************************************************* Although this position will work a fully remote schedule, candidates residing in the eastern time zone will have priority consideration, so as to to maintain our standard operating hours and attend ACR's annual meeting in the spring. Remote workers must be self-motivated, possess excellent time management, and be highly organized. Reliable internet connection is a must!
 *******************************************************************
 ACR is committed to a total rewards compensation philosophy that includes base salary in addition to our full suite of comprehensive benefits (https://www.acr.org/-/media/ACR/NOINDEX/HR/ACR-Benefits-Overview.pdf). ACR’s goal is to pay competitively and equitably. It is typical for individuals to be hired in the entry to middle of the range for their role, and compensation decisions depend on each case’s circumstances. A reasonable estimate of the compensation range is $85,500 – $114,000.
 *******************************************************************
 If you would like to put your experience to great use in a professional team-oriented environment, please apply online. To learn more about ACR’s rewarding employee experience, culture, and benefits, visit: https://www.acr.org/About-ACR/Work-With-Us
 ACR offers a rewarding employee experience: innovative culture, professional growth potential, competitive compensation and an exceptional benefits package, including a defined contribution pension plan, 403(b); generous paid time off package; insurance plans with the leading providers; flexible spending; tuition reimbursement; training opportunities; and wellness reimbursement.




",85500,"['python', 'machine learning', 'tableau', 'aws', 'sql']"
Data Scientist,Booz Allen Hamilton,VA,Full-time,"


Job Description










         Location: 
        

         Norfolk,VA,US 
        



         Remote Work: 
        

         No 
        



         Job Number: 
        

         R0183963
        


















         Data Scientist
          The Opportunity:
 Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection to cancer research, to national intelligence — you know the answers are in the data.

 We have an opportunity for you to use your leadership and analytical skills to improve a client's data science capability. You’ll work closely with your client to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You’ll mentor teammates and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help leadership make informed decisions. You’ll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in building this capability.

 Join us. The world can't wait.

 You Have:

 3+ years of experience in the data science field, including providing analysis and advice
 Experience with building and optimizing big data pipelines, architectures, and data sets
 Experience with visualizing data and producing high-quality graphs and charts
 Experience with the preparation and development of senior leadership-level background papers, reports, and speeches
 Ability to use office tools, including Microsoft Office
 Secret clearance
 Bachelor’s degree


 Nice If You Have:

 Experience with multiple programming languages, including Python, C++, R, MATLAB, or SAS
 Experience with big data architecture platforms and extracting information from disparate data sources, then merging them together for analysis
 Knowledge of various machine learning algorithms, statistics, and mathematics principles
 Knowledge of advanced machine learning capabilities, including gradient boosting, random forests, or convolutional neural networks
 Ability to learn new programming languages


 Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.
 #LI-AH1
        







",93300,"['python', 'machine learning']"
"Sr. Data Scientist, Patient Engagement and Personalization",CVS Health,RI,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary The Sr. Data Scientist (Manager) of Patient Engagement and Experimentation is directly responsible for designing and developing patient engagement use cases (including experiments, mini-tests, campaigns and patient engagement tactics) to enhance patient experiences and business outcomes. The Manager leads the deployment of patient engagement use cases and analytical models (including descriptive/inferential statistics, machine learning, etc.) by effectively managing and guiding data scientists and data engineers through end-to-end product development. The Manager also performs hands-on analyses in product diagnostics, opportunity assessment, pre-deploayment validation and post-deployment evaluation by querying, mining and analyzing big data in CVS’ cloud computing environment using programming tools including Python (Pyspark) and SQL.  Required Qualifications

 Academic background or prior experiences in data science, statistics, computer science, product analytics, marketing analytics, or business analytics
 Proficiency in programming languages including SQL, Python and PySpark
 Experience with cloud computing and programming in a cloud platform (e.g. Azure, GCP, AWS)
 Strong understanding of descriptive and inferential statistics (e.g. sample size calculation, statistical significance determination)
 Solid understanding of the design of both experimental studies (e.g. A/B testing) and observational studies
 Working knowledge of supervised and unsupervised machine learning and data engineering
 Ability to structure problems and influence stakeholders in a data-driven way
 Experienced in leading complex projects with multiple stakeholders in a cross-matrixed environment
 Effective communication and presentation skills

 Preferred Qualifications

 Hands-on experiences with building machine learning models including deep-learning models
 Hands-on experiences with data engineering pipeline, analysis of algorithm, optimization of complex codes and code automation
 Experiences with data visualization and business intelligence

 Education
 Academic background or prior experiences in data science, statistics, computer science, product analytics, marketing analytics, or business analytics

 Pay Range
 The typical pay range for this role is:
 $94,500.00 - $196,000.00
 
 This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",94500,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'sql', 'pyspark']"
AI & Data Solutions Architect,Sterling Check,Remote,Full-time,"

  We have great people here and are looking for more. Come join us - you will love it!
 


 About the Role:
   Are you passionate about data engineering and eager to dive into the world of AI? Do you have experience with AI/ML services in the cloud? Do you want to be at the forefront of AI-driven digital transformation, playing a crucial role in our company's growth and innovation. If you also possess strong data architecture and AI/ML skill sets, we have an exciting opportunity for you at Sterling's AI Enablement Team.
 


   This role is a vital member of our team, bridging the gap between business leaders, data professionals, and the technical team. They must be forward-thinking, have a keen sense of the latest in AI trends, and be able to provide architectural solutions that integrate seamlessly with our existing systems.
 

 This Is What You'll Do:
 

 Engagement: Collaborate with senior stakeholders, capturing technical and functional requirements.
 Solution Blueprint: Convert business needs into technical solutions; devise project scope, deliverables, and timeline proposals.
 Trailblazing: Be the Champion of technology and innovation and drive technology and product teams to continuously modernize.
 Architectural Expertise: Guide various teams; define AI structures, choose technologies, and decide on deployment strategies.
 Data Solutions: Design and implement data-driven solutions, ensuring data integrity, availability, and optimal performance. Develop and maintain reference architecture blueprints to guide and standardize data solutions across the organization.
 Risk & Security: Anticipate and address risks in Data & Analytics, uphold ethical AI standards, and align with relevant regulations.
 Oversight & Enhancement: Direct delivery teams, audit AI tools, and ensure continuous improvement in AI practices.



   This Is The Job For You, If You:
 

 Are passionate about both data architecture and AI technologies.
 Possess analytical, problem-solving, and logical thinking skills with attention to detail.
 Thrive in a fast-paced environment and can multitask effectively.
 Have a knack for quickly picking up new technologies and concepts.
 Can work independently with minimal supervision.
 Excel in verbal and written communication.



   This Is What We're Looking For:
 

 Minimum of 7 years of experience in a technical role with extensive exposure to data; data architect, data engineer, data analyst, data scientist, or similar relevant experience.
 Minimum of 3 years of experience in AI/ML technologies
 Familiarity with Generative AI technologies and concepts
 Knowledge of advanced analytics tools (such as Python,R,SAS) along with applied mathematics, ML and Deep Learning frameworks (such as TensorFlow) and ML techniques (such as random forest and neural networks)
 Strong understanding of data management, governance, model building, deployment and production workflows of AI is a must.
 Hands-on experience in implementing reference implementations for Data and AI solutions.
 Hands-on experience in projects relating to data solutions (data lake, system integration, data migration, data warehousing experience with cloud-based data platforms).
 Sound knowledge on modern data solutions such as data lakes, data platforms, data streaming, and data security best practices.
 General knowledge of cloud native computing, public hyperscalers (AWS and/or Azure)
 Prior experience building large scale enterprise data architectures using commercial and/or open-source Data Analytics technologies
 Data modelling and architecting skills including strong foundation in data warehousing concepts, data normalisation, and dimensional data modelling such as OLAP, or data vault
 Good fundamentals around security integration including Kerberos authentication, SAML and data security and privacy such as data masking and tokenization techniques




    The pay range for this position is $130,000 to $155,000. Base pay offered may vary depending on job-related knowledge, skills, and experience. In addition to base pay, this role is eligible to participate in the Annual Incentive bonus plan. A full range of benefits including but not limited to medical, financial, unlimited sick time, 22 days’ vacation annually (for FT workers; prorated 1st year of employment), parental leave and other benefits are also provided. This information is provided per several state and local Equal Pay and Pay Transparency Laws. Base pay information is based on market location. Applicants should apply via Sterling’s internal or external careers site.
  



 Follow us:


www.instagram.com/sterlingcheck



www.linkedin.com/company/sterlingcheck



www.facebook.com/SterlingCheck/



Equal Employment Opportunities at Sterling

Sterling is an equal opportunity employer and prohibits discrimination based on race, color, religion, creed, national origin or ancestry, ethnicity, sex (including pregnancy, childbirth or related conditions), gender identity and expression, age, disability, citizenship, sexual orientation, military service, genetic information, and any other characteristic protected by law. In addition, Sterling is committed to taking affirmative action to employ and to advance in employment individuals regardless of race, color, religion, creed, national origin or ancestry, ethnicity, sex (including pregnancy, childbirth or related conditions), gender identity and expression, age, marital status, disability, citizenship, sexual orientation, military service and genetic information; and to base all employment decisions only on valid job requirements.



 Disclaimer

This job description has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to the job.

",130000,"['tensorflow', 'python', 'deep learning', 'aws', 'azure']"
Data Scientist,Leidos,VA,Full-time,"
Description 
Leidos is seeking an experienced Data Scientist professional to serve in the office the Presidential Daily Briefing. The selected candidate will provide ongoing critical support to the Presidential Daily Briefing Staff by assisting the sponsor in building new tools, such as electronic databases and tracking mechanisms, to respond to the evolving needs and requirements of the PDB enterprise to support managers, briefers, analysts, and other contributors to the PDB process. These tools will assist to inform executive decision-making for the PDB and senior leadership. The PDB requires dedicated data analysis and output reports to inform decision-making at ODNI and across the IC. At any given time, there are multiple data management planning, vetting, and analysis projects in motion; and daily, weekly, and monthly tasking for data output in support of PDB mission requirements.

 The selected candidate shall assist in the following tasks:

 Translating users' needs and capabilities into requirements and detailed technical options for government consideration.
 Modeling, adapting, developing, and maintaining logical data, service, and interface specifications.
 Collecting, monitoring, and reporting on key performance indicators.
 Conducting trend analysis.
 Developing dashboards and reports to support government oversight and measures of performance of IC investments.
 Making recommendations to the Sponsor on improving business and enterprise oversight processes.
 Adapting, developing, and maintaining new physical data, service, and interface specifications in differing formats.
 Translating requirements into scalable and supportable solutions that work well within the overall system architecture.
 Developing program assessment processes and methodologies to measure and report on portfolios' effectiveness.
 Developing data collection needs and collecting data to facilitate the Sponsor's decision on investments.


 Requirements:

 TS/SCI clearance with polygraph required.
 Must have the ability to be approved for compartmented access and special clearances.
 Strong experience working with Python.
 Experience with the following applications/databases: Oracle SQL Developer; Anaconda; Tableau Desktop and Tableau Prep; PGadmin and PostgreSQL; Microsoft Office, specifically Excel; GitHub and Jira.
 Experience working with data manipulation, analytic/business insight tools, and data visualization experience.
 Experience constructing and performing complex database search queries.
 Ability to communicate technical findings to non-technical audiences.
 Candidates must be able to work with multiple IC agencies and serve as an interface between agencies.
 Candidate must be able to work the required schedule, which may include infrequent early morning or overnight shifts.
 Experience working with at or in support of the most senior levels of the U.S. government.
 BS degree and 2 – 4 years of prior relevant experience or Masters with less than 2 years of prior relevant experience.


 Pay Range: Pay Range $63,050.00 - $113,975.00
 
 The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.
",63050,"['python', 'tableau', 'postgresql', 'sql']"
Machine Learning Engineer,Ladder,CA,Full-time,"
About Ladder
 We saw a problem within the life insurance industry: getting covered took too long, involved too much paperwork, and required too many in-person meetings with sales agents. Having lost his father at a young age, our CEO, Jamie, was determined to make it easier for people to get the coverage they needed to provide for their families. So, we got to work. We developed a method of real-time underwriting and, in doing so, reduced the months-long process of applying for life insurance to minutes. Our digital experience is quick (instant decisions!), loved by users (check out our Trustpilot or Google reviews) and prolific ($60 billion+ in coverage provided).
 About the role
 We're hiring a Machine Learning Engineer to join our team and help us reimagine life insurance. The ideal candidate will have a deep understanding of machine learning algorithms and techniques, as well as experience in software development and data engineering. You will be responsible for designing, developing, tuning and deploying machine learning models to solve challenging problems in the life insurance industry. This is a hybrid role, requiring 1-2 days a week in our Palo Alto headquarters.
 Responsibilities

Design, develop, tune and deploy machine learning models to improve the life insurance experience for our customers
Work with data scientists and engineers to build and maintain data pipelines and infrastructure
Collaborate with cross functional partners to understand their needs and develop machine learning solutions to meet those needs
Monitor and evaluate the performance of machine learning models and make necessary adjustments
Stay up-to-date on the latest machine learning research and trends, utilize emerging technologies to address business issues through technical innovation

Requirements

3+ years experience in machine learning engineering, specifically building and launching production models
2+ years of software development in one or more programming languages with basic data structures/algorithms knowledge
Full-stack development with some exposure to front-end frameworks a plus
2+ years in a highly regulated environment such as healthcare, finance, insurance or pharmaceuticals a big plus
Master's degree or PhD in Computer Science or related technical field a plus
Hybrid role in our Palo Alto headquarters as needed

Tech Stack
 It's great if you're familiar with these technologies but at Ladder we believe general technical proficiency is more important than specific technologies knowledge.

Frontend: Clojurescript, React, GraphQL
Backend: Clojure, JVM
Infrastructure: Kafka, Docker, Kubernetes, Packer, Terraform, AWS
Data: BigQuery, Tableau, BEAM

Our engineering culture & values
 Check out our Company Values to learn more about who we are. We are passionate about:

Bottom-up leadership: teams are most successful when everybody shares their ideas, comfortable that they'll be seriously considered. engineers can and should provide product & business insights.
Shipping fast without breaking things: we've invested heavily in engineering tooling that provides guardrails without getting in your way. We believe in shipping MVPs & iterating quickly rather than waiting for perfection to ship.
Investing in automation: automating repetitive tasks saves time and reduces errors. We're always on the lookout for manual workflows to automate away.
Continuous improvement: we learn from our past wins & losses by conducting blameless retros.

What we Offer
 Whether you work in our beautiful office in Palo Alto or remotely, Ladder is highly collaborative and fun. To support you in your role, we offer fantastic perks and benefits that reflect our mission of care and support, including:

Excellent medical, dental, and vision coverage | We offer competitive healthcare, dental and vision plans for you and your family.
Flexible paid time off | Take the time that you need to rest and recharge, including our week-long winter holiday closure.
Stock options | We offer competitive stock option packages to participate in the success of building Ladder, including an extended option exercise window of 7 years after two years with Ladder.
A rewarding 401k match program | We'll match up to 4% of your contributions as you save for your retirement goals.
Ladder Fit Program | Your health matters. That's why Ladder provides a monthly reimbursement for wellness-related expenses.
Commuter benefits | When you work from the office, you will receive pre-tax benefits for your commute and free parking.
A stocked, beautiful new office | Located in downtown Palo Alto, our office was specifically designed to accommodate all working styles. We've invested in technology to support our hybrid team, plus we provide office snacks and daily catered lunches so that team members can work well and have fun together.
Paid parental leave | We think it's crucial that new parents have time to adjust to their new lives without worrying about work. For birthing parents, they are eligible for 6-8 weeks post delivery recovery. Afterwards, all parents inclusive of birthing, adoption, or fostering are eligible for ten weeks of paid baby bonding with a gentle phase-back program, where parents can return to work on a reduced schedule for the first month at full pay.
Work-from-home flexibility and support | We recognize that everyone's home life is different and support remote and hybrid work. Upon joining, we provide a one-time remote office stipend for all team members and then a monthly stipend to cover WFH costs such as the internet.
Fun company-wide events | Whether we work locally or remotely, we genuinely enjoy spending time together. That's why we plan fun virtual and in-person events to let loose and laugh.

This role is mapped to the job level of P2/L4 and thus the base pay range targeted for this position is $121,125 - $154,500 per year. This role is eligible for equity and benefits as shared above. Base pay is determined by market location and may vary depending on job-related knowledge, skills, and experience.
 Ladder is building a diverse team of talented and enthusiastic people. We are an equal opportunity workplace. At Ladder, differences are celebrated and supported to benefit our people, product, and community. Let us know why you're interested in this position and what unique contributions you can make to the Ladder team. We look forward to hearing from you.
 Research shows that candidates from underrepresented backgrounds often don't apply for roles if they don't meet all the criteria – unlike majority candidates meeting significantly fewer requirements. We strongly encourage you to apply if you're interested: we'd love to know how you can elevate our team with your unique experience!
 By clicking ""Submit Application,"" you acknowledge that you have read and agree to the Ladder Job Applicant Privacy Policy and Notice at Collection.

 By clicking ""Submit Application,"" you acknowledge that you have read and agree to the Ladder Job Applicant Privacy Policy and Notice at Collection.

",121125,"['machine learning', 'tableau', 'aws', 'docker', 'kafka']"
Machine Learning Engineer II - Java Development,Warner Bros. Discovery,CA,Full-time,"
Every great story has a new beginning, and yours starts here.
 Welcome to Warner Bros. Discovery… the stuff dreams are made of.

 Who We Are… 
When we say, “the stuff dreams are made of,” we’re not just referring to the world of wizards, dragons and superheroes, or even to the wonders of Planet Earth. Behind WBD’s vast portfolio of iconic content and beloved brands, are the storytellers bringing our characters to life, the creators bringing them to your living rooms and the dreamers creating what’s next…

 From brilliant creatives, to technology trailblazers, across the globe, WBD offers career defining opportunities, thoughtfully curated benefits, and the tools to explore and grow into your best selves. Here you are supported, here you are celebrated, here you can thrive.

 Warner Bros. Discovery's DTC technology and product organization sits at the intersection of tech, entertainment, and everyday utility. We are continuously leveraging new technology to build immersive and interactive viewing experiences. Our platform covers everything from search, content catalog, and video transcoding, to personalization, global subscriptions, and more. We are committed to delivering unique and quality user experiences, ranging from video streaming to applications across connected TV, mobile, web and consoles. As a pure tech organization, we are essential to Warner Bros. Discovery’s continued growth, building world-class streaming products from the ground-up for our iconic brands like HBO Max, Discovery Channel, CNN, Food Network, HGTV, Eurosport, MotorTrend, and many more.

 Your New Role...
 We are looking for a passionate Machine Learning Engineer to build and scale the DTC personalization systems and services for our new global streaming app, Max, as well as any future DTC streaming apps. You are excited about working in an environment that fosters innovation via prototyping, development, experimentation and productionalization. You will bring the right balance between rapid feature iteration and building a common set of platforms and tools to move quickly in the future.In your role, you will be working alongside a team of passionate machine learning engineers and applied researchers to build and contribute to architecting a system that serves millions of users worldwide.

 Your Role Accountabilities…

 Architect, build and scale a recommendation system that powers a state of the art personalization experience to users across Max, HBO, Discovery+ and other WBD offerings
 Collaborate with other ML/Ops engineers to develop and improve core components, infrastructure and architecture to train, deploy and serve models at scale
 Lead architecture improvements for our personalization services and infrastructure
 Collaborate with data scientists, engineers, product teams and other key stakeholders and drive ML projects from conception to completion
 Author, test, review, and optimize production-level code in Python, Go and Java while executing best practices in version control and code integration
 Use and build upon open-source cloud computing technologies
 Participate and support engineering leaders in strategic planning and demonstrate good judgment in setting and delivering against strategic goals for the team
 Motivate, inspire and create a culture of experimentation and data-driven innovation while constantly striving to be an advocate for doing what is right for our customers


 Qualifications and Experience…

 2+ years of industry experience as a software engineer or machine learning engineer is preferred
 4+ years of programming experience in at least one of the following: Java/Go with ability to rapidly prototype ideas, and refine towards production.



 Experience with one of the cloud platforms AWS/GCP/Azure
 Understanding of sql and relational databases
 Experience with CI/CD tools like GitHub Actions, Jenkins etc.
 Experience with design, implementation and performance tuning
 Knowledge of large-scale distributed application architecture and good practical knowledge in modern machine learning lifecycle is a bonus
 Practical knowledge of large scale recommender systems, or large scale ML ranking/retrieval/targeting systems and familiarity with A/B Tests and hypothesis testing is preferred
 Excellent written and verbal communications skills and can present technical topics to large audiences



 Advanced degree (M.S.), or equivalent industry experience in software engineering, computer science, machine learning or related fields 


How We Get Things Done…

 This last bit is probably the most important! Here at WBD, our guiding principles are the core values by which we operate and are central to how we get things done. You can find them at www.wbd.com/guiding-principles/ along with some insights from the team on what they mean and how they show up in their day to day. We hope they resonate with you and look forward to discussing them during your interview.

 The Legal Bits… In compliance with local law, we are disclosing the compensation, or a range thereof, for roles in locations where legally required. Actual salaries will vary based on several factors, including but not limited to external market data, internal equity, location, skill set, experience, and/or performance. Base pay is just one component of Warner Bros. Discovery’s total compensation package for employees. Pay Range: $119,700.00 - $222,300.00 salary per year. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Warner Bros. Discovery provides a variety of benefits to employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays and sick time and vacation.
  Warner Bros. Discovery embraces the opportunity to build a workforce that reflects the diversity of our society and the world around us. Being an equal opportunity employer means that we take seriously our responsibility to consider qualified candidates on the basis of merit, without regard to race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, and genetic information, marital status, citizenship status, military status, protected veteran status or any other category protected by law.
  If you’re a qualified candidate with a disability and you need a reasonable accommodation in order to apply for this position, please contact us at recruitadmin@wbd.com.
",119700,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'sql']"
AI/ML Packaging Engineer,Booz Allen Hamilton,VA,Full-time,"


Job Description










         Location: 
        

         Arlington,VA,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184621
        


















         AI/ML Packaging Engineer
          The Opportunity:
 As an experienced engineer, you know that machine learning is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on business processes using ML techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support the defense of critical infrastructure. As a machine learning engineer support our defense business you’ll train, test, deploy, and maintain models that learn from data.

 In this role, you’ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You’ll be part of a large community of machine learning engineers across the firm and collaborate with data scientists, software engineers, and mission SMEs to deliver world class solutions to transfer the mission for our clients. Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks.

 Join us. The world can’t wait.

 You Have:

 3+ years of experience with developing software architectures and containerization tools, including Docker and Kubernetes
 3+ years of experience developing and managing Python packages
 1+ years of experience with data science, machine learning engineering, and MLOps subject matter
 1+ years of experience with deploying Machine Learning capabilities to production environments
 Experience with software development, including API development or database management, and model deployment
 Experience with producing technical documentation and designs
 Ability to obtain a security clearance
 Bachelor's degree in Computer Science or Statistics


 Nice If You Have:

 Experience with GPU-programming, including CUDA or RAPIDs
 Experience with testing and quality assurance
 Experience with integrating AI or ML capabilities into software architecture design


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['python', 'machine learning', 'docker']"
Associate Machine Learning Platform Field Engineer,CVS Health,TX,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary
 Analytics & Behavior Change is an innovation engine supporting the entire CVS Health organization by embedding deep insights into key decision processes and focusing on our biggest, most complex problems. We partner with business leaders throughout the organization using advanced analytics tools, modeling, and machine learning to generate insights by using data to create meaningful impact. Agility and platform support are critical to delivering on these commitments. The Enterprise Data and Machine Learning Platform team within the Consumer Analytics organization owns the delivery of Machine learning & feature store platform capabilities for the organization. The team has a deep understanding of healthcare data domains, including Insurance, PBM, and Retail, and the technical expertise to innovate and accelerate on the cloud platforms.
 As the Platform Field Engineer on the Enterprise Machine Learning Platform team, you will work closely with the customer success team to help users with their model deployments. You will be a part of the core MLP Engineering team and learn from an exceptional group of DevOps, ML, Data and Cloud Engineers, and grow your engineering career in one of these specializations. The user support activities include building reports, enabling users, automating processes, and hands-on debugging and problem solving with the users. You will collaborate closely with product owners, data scientists, analytics engineers, and core MLP engineering team and bring issues to a resolution. Other responsibilities include:

 Hands-on debugging/issue resolution and contributing to the platform Knowledge base in StackOverflow or GitHub
 Proactively monitor system health dashboards and identify risks and issues for users
 Manage a backlog of user requests and prioritization with customer support team
 Contribute patches to MLP core platform to resolve user issues

 Required Qualifications
 Technical Skills - 

Hands on (internship or otherwise) experience in ML and data engineering
 Hands on (internship or otherwise) experience in Cloud technologies
 Understanding of cloud services (GCP preferred, AWS acceptable): bucket storage, BigQuery, DataProc, VertexAI
 Identify and troubleshoot data or access issues, pipeline failures, product gaps
 Experience with Linux OS, docker, Jenkins, GitHub, and Airflow
 Understanding of IAM, VPC, TCP/IP (basic networking, troubleshooting & configurations)
 Understanding of modeling frameworks and libraries like Scikit-learn, Pytorch, Tensorflow

 Soft Skills - 

Effective communication skills and fluency in written and spoken English
 Effective in collaboration and teamwork
 Passion for continuous learning and growth mindset
 Focus on user experience and building relationships
 Ability to estimate work with the team and communicate clear timelines to customers

 Preferred Qualifications

 Healthcare, Retail, Pharmacy and/or Insurance domain experience
 Issue and work management using Rally
 Programming experience in Python

 Education

 Bachelor’s Degree in Computer Science

 Pay Range
 The typical pay range for this role is:
 $60,000.00 - $120,000.00
 
 This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",60000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'aws', 'docker', 'gcp', 'airflow']"
Principal Applied Scientist,Microsoft,WA,Full-time,"

  Security represents the most critical priorities for our customers in a world awash in digital threats, regulatory scrutiny, and estate complexity. Microsoft Security aspires to make the world a safer place for all. We want to reshape security and empower every user, customer, and developer with a security cloud that protects them with end to end, simplified solutions. The Microsoft Security organization accelerates Microsoft’s mission and bold ambitions to ensure that our company and industry is securing digital technology platforms, devices, and clouds in our customers’ heterogeneous environments, as well as ensuring the security of our own internal estate. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. In doing so, we create life-changing innovations that impact billions of lives around the world.
 


 The Cyber Foundational AI (CyFAI) Team is looking for a Principal Applied Scientist to help build on Microsoft’s unique capabilities in AI super compute, unmatched data breadth and depth, and state-of-the-art AI research to innovate unique AI differentiators in security. The CyFAI team identifies and addresses our hardest current and future security challenges. We work across Microsoft Security to proactively support application and communication of AI advances for security. The team publishes and presents our work in various forums and collaborates widely to improve outcomes and grow the success of AI and ML in digital transformation.
 


 Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.
 
 Responsibilities

 Bringing the State of the Art to Products


 Nurtures and grows multiple collaborative relationships with product or business group leaders inside or outside Microsoft and provides knowledge or technology to create business impact. Influences product or business group decisions at a strategic level. Authors white papers, begins to be involved in events, develops or maintains tools/services for internal Microsoft use, or conducts consulting for product or business groups. May publish research to promote receiving new intellectual property for business impact.
 Collaborates with and bridges the gap between researchers (in community across the company, Microsoft Research [MSR], or in their own organizations) and development teams. Brings new technology and approaches into production by applying long-term research efforts to solve immediate product needs. Drives high-stakes negotiations across teams to ensure cutting edge technology is being applied to products in a practical way that meets key business objectives. Applies an understanding of research approaches used across the company and industry to leverage (and not re-invent) solutions. Begins to represent the organization across the company.
 Independently works to create product impact. Identifies approach and applies, improves, or creates a research-backed solution (e.g., novel, data driven, scalable, extendable) to positively impact a Microsoft product or service. Helps to shape the direction of Microsoft and/or the industry with industry-leading product/tooling work. Identifies significant business problems hindering product impact with other disciplines. May publish research to promote receiving new intellectual property for product impact.


 Leveraging Applied Research


 Masters a broad area of research (e.g., Machine Learning, Natural Language Processing, Computer Vision, Statistical Modeling, Data-Driven Insights) or gains unique knowledge in a specific area of research. Understands the corresponding literature, applicable research techniques, and business context (e.g., revenue). Demonstrates awareness of the relevant people and organizations as it relates to the research agenda.
 Serves as a wealth of knowledge within team on changes in industry/market trends, products, industry advances, and opportunities in applied technologies across a broad range of applied research areas. Shares and acquires knowledge of applied research areas with engineers and product teams to apply advanced concepts to influence product needs and drive action toward solutions.
 Reviews business and product requirements and incorporates state-of-the-art research occurring at Microsoft and the academic field to formulate plans that will meet business goals. Identifies complex or difficult problems and develops strategy to resolve problems across the company. Provides strategic direction for the kinds of data used to solve problems.
 Identifies gaps and determines which tools, technologies, and methods to incorporate to ensure quality and scientific rigor. Supports the development and implementation of new or modified tools, technologies, and methods. Applies deep subject matter knowledge around a broad array of specialized tools/methods to support business impact.


 Capability Management and Networking


 Proactively provides mentorship and coaching to less experienced and mid-level team members (e.g., interns, research associates, researchers, Ph.D. candidates) by sharing knowledge to build team capabilities and guiding team members in projects, and their careers, and may help to establish best practices and standards. Serves as a technical lead and develops academics to be members of multi-discipline teams.
 Identifies and inspires peers and new research talent to join Microsoft. Builds trusted relationships with key internal and external stakeholders to develop long-term partnerships and advocate for research initiatives. Participates in candidate screening and interviewing and forms job descriptions for attracting new talent. May share research findings through publications or industry outreach. Collaborates with the academic community to develop the recruiting pipeline, identify cutting-edge solutions for products, and establish awareness of their work.


 Documentation


 Performs documentation of work in progress, experimentation results, plans, etc. Documents scientific work to ensure process is captured. Creates informal documentation and may share findings to promote innovation within group or with other groups. Performs higher-level extraction and distills down to core ideas. Assists less experienced team members with documentation of processes used. Provides guidance as needed when capturing processes.


 Ethics and Privacy


 May contribute to ethics and privacy policies related to research processes and/or data/information collection by providing updates and suggestions around internal best practices. Seeks to identify potential bias in the development of products and provides solutions to avoid such biases.


 Specialty Responsibilities


 Ensures selection of data to be used for analysis reflects developed criteria (e.g., quality, technical constraints, and overall goals of the project). Considers impact of data cleaning on analysis results. Mentors and coaches less experienced members in data cleaning and analysis best practices. Identifies gaps in current datasets and drives onboarding of new datasets (e.g., bringing on third-party datasets). Scales the feature ideation and data preparation. Takes cleaned or raw data and adapts for machine learning purposes. Demonstrates intuition of the importance of features for a particular machine learning model and proposes or extracts the right features that affect the model, understands which features are important that come out of the model, and identifies the optimal features. Works across boundaries to influence signal system and lead developers to design and identify new sources of data/signal in support of converting to useable data train and evaluate models. Builds pipelines that can scale data. Ensures business justification for data changes.
 Guides team to perform machine learning/data extraction, transformation, and loading (ETL) pipelines (e.g., data collection, cleaning) based on data prepared. Guides the architecture of scalable pipelines and datasets. Influences the direction of the team. Begins to anticipate potential data pipeline issues and provides solutions. Collaborates with data providers across disciplines. Guides team to use data pipelines for training, as well as for shipping models which should execute correctly.
 Leads collaboration among team and leverages data to identify pockets of opportunity to create state-of-the-art algorithms to improve a solution to a business problem. Consistently leverages knowledge of techniques to optimal analysis using algorithms. Identifies opportunity areas regarding new statistical analyses and drives solutions. Modifies statistical analysis tools for evaluating Machine Learning models and validates assumptions about the data while also reviewing consistency against other sources. Runs complex descriptive, diagnostic, predictive, and prescriptive statistics. Represents the insights across disciplines. Solves problems when the data is not clean and which analyses to run are not clear and the process is ambiguous. Aligns feature level metrics with business metrics.
 Defines and sets the success criteria for machine learning improvements. Analyzes complex problems by designing, adopting, and driving state-of-the-art algorithms that structures, analyzes, and uses data in product and platforms to train algorithms for scalable artificial intelligence solutions before deploying. Pushes forward state-of-the art algorithms. Anticipates issues with algorithms and provides suggestions to overcome challenges. Builds frameworks that solve problems across diverse problems. Demonstrates deep understanding of machine learning frameworks. Surveys and summarizes state of the art and quickly leverages this to change the direction of the team. Helps guide the team through the process of defining metrics for a problem and identifying which models to use based on insights from metrics.
 Addresses scalability problems by adjusting to stakeholder needs. Directs others in the use of large-scale computing frameworks and pros and cons of each (e.g., bottlenecks for scalability and how to solve them), and modeling environments using cutting-edge industry methodologies to improve models. Leads the creation of a model, applies the model to real products, and then verifies effects through iterations. Leads experiments by putting multiple models in production and evaluating their performance. Proposes modifications to how algorithm performs against traffic based on how the model performs in production. Makes design decisions to allow debugging and updates and refresh in the future. Implements mechanisms that allow quick turnaround times to enable spot fixes. Builds reusable assets for monitoring, as well as frameworks.


 Other


 Embody our culture and values

 Qualifications

 Required/Minimum Qualifications


 Bachelor's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research)
   
 OR Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 4+ years related experience (e.g., statistics, predictive analytics, research)
 OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 3+ years related experience (e.g., statistics, predictive analytics, research)
 OR equivalent experience.

 5+ years’ experience demonstrating technical competencies in security and artificial intelligence
 1+ years of Subject matter knowledge in one or more cybersecurity disciplines
 2+ years of working knowledge with transformer models, data science, data engineering, cloud stack technologies, machine learning pipelines, and evaluation
 5+ years’ industry experience with hands-on coding, integration and testing


 Other Requirements



 Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings:
 

 Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter.


 Additional or Preferred Qualifications


 Master's Degree in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 9+ years related experience (e.g., statistics, predictive analytics, research)
   
 OR Doctorate in Statistics, Econometrics, Computer Science, Electrical or Computer Engineering, or related field AND 6+ years related experience (e.g., statistics, predictive analytics, research)
 OR equivalent experience.



   Applied Sciences IC5 - The typical base pay range for this role across the U.S. is USD $133,600 - $256,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $173,200 - $282,200 per year.
 

 Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay
 


 #MSFTSecurity #ArtificialIntelligence #MachineLearning #CloudSecurity #MSECAI
  Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
",133600,"['machine learning', 'etl']"
"Principal Product Manager- Insights, Data Engineering & Analytics (IDEAs)",Microsoft,WA,Full-time,"
Insights, Data Engineering & Analytics (IDEAs)
 Microsoft 365 is key to Microsoft's cloud strategy and we have one of the richest productivity offerings in the world. Our charter is central to Microsoft 365 business's growth strategy as we provide the end to end data fabric that produces business and customer intelligence that fuels growth initiatives. We use cutting edge big data technologies and turn data and insights into data products that drive customer growth, product engagement, customer satisfaction, quality of product and features. We power product experiences and customer outreach initiatives through predictive modeling, machine learning models and recommenders that nurture the customer throughout their lifecycle from pre-acquisition to retention. We build durable, high quality, privacy compliant data platform as the backbone of Microsoft 365's data strategy.
 Principal Product Manager- Insights, Data Engineering & Analytics (IDEAs)
 The position requires product vision, ability to innovate & create a new product value, strategic thinking, customer obsession, technology depth, passion for development of cutting edge artificial intelligence solutions, ability to define requirements and roadmaps, and expertise in managing partnerships and business groups. The position requires a self-motivated, driven individual who will be responsible for end to end ownership and delivery of the product vision. The position also requires defining clear success metrics for impact on Microsoft 365's bottom line, be open to experimentation, evaluation and iteration till product impact is successfully delivered
 Responsibilities

 Product Strategy: Develop and communicate a clear and compelling product vision and strategy tailored to software sales growth in the SMB market via in-product, email and 3P channels. Collaborate with cross-functional teams to align product objectives with overall company goals.
 Market Research: Conduct in-depth market research to understand the unique needs, pain points, and preferences of SMB customers to drive growth and usage of Microsoft’s suite of software solutions. Stay updated on industry trends and competitive landscape.
 Product Roadmap: Define and manage the product roadmap for software solutions that grow usage of Microsoft software in the SMB segment, prioritizing features and enhancements that deliver maximum value to our target customers.
 Customer-Centric Approach: Champion a customer-centric mindset within the product team. Gather feedback, conduct user interviews, and analyze data to ensure product improvements are aligned with customer needs.
 Go-to-Market Strategy: Collaborate with marketing and sales teams to create effective go-to-market strategies, including product positioning, pricing, and marketing campaigns tailored to the SMB market.
 Product Development: Work closely with engineering and design teams to oversee the end-to-end product development process. Ensure on-time delivery of high-quality features and updates.
 Performance Metrics: Define and monitor key results (KRs) for growth and usage of SMB related software products. Regularly analyze product performance and make data-driven decisions for continuous improvement.
 Cross-Functional Collaboration: Collaborate with sales, product team, and other teams to ensure effective product launches, customer onboarding, and ongoing customer success
 Embody our culture and values

 Qualifications

 Required/Minimum Qualifications:


 Bachelor’s Degree AND 10+ years experience in product/service/project/program management or software development role, indcluding delivering high-scale on-line or cloud services.


   o OR equivalent experience
 


 Preferred qualifications:


 Demonstrated ability to design visually appealing and customer facing data products
 Demonstrated record of structuring and solving complex problems
 Demonstrated experience managing global delivery of highly scalable cloud services
 Demonstrated experience effectively negotiate and collaborate across teams and organizations
 Demonstrated ability to handle significant ambiguity and rapid change



 Product Management IC6 - The typical base pay range for this role across the U.S. is USD $158,500 - $276,600 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $202,800 - $304,200 per year.
  
 Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay
 

 Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
",158500,['machine learning']
Senior System Software Engineer - Automotive AI Applications,NVIDIA,CA,Full-time,"

  The Automotive sensing team is searching for engineers to develop and bring NVIDIA's automotive sensing AI solution out to the world. You will participate in a focused effort to develop and productize ground-breaking solutions that will revolutionize the world of transportation and the growing field of self-driving cars. You will work with hardworking and dedicated multi-functional engineering development teams across various vehicle functions to create AI perception solutions, while achieving or exceeding all meaningful NVIDIA and automotive standards & guidelines. You'll find the work is exciting, fun, and very substantial. We have deadlines, customers, and competition.
 


   Our team builds the NVIDIA AI Automotive sensing Software, with the goal to provide a scalable software stack and framework to build AI perception and sensing for autonomous vehicles. We are looking for hands-on software engineers to join our team to redefine experiences inside car. As part of this team you will work on our AI system and perception software solutions, defining a high performance and safe application architecture. The role encompasses working with the various teams developing the software, from system software to full cabin monitoring, as well as the safety team and performance team. You will have the opportunity to develop and truly have the first-hand experience of your work defining cockpit and experience of the cars of the future.
 


   What you will be doing:
 



     Design and optimize application software architectures and frameworks for real-world performance while matching or exceeding customer requirements.
   


     Design and profile efficient mechanisms to improve utilization on computers with multiple heterogeneous hardware engines.
   


     Working on areas such as component abstraction layers, inter-process data sharing and communication, and process scheduling.
   


     Collaborate with hardware, platform, safety, performance and algorithmic teams.
   



   What we need to see:
 



     MS or higher in computer engineering, computer science or related engineering fields (or equivalent experience).
   


     5+ years of experience.
   


     Excellent Python, C and C++ programming skills.
   


     Experience designing, developing and debugging multithreaded/distributed applications like multimedia systems, game engines, etc.
   


     Solid understanding on QNX, Linux, Android, and/or other real-time operating systems.
   


     Thrive on designing low latency, highly performant code.
   


     Excellent communication and analytical skills.
   


     Self-motivated and a great teammate.
   



   Ways to stand out from the crowd:
 



     Understanding of embedded and high efficiency software architectures.
   


     Experience with large frameworks like used in ROS, android etc and developing software in heterogeneous architectures, including GPUs and other types of accelerators.
   


     Be hands-on and work well within a team of algorithm, software and hardware engineers, with a significant level of detail orientation and a penchant for data organization and presentation.
   


     Familiarity with project/task management tools like Jira and JAMA.
   


     Experience with version control systems GIT and build system like CMake/Bazel.
   

 The base salary range is 144,000 USD - 270,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
 







          You will also be eligible for equity and 
         
          benefits
         . 
         NVIDIA accepts applications on an ongoing basis.








 NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

",144000,"['python', 'git']"
"CIR Statistician, Bureau of Immunization Statistician",NYC Careers,NY,Full-time,"




CIR Statistician, Bureau of Immunization Statistician 



      Apply 
     









CIR Statistician, Bureau of Immunization Statistician 




Agency: DEPT OF HEALTH/MENTAL HYGIENE 





       Posted on: 11/15/2023 
      




Job type: Full-time 





Location 
QUEENS





Title Classification: No exam required 






Department
Immunization Registry





      Salary range: $92,301.00 – $114,637.00 
     







Job Description




      Established in 1805, the New York City Department of Health and Mental Hygiene (the NYC Health Department) is the oldest and largest health department in the country. Our mission is to protect and improve the health of all New Yorkers, in service of a vision of a city in which all New Yorkers can realize their full health potential, regardless of who they are, how old they are, where they are from, or where they live. 
      
 As a world-renowned public health agency with a history of building transformative public health programming and infrastructure, innovating in science and scholarship to advance public health knowledge, and responding to urgent public health crises from New York City’s yellow fever outbreak in 1822, to the COVID-19 pandemic we are a hub for public health innovation, expertise, and programs, and services. We serve as the population health strategist, and policy, and planning authority for the City of New York, while also having a vast impact on national and international public policy, including programs and services focused on food and nutrition, anti-tobacco support, chronic disease prevention, HIV/AIDS treatment, family and child health, environmental health, mental health, and racial and social justice work, among others. 
      
 Our Agency’s five strategic priorities, building off a recently-completed strategic planning process emerging from the COVID-19 emergency, are: 
       1) To re-envision how the Health Department prepares for and responds to health emergencies, with a focus on building a “response-ready” organization, with faster decision-making, transparent public communications, and stronger surveillance and bridges to healthcare systems 2) Address and prevent chronic and diet-related disease, including addressing rising rates of childhood obesity and the impact of diabetes, and transforming our food systems to improve nutrition and enhance access to healthy foods 
       3) Address the second pandemic of mental illness including: reducing overdose deaths, strengthening our youth mental health systems, and supporting people with serious mental illness 
       4) Reduce black maternal mortality and make New York a model city for women’s health 
       5) Mobilize against and combat the health impacts of climate change 
      
 Our 7,000-plus team members bring extraordinary diversity to the work of public health. True to our value of equity as a foundational element of all of our work, and a critical foundation to achieving population health impact in New York City, the NYC Health Department has been a leader in recognizing and dismantling racism’s impacts on the health of New Yorkers and beyond. In 2021, the NYC Board of Health declared racism as a public health crisis. With commitment to advance anti-racist public health practices that dismantle systems that perpetuate inequitable power, opportunity and access, the NYC Health Department continues to work in and with communities and community organizations to increase their access to health services and decrease avoidable health outcomes.
      
 PROGRAM AND JOB DESCRIPTION:
      
 The mission of the Department of Health and Mental Hygiene (DOHMH) Bureau of Immunization (BOI) is to prevent the occurrence and transmission of diseases through immunization. The BOI promotes the immunization of children and adults against numerous diseases such as hepatitis A, hepatitis B, measles, mumps, rubella, varicella, diphtheria, tetanus, pertussis, Haemophilus influenzae type B, polio, influenza, pneumococcal disease, the human papillomavirus (HPV), COVID-19 and monkey pox. 
      
 BOI promotes immunization of children and adults through the tracking of individual immunization status and monitoring of immunization levels in the NYC population using the Citywide Immunization Registry (CIR). The CIR is a central record-keeping system established by the DOHMH and accessible to the public, licensed health care providers, parents, and agencies authorized by the DOHMH for the purpose of ensuring that NYC children and adults are protected from vaccine-preventable diseases. 
      
 The Bureau of Immunization (BOI) is seeking a highly motivated, experienced public health professional to serve as a Statistician and assist with data analysis and research projects aiming to inform BOI's vaccination coverage improvement activities, in particular those related to the COVID-19 and monkeypox responses. 
      
 DUTIES WILL INCLUDE BUT NOT BE LIMITED TO: 
      
 Participate in or leads the design and execution of research to describe vaccination coverage levels in the NYC population and inform initiatives related to the COVID-19, monkeypox and other vaccination campaigns. 
      
 Plan and conduct research studies using advanced statistical techniques and modelling methods to examine current vaccination trends and provide projection on future trends. 
      
 Work closely with internal staff and the CDC to perform the evaluation of key programmatic interventions in the CIR. 
      
 Assist with the planning, development and implementation of protocols and research related to CIR data quality and vaccination coverage improvements. 
      
 Ensure data integrity by performing rigorous cleaning, error checking and validation. 
      
 Work closely with internal teams and CIR IT consultants to contribute to the development and application of solutions for observed data challenges, especially those related to data quality. 
      
 Participate in grant preparation and IRB submission. 
      
 Work with other DOHMH teams and federal agencies in collaborative research projects. 
      
 Supervise and supports junior data analysts and contributes to building team capacity. 
      
 Prepare reports, abstracts and manuscripts for presentation and peer-reviewed publication. 
      
 Develop reports for senior management and external stakeholders. 
      
 **IMPORTANT NOTES TO ALL CANDIDATES:
      
 Please note: If you are called for an interview you will be required to bring to your interview copies of original documentation, such as:
      

A document that establishes identity for employment eligibility, such as: A Valid U.S. Passport, Permanent Resident Card/Green Card, or Driver’s license. 



Proof of Education according to the education requirements of the civil service title. 



Current Resume 



Proof of Address/NYC Residency dated within the last 60 days, such as: Recent Utility Bill (i.e. Telephone, Cable, Mobile Phone) 

 Additional documentation may be required to evaluate your qualification as outlined in this posting’s “Minimum Qualification Requirements” section. Examples of additional documentation may be, but not limited to: college transcript, experience verification or professional trade licenses.
      
 If after your interview you are the selected candidate you will be contacted to schedule an on-boarding appointment. By the time of this appointment you will be asked to produce the originals of the above documents along with your original Social Security card. 
      
 **LOAN FORGIVENESS
      
 As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at StudentAid.gov/PSLF.
      
 ""FINAL APPOINTMENTS ARE SUBJECT TO OFFICE OF MANAGEMENT & BUDGET APPROVAL”
     

 Minimum Qualifications
     
 1. For Assignment Level I (only physical, biological and environmental sciences and public health) A master's degree from an accredited college or university with a specialization in an appropriate field of physical, biological or environmental science or in public health.  To be appointed to Assignment Level II and above, candidates must have:  1. A doctorate degree from an accredited college or university with specialization in an appropriate field of physical, biological, environmental or social science and one year of full-time experience in a responsible supervisory, administrative or research capacity in the appropriate field of specialization; or  2. A master's degree from an accredited college or university with specialization in an appropriate field of physical, biological, environmental or social science and three years of responsible full-time research experience in the appropriate field of specialization; or  3. Education and/or experience which is equivalent to ""1"" or ""2"" above. However, all candidates must have at least a master's degree in an appropriate field of specialization and at least two years of experience described in ""2"" above. Two years as a City Research Scientist Level I can be substituted for the experience required in ""1"" and ""2"" above.   NOTE:  Probationary Period  Appointments to this position are subject to a minimum probationary period of one year.

 Preferred Skills
     
 Advanced degree in Statistics or Biostatistics Experience in research study design and quantitative data analysis Advanced knowledge of principles, methods and latest techniques used in descriptive and inferential statistics. Ability to plan, design and conduct original research using advanced methods and statistical tools Experience in research using regression models, causal inference, time-series analysis, complex multivariate models, survey analysis and geospatial analysis Proficiency in using data query tools such as SQL, statistical software such as R or SAS, and data visualization tools such as Tableau or Power BI Experience in manipulation of large datasets, preferably healthcare data Ability to interpret and present findings in various settings Ability to balance competing priorities while meeting deadlines Ability to communicate effectively, both orally and in writing.
     

       Residency Requirement
     
 New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview.
     

       Additional Information
     

 The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.



 Minimum Qualifications
    
 1. For Assignment Level I (only physical, biological and environmental sciences and public health) A master's degree from an accredited college or university with a specialization in an appropriate field of physical, biological or environmental science or in public health.  To be appointed to Assignment Level II and above, candidates must have:  1. A doctorate degree from an accredited college or university with specialization in an appropriate field of physical, biological, environmental or social science and one year of full-time experience in a responsible supervisory, administrative or research capacity in the appropriate field of specialization; or  2. A master's degree from an accredited college or university with specialization in an appropriate field of physical, biological, environmental or social science and three years of responsible full-time research experience in the appropriate field of specialization; or  3. Education and/or experience which is equivalent to \""1\"" or \""2\"" above. However, all candidates must have at least a master's degree in an appropriate field of specialization and at least two years of experience described in \""2\"" above. Two years as a City Research Scientist Level I can be substituted for the experience required in \""1\"" and \""2\"" above.   NOTE:  Probationary Period  Appointments to this position are subject to a minimum probationary period of one year.

 Preferred Skills
    
 Advanced degree in Statistics or Biostatistics\n\nExperience in research study design and quantitative data analysis\n\nAdvanced knowledge of principles, methods and latest techniques used in descriptive and inferential statistics. Ability to plan, design and conduct original research using advanced methods and statistical tools\n\nExperience in research using regression models, causal inference, time-series analysis, complex multivariate models, survey analysis and geospatial analysis\n\nProficiency in using data query tools such as SQL, statistical software such as R or SAS, and data visualization tools such as Tableau or Power BI\n\nExperience in manipulation of large datasets, preferably healthcare data\n\nAbility to interpret and present findings in various settings\n\nAbility to balance competing priorities while meeting deadlines\n\nAbility to communicate effectively, both orally and in writing.
    

      Residency Requirement
    
 New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview.
    

      Additional Information
    

 The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.















Job ID 
615686





Title code
21744






Civil service title
CITY RESEARCH SCIENTIST






Title classification
Non-Competitive-5






Business title
CIR Statistician, Bureau of Immunization Statistician






Posted until
2024-03-08






Experience level: Entry-Level 






Number of positions
1






Work location
42-09 28th Street






Category: Constituent Services & Community Programs








",92301,"['tableau', 'sql']"
"Data Scientist 2 - Price Optimization - Hybrid - Seattle, WA, Los Angeles, CA, Denver, CO, or Chicago, IL",Nordstrom Inc,CA,Full-time,"
Job Description
 Nordstrom is a specialty retailer offering the very best in fashion and customer service since 1901. We live by five simple values that guide how we work together day-to-day and how we deliver data science & analytics products. We are customer-obsessed, owners at heart, curious and ever-changing, we extend ourselves to our peers and our customers, and we’re here to win!

 Our Pricing Data Science & Analytics team is re-imagining Nordstrom’s core pricing capabilities & developing innovative data products to drive value for our customers. As an integral part of the team, the Data Scientist 2 – Price Optimization will research and implement machine learning & optimization techniques across all areas of our pricing strategy. The ideal candidate is a relentless problem solver with strong technical skills and the ability to create robust data solutions end-to-end. They should be energized by the chance to solve open-ended, high-impact research questions and thrive when collaborating with both technical and non-technical partners.

 If you are passionate about problem solving and want to work on a team dedicated to a culture of inclusion, growth mindset and collaboration, we need you!

 A day in the life…

 Partner with key stakeholders to understand the challenges in the pricing landscape and their current processes and workflows
 Dive deep into complex business problems and immerse yourself in Nordstrom data & outcomes
 Research analytical approaches within the pricing domain and bring forth ideas
 Work on complex and highly ambiguous projects that may connect multiple domains (e.g. pricing, financial planning, demand forecasting)
 Develop, assess, and deploy statistical and machine learning and/or optimization models that make large scale pricing recommendations
 Present findings to business senior management team to inform business strategy and decisions
 Collaborate with cross-functional teams across discipline such as business, product, engineering partners to drive high quality end-to-end solutions from ideation to productionization
 Design experiments to measure success of pricing data products & interpret findings to share with audiences of all technical abilities


 You own this if you have…

 Ph.D. or MS degree in, Statistics, Economics, Machine Learning, Operations Research, Computer Science or other quantitative fields
 3+ years of professional experience analyzing complex data, drawing conclusions, and making recommendations, with direct experience in pricing a plus
 2+ years of experience in extracting & manipulating large data sets from relational databases using SQL
 Experience developing and implementing statistical and machine learning algorithms (e.g. regression, classification and/or clustering) from inception to deployment
 Familiarity with experimental design and the ability to identify, compute and validate the appropriate metrics to measure success
 Demonstrated success working in a highly collaborative technical environment (e.g., code sharing, using revision control, contributing to team discussions/workshops, and collaborative documentation)
 Passion and aptitude for turning complex business problems into concrete hypotheses that can be answered through rigorous data analysis and experimentation
 Proficient coding skills in Python or R
 Expertise in analytical storytelling and stellar communications skills


 #LI-EB1

 We’ve got you covered…

 Our employees are our most important asset and that’s reflected in our benefits. Nordstrom is proud to offer a variety of benefits to support employees and their families, including:

 Medical/Vision, Dental, Retirement and Paid Time Away
 Life Insurance and Disability
 Merchandise Discount and EAP Resources


 A few more important points...

 The job posting highlights the most critical responsibilities and requirements of the job. It’s not all-inclusive. There may be additional duties, responsibilities and qualifications for this job.

 Nordstrom will consider qualified applicants with criminal histories in a manner consistent with all legal requirements.

 Applicants with disabilities who require assistance or accommodation should contact the nearest Nordstrom location, which can be identified at www.nordstrom.com.

 © 2022 Nordstrom, Inc

 Current Nordstrom employees: To apply, log into Workday, click the Careers button and then click Find Jobs.

 Pay Range Details

 The pay range(s) below are provided in compliance with state specific laws. Pay ranges may be different in other locations.
 California: $130,000-$201,500 Annually, Colorado: $114,000-$176,500 Annually, Washington: $130,000-$201,500 Annually
  This position may be eligible for performance-based incentives/bonuses. Benefits include 401k, medical/vision/dental/life/disability insurance options, PTO accruals, Holidays, and more. Eligibility requirements may apply based on location, job level, classification, and length of employment. Learn more in the Nordstrom Benefits Overview by copying and pasting the following URL into your browser: https://careers.nordstrom.com/pdfs/Ben_Overview_17-19.pdf

",114000,"['python', 'machine learning', 'sql']"
Machine Learning Researcher,Booz Allen Hamilton,MD,Full-time,"


Job Description










         Location: 
        

         Annapolis Junction,MD,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184737
        


















         Machine Learning Researcher
          The Opportunity: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by machine learning and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities.

 As a Machine Learning Researcher, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors — from fraud detection, to cancer research, to national intelligence — you know the answers are in the data. You'll design and implement machine learning solutions for complex tasks on large datasets, including extracting insights from multiple disparate data sources and types, such as cyber, language, and vision. You'll perform research in machine learning, including adversarial machine learning, algorithmic fairness, and model interpretability. You'll write journal articles, present at academic conferences, and produce whitepapers and briefings to both technical and non-technical audiences. You'll serve as the client interface and maintain responsibility across the entire life cycle, including requirements gathering and analysis, process and systems definition, data analysis, presentation of analysis to clients in a format they can digest, and development of algorithm driven products and solutions.

 Join us. The world can’t wait.

 You Have:

 Experience with programming in Python and C
 Experience with functional programming in OCaml
 Experience with machine learning, including Bayesian machine learning methods
 Knowledge of adversarial machine learning or differential privacy
 Knowledge of mathematics and statistics, including coursework in the theory of probability, statistical inference, algorithms, linear algebra, and calculus
 Ability to derive a variational inference procedure mathematically for a novel model and implement the inference procedure in a framework, including PyTorch or Numpy
 Ability to communicate results to both technical and non-technical audiences effectively
 Ability to obtain a security clearance
 Bachelor's degree in Computer Science, Statistics, Mathematics, Physics, Applied Mathematics, or Engineering


 Nice If You Have:

 Experience with application areas of machine learning, including computer vision, natural language processing, and learning on graphs
 Experience with Bayesian deep learning and Gaussian processes
 Experience with building complex data pipelines
 Experience with using GPUs for machine learning using frameworks, including PyTorch or TensorFlow
 Knowledge of cloud systems, including AWS, Azure, or GCP
 Ability to work independently on complex tasks


 Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['tensorflow', 'pytorch', 'python', 'numpy', 'machine learning', 'deep learning', 'aws', 'azure', 'gcp']"
Sr. Healthcare Data Analyst - Professional Services Data Integration,MedeAnalytics,TX,Full-time,"

MedeAnalytics is a leader in healthcare analytics, providing innovative solutions that enable measurable impact for healthcare payers and providers. With the most advanced data orchestration in healthcare, payers and providers count on us to deliver actionable insights that improve financial, operational, and clinical outcomes. To date, we've helped uncover millions of dollars in savings annually.

 MedeAnalytics is seeking a highly experienced Sr. Healthcare Data Analyst. This role reports to the Sr. Director of Professional Services acting as a liaison, facilitating collaboration between core Mede and Professional Services teams. This client facing position will guide healthcare payer and provider clients through extracting, analyzing, and interpreting large data sets to build various reports and dashboards. The analyst will provide clients with analytical consultative expertise and guidance to create metrics enabling measurements of progress towards initiative goals and ensuring the proper data is being collected for those metrics. Performing extensive data analysis, creating documentation of data issues, and developing implementation strategies for improving data quality and data standardization is a core function of our role.
 The ideal candidate is not new to the data realm and has potentially worn multiple hats as an Analytics Engineer, Data Analyst, or Data Architect. Must be proficient in SQL and have experience using a BI tool. This role requires strong data modeling, data mapping & integration skills coupled with current experience in B2B, EAI, ESB, web services, service-oriented architectures, and standardized terminology services. Epic certifications with a focus on analytical capabilities is strongly preferred. Having up-to-date knowledge and understanding of HEDIS & CMS STARs measures' technical specifications is required.
 Essential Duties and Responsibilities:

Lead the design, development, and ongoing support of clinical and financial integrated data models and reports used by provider and payer management in decision-making. This includes but is not limited to determining appropriate data transformations and governance strategies needed to provide trusted data sets for NCQA HEDIS & CMS STARs reporting and analytics.
Responsible for designing new data structures, mapping data from client source data to our data models, writing SQL/SQL like scripts to load and transfer the data to databases and performing data analysis with ETL.
Leads ideation sessions using lean principles to develop, document and analyze present state process maps and develop future state models.


Conduct, assess and profile data mappings to adhere to specific data structures, ensuring data quality is clearly defined to meet requested business use cases.
Design, create and maintain accurate and efficient data models.
Summarizes testing and validation results and be able to communicate and make recommendations on the best course for remediation.
Resourceful in arriving at solutions using existing or available resources.
Participate in agile work environment, completing sprint deliverables on time.
Contribute to our evolving development and testing standards and best practices.
Knowledge and experience in discrete data elements utilized in healthcare analytics.
Experience querying data, data interpretation and report generation using modern analytics tools (i.e., Power BI)
Work with product owners and business analysts on requirements and design.
Create and maintain comprehensive project documentation, using Mede's standard technical templates, methodologies, and standards.
Consultative engagement with clients to assess and guide requirements specifications.
Conduct meetings, internal and with clients, to review integration progress, upcoming activities and deliverables required to fulfil the Integration project delivery.
Create and maintain data integrity by providing quality data profiling ensuring known constraints to operate in the Client's environment.

Education, Experience, and Required Qualifications: 

Bachelor's Degree (Bachelor of Science, Computer Science or equivalent) strongly desired; advanced degree (MS or MBA) preferred.
7+ year(s) of experience in working with MEDITECH Expanse, Cerner, Allscripts or Epic health information systems and/or 7 + years of relevant professional work experience with complex analysis background in healthcare data, HL7, C-CDA, HEDIS, CMS & STARS
Epic certifications with a focus on analytical capabilities is strongly preferred
CAQH certification and/or Certified Health Data Analyst (CHDA®) a plus
Expertise with standard healthcare terminologies and vocabularies (ICD, DRG, CPT, SNOMED CT, LOINC, NDC, Medispan, RxNorm, etc.)
3+ years of Enterprise Software Packaged/SaaS Integration experience.
3+ years of Enterprise Integration Tool (Informatica is preferred) experience.
7+ years of database design and construction, ETL, and data modeling with an understanding of relational and dimensional data models
7+ years of procedural programming and markup languages such as JAVA, JavaScript, Python, SQL, XML, and JSON
3+ years managing big data (Data transfer, import/export, storage, performance, and security) and MS OLAP; additional experience with ETL framework, Linux and open-source technologies preferred.
3+ years RDBMS and Cloud data platforms with preferred experience leveraging AWS, Mondrian, Oracle, Databricks, Vertica, Hadoop, Apache Spark, Mondrian & MongoDB
Familiar with data visualization tools, Data Lake, Git, and version control

This job description reflects management's assignment of essential functions. Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time.
 Benefits Include:

Great Medical, Dental, Vision benefits - Effective on the first of the month after your start
Company paid Basic Life & AD&D Insurance, STD/LTD
ROBUST Employee Assistance Program (EAP)
401k with Company Match
9 paid holidays AND 3 floating holidays = 12 total!
Paid Time Off (PTO) Accrual
Employee Referral Bonus
Professional Development
and more!

MedeAnalytics believes in fair and equitable pay. A reasonable estimate of the base salary range for this role is $125,000 – 155,000 USD. Please note that actual salaries may vary within the range, or be above or below the range, based on factors including, but not limited to, education, training, relevant experience, professional achievements/qualifications, business need and location.
 Applicants must be authorized to work for ANY employer in the US. We are unable to sponsor or take over sponsorship of employment Visa at this time.
 Mede/Analytics is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, age or protected veteran status.
 MedeAnalytics does not utilize any outside vendors/agencies. Please no unsolicited phone calls or invites.

 At MedeAnalytics we deeply value each and every one of our committed, inspired and passionate employees. If you're looking to make an impact doing work that matters, you're in the right place. Help us shape the future of healthcare by joining #TeamMede.

",125000,"['python', 'aws', 'etl', 'sql', 'git', 'hadoop', 'apache spark']"
Machine Learning Research Scientist (Fully Cleared),Peraton,MD,Full-time,"
Peraton Overview
 Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.
 
Responsibilities

 With a distinguished heritage tracing back to Bell Labs, Bellcore, and Telcordia, our experts pave the way. 
 Peraton Labs delivers innovative solutions and revolutionary new capabilities to solve the most difficult and complex challenges for government agencies, utilities, and commercial customers. Peraton Lab's cybersecurity research protects mission-critical systems and national cyber infrastructure through a broad range of initiatives in computer network defense, secure-by-design techniques and cyber operations and experimentation platforms. Your expertise and areas of interest may be applied on one or more programs, providing you new opportunities to learn and grow. 
 
 We are actively seeking an entry to mid-level software engineer with machine learning experience to join our team of software research scientists working on full scope polygraph research within the maryland customer footprint. The perfect candidate for this role is someone with a strong technical prowess, inquisitive and curious nature, and strong desire to learn. 
 
 Primary responsibilities may include: 
 

Designing, developing, and prototyping signal processing algorithms for wireless systems 
Conducting Radio Frequency (RF) machine learning research 
Implementing, debugging, and testing wireless application prototypes on third-party software-defined radio (SDR) platforms 
Communicating the results of research through customer presentations and publications 
Writing design documents, simulation reports, and system documentation 


Qualifications


Minimum Requirements: 


5 years with BS/BA or 3 years with MS/MA or 0 years with PhD within a software engineering focused degree. 
Experience coding within one or more of the following: Python, C, C++, and/or MATLAB 
Interest and/or experience in one or more of the following domains: digital signal processing, RF software engineering, algorithm development, software defined radio, and machine learning  
Experience with modern machine learning development frameworks and platforms (e.g. Keras, TensorFlow, PyTorch) is expected  
US Citizen with an active TS/SCI w/ Full Scope Poly through MD customer 


Great to haves: 


Familiarity with common software defined radio platforms (e.g. Ettus USRPs) and software (e.g. GNU Radio) 
Familiarity with Open Air Interface(OAI) or srsLTE software stacks 
Familiarity with multiple-antenna or distributed signal processing techniques Knowledge of LTE standards 
    


Benefits: Our comprehensive Benefits and Beyond package is designed to support every aspect of your health, wealth, self and beyond. 
 

Health - Comprehensive medical, dental, and vision plans, HSAs and FSAs, and supplemental health options to keep you and your family healthy all year long. 
Well-being - We strive to support your overall well-being - including emotional, financial, social/community, and physical wellness programs. 
PTO & holidays - Our PTO programs helps you take the time in the ways that matter most. With 20 days a year of accrued PTO, 6 paid federal holidays, 4 floating holidays, and a flexible approach, Peraton Labs avidly supports a healthy work/life balance. 
Retirement - All regular employees are eligible to participate in Peraton's 401(k) retirement savings plan through Fidelity. Peraton will match 100% of the first 4% you contribute, and 50% of the next 2% you contribute. All contributions are 100% vested after two years of service. 
Career Development - We are invested in your future, and pride ourselves on providing best-in-class training to our team through Skillsoft e-Learning Suite for formal and informal learning, professional and technical certification preparation, and education assistance for career path-related courses at accredited institutions. 
TA and Student Loan Refinancing - Peraton provides tuition and training assistance for its employees, in addition to access to a student loan refinancing service and 529 plan through tuition.io to support your continued education aspirations. 

Target Salary Range

 $146,000 - $234,000. This represents the typical salary range for this position based on experience and other factors.
 

SCA / Union / Intern Rate or Range


EEO
 An Equal Opportunity Employer including Disability/Veteran.
 

Our Values


Benefits
 At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.
 

 Paid Time-Off and Holidays
 Retirement
 Life & Disability Insurance
 Career Development
 Tuition Assistance and Student Loan Financing
 Paid Parental Leave
 Additional Benefits
 Medical, Dental, & Vision Care

",146000,"['tensorflow', 'pytorch', 'python', 'machine learning']"
"AVP, Mortgage Portfolio Analytics - 100% Remote",Radian,CO,Full-time,"
See yourself at Radian? We see you here too.

 At Radian, we see you. For the person you are and the potential you hold. That’s why we’ve embraced a new way of working that lets our people across the country be themselves, be their best and be their boldest. Because when each of us is truly seen, each of us gives our best – and at Radian, we’ll give you our best right back.

 Studies have shown that job seekers may hesitate to apply for jobs unless they meet every single qualification listed. We strive to see the potential in each applicant, so if you’re excited about this role but your experience or education level doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.
 See Yourself as an AVP, Mortgage Portfolio Analytics
 The AVP, Mortgage Portfolio Analytics role is responsible for the design, development, and delivery of quantitative tools to help price and manage the risk of radian’s mortgage loan portfolio and structured mortgage transactions. This role will work within the Secondary Marketing team to build and maintain relevant financial models and reports to analyze financial targets and risk tolerances.

 Primary Duties and Responsibilities:

 Support quantitative models for risk management activities. Establish and support the models embedded in the hedging models for loans and MSRs. This includes pull-through, mark to market and duration models for agency and nonagency products. Familiarity with mortgage risk management software such as Compass Analytics a plus.
 Utilize and implement internal credit analysis and financing strategies in pricing and risk management models – Understand and incorporate the organizations credit knowledge and financing in the analysis of pricing and best execution. Create strong internal relationships in the organization to leverage knowledge and incorporate into trading strategies.
 Conduct in-depth analysis of secondary mortgage market trends including interest rates, loan pricing, and investor demand.
 Establish and support a pricing methodology for acquiring loans. This includes understanding structure as well as the tools used to interpret the pricing impacts in agency and nonagency markets. (ie. Intex, Bloomberg, refinitiv and S&P levels).
 Research and buildout of new products and offerings to help drive business growth and lock volume.
 Using subject matter expertise, make recommendations to the process of model and technology improvements across various analytic and database tools.
 Assist in more complex secondary markets operations and analysis including daily management of Compass Analytics, TBA hedging, MSR valuations, and MBS structuring.


 Education Level: Bachelor’s degree in a quantitative field such as Mathematics, Statistics, Finance or Engineering. Master’s degree preferred.

 Years of Prior Work-Related Experience: 5 years of working experience in residential mortgage secondary marketing or mortgage-related industry.

 Additional Qualifications including any special skills, capabilities, and competencies:

 Working experience with a scripting language (SQL, VBA, Python, R) required.
 Previous support of trading desks or knowledge of fixed income trading, mortgage banking or correspondent lending, a plus.
 Solid knowledge in database systems, programming software, application tools and business intelligence reporting standards. Experience manipulating and analyzing complex, high-volume, data from varying sources.
 Excellent technical skills with ability to design and maintain complex financial models.
 Strong analytical skills along with the ability and willingness to effectively make recommendations on transactions based on sound business judgment. 
Clear and effective interpersonal, written, and verbal communications skills. Must be able to clearly and effectively communicate with various groups within the company as well as various external business partners, both verbally and in writing.
 Highly motivated, self-starter, dependable, responsible and able to use good judgment.
 Ability to work in fast-faced, multi-tasking environment and to manage multiple deadlines.
 Strong aptitude for detail and accuracy.


 See Your Location


 Radian is committed to a flexible work environment for many of our roles. This is a *Work From Anywhere* role meaning you have the flexibility to work from home (or another designated workspace that fits your needs).


 This role provides additional flexibility should you want to work on-site at a Radian office. Explore our office locations here and let your Talent Acquisition Partner know you would be interested in working on-site.



Work From Anywhere is subject to Radian’s Alternative Work Policy and business needs.


 See Why You Should Work With Us



 Competitive Compensation: anticipated base salary from $105,120 to $168,400 based on skills and experience. This position is eligible to participate in an annual incentive program.
 Rest and Relaxation. This role is eligible for 25 days of paid time off annually, which is prorated in the year of hire based on hire date. In addition, based on your hire date, you will be eligible for 9 paid holidays + 2 floating holiday in support of our DEI culture. Parental leave is also offered as an opportunity for all new parents to embrace this exciting change in their lives.
 Our Company Makes an Impact. We’ve been recognized by multiple organizations like Bloomberg’s Gender-Equality Index, HousingWire’s Tech 100, and The Forum of Executive Women’s Champion of Board Diversity. Radian has also pledged to PwC’s CEO Action for Diversity & Inclusion commitment.
 Comprehensive Health Benefits. Multiple medical plan choices, including HSA and FSA options, dental, vision, and basic life insurance.
 Prepare for your Future. 401(k) with a top of market company match (did we mention the company match is immediately vested?!) and an opportunity to participate in Radian’s Employee Stock Purchase Plan (ESPP).
 Homebuyer Perks. Our Homebuyer Perks program helps employees navigate the home searching, buying, selling, and refinancing processes and provides valuable financial benefits to encourage, enable, and support home ownership.





 See More About Radian

 Radian is a fintech servicing the mortgage and real estate services industry. As a team, we pride ourselves on seeing the potential of every person, every idea and every day.

 Seeing each other at Radian goes far beyond our open, flexible culture. It means seeing our people’s potential – and creating inspiring career paths that help them get there. Or seeing new pathways and innovating for the future of our industry. It means seeing each other for all that we are. And it means seeing our purpose as one that extends beyond the bottom line – having an impact on communities across the country to help more people achieve the American Dream of homeownership.

 We hope you’ll see yourself at Radian. See more about us at Radian.com.

 Defining Roles for Radian's Future

 Understanding the qualities and characteristics that define a Leader and an Employee is important to building our future-fit workforce. Radian's future is only as bright as its people. For that reason, our People Plan includes profiles to support the qualities and characteristics that each Leader as well as each Employee should embody upon hire or via development.

 EEO Statement

 Radian complies with all applicable federal, state, and local laws prohibiting discrimination in employment. All qualified applicants will receive consideration for employment without regard to gender, age, race, color, religious creed, marital status, gender identity, sexual orientation, national origin, ethnicity, ancestry, citizenship, genetic information, disability, protected veteran status or any other characteristic protected by applicable federal, state, or local law.
 
Equal Opportunity Employer Details

 View the ""EEO is the Law"" poster [Link]. View the ""EEO is the Law"" Supplement [Link]. View Pay Transparency Nondiscrimination Provision [Link].
 
Accommodation

 Whether you require an accommodation for the job application or interview process, Radian is dedicated to a barrier-free employment process and encourages a diverse workforce. If you have questions about the accommodation process, please e-mail careers@radian.com.
",105120,"['python', 'sql']"
Sr SDoH and Population Insights Data Analyst - Remote,UnitedHealthcare,MN,Full-time,"
At UnitedHealthcare, we’re simplifying the health care experience, creating healthier communities and removing barriers to quality care. The work you do here impacts the lives of millions of people for the better. Come build the health care system of tomorrow, making it more responsive, affordable and equitable. Ready to make a difference? Join us to start Caring. Connecting. Growing together.

 
Around here, we're always striving for better. A better way to think. A better way to care. A better way to succeed. As the Sr SDoH and Population Insights Data Analyst, you'll drive the improvements and enhancements of our data model. You’ll partner with team members in IT and offshore. And you’ll be part of making sure our data model is accurate and supportive of regulatory requirements. Not to mention, since UHC is part of the UnitedHealth Group family of businesses, you will also have the support and resources of a Fortune 5 industry leader. It's a chance to be a part of something transformative. Sound good? Join us today.


 You’ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges.

 
Primary Responsibilities:

Onshore lead infrastructure analyst for the UHC Social Determinants of Health platform, responsible for prioritizing and defining work for offshore resources, mentoring them on data knowledge as well as technical skills, reviewing their results, and presenting to SDoH leadership for feedback and approval
Responsible for performing in-depth data analysis on the enterprise data
Responsible for monitoring the data quality and engaging with the stakeholders and reporting team to ensure right enhancements are documented, prioritized and road mapped
Partnering with the data platform scrum team to implement enhancements and ensure quality data is delivered
Functioning as a data SME for the tech team
Conducting and managing outcomes of various studies that include analyzing, reviewing, forecasting, trending, and presenting information for operational and business planning
Supporting short and long term operational/strategic business activities - by developing, enhancing, and maintaining operational information and models
Developing and implementing effective/strategic business solutions through research and analysis of data and business processes
Responsible for creating specifications to bring different data into a common structure, creating product specifications and models, developing data solutions to support analyses, performing analysis, interpreting results, developing actionable insights and presenting recommendations for use across the enterprise
Serves as a key resource on complex and/or critical issues that arise around the SDoH platform



 
You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.
 Required Qualifications:

4+ years of experience writing code for various SQL applications; such as Oracle, Snowflake, MS SQL, Azure SQL, Hive, etc.
Experience with data modeling and data warehousing
Experience with Medicaid & Medicare including member eligibility and claims data
Experience translating business requirements into capabilities and features
Experience with data analysis and interpreting results
Experience mentoring and partnering with other team members of various grade levels; with ability to motivate and inspire team members
Experience reviewing work performed by others and provides recommendations for improvement
Willing to adjust working hours to accommodate East Coast and offshore business hours as needed



 Preferred Qualifications:

Experience with UHC applications (SMART for C&S, GPS for M&R, CMS warehouse, CDB, etc.)
Experience with visualization tools like Tableau, Power BI
Excellent communication skills with the ability to explain complex technical issues in the appropriate way for the current audience (technical or business)
Self-reliant, self-driving, curious and a fast learner




All employees working remotely will be required to adhere to UnitedHealth Group’s Telecommuter Policy



 California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island, or Washington Residents Only: The salary range for California/Colorado/Connecticut/Nevada/New Jersey/New York/Rhode Island/Washington residents is $85,000 to $167,300 annually. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives.


 At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone–of every race, gender, sexuality, age, location and income–deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes — an enterprise priority reflected in our mission.


 Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.


 UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.
",85000,"['tableau', 'azure', 'sql']"
"AVP, Mortgage Portfolio Analytics - 100% Remote",Radian,CO,Full-time,"
See yourself at Radian? We see you here too.

 At Radian, we see you. For the person you are and the potential you hold. That’s why we’ve embraced a new way of working that lets our people across the country be themselves, be their best and be their boldest. Because when each of us is truly seen, each of us gives our best – and at Radian, we’ll give you our best right back.

 Studies have shown that job seekers may hesitate to apply for jobs unless they meet every single qualification listed. We strive to see the potential in each applicant, so if you’re excited about this role but your experience or education level doesn’t align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.
 See Yourself as an AVP, Mortgage Portfolio Analytics
 The AVP, Mortgage Portfolio Analytics role is responsible for the design, development, and delivery of quantitative tools to help price and manage the risk of radian’s mortgage loan portfolio and structured mortgage transactions. This role will work within the Secondary Marketing team to build and maintain relevant financial models and reports to analyze financial targets and risk tolerances.

 Primary Duties and Responsibilities:

 Support quantitative models for risk management activities. Establish and support the models embedded in the hedging models for loans and MSRs. This includes pull-through, mark to market and duration models for agency and nonagency products. Familiarity with mortgage risk management software such as Compass Analytics a plus.
 Utilize and implement internal credit analysis and financing strategies in pricing and risk management models – Understand and incorporate the organizations credit knowledge and financing in the analysis of pricing and best execution. Create strong internal relationships in the organization to leverage knowledge and incorporate into trading strategies.
 Conduct in-depth analysis of secondary mortgage market trends including interest rates, loan pricing, and investor demand.
 Establish and support a pricing methodology for acquiring loans. This includes understanding structure as well as the tools used to interpret the pricing impacts in agency and nonagency markets. (ie. Intex, Bloomberg, refinitiv and S&P levels).
 Research and buildout of new products and offerings to help drive business growth and lock volume.
 Using subject matter expertise, make recommendations to the process of model and technology improvements across various analytic and database tools.
 Assist in more complex secondary markets operations and analysis including daily management of Compass Analytics, TBA hedging, MSR valuations, and MBS structuring.


 Education Level: Bachelor’s degree in a quantitative field such as Mathematics, Statistics, Finance or Engineering. Master’s degree preferred.

 Years of Prior Work-Related Experience: 5 years of working experience in residential mortgage secondary marketing or mortgage-related industry.

 Additional Qualifications including any special skills, capabilities, and competencies:

 Working experience with a scripting language (SQL, VBA, Python, R) required.
 Previous support of trading desks or knowledge of fixed income trading, mortgage banking or correspondent lending, a plus.
 Solid knowledge in database systems, programming software, application tools and business intelligence reporting standards. Experience manipulating and analyzing complex, high-volume, data from varying sources.
 Excellent technical skills with ability to design and maintain complex financial models.
 Strong analytical skills along with the ability and willingness to effectively make recommendations on transactions based on sound business judgment. 
Clear and effective interpersonal, written, and verbal communications skills. Must be able to clearly and effectively communicate with various groups within the company as well as various external business partners, both verbally and in writing.
 Highly motivated, self-starter, dependable, responsible and able to use good judgment.
 Ability to work in fast-faced, multi-tasking environment and to manage multiple deadlines.
 Strong aptitude for detail and accuracy.


 See Your Location


 Radian is committed to a flexible work environment for many of our roles. This is a *Work From Anywhere* role meaning you have the flexibility to work from home (or another designated workspace that fits your needs).


 This role provides additional flexibility should you want to work on-site at a Radian office. Explore our office locations here and let your Talent Acquisition Partner know you would be interested in working on-site.



Work From Anywhere is subject to Radian’s Alternative Work Policy and business needs.


 See Why You Should Work With Us



 Competitive Compensation: anticipated base salary from $105,120 to $168,400 based on skills and experience. This position is eligible to participate in an annual incentive program.
 Rest and Relaxation. This role is eligible for 25 days of paid time off annually, which is prorated in the year of hire based on hire date. In addition, based on your hire date, you will be eligible for 9 paid holidays + 2 floating holiday in support of our DEI culture. Parental leave is also offered as an opportunity for all new parents to embrace this exciting change in their lives.
 Our Company Makes an Impact. We’ve been recognized by multiple organizations like Bloomberg’s Gender-Equality Index, HousingWire’s Tech 100, and The Forum of Executive Women’s Champion of Board Diversity. Radian has also pledged to PwC’s CEO Action for Diversity & Inclusion commitment.
 Comprehensive Health Benefits. Multiple medical plan choices, including HSA and FSA options, dental, vision, and basic life insurance.
 Prepare for your Future. 401(k) with a top of market company match (did we mention the company match is immediately vested?!) and an opportunity to participate in Radian’s Employee Stock Purchase Plan (ESPP).
 Homebuyer Perks. Our Homebuyer Perks program helps employees navigate the home searching, buying, selling, and refinancing processes and provides valuable financial benefits to encourage, enable, and support home ownership.





 See More About Radian

 Radian is a fintech servicing the mortgage and real estate services industry. As a team, we pride ourselves on seeing the potential of every person, every idea and every day.

 Seeing each other at Radian goes far beyond our open, flexible culture. It means seeing our people’s potential – and creating inspiring career paths that help them get there. Or seeing new pathways and innovating for the future of our industry. It means seeing each other for all that we are. And it means seeing our purpose as one that extends beyond the bottom line – having an impact on communities across the country to help more people achieve the American Dream of homeownership.

 We hope you’ll see yourself at Radian. See more about us at Radian.com.

 Defining Roles for Radian's Future

 Understanding the qualities and characteristics that define a Leader and an Employee is important to building our future-fit workforce. Radian's future is only as bright as its people. For that reason, our People Plan includes profiles to support the qualities and characteristics that each Leader as well as each Employee should embody upon hire or via development.

 EEO Statement

 Radian complies with all applicable federal, state, and local laws prohibiting discrimination in employment. All qualified applicants will receive consideration for employment without regard to gender, age, race, color, religious creed, marital status, gender identity, sexual orientation, national origin, ethnicity, ancestry, citizenship, genetic information, disability, protected veteran status or any other characteristic protected by applicable federal, state, or local law.
 
Equal Opportunity Employer Details

 View the ""EEO is the Law"" poster [Link]. View the ""EEO is the Law"" Supplement [Link]. View Pay Transparency Nondiscrimination Provision [Link].
 
Accommodation

 Whether you require an accommodation for the job application or interview process, Radian is dedicated to a barrier-free employment process and encourages a diverse workforce. If you have questions about the accommodation process, please e-mail careers@radian.com.
",105120,"['python', 'sql']"
Sr SDoH and Population Insights Data Analyst - Remote,UnitedHealthcare,MN,Full-time,"
At UnitedHealthcare, we’re simplifying the health care experience, creating healthier communities and removing barriers to quality care. The work you do here impacts the lives of millions of people for the better. Come build the health care system of tomorrow, making it more responsive, affordable and equitable. Ready to make a difference? Join us to start Caring. Connecting. Growing together.

 
Around here, we're always striving for better. A better way to think. A better way to care. A better way to succeed. As the Sr SDoH and Population Insights Data Analyst, you'll drive the improvements and enhancements of our data model. You’ll partner with team members in IT and offshore. And you’ll be part of making sure our data model is accurate and supportive of regulatory requirements. Not to mention, since UHC is part of the UnitedHealth Group family of businesses, you will also have the support and resources of a Fortune 5 industry leader. It's a chance to be a part of something transformative. Sound good? Join us today.


 You’ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges.

 
Primary Responsibilities:

Onshore lead infrastructure analyst for the UHC Social Determinants of Health platform, responsible for prioritizing and defining work for offshore resources, mentoring them on data knowledge as well as technical skills, reviewing their results, and presenting to SDoH leadership for feedback and approval
Responsible for performing in-depth data analysis on the enterprise data
Responsible for monitoring the data quality and engaging with the stakeholders and reporting team to ensure right enhancements are documented, prioritized and road mapped
Partnering with the data platform scrum team to implement enhancements and ensure quality data is delivered
Functioning as a data SME for the tech team
Conducting and managing outcomes of various studies that include analyzing, reviewing, forecasting, trending, and presenting information for operational and business planning
Supporting short and long term operational/strategic business activities - by developing, enhancing, and maintaining operational information and models
Developing and implementing effective/strategic business solutions through research and analysis of data and business processes
Responsible for creating specifications to bring different data into a common structure, creating product specifications and models, developing data solutions to support analyses, performing analysis, interpreting results, developing actionable insights and presenting recommendations for use across the enterprise
Serves as a key resource on complex and/or critical issues that arise around the SDoH platform



 
You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.
 Required Qualifications:

4+ years of experience writing code for various SQL applications; such as Oracle, Snowflake, MS SQL, Azure SQL, Hive, etc.
Experience with data modeling and data warehousing
Experience with Medicaid & Medicare including member eligibility and claims data
Experience translating business requirements into capabilities and features
Experience with data analysis and interpreting results
Experience mentoring and partnering with other team members of various grade levels; with ability to motivate and inspire team members
Experience reviewing work performed by others and provides recommendations for improvement
Willing to adjust working hours to accommodate East Coast and offshore business hours as needed



 Preferred Qualifications:

Experience with UHC applications (SMART for C&S, GPS for M&R, CMS warehouse, CDB, etc.)
Experience with visualization tools like Tableau, Power BI
Excellent communication skills with the ability to explain complex technical issues in the appropriate way for the current audience (technical or business)
Self-reliant, self-driving, curious and a fast learner




All employees working remotely will be required to adhere to UnitedHealth Group’s Telecommuter Policy



 California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island, or Washington Residents Only: The salary range for California/Colorado/Connecticut/Nevada/New Jersey/New York/Rhode Island/Washington residents is $85,000 to $167,300 annually. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you’ll find a far-reaching choice of benefits and incentives.


 At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone–of every race, gender, sexuality, age, location and income–deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes — an enterprise priority reflected in our mission.


 Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.


 UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment.
",85000,"['tableau', 'azure', 'sql']"
Statistician (Data Scientist),US Patent and Trademark Office,VA,Full-time,"

Duties

The physical worksite for this position is located in Alexandria, Virginia. This position is telework eligible per agency and business unit discretion/policy.   Major Duties:

Develops Patents data analytic metrics and algorithms using programming languages and a variety of statistical and data analytics tools (e.g. SQL, Python, R, and Alteryx).
Utilizes statistical research techniques such as modeling, forecasting, and predictive analysis to identify trends, patterns, and relationships using Patent operational data.
Plans and conducts analyses of Patents structured and unstructured data relating to management issues.
Conducts cross-organizational meetings with Patent operations managers to communicate findings in an oral, visual, and written manner.




Requirements
Conditions of Employment

Applications will only be accepted from United States Citizens and Nationals.
Your resume and question responses must demonstrate the job-related competencies.
You must meet the definition of specialized experience.
Required to pass a background investigation and fingerprint check.
Must be registered for Selective Service, if applicable (www.sss.gov).
If selected, you may be required to complete a one year probationary period.
You must meet all qualification requirements upon the closing date of this announcement.
Suitable for Federal Employment


Qualifications

    You must meet the United States Office of Personnel Management's (OPM) qualification requirements (including specialized experience and/or educational requirements) for the advertised position. You must meet all eligibility and qualifications requirements by the closing date of the job announcement. OPM Qualifications Standards are available at OPM Statics Series 1530
    

BASIC QUALIFICATION REQUIREMENTS:

 To be considered for this position, you must have either: 
    

Degree: that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR 
Combination of education and experience 
     
- courses as shown in A above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.


 Specialized Experienceis experience that has equipped applicants with the particular knowledge, skills and abilities to successfully perform the duties of the position, and that is typically in or related to the position to be filled. To be creditable, specialized experience must have been equivalent to at least the next lower grade level in the federal service. For this position, the next lower grade level is a 
    GS-12.
    

Specialized experience for this position includes: Planning, directing, and coordinating a variety of specialized and complex analytical and statistical research projects; making authoritative and final decisions; developing data collection methods, and analyzing data through the use of valid statistical techniques; utilizing a variety of software packages to carry out analyses; preparing and disseminating reports on results; providing advice and consultation on a variety of data analytical problems.
    
 Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience. 
   


Education

If this position requires proof of higher education, or you are substituting education for experience, you must submit an unofficial transcript or a list of courses that includes the following information: name of accredited institution, grades earned, completion dates, and quarter and semester hours earned. Education completed in foreign colleges or universities may be used to meet the requirements. Please refer to http://www.opm.gov/qualifications/policy/ApplicationOfStds-04.asp for more information. You are not required to submit official documents at this time; copies are sufficient.  Special Instructions for Foreign Education: Qualifying education from colleges and universities in foreign countries must be evaluated in terms of equivalency to that acquired in U.S. colleges and universities. Applicants educated in whole or in part in foreign countries must submit sufficient evidence, including transcripts, to an accredited private organization for an equivalency evaluation of course work and degree. A listing of these accredited organizations can be found on the Department of Education's website - US Department of Education. Another listing of services that can perform this evaluation is available at the National Association of Credential Evaluation Services (NACES) website. You must provide a copy of the letter containing the results of the equivalency evaluation with a course by course listing along with your application. Failure to provide such documentation when requested will result in lost consideration.  NOTE: Only education and experience acquired before the filing deadline will be considered. Report only attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.



Additional information

If you are a male applicant born after December 31, 1959, you must certify that you have registered with the Selective Service System. If you are exempt from registration under Selective Service Law, you must provide appropriate proof of exemption. Please visit the Selective Service System website for more information.  This is a Bargaining Unit position and represented by The Patent Office Professional Association (POPA).  If selected for this position, you may be required to complete the Fair Credit Act Memo, which gives consent so that one or more consumer credit reports may be obtained for employment purposes.  This is a Public Trust position and has a risk level designation of ""moderate"".  Background Investigation - If selected for this position, you may be required to complete a Declaration for Federal Employment (OF-306), which includes a fingerprint and credit check, to determine your suitability for Federal employment and to authorize a background investigation.  The USPTO participates in E-Verify. For more information on E-Verify, please visit the Department of Homeland Security Website.  All Federal employees are required to have Federal salary payments made by direct deposit to a financial institution of their choice.  Relocation Expenses are not authorized and will not be paid.  CTAP and ICTAP candidates will be eligible for selection priority if it is determined that they have exceeded the minimum qualifications for the position by attaining at least a ""well qualified"" rating of 85 out of 100. Information about CTAP and ICTAP eligibility is on the Office of Personnel Management's Career Transition Resources website at: OPM CTAP/ICTAP.  CTAP/ICTAP documentation requirements are listed in the 'Required Documents' section of this announcement.  More than one selection may be made from this announcement if additional identical vacancies in the same title, series, grade, and unit occur within 90 days from the date the certificate was issued.  All application materials become the property of the United States Patent and Trademark Office.  USPTO Job Applicants requiring reasonable accommodation for any part of the application and hiring process should request accommodation(s) from the USPTO at http://www.uspto.gov/accommodation.  The United States Patent and Trademark Office is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factors. If you believe that you have been discriminated against and would like to file an EEO complaint, you must do so within 45 days of the date of the alleged discriminatory act. Claims of employment discrimination must be submitted to the attention of the USPTO's Office of Equal Employment Opportunity & Diversity via email (oeeod@uspto.gov) or phone (571-272-8292).





Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.
Your resume, optional cover letter and supporting documentation will be reviewed to determine if you meet the minimum qualifications for the position. If you meet the minimum qualifications stated in the job opportunity announcement, we will compare your resume, optional cover letter and supporting documentation to your responses on the self-assessment questions (True/False, Yes/ No, Multiple Choice questions) and place you in one of three pre-defined categories. These categories are ""gold,"" ""silver,"" and ""bronze."" Your resume and/or optional cover letter must support your responses to the scored occupational questionnaire, or your score may be lowered. Candidates placed in the ""gold"" category will be identified for referral to the hiring manager and may be invited for an interview.  How you will be evaluated for Veteran's Preference eligibility: Preference eligibles with a service-connected disability of 10% or more will be listed at the top of their quality category.  Your resume will be evaluated based on evidence of your ability to demonstrate possession of any specialized experience and how well your background and experience relates to the self-assessment questions in the job announcement. Responses to job questions that are not fully supported by the information in your resume may result in adjustments to your rating. Any experience claimed in a cover letter should be substantiated by information contained in your resume. A HR Representative will validate the qualifications of those candidates eligible to be referred to the hiring official.  The scored occupational questionnaire will evaluate you on the following competencies; Please do not provide a separate written response. 

Database Administration
 Research
 Software Testing and Evaluation
 Writing


 For more information on category rating, please go to: DOC Bulletins
   

Please click the link below to preview the Assessment Questionnaire:
 https://apply.usastaffing.gov/ViewQuestionnaire/12174974
   
 Please note that a complete application is required for consideration. (Please review the ""Required Documents"" section of this job announcement to see what must be included in a complete application).
   





Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
A complete application consists of:  1. A resume or any other written format you choose to describe your job-related qualifications; optional cover letter: Your resume should indicate your citizenship and should list your educational and work experience including titles, salary, employment dates, duties, experience and how it relates to the specialized experience in the job announcement.  2. Transcripts: You MUST submit copies of your college transcripts for verification of the education requirements. Unofficial copies are accepted, however, if selected you will be required to furnish official transcripts. It is your responsibility to provide adequate proof that you meet the above educational requirement. Inadequate or illegible information could result in non-qualification and loss of consideration. (For Individual Occupational Requirements and/or Substitution of Education for specialized experience.   Supporting Documents:  PLEASE NOTE: Applicants who meet the minimum eligibility and qualification requirements for this position may be contacted within 7 business days of the closing date of this announcement to submit follow-up supporting documentation if applicable. Applicants claiming veterans' preference entitlement or CTAP/ICTAP eligibility who fail to submit supplemental documentation within 5 business days of receiving the request will not lose consideration for this position, however they will not be entitled to special or priority consideration.  1. Veterans' Preference Documentation: If you are a veteran with preference eligibility, you will be asked to submit a copy of your DD-214 containing your discharge disposition, dates of service, and rank. If you are a preference eligible claiming a service-connected disability of 10 percent or more, you will be asked to submit documentation (i.e., a letter dated 1991 or later from the Department of Veterans Affairs or from a branch of the Armed Forces) certifying to the veteran's present receipt of compensation. Veterans must include dates of military service within the automated application process and submit a copy of each Certificate of Release or Discharge from Active Duty, DD-214. For more information, please visit Feds Hire Vets.  2. Career Transition Assistance Program (CTAP) or Interagency Career Transition Assistance Program (ICTAP) documents -  CTAP applicants MUST submit the following documents: 1. A copy of your RIF separation notice, notice of proposed removal for declining a directed geographic relocation outside of the local commuting area; a Certificate of Expected Separation (CES); or certification that you are in a surplus organization or occupation (this could be a position abolishment letter, a notice of eligibility for discontinued service retirement, or similar notice); 2. A copy of your SF-50 ""Notification of Personnel Action"", noting current position, grade/band level, and duty location; 3. A copy of your latest performance appraisal including your rating; and 4. Any documentation from your bureau/operating unit that shows your current promotion potential.  ICTAP applicants MUST submit the following documents: 1. A copy of your RIF separation notice, notice of proposed removal for declining a directed geographic relocation outside of the local commuting area, notice of disability annuity termination, certification from your former agency that it cannot place you after your recovery from a work-related compensable injury; or certification from the National Guard Bureau or Military Department that you are eligible for disability retirement; 2. A copy of your SF-50 ""Notification of Personnel Action"", documenting your RIF separation, noting your position, grade/band level, and duty location, and/or Agency certification of inability to place you through RPL, etc.; 3. A copy of your latest performance appraisal including your rating; and 4. Any documentation from your agency that shows your current promotion potential.  You can upload your documents when you register or update your information on the Dept. of Commerce site which you access through the USAJobs site.  Your application and all required documents must be received by 11:59 pm ET on the closing date of this job announcement. NOTE: The preceding documents requirement are based on job requirements and individual applicant eligibility. Not all documents are applicable to all applicants; if you are unsure which documents apply to you, contact the HR Specialist listed on this announcement. 

How to Apply


 You MUST apply online. If you experience difficulties with the application process or do not have access to a computer, please contact the HR Specialist listed as the point of contact before the closing date of this job announcement.  If you are a new user to the USAJobs Site and have never registered for an account, you will first need to create an account profile with your basic contact information and a resume to begin applying. You must be a registered USAJobs user AND you must be signed-in to your account in order to apply for this position. For help setting up an account or for general help using USAJobs, go to USAJobs Help Page. Once you have gathered all of the required information and are ready to begin the application process, click the ""APPLY"" button at the right side of the page. You will then be directed away from USAJobs to the Department of Commerce application site for USPTO. You must click ""Submit"" at the end of the application process to send your application for consideration.  To return to your saved application, log in to your USAJOBS account at http://www.usajobs.gov/ and click on ""Applications."" Click on the position title, then select ""Update Application.""  If you experience any difficulties with the application site, help is available! OPM has a Help feature on each page. Use this option when you need assistance.  All required supporting documents will be collected electronically via the USAJobs ""Saved Documents"" feature.  Personally Identifiable Information (PII) Personally Identifiable Information (PII) is defined as information that can be traced back to a specific individual and potentially compromise their security or privacy. Examples of PII include: date of birth, Social Security Number, and place of birth.  Please ensure that you have removed all Personally Identifiable Information from all documents prior to submitting or uploading your applications material.


Agency contact information
Angela Cardona 


Phone
571-272-4318 
Email
ANGELA.CARDONA@USPTO.GOV 


Address


PATS - Office of the Chief Data Analytics Officer

Office of Human Resources

Mail Stop 171 

P.O. Box 1450 

Alexandria, VA 22313-1450

US 




Next steps

You will receive a notice generated by the USAJobs System when you have successfully submitted your application.  You will be notified of your application status through USAJOBS at four points during the hiring process, as applicable. You can check the status of your application by accessing the USAJOBS website at http://usajobs.gov/ and clicking on ""Track Your Online Application."" The four points of notification are:  1. Application Received or Application Incomplete; 2. Minimum Qualification Requirement Met or Minimum Qualification Requirement Not Met; 3. Eligible (Application Referred to the Selecting Official) or Eligible (Application Not Referred to the Selecting Official); and 4. Selected or Not Selected  After all application packages have been received, we will review your application and transcript(s) (if you are qualifying based on education) to ensure you meet the basic qualification requirements. We will evaluate each applicant who meets the basic qualifications on the information provided and you may be contacted for follow-up supplemental documentation. It is the applicant's responsibility to provide any supplemental documents or information requested by the Office of Human Resources within the allocated timeframes.  You will be required to submit official documentation prior to appointment. The agency will then verify the information provided on your application (i.e., degree, veterans' preference, disability, etc.). You can check the status of your application by logging into USAJOBS. You may also sign up to receive automatic emails anytime the status of your application has changed by logging into your USAJobs Account, editing your profile and changing the ""Notification Settings"" to indicate that you want to be notified by email when the status changes. Information regarding the status of your application should be updated in the system within 2 weeks after the closing date of this job announcement. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents

A complete application consists of:  1. A resume or any other written format you choose to describe your job-related qualifications; optional cover letter: Your resume should indicate your citizenship and should list your educational and work experience including titles, salary, employment dates, duties, experience and how it relates to the specialized experience in the job announcement.  2. Transcripts: You MUST submit copies of your college transcripts for verification of the education requirements. Unofficial copies are accepted, however, if selected you will be required to furnish official transcripts. It is your responsibility to provide adequate proof that you meet the above educational requirement. Inadequate or illegible information could result in non-qualification and loss of consideration. (For Individual Occupational Requirements and/or Substitution of Education for specialized experience.   Supporting Documents:  PLEASE NOTE: Applicants who meet the minimum eligibility and qualification requirements for this position may be contacted within 7 business days of the closing date of this announcement to submit follow-up supporting documentation if applicable. Applicants claiming veterans' preference entitlement or CTAP/ICTAP eligibility who fail to submit supplemental documentation within 5 business days of receiving the request will not lose consideration for this position, however they will not be entitled to special or priority consideration.  1. Veterans' Preference Documentation: If you are a veteran with preference eligibility, you will be asked to submit a copy of your DD-214 containing your discharge disposition, dates of service, and rank. If you are a preference eligible claiming a service-connected disability of 10 percent or more, you will be asked to submit documentation (i.e., a letter dated 1991 or later from the Department of Veterans Affairs or from a branch of the Armed Forces) certifying to the veteran's present receipt of compensation. Veterans must include dates of military service within the automated application process and submit a copy of each Certificate of Release or Discharge from Active Duty, DD-214. For more information, please visit Feds Hire Vets.  2. Career Transition Assistance Program (CTAP) or Interagency Career Transition Assistance Program (ICTAP) documents -  CTAP applicants MUST submit the following documents: 1. A copy of your RIF separation notice, notice of proposed removal for declining a directed geographic relocation outside of the local commuting area; a Certificate of Expected Separation (CES); or certification that you are in a surplus organization or occupation (this could be a position abolishment letter, a notice of eligibility for discontinued service retirement, or similar notice); 2. A copy of your SF-50 ""Notification of Personnel Action"", noting current position, grade/band level, and duty location; 3. A copy of your latest performance appraisal including your rating; and 4. Any documentation from your bureau/operating unit that shows your current promotion potential.  ICTAP applicants MUST submit the following documents: 1. A copy of your RIF separation notice, notice of proposed removal for declining a directed geographic relocation outside of the local commuting area, notice of disability annuity termination, certification from your former agency that it cannot place you after your recovery from a work-related compensable injury; or certification from the National Guard Bureau or Military Department that you are eligible for disability retirement; 2. A copy of your SF-50 ""Notification of Personnel Action"", documenting your RIF separation, noting your position, grade/band level, and duty location, and/or Agency certification of inability to place you through RPL, etc.; 3. A copy of your latest performance appraisal including your rating; and 4. Any documentation from your agency that shows your current promotion potential.  You can upload your documents when you register or update your information on the Dept. of Commerce site which you access through the USAJobs site.  Your application and all required documents must be received by 11:59 pm ET on the closing date of this job announcement. NOTE: The preceding documents requirement are based on job requirements and individual applicant eligibility. Not all documents are applicable to all applicants; if you are unsure which documents apply to you, contact the HR Specialist listed on this announcement.





 Help 
 This job is open to




Career transition (CTAP, ICTAP, RPL)
Federal employees who meet the definition of a ""surplus"" or ""displaced"" employee.




Individuals with disabilities




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.



Clarification from the agency
Applications will be accepted from all U.S. Citizens or Nationals.

",112015,"['python', 'sql']"
Machine Learning Engineer,Ladder,CA,Full-time,"
About Ladder
 We saw a problem within the life insurance industry: getting covered took too long, involved too much paperwork, and required too many in-person meetings with sales agents. Having lost his father at a young age, our CEO, Jamie, was determined to make it easier for people to get the coverage they needed to provide for their families. So, we got to work. We developed a method of real-time underwriting and, in doing so, reduced the months-long process of applying for life insurance to minutes. Our digital experience is quick (instant decisions!), loved by users (check out our Trustpilot or Google reviews) and prolific ($60 billion+ in coverage provided).
 About the role
 We're hiring a Machine Learning Engineer to join our team and help us reimagine life insurance. The ideal candidate will have a deep understanding of machine learning algorithms and techniques, as well as experience in software development and data engineering. You will be responsible for designing, developing, tuning and deploying machine learning models to solve challenging problems in the life insurance industry. This is a hybrid role, requiring 1-2 days a week in our Palo Alto headquarters.
 Responsibilities

Design, develop, tune and deploy machine learning models to improve the life insurance experience for our customers
Work with data scientists and engineers to build and maintain data pipelines and infrastructure
Collaborate with cross functional partners to understand their needs and develop machine learning solutions to meet those needs
Monitor and evaluate the performance of machine learning models and make necessary adjustments
Stay up-to-date on the latest machine learning research and trends, utilize emerging technologies to address business issues through technical innovation

Requirements

3+ years experience in machine learning engineering, specifically building and launching production models
2+ years of software development in one or more programming languages with basic data structures/algorithms knowledge
Full-stack development with some exposure to front-end frameworks a plus
2+ years in a highly regulated environment such as healthcare, finance, insurance or pharmaceuticals a big plus
Master's degree or PhD in Computer Science or related technical field a plus
Hybrid role in our Palo Alto headquarters as needed

Tech Stack
 It's great if you're familiar with these technologies but at Ladder we believe general technical proficiency is more important than specific technologies knowledge.

Frontend: Clojurescript, React, GraphQL
Backend: Clojure, JVM
Infrastructure: Kafka, Docker, Kubernetes, Packer, Terraform, AWS
Data: BigQuery, Tableau, BEAM

Our engineering culture & values
 Check out our Company Values to learn more about who we are. We are passionate about:

Bottom-up leadership: teams are most successful when everybody shares their ideas, comfortable that they'll be seriously considered. engineers can and should provide product & business insights.
Shipping fast without breaking things: we've invested heavily in engineering tooling that provides guardrails without getting in your way. We believe in shipping MVPs & iterating quickly rather than waiting for perfection to ship.
Investing in automation: automating repetitive tasks saves time and reduces errors. We're always on the lookout for manual workflows to automate away.
Continuous improvement: we learn from our past wins & losses by conducting blameless retros.

What we Offer
 Whether you work in our beautiful office in Palo Alto or remotely, Ladder is highly collaborative and fun. To support you in your role, we offer fantastic perks and benefits that reflect our mission of care and support, including:

Excellent medical, dental, and vision coverage | We offer competitive healthcare, dental and vision plans for you and your family.
Flexible paid time off | Take the time that you need to rest and recharge, including our week-long winter holiday closure.
Stock options | We offer competitive stock option packages to participate in the success of building Ladder, including an extended option exercise window of 7 years after two years with Ladder.
A rewarding 401k match program | We'll match up to 4% of your contributions as you save for your retirement goals.
Ladder Fit Program | Your health matters. That's why Ladder provides a monthly reimbursement for wellness-related expenses.
Commuter benefits | When you work from the office, you will receive pre-tax benefits for your commute and free parking.
A stocked, beautiful new office | Located in downtown Palo Alto, our office was specifically designed to accommodate all working styles. We've invested in technology to support our hybrid team, plus we provide office snacks and daily catered lunches so that team members can work well and have fun together.
Paid parental leave | We think it's crucial that new parents have time to adjust to their new lives without worrying about work. For birthing parents, they are eligible for 6-8 weeks post delivery recovery. Afterwards, all parents inclusive of birthing, adoption, or fostering are eligible for ten weeks of paid baby bonding with a gentle phase-back program, where parents can return to work on a reduced schedule for the first month at full pay.
Work-from-home flexibility and support | We recognize that everyone's home life is different and support remote and hybrid work. Upon joining, we provide a one-time remote office stipend for all team members and then a monthly stipend to cover WFH costs such as the internet.
Fun company-wide events | Whether we work locally or remotely, we genuinely enjoy spending time together. That's why we plan fun virtual and in-person events to let loose and laugh.

This role is mapped to the job level of P2/L4 and thus the base pay range targeted for this position is $121,125 - $154,500 per year. This role is eligible for equity and benefits as shared above. Base pay is determined by market location and may vary depending on job-related knowledge, skills, and experience.
 Ladder is building a diverse team of talented and enthusiastic people. We are an equal opportunity workplace. At Ladder, differences are celebrated and supported to benefit our people, product, and community. Let us know why you're interested in this position and what unique contributions you can make to the Ladder team. We look forward to hearing from you.
 Research shows that candidates from underrepresented backgrounds often don't apply for roles if they don't meet all the criteria – unlike majority candidates meeting significantly fewer requirements. We strongly encourage you to apply if you're interested: we'd love to know how you can elevate our team with your unique experience!
 By clicking ""Submit Application,"" you acknowledge that you have read and agree to the Ladder Job Applicant Privacy Policy and Notice at Collection.

 By clicking ""Submit Application,"" you acknowledge that you have read and agree to the Ladder Job Applicant Privacy Policy and Notice at Collection.

",121125,"['machine learning', 'tableau', 'aws', 'docker', 'kafka']"
Machine Learning Engineer II - Java Development,Warner Bros. Discovery,CA,Full-time,"
Every great story has a new beginning, and yours starts here.
 Welcome to Warner Bros. Discovery… the stuff dreams are made of.

 Who We Are… 
When we say, “the stuff dreams are made of,” we’re not just referring to the world of wizards, dragons and superheroes, or even to the wonders of Planet Earth. Behind WBD’s vast portfolio of iconic content and beloved brands, are the storytellers bringing our characters to life, the creators bringing them to your living rooms and the dreamers creating what’s next…

 From brilliant creatives, to technology trailblazers, across the globe, WBD offers career defining opportunities, thoughtfully curated benefits, and the tools to explore and grow into your best selves. Here you are supported, here you are celebrated, here you can thrive.

 Warner Bros. Discovery's DTC technology and product organization sits at the intersection of tech, entertainment, and everyday utility. We are continuously leveraging new technology to build immersive and interactive viewing experiences. Our platform covers everything from search, content catalog, and video transcoding, to personalization, global subscriptions, and more. We are committed to delivering unique and quality user experiences, ranging from video streaming to applications across connected TV, mobile, web and consoles. As a pure tech organization, we are essential to Warner Bros. Discovery’s continued growth, building world-class streaming products from the ground-up for our iconic brands like HBO Max, Discovery Channel, CNN, Food Network, HGTV, Eurosport, MotorTrend, and many more.

 Your New Role...
 We are looking for a passionate Machine Learning Engineer to build and scale the DTC personalization systems and services for our new global streaming app, Max, as well as any future DTC streaming apps. You are excited about working in an environment that fosters innovation via prototyping, development, experimentation and productionalization. You will bring the right balance between rapid feature iteration and building a common set of platforms and tools to move quickly in the future.In your role, you will be working alongside a team of passionate machine learning engineers and applied researchers to build and contribute to architecting a system that serves millions of users worldwide.

 Your Role Accountabilities…

 Architect, build and scale a recommendation system that powers a state of the art personalization experience to users across Max, HBO, Discovery+ and other WBD offerings
 Collaborate with other ML/Ops engineers to develop and improve core components, infrastructure and architecture to train, deploy and serve models at scale
 Lead architecture improvements for our personalization services and infrastructure
 Collaborate with data scientists, engineers, product teams and other key stakeholders and drive ML projects from conception to completion
 Author, test, review, and optimize production-level code in Python, Go and Java while executing best practices in version control and code integration
 Use and build upon open-source cloud computing technologies
 Participate and support engineering leaders in strategic planning and demonstrate good judgment in setting and delivering against strategic goals for the team
 Motivate, inspire and create a culture of experimentation and data-driven innovation while constantly striving to be an advocate for doing what is right for our customers


 Qualifications and Experience…

 2+ years of industry experience as a software engineer or machine learning engineer is preferred
 4+ years of programming experience in at least one of the following: Java/Go with ability to rapidly prototype ideas, and refine towards production.



 Experience with one of the cloud platforms AWS/GCP/Azure
 Understanding of sql and relational databases
 Experience with CI/CD tools like GitHub Actions, Jenkins etc.
 Experience with design, implementation and performance tuning
 Knowledge of large-scale distributed application architecture and good practical knowledge in modern machine learning lifecycle is a bonus
 Practical knowledge of large scale recommender systems, or large scale ML ranking/retrieval/targeting systems and familiarity with A/B Tests and hypothesis testing is preferred
 Excellent written and verbal communications skills and can present technical topics to large audiences



 Advanced degree (M.S.), or equivalent industry experience in software engineering, computer science, machine learning or related fields 


How We Get Things Done…

 This last bit is probably the most important! Here at WBD, our guiding principles are the core values by which we operate and are central to how we get things done. You can find them at www.wbd.com/guiding-principles/ along with some insights from the team on what they mean and how they show up in their day to day. We hope they resonate with you and look forward to discussing them during your interview.

 The Legal Bits… In compliance with local law, we are disclosing the compensation, or a range thereof, for roles in locations where legally required. Actual salaries will vary based on several factors, including but not limited to external market data, internal equity, location, skill set, experience, and/or performance. Base pay is just one component of Warner Bros. Discovery’s total compensation package for employees. Pay Range: $119,700.00 - $222,300.00 salary per year. Other rewards may include annual bonuses, short- and long-term incentives, and program-specific awards. In addition, Warner Bros. Discovery provides a variety of benefits to employees, including health insurance coverage, an employee wellness program, life and disability insurance, a retirement savings plan, paid holidays and sick time and vacation.
  Warner Bros. Discovery embraces the opportunity to build a workforce that reflects the diversity of our society and the world around us. Being an equal opportunity employer means that we take seriously our responsibility to consider qualified candidates on the basis of merit, without regard to race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, and genetic information, marital status, citizenship status, military status, protected veteran status or any other category protected by law.
  If you’re a qualified candidate with a disability and you need a reasonable accommodation in order to apply for this position, please contact us at recruitadmin@wbd.com.
",119700,"['python', 'machine learning', 'aws', 'azure', 'gcp', 'sql']"
AI/ML Packaging Engineer,Booz Allen Hamilton,VA,Full-time,"


Job Description










         Location: 
        

         Arlington,VA,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184621
        


















         AI/ML Packaging Engineer
          The Opportunity:
 As an experienced engineer, you know that machine learning is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on business processes using ML techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support the defense of critical infrastructure. As a machine learning engineer support our defense business you’ll train, test, deploy, and maintain models that learn from data.

 In this role, you’ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You’ll be part of a large community of machine learning engineers across the firm and collaborate with data scientists, software engineers, and mission SMEs to deliver world class solutions to transfer the mission for our clients. Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks.

 Join us. The world can’t wait.

 You Have:

 3+ years of experience with developing software architectures and containerization tools, including Docker and Kubernetes
 3+ years of experience developing and managing Python packages
 1+ years of experience with data science, machine learning engineering, and MLOps subject matter
 1+ years of experience with deploying Machine Learning capabilities to production environments
 Experience with software development, including API development or database management, and model deployment
 Experience with producing technical documentation and designs
 Ability to obtain a security clearance
 Bachelor's degree in Computer Science or Statistics


 Nice If You Have:

 Experience with GPU-programming, including CUDA or RAPIDs
 Experience with testing and quality assurance
 Experience with integrating AI or ML capabilities into software architecture design


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['python', 'machine learning', 'docker']"
"Data Scientist, Responsibility & Privacy",Meta,CA,Full-time,"
 The Monetization Responsibility & Privacy team (R&P) focuses on product investments which directly enable people and advertisers to maximize the value they receive from personalized advertising within the evolving privacy and regulatory landscape. R&P does this through building privacy into the design of our ads products; empowering people with tools to make informed decisions; breaking new ground with innovative privacy technologies; and collaborating with industry partners and privacy advocates on the evolution of advertising. We are looking for a Data Scientist who can see the big picture, identify pivotal questions, work closely with leadership, and lead data scientists around the company to steer the product strategy.As a Monetization-focused Data Scientist at Meta, you will have the opportunity to help people and businesses make meaningful connections and build premium services across our entire family of applications. By applying your technical skills, analytical mindset, and product intuition to one of the richest data sets in the world, you will help define the experiences we build for billions of people and hundreds of millions of businesses around the world, and change the way they connect. You will collaborate on a wide array of product and business problems with a diverse set of cross-functional partners across Product, Engineering, Research, Data Engineering, Marketing, Sales, Finance and others. You will use data and analysis to identify and solve product development’s biggest challenges. You will influence product strategy and investment decisions with data, be focused on impact, and collaborate with other teams. By joining Meta, you will become part of a world-class analytics community dedicated to skill development and career growth in analytics and beyond. Product leadership: You will use data to shape product development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and Meta. You will help your partner teams prioritize what to build, set goals, and understand their product’s ecosystem. Analytics: You will guide teams using data and insights. You will focus on developing hypotheses and employ a diverse toolkit of rigorous analytical approaches, different methodologies, frameworks, and technical approaches to test them. Communication and influence: You won’t simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.
 


Data Scientist, Responsibility & Privacy Responsibilities:  

Apply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our consumer & business users interact with both our consumer and business products
 Define ambiguous analytical problems and opportunities in a complex or ambiguous ecosystem area
 Leverage data and work closely with leadership to challenge and evolve the long term and short term strategy
 Collaborate with data scientists and product teams across the company to drive foundational understanding of the product experience and inform product decisions
 Mentor other data scientists on the team, provide project leadership and technical feedback




Minimum Qualifications: 

 Bachelor's degree in Mathematics, Statistics, a relevant technical field, or equivalent practical experience.
 8+ years of work experience solving analytical problems using quantitative approaches (minimum of 6 years with a Ph.D.)
 Experience in Python, SQL or other programming languages
 Experience with experimentation/causal inference methods and modeling




Preferred Qualifications: 

 Masters or Ph.D. Degree in quantitative field
 Experience in ads or eCommerce
 Experience working with executives or senior leadership




About Meta:  Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.
 



  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. 
  
 Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
 
",197000,"['python', 'machine learning', 'sql']"
"Associate Director, Solid Tumor, Oncology Data Science (JRD)",Johnson & Johnson,NJ,Full-time,"




Janssen Research & Development LLC (JRD), a Johnson & Johnson company, is recruiting for an Associate Director to join the J&J Research and Development Data Science and Digital Health team. You will report to the Senior Director of Data Sciences, Solid Tumor – Oncology. 
The primary location for this position is flexible – either; New Brunswick, NJ; Titusville, NJ; Raritan, NJ; San Diego, CA ; South San Francisco, CA, Boston, MA; remote will also be considered. This position may require up to 10% travel. 
Who we Are: Janssen develops treatments that improve the health and lifestyles of people worldwide. Research and Development areas encompass Oncology, Cardiovascular and Metabolic disorders, Immunology, Neuroscience, and Infectious diseases. Our ultimate goal is to help people live longer, healthier lives. We have produced and marketed many first-in-class prescription medications and are poised to serve the broad needs of the healthcare market – from patients to practitioners and from clinics to hospitals. To learn more about Janssen, one of the Pharmaceutical Companies of Johnson & Johnson, visit www.janssenpharmaceuticalsinc.com. You will: 
Key Responsibilities : 

Serve a bifunctional role as a Data Science translator and a Clinical Leader/ Data Science liaison to the Oncology Therapeutic Area 
Lead Oncology Data Sciences projects aligned to Compound Development Team(s) including Apalutamide and other GU assets. This includes serving as the Data Science line function leader developing Data Sciences solutions for key clinical program(s), coordinating internal resources, collaborating with external partners, and working with matrixed R&D Data Science team to deliver solutions. 
Conceive, develop and implement end-to-end study design and data analytical solutions (e.g., identification of at risk patient populations through development of novel predictive algorithms) 
Work closely with individual clinical project teams as well as functional area partners in Regulatory Affairs, Market Access, Clinical Development, Epidemiology, Commercial Data Science, Statistics, and others. 
Consult to, collaborate on and, in some cases, own end-to-end execution of high-impact portfolio-level initiatives (e.g., development and oversight of novel patient recruitment strategy, development of RWE methods) 
Establish and maintain strategic partnerships across J&J 
Support day-to-day goals of the Oncology R&D Data Science team by providing clinical consultation (e.g., review of study inclusion/exclusion criteria, cohort specifications) 
Possibility for direct accountability to Oncology R&D Clinical Development, serving as SRP on Janssen late phase clinical trials, as well as other associated clinical responsibilities 

QUALIFICATIONS

MD with clinical experience (e.g., residency), Ph.D., or Masters in Medicine, Biotechnology, Statistics, Machine Learning & Artificial Intelligence, Physics, Mathematics, Computational Chemistry, Computational Biology, Biology or a related field. 
A minimum of 2 years experience in drug development or related discipline in the field of biotechnology or real-world evidence 
Working knowledge of clinical oncology, such as treatment paradigms, patient experience, clinical trials 
Familiarity with healthcare relevant datasets, such as EHR, insurance claims or registry data. 
Prior experience working and driving external partnerships, either corporate or academic 
Consistent track record of managing timelines and driving key results in a complex organization 
Excellent communication, interpersonal, and written skills 

Preferred: 

Hematology/ Oncology fellowship training 
R&D Experience at a pharmaceutical company, biotech or partner organization 
A non-technical understanding of common data science research practices, such as predictive technologies, data mining and/or text mining 
Hands-on experience with a range of data science use cases in R&D (e.g., ECAs, site selection algorithms) and strong problem-solving abilities 

Other: 
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. 
Expected Base Salary : $135,000 - $232,300 
Benefits 
Employees may be eligible to participate in Company employee benefit programs such as health insurance, savings plan, pension plan, disability plan, vacation pay, sick time, holiday pay, and work, personal and family time off in accordance with the terms of the applicable plans. For additional general information on company benefits, please go to: https://www.careers.jnj.com/employee-benefits 
Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability. 
#LI-GR1 
#JRDDS 
#JNJDataScience 
#JRD




",135000,['machine learning']
AI Architect,HP,CO,Full-time,"
ACS (Advanced Compute & Solutions) is seeking an AI Architect to lead ACS Software Development in our high growth, future-oriented businesses, including Data Science, AI and other emerging areas. This role will work with some of the most exciting up-and-coming products in HP.  The AI Architect will play a pivotal role in designing and implementing AI solutions to drive innovation and business growth. You will work closely with cross-functional team and business partners to identify opportunities, architect AI solutions, and ensure successful implementation.
 
The role offers an opportunity to help build processes for emerging business areas, drive the scaling of exciting technology and play an important role in creating the future of computing.

 Responsibilities:

 Collaborate with internal and external stakeholders to understand business requirements and define AI project goals. 
Design & architect scalable and robust AI systems and solutions. 
Lead the development, testing, and deployment of AI models and applications. 
Lead the integration of technologies with external partner’s systems and applications. 
Stay current with the latest AI technologies and industry trends. 
Ensure data quality and security in AI applications. 
Mentor and guide junior AI professionals within the organization. 
Provide technical leadership and expertise in AI strategy and decision-making 
Develop and maintain strong relationships with partners organizations.

 
Skills & Qualifications:

 Bachelor's or Master’s degree in Computer Science, Machine Learning, or a related field. 
Proven experience as an AI Architect, AI engineer, or similar role with focus on technology integrations. 
Proficiency in AI and machine learning technologies, including deep learning, reinforcement learning, natural language processing, and computer vision.
 Strong programming skills in languages like Python, Java or C++.
 Expertise in popular AI frameworks and libraries, such as TensorFlow, PyTorch, or scikit-learn.
 Experience with cloud platforms (i.e. AWS, Azure, GCP) for AI development and deployment. 
Knowledge of big data technologies and distributed computing.
 Ability to lead complex AI projects from inception to public availability.
 Strong communication and teamwork skills. Including experience with Agile methodology.


 Education and Experience Required:

 8+ years of experience working as an AI Architect, AI engineer, or similar role. 
Bachelor's or Master’s degree in Computer Science, Machine Learning, or a related field. 
Preferred (not required) PhD in AI, Machine Learning, or related field. 
Experience in AI research and publications.


 
HP offers a comprehensive benefits package, including:

 Dental insurance
 Disability insurance
 Employee assistance program
 Flexible schedule
 Flexible spending account
 Health insurance
 Life insurance


 Our compensation reflects the cost of labor across several U.S. geographic markets, and we pay differently based on those defined markets. The typical base pay range for this role across the U.S. is $137,000.00 - $198,650.00 annually with additional opportunities for pay in the form of bonus and/or equity. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.


 About HP





  You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you.
 

   So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.
 



   HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.
 



   Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are.
 

   From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!
 
",137000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'aws', 'azure', 'gcp']"
Data Scientist - Lead,California State University,CA,Full-time,"



Campus:
 Chico 
   




Job ID: 529742 
   




Job Title:
 Data Scientist - Lead (Research Technician III) REVISED 
   




Appointment Type:
 Probationary 
   




Time Base:
 Full-Time 
   




Date Posted:
 November 14, 2023 
   

Closing Date:
 Open until filled
   










Description:

Our Commitment to Equity, Diversity, and Inclusion:
 California State University (CSU), Chico is a comprehensive and residential public university, holding Hispanic-Serving Institution (HSI) designation. Chico State operates as part of the 23-campus CSU system, which educates the most ethnically, economically, and academically diverse student body in the nation. The University enrolls over 15,000 students, with over half identifying as first-generation college students.
 Chico State is committed to recruiting outstanding candidates who reflect the intersectional identities of our student body. The ideal candidate will embrace our values predicated on the primacy of student success and the elimination of equity gaps, have demonstrated experience working with diverse populations, and will contribute to policies, programs, and practices that support an inclusive, accessible, and equitable learning and working environment. Black, Indigenous, People of Color, veterans, and those with diverse abilities are encouraged to apply.
 Job/Department Summary:
 Reporting to the Senior Director of Institutional Research and Strategic Analytics, this position requires significant lead experience since they will be leading a team of Research Technicians in delivering actionable data making it easier for analytics and policy makers to quickly access and utilize data as knowledge in managing academic and operational functions. They will participate in ensuring data integrity and providing accurate, timely, and relevant data for internal use, mandatory state and federal reports, and external agencies, data exchange groups, and others as necessary. The incumbent will develop relationships and work closely with cross functional teams to create structured and reliable data sets which will allow the extraction of data. The Data Scientist develops, supports, and maintains simple to complex business intelligence queries and reports while partnering with stakeholders to define deliverables. This role will support the Senior Director of IRSA and campus constituents by bringing data sources together and using the necessary machine learning and AI tools, statistical and/or predictive modeling techniques.
 Preferences:
 Preference may be given to applicants with the following as they may be considered specialized skills:

Bilingual.
Graduate degree in data science or related discipline, and at least five years of research or related technical experience; or a Bachelor’s degree and seven years of experience designing and conducting research.
Experience in a higher education environment; experience with student learning outcomes assessment is strongly preferred.
Training and/or experience with the use of data mining (or machine learning, AI) techniques and algorithms such as decision trees and cluster analysis.
Working knowledge of predictive modeling and model verification.
Demonstrated experience using business intelligence and analytics platforms such as MS Power BI, Tableau, IBM Cognos, or data science toolkits such as R and SPSS.

Required Education and Experience:
 Equivalent to graduation from a four-year college or university (Additional qualifying professional experience may be substituted for the required education on a year-for-year basis. AND Three years of progressively responsible technical research or statistical experience including or supplemented by one year in the interpretation and graphic presentation of data.

Graduate study in the social sciences, economics, mathematics, statistics, public or business administration or engineering may be substituted for the required experience on a year for year basis.

 Time Base: Full-time

 Pay Plan: 12/12
 Work Schedule: Mon-Fri 8:00am-5:00pm, Summer: Mon-Thurs 7:00am-5:30pm.
 CSU Classification Salary Range: $57,468 - $103,968 per year.
 Benefits: This position qualifies for benefits including tuition fee waiver (if eligible).
 CSU, Chico offers a number of benefits to its employees (e.g., sick leave, vacation, health insurance). For more information please visit
 Additional Information:
 California State University, Chico, in accordance with CSU policy, requires that the successful candidate complete a background check (including a criminal records check, sexual offender registry check, and/or fingerprinting) prior to assuming this position. Failure to satisfactorily complete or pass the background check may impact the job offer or continued employment of current CSU employees who apply for posted positions identified as sensitive. This position is considered a sensitive position based on CSU guidelines. Incumbent is responsible for the safety and security of Level 1 data, sometimes also referred to as Level 1 protected data. This is confidential information that is in most cases protected by statutes, regulations, or other legal mandates.
 This position requires travel, evening, and weekend time commitments.
 About Chico State:
 Graduate and undergraduate programs boast high-quality research experiences, exceptional faculty mentoring, and civic and global engagement opportunities. The campus motto, “Today Decides Tomorrow,” is brought to life by inclusive pedagogy, experiential learning, and co-curricular programming. The Chico Experience prepares students to be critical thinkers, engaged citizens, and inspired stewards of environmental, social, and economic resources. Together, they will become leaders solving the challenges of the 21st century.
 The campus is located in Northern California, 90 minutes from the state capital, Sacramento, and a three-hour drive from the San Francisco Bay Area. Chico offers year-round natural beauty, outdoor leisure activities, and a thriving arts, music, and events scene. We acknowledge and are mindful that Chico State stands on lands that were originally occupied by the first people of this area, the Mechoopda, and we recognize their distinctive spiritual relationship with this land, the flora, the fauna, and the waters that run through campus. We are humbled that our campus resides upon sacred lands that since time immemorial have sustained the Mechoopda people and continue to do so today.
 The University is an Equal Opportunity Employer and does not discriminate against persons on the basis of race, religion, color, ancestry, age, disability, genetic information, gender, gender identity, gender expression, marital status, medical condition, National origin, sex, sexual orientation, covered veteran status, or any other protected status.
 Chico State is not a sponsoring agency for staff and management positions (i.e. H-1B Visas).
 Open Until Filled (Review of Applications will begin 11/28/23. Applications received after that date may be considered.)



",57468,"['machine learning', 'tableau']"
AI Integration Engineer,Booz Allen Hamilton,VA,Full-time,"


Job Description










         Location: 
        

         Arlington,VA,US 
        



         Remote Work: 
        

         No 
        



         Job Number: 
        

         R0184597
        


















         AI Integration Engineer
          The Opportunity:
 Are you looking for an opportunity to create technical synergy that will modernize federal infrastructure? As an integration engineer, you know the importance of ensuring systems work together. You’re eager to apply your consulting experience and technical knowledge to implement creative solutions.

 On our team, you’ll design, develop, and implement solutions for software integration projects across functions or between organizations that’ll directly impact national defense. Using the Agile framework, you’ll work alongside software development engineers to deploy, configure, and integrate software applications in mission environments. You'll use tools like Docker, Kubernetes, and cloud infrastructure to plan, organize, and conduct integration projects that meet design specifications and standards from inception to completion.

 In this role, you’ll impact the defense space and gain access to opportunities to learn new tools and skills. We focus on growing and collaborating as a team to make the best solutions for our customers.

 Join us. The world can’t wait.

 You Have:

 3+ years of experience with administering Linux systems
 3+ years of experience debugging performance and behavior issues on Linux
 3+ years of experience with Kubernetes administration
 Knowledge of Linux-based operating systems, such as Ubuntu, RHEL, or CentOS
 Knowledge of Linux debugging tools, such as top, strace, vmstat, nc, tcpdump, ss, or lsof
 Ability to debug common Linux and Kubernetes issues with limited access to the Internet
 Ability to solve complex technical challenges and independently learn technical concepts
 Ability to obtain a security clearance
 HS diploma or GED


 Nice If You Have:

 1+ years of experience with deploying and managing distributed systems
 1+ years of experience with Python
 Experience with helm
 Experience working with authentication or active directory services
 Knowledge of Kubernetes distributions, such as K3S, RKE2, or OpenShift
 Ability to provision a STIG’d Linux operating system, such as virtualized or bare-metal
 Ability to provision a STIG’d Kubernetes cluster


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:
 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['python', 'docker']"
Senior Decision Scientist - Network Configuration Product,CVS Health,NY,Full-time,"
Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.  Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

 Position Summary

 As a Sr. Decision Scientist in our network configuration team, you will be responsible for ensuring our data and analytics products deliver value to our business partners, colleagues, and users
 Develop a deep understanding of the business and business needs to ensure analytical requirements are accurately captured in the form of capabilities, features, and stories, and communicated to the product team
 Acts as an analytics product owner translating business needs into analytics projects and actions
 Solves complex problems and takes a new perspective on existing solutions
 Manage scope of development for new product features through triage and prioritization
 Track progress, assess risks, coordinate delivery, and actively communicate contingency and mitigation plans for the team
 Involve key stakeholders from the leadership team at the appropriate stages of the project
 Perform data analysis, data integrity checks, and business validation testing, leveraging (SQL / Python)
 Collaborate with business partners and drive value through the development of business cases, performance reports and metrics to help hit those goals

 Required Qualifications

 2+ years of experience in management, strategy, or analytic consulting with demonstrated business impact 
2+ years of experience in product management with technology or healthcare focused companies
 2+ years of experience programming using SQL and Python

 Preferred Qualifications

 Be a self-starter who can create a vision and organize a plan to execute it
 History of creating and communicating data-driven stories to customers
 Data-driven mindset and approach to analysis and decision making
 Experience with forecasting, what-if scenario modeling, and financial analysis
 Can move projects ahead and problem solve obstacles encountered without senior leader input; anticipates roadblocks prior to their occurring

 Education

 Preferred: Master’s Degree in Computer Science, Applied Math, Operation Research, Statistics, Health Policy, or other related field, or MBA
 Minimum: Bachelor’s degree in quantitative field, or an equivalent combination of formal education and experience.


 Pay Range
 The typical pay range for this role is:
 $103,500.00 - $200,000.00
 
 This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.  In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.  For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

 CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

 You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

 CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.
",103500,"['python', 'sql']"
"Senior Director, Data Science",Confluent,US,Full-time,"
Description

Position at Confluent Inc



  Confluent is pioneering a fundamentally new category of data infrastructure focused on data in motion. Have you ever found a new favorite series on Netflix, picked up groceries curbside at Walmart, or paid for something using Square? That’s the power of data in motion in action—giving organizations instant access to the massive amounts of data that is constantly flowing throughout their business. At Confluent, we’re building the foundational platform for this new paradigm of data infrastructure. Our cloud-native offering is designed to be the intelligent connective tissue enabling real-time data, from multiple sources, to constantly stream across the organization. With Confluent, organizations can create a central nervous system to innovate and win in a digital-first world.
 



   We’re looking for self-motivated team members who crave a challenge and feel energized to roll up their sleeves and help realize Confluent’s enormous potential. Chart your own path and take healthy risks as we solve big problems together. We value having diverse teams and want you to grow as we grow—whether you’re just starting out in your career or managing a large team, you’ll be amazed at the magnitude of your impact.
 



 About the Role:


   The Data Team strives to build out the central nervous system for the company in order to drive better and faster decisions via data. Our charter includes Data Engineering, Data Science, and Analytics & Insights. It is our responsibility to build world class data infrastructure, tooling, governance, dashboards, and ML models to enable company-wide analytics, create insights & models and data products to drive business growth at scale, and to be a model user of Confluent Cloud.
 


  As the Senior Director of Data, you will lead and grow a team of high performing Data Engineers, Data Scientists, BI Developers, and Analysts. You will articulate and execute the overall vision & strategy of the Data team, including a heavy focus on business partnership, data architecture, and our Customer Zero program.
 



 What You Will Do:



Own and drive the vision, strategy and roadmap for Data and lead the team to execute. Specifically, be responsible for building: 
    
A world class Customer Zero program
Foundational datasets & data marts to promote self-service analytics
Maturation of our approach to analytics, moving closer away from descriptive analytics towards more predictive & prescriptive analytics

Implement an approach for holistic prioritization to ensure resources are aligned to the highest impact and highest value initiatives
Build and scale a world class, multi-geo team of professionals across all disciplines within Data
Engage with Product & Engineering teams to deliver analytics and Data Science solutions to improve Confluent’s products, adoption, and consumption
Partner with GTM to evolve our approach to Customer 360, including building additional predictive models
Build a comprehensive Data Governance & compliance program
Mature Data team processes for support, agile, monitoring, and incident response
Partner with cross-functional stakeholders and partners, including Product, Engineering, Business Systems, and functional operation teams, to align on Data teams’ dependencies, roadmap, priorities, engagement model, and key processes
Be a thought leader, identify high impact project opportunities and process changes, and improve productivity of the overall Data Team






What You Will Bring:


15+ years of experience in the Data, from companies with a heavy reliance on Data
10+ years of experience managing a multi discipline Data team, with experience overseeing Data Science, BI, Data Engineering, and Analytics
Experience running and building large high performing & diverse teams across multiple geographies with multiple levels of management (40+ team members)
Deep knowledge of modern data stack and infrastructures, i.e., Cloud Data warehouse, data integration tools, Airflow, DBT, Tableau, etc.
Working knowledge of programming languages, i.e. SQL, Python, Java/Scala
Experience with Kafka or Confluent in a Production environment
Experience implementing data foundations, data marts, and building a single source of truth
Experience implementing Data governance & lineage programs
Experience implementing machine learning models for predictive business outcomes
Business acumen with an understanding of GTM, Product, and Finance landscapes
Strong ability to communicate cross-functionally, derive requirements and architect; to synthesize, simplify and explain complex problems to different types of audiences, including executives




 Come As You Are




   At Confluent, equality is a core tenet of our culture. We are committed to building an inclusive global team that represents a variety of backgrounds, perspectives, beliefs, and experiences. The more diverse we are, the richer our community and the broader our impact. Employment decisions are made on the basis of job-related criteria without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other classification protected by applicable law.
 



   At Confluent, we are committed to providing competitive pay and benefits that are in line with industry standards. We analyze and carefully consider several factors when determining compensation, including work history, education, professional experience, and location. This position has an annual estimated salary of $251,550 - $295,560, an annual bonus, and a competitive equity package. The actual pay may vary depending on your skills, qualifications, experience, and work location. In addition, Confluent offers a wide range of employee benefits. .
 

",251550,"['python', 'machine learning', 'tableau', 'sql', 'airflow', 'kafka']"
Director of Data Science,National Funding,CA,Full-time,"
Director of Data Science - San Diego, CA
Hybrid 3 days/week, Full time M-F 8am-5pm PST
Being authorized to work in the U.S. is a precondition of employment.
National Funding does not consider candidates requiring 1099 or C2C.
Exempt/Salary: $130,000-$230,000 + Bonus
National Funding is is seeking an experienced and dynamic professional to join us as the Director of Data Science. This leadership role will drive the strategic utilization of statistical and machine learning techniques, leading model development initiatives for our Small Lending business. The successful candidate will manage a team of 4-6 model developers, overseeing the entire modeling life cycle, including development, implementation, use, and monitoring.
Responsibilities:
Model Development and Performance:

Spearhead the creation and optimization of Marketing, Credit, and custom score models, along with associated processes, systems, and ML Ops.
 Formulate and execute Generative AI and LLM strategies across all facets of the company, from Data Science to Operations.

Collaboration and Communication:

Foster effective communication and collaboration with cross-functional teams, including Marketing, Credit, Sales, Finance, Tech, and Product, ensuring alignment in strategy, model governance, risk, and technology.

Team Leadership and Management:

Lead day-to-day operations of the Data Science team, providing guidance, coaching, and project management.
 Drive the creation and execution of custom models, processes, and systems.
 Manage projects of varying complexity, from conceptualization to business requirements, project plans, and successful execution.

Special Projects and Documentation:

Oversee special requests and projects, meticulously documenting processes, and procedures.

Experience:

Minimum 5-7 years of work experience, including 3-5 years in a managerial capacity.
 Proven expertise in designing, building, and deploying production-quality models using statistical/ML techniques.
 Deep experience in creating, monitoring, and improving custom ML scorecards.
 Proficiency in SQL, Python, programming, database management, and ML Ops implementation.
 Background in management, strategic leadership, and/or leadership roles.


Strong project management experience.

Requirements:

Exceptional leadership skills with a demonstrated ability to guide, coach, and build high-value teams.
 Track record of creating and fine-tuning custom scorecards, incorporating continuous improvement processes.
 In-depth working knowledge of Generative AI, LLM, deep neural networks, and deep learning modeling.
 Ability to thrive in a fast-paced and dynamic business environment.
 Keen sense of responsibility and ownership, detail-oriented, with project management and implementation experience.
 Master's Degree in statistics or other quantitative areas of study.
 Excellent interpersonal, written, and verbal communication skills, including influencing and presentation skills.
 Demonstrated business and financial acumen.
 Critical thinker with an analytical mindset and a process-oriented approach.


Physical Demands:


Working in a temperature-controlled office environment
Sitting at a desk for prolonged periods of time while viewing multiple computer screen monitors
Potential lifting of boxes around 5-10lbs


Why National Funding?

Positive, energetic, passionate, business casual environment with management who commits to your success


Fantastic benefits package: Our current benefit package includes medical, dental, vision, life, LTD and AD&D insurance as well as a 401(k) Retirement Savings plan with an employer match. Eligibility for all benefits will start at the first of the month following 60 days of employment.
 Numerous employee events throughout the year, including our annual traditions such as a Day at the Del Mar Racetrack, Del Mar Mud Run, Bring Your Kid to Work Day, Holiday Party, Employee and Family Picnic, sporting events and more.

National Funding is one of the leading providers of short-term loans and equipment leasing for small businesses across the United States. In both 2013 and 2014, we were ranked by the San Diego Business Journal as one of the 100 Fastest Growing Private Companies in San Diego and listed on the Inc. 5000 List of America's Fastest Growing Private Companies. We serve the small business community nationwide by offering a range of financial services and products. Since 1999, we have been in the forefront of the equipment leasing business, working with businesses in hundreds of communities and industries to expand and upgrade their business equipment. As we have grown, so too has our product line, and now we are one of the country's largest private lenders of small business loans. Our customers call on us to get working capital, merchant cash advances, credit card processing, and of course, equipment leasing.
National Funding is an Equal Opportunity Employer.
",130000,"['python', 'machine learning', 'deep learning', 'sql']"
Senior Machine Learning Engineer,IBR (Imagine Believe Realize),Remote,Full-time,"The Lead AI/ML Engineer must be able to meet the key criteria below:

Location: 100% telework
Years' Experience: 14+ years
Education: Bachelor’s in IT related field
Security Clearance: IBR is a federal contractor. Applicants must be able to meet the requirements to obtain an Public Trust security clearance. NOTE: United States Citizenship is required.
Work Authorization: Must show that applicant is legally permitted to work in the United States.
Employment Type: Full-Time, W-2
Key Skills:
10+ years of IT experience focusing on enterprise data architecture and management
Experience with Databricks required
8+ years experience in Conceptual/Logical/Physical Data Modeling & expertise in Relational and Dimensional Data Modeling
Experience with ETL and ELT tools such as SSIS, Pentaho, and/or Data Migration Services
Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design, Postgres performance optimization)
Experience with AWS environment, CI/CD pipelines, and Python (Python 3) a bonus

Overview
Do you want to help build a portfolio of next-generation mobile-enabled data collection systems and enterprise portals? As a Lead Artificial Intelligence / Machine Learning Engineer at IBR, you will support the Agile based engineering of a robust, secure, and scalable enterprise web portal solutions hosted in AWS. You will perform research, build, and design AI systems that automate predictive models. Design and create algorithms capable of capable of learning and making predictions that define machine learning. As the lead you will work with the data science team to design algorithms to meet DHS requirements. This position will work closely with the solutions delivery team to supporting the operations team performing Deployment, Systems Integration Testing, and Operations & Maintenance activities.
Responsibilities

Serve as the Artificial Intelligence / Machine Learning lead and will be responsible for reviewing the AL/ML architecture and development as well as mentoring more junior program staff
Analyze complex datasets and algorithms to assess performance or find new patterns and apply machine learning techniques to data sets related to immigration, with the goal to make an impact across federal government
Lead architecture design, technical support, and advisement services to ensure identity management system technologies are integrated and meeting the appropriate security requirements
Present results to diverse audience in presentation and report form
Provide support to leadership team members who engage with senior-level executives at a public-facing Federal agency and provide subject matter expertise in security architecture, AI/ML, and other key domain areas.

Qualifications

14+ years of IT experience focusing on enterprise data architecture and management
Bachelor degree in IT related field (computer science, mathematics and statistics)
Must be able to obtain a Public Trust security clearance
Experience in Conceptual/Logical/Physical Data Modeling & expertise in Relational and Dimensional Data Modeling & Data Reconciliation
Experience modeling solutions in AWS that use AI/ML algorithms and in cloud architecture, specifically AWS as it relates to data processing (ie. EC2, S3, Lambda, Databricks, Redshift, etc)
Ability analyze and organize large amounts of data while executing tests and optimizing ML systems and algorithms.
Experience with AI/ML Object Detection and Tracking (FairMOT, SSD, Yolo v5)
Experience with AI/ML tools such as Tensorflow, Keras, OpenCV, MXNet, MS Cognitive Services, and/or SciKit-Learn
Experience with the development of Microservices Architecture and deploying to AWS
Ability to define and maintain BI/Data Warehouse methodologies, standards, and industry best practices
Experience leading and architecting enterprise-wide initiatives, specifically system integration, data migration, transformation, data warehouse build, data mart build, data lakes implementation/support, as well as O&M etc. for a large enterprise
Experience with Spark ETL and ELT tools such as SSIS, Pentaho, and/or Data Migration Services
Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design, Postgres performance optimization)
Experience with AWS environment, CI/CD pipelines (Kubernetes, Fargate, Cloud Formation, Terraform), and Python (Python 3) a bonus
Experience with Kafka a bonus
Identifying differences in data distribution that affect modeling performance and verify data quality.
Experience in large-scale database requirements supporting diverse data types and experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior level management
Ability to continuously learn and stay up to date on new trends and technologies in ML and AI including cyber security requirements from presidential directives and NIST guidance.
Software development background with experience in knowledge in Java, Spring, Angular, Postgres, NodJS desired but not required

Physical Demands
Position consists of sitting for long periods of time, bending, stooping, crouching, and lifting up to 20 pounds. Frequently uses hands/fingers for manipulation of keyboard and mouse.
Work Environment
Work is performed primarily indoors in a well-lit office environment. The environment is normally air conditioned, but conditions may change dependent upon circumstances. Work may need to be performed in a fast-paced environment requiring quick thinking and rapid judgements. Employee will be exposed to a wide variety of clients in differing functions, personalities, and abilities.
About IBRImagine Believe Realize, LLC (IBR) is an emerging small business focused on delivering software and systems engineering solutions to government and commercial clients. Our talent acquisition strategy is tailored to career seeking candidates who embrace continuous learning and desire to grow as a professional in the software/systems engineering industry. We strive to enhance our team members ability to thrive in the workplace by creating a proper work/life balance and first-class benefits package that includes:

Nationwide medical, dental, and vision insurance
3 weeks of Paid Time Off and 11 Paid Federal Holidays
401k matching
Life Insurance, Short-Term Disability, and Long-Term Disability at no cost to our employees
Flexible spending accounts and Dependent Care spending accounts
Wellness incentives
Reimbursement for professional development and certifications
Training assistance opportunities

Upon hire and in compliance with federal law, all persons hired are required to verify identity and eligibility to work in the United States, and to complete the required employment eligibility verification and background check. IBR is a Federal Contractor.
Imagine Believe Realize, LLC is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate based upon race, age, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.”Learn more at http://www.teamibr.com
If alternative methods of assistance are needed with the application process, additional contact information has been provided below:
info@teamibr.com​​​​​​​407.459.1830
Job Type: Full-time
Pay: $155,000.00 - $210,797.08 per year
Benefits:

401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Referral program
Vision insurance

Schedule:

Monday to Friday

Work Location: Remote",155000,"['tensorflow', 'python', 'machine learning', 'aws', 'etl', 'sql', 'kafka']"
Machine Learning Engineer,Dezign Concepts LLC,VA,Full-time,"


20231112-2219-01
 Active Top Secret Clearance with Poly Required
 Salary Range: Up to $225K **salary is commensurate with education and experience**
 Job Summary
 The Sponsor seeks to develop and adapt Large Language Models (LLM) and Natural Language Processing (NLP) methodologies using artificial intelligence and machine learning (AI/ML) frameworks and programming languages to create new capabilities to improve analytic workflows and address key intelligence questions. The Sponsor needs experienced AI/ML engineering skills to build tools and analytics that use the Sponsor’s structured and unstructured data to yield novel analytic insights, accelerate workflows, enable analysts to surface relevant information from massive data stores. The work will be performed within a team environment.

 **Please note: This job requires an existing Top Secret Clearance and Polygraph**
 Responsibilities and Duties

 Leverage open source best-in-class models to create new models—through fine tuning, transfer learning, and more— and ensembles that can be re-purposed and reused, covering the following domains:
   
 Classification
 Supervised (CNN, Unet, YOLO, or similar)
 Unsupervised (DBSCAN, K-Nearest, Adaboost, or similar)
 Prediction
 Predictors (LSTM, UConv, or similar)
 Regressors (Bayesian, linear, or similar)
 Fusion (sensor level and entity level)
 Decision making (Task assignments, combinational and parametric optimizations, Reinforcement Learning, Path Planning, or similar)
 Generative (LLMs, Stackable LLMs, or similar)
 Machine Learning, AI, Deep Learning (TensorFlow, PyTorch), Text, (Classification, NLP, Topic and Language Modeling, Sentiment Analysis, Information Retrieval), Recommender Systems and Personalization, Threat Detection, Computer Vision, Data Mining, Statistics, or similar.

 Analyze large amounts of raw data, including text data, to determine utility for training or testing AI models.
 Preprocess or clean structured and unstructured Sponsor data, including text data.
 Design and implement advanced ETL code and table configurations for complex data sets.
 Use Structured Query Language (SQL) to develop and organize relevant information.
 Cooperation with a team, author analytic publications and produce ad-hoc reports to include data visualizations using the Sponsor’s templates, and document methods in Github.
 Implement the Sponsor’s existing coordination process.
 Provide technical education to staff on an ad-hoc basis.
 Provide subject matter expertise in AI/ML to support Sponsor’s initiatives.


 Experience Needed:

 Citizenship: Must Be a US Citizen
 Existing Clearance Required: Active Top Secret SCI with Poly
 Demonstrated experience tuning neural networks, such as LLMs, on custom data sets and applying results to specific use cases.
 Demonstrated professional or academic experience developing models and ensembles in the AI/ML space, including selecting the best Python libraries for a given task, choosing appropriate pre-processing actions, performing analysis, and assessing model performance.
 Demonstrated professional or academic experience using Python or R.
 Demonstrated professional or academic experience with deep learning frameworks such as PyTorch, Tensorflow, or Keras.
 Demonstrated professional or academic experience and proficiency with SQL to include using common table expressions, set operations, aggregated functions and nested subqueries.
 Demonstrated professional or academic experience with version control systems such as Github and Jenkins.
 Demonstrated experience leveraging GPUs for accelerated computing.

 Other skills and demonstrated experiences that are highly desired but not required to perform the work include:

 Demonstrated professional or academic experience with the HuggingFace Transformers library and hub.
 Demonstrated experience with cloud computing development and architecture.
 Demonstrated experience with front-end web development frameworks such as Flask.
 Demonstrated experience creating machine learning models that conduct text classification and topic modeling in Python using standard machine learning (SciKit Learn-) or deep learning models.
 Demonstrated experience developing applications for semantic search.
 Demonstrated professional or academic experience and proficiency with Tableau to produce visualizations and dashboards.
 Demonstrated academic or professional experience communicating methodological choices and model results.
 Demonstrated experience with verification and validation test benches.
 Demonstrated experience with Explainable AI (XAI) techniques.
 Demonstrated experience with ONNX (Open Neural Net Exchange).

 Travel is anticipated for this position:

 Local travel/POV will be on an as needed basis, within the local place of performance.




 Health Benefits
 Work/Life Balance
 Financial Opportunities


 Medical, Dental, Vision, Health Savings Account and more.
 Paid Time Off, Holidays, Social Events, Employee Assistance Program and Team Building
 401K, Tuition Assistance, Annual and Referral Bonuses



 Main Number: 1-888-663-2690 | info@Dezign-Concepts.com | www.dezign-concepts.com
 Dezign Concepts provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
 
diPoSw0pO2
",225000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'tableau', 'etl', 'sql']"
AI/ML Lead Engineer,NEXT GEN IT INC,Remote,Full-time,"***Urgent Role & Immediate Interview**** 
AI/ML Lead Engineer
TOTAL- 9+yrs IT exp
REMOTE
NON VISA Candidates (OPT/CPT/H4EAD/GC/USC/TN)
NOTE:
H1-B VISA CANDIDATES - DONOT APPLY (NO EXCEPTIONS)
ANYONE LESS THAN 9+ OVERALL EXP - DONOT APPLY (NO EXCEPTIONS)
THIS ROLE IS FOR AI/ML USE CASE ANALYST EXP CANDIDATES ONLY
Job Description:
As an AI Use Case Analyst, your primary responsibility will be to elicit and gather AI use cases by leveraging your expertise in artificial intelligence technologies. This role requires an understanding of AI tools and technologies and the ability to translate business requirements into AI-driven solutions.
Responsibilities:
· Identify AI/ML Opportunities: Collaborate with cross-functional teams, primarily business stakeholders, to identify potential AI use cases within the organization. Utilize your knowledge and expertise in AI tools and technologies to recognize opportunities for AI-driven solutions.
· Elicit Business Requirements: Engage with business users to understand their specific needs and challenges. Conduct thorough analysis to elicit detailed requirements for AI projects, considering factors such as data availability, technical feasibility, and business impact.
· Perform Research and Analysis: Stay up-to-date with the latest advancements in AI technologies, tools, and industry trends. Conduct research and analysis to identify potential AI applications and use cases that align with the organization's goals and objectives.
· Documentation and Reporting: Create documentation, including use cases, visual requirements models, and business requirements documents. Prepare reports and presentations to communicate findings, recommendations, and project progress to stakeholders and management.
Requirements:
1. Experience with AI Technologies: Possess a solid understanding of artificial intelligence technologies. Familiarity with machine learning, natural language processing, computer vision, and other AI domains is highly desirable.
2. Business Analysis Skills: Proven experience in eliciting, analyzing, and documenting business requirements. Ability to translate business needs into technical specifications and vice versa. Strong analytical thinking and problem-solving skills are essential.
3. Communication and Collaboration: Excellent communication skills, both verbal and written, with the ability to effectively interact with diverse stakeholders. Demonstrated experience in collaborating with cross-functional teams, including data scientists, engineers, and business stakeholders.
4. Domain Knowledge: Familiarity with various industries and domains where AI is commonly applied, such as healthcare, finance, retail, or manufacturing. Ability to understand and analyze specific business processes and requirements within these domains.
Research and Adaptability: Strong research skills to stay updated with the latest advancements in AI technologies and industry trends. Ability to quickly adapt to new technologies and tools as they emerge in the AI landscape.
Job Types: Full-time, Contract
Pay: $65.00 - $70.00 per hour
Schedule:

8 hour shift
Day shift
Monday to Friday

Work Location: Remote",130000,['machine learning']
Machine Learning Engineer,Kudu Dynamics,CO,Full-time,"

Machine Learning Engineer - Job Description



Who We Are
 Kudu Dynamics is a 100% employee-owned company, forged out of a decade of experience in
   computer network operations and staffed with talent who have built, overseen, and enhanced
   capabilities throughout the entire USG arsenal. Our team of hackers, engineers, makers, and
   shakers have experience spanning centuries of research, development, and operations missions -
   across desktop, mobile, IoT, and embedded platforms. Kudu Dynamics is uniquely qualified to
   anticipate tomorrow’s threats and build the next generation of capabilities.
 




Job Description:
Our Large Language Models (LLM) team is currently exploring the use of Generative AI to develop production software components for use by our customers. Our solutions embrace the bleeding-edge, state-of-the-art machine learning models and techniques to add measurable value to government agencies, commercial organizations, and academic institutions worldwide.
Qualifications

Proficiency in Python and C/C++
Experience in machine learning workflows including model selection, architecting, training, validation, testing, and deployment
Experience using and fine-tuning large language and generative AI models
Experience with modern software development processes
Experience using CICD pipelines to automate the software build process
Ability to obtain a Security Clearance

Responsibilities

Collaborate with other engineers and researchers on projects using Large Language Models to generate code
Evaluate and select appropriate AI tools and machine learning models for tasks, as well as building and training working versions of those models using Python and other open-source technologies
Engineer LLM prompts, validate generated code for correctness, and compare results to other models
Perform rapid prototyping and enhanced development to be integrated into customer systems.
Perform troubleshooting, bug fixes, and maintenance of existing and new code to ensure stability and robustness.




Benefits We Provide:



 Equity at a company that is doing dynamic, fun, meaningful, and interesting work.
 A flexible work schedule, with the option to work remotely most days, if that’s your style.
 Your own yearly discretionary budget to buy the things that make you happy.
 In addition to highly competitive salaries, we offer premium healthcare options, 401k matching, and an annual pass to a swim in the bonus pool. We also offer four weeks of paid time off and 11 federal holidays to utilize whenever you want throughout the year.
 Awesome, enthusiastic co-workers and a company culture that promotes a jerk- free environment. Rattle the windows with the company band, participate in board game or movie nights, and help balance out the scotch vs. bourbon ratio in the office.



 Kudu provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
   


",145000,"['python', 'machine learning']"
Data Scientist,National Security Agency,MD,Full-time,"

At NSA Data Science is a broad field, and a team effort, spanning all the expertise needed to derive value from data. As a Data Scientist, you will uses elements of mathematics, statistics, computer science, and application-specific knowledge to gather, make, and communicate principled conclusions from data. You will employ your mathematical science, computer science, and quantitative analysis skills to develop solutions to complex data problems and take full advantage of NSA's capabilities to tackle the highest priority challenges. Responsibilities include: - Exploring data analysis and model-fitting to reveal data features of interest - Using the machine-learned predictive modeling - Constructing usable data sets from multiple sources to meet customer needs - Identifying and analyzing anomalous data (including metadata) - Developing conceptual design and models to address mission requirements - Developing qualitative and quantitative methods for characterizing datasets in various states - Performing analytic modeling, scripting, and/or programming - Working collaboratively and iteratively throughout the data-science lifecycle - Designing and developing analytics and techniques for analysis - Analyzing data using mathematical and statistical methods - Evaluating, documenting, and communicating research processes, analyses, and results to customers, peers, and leadership - Creating interpretable visualizations


 Job Summary
 Depending on the skill-sets currently in demand, newly hired Data Scientists may be assigned to a mission office, or alternatively enrolled in the three-year Data Science Development Program (DSDP) in which they will both broaden and specialize their data science skills by taking courses and touring with a variety of mission offices (each for several months). In either case you will work with NSA experts in data science, related technical domains, and specialized subject areas. You will have opportunities to participate in internal technical roundtables, and to attend technical conferences with experts from industry and academia.


 Qualifications
 Applicants will be asked to complete the Data Science Examination (DSE) evaluating their knowledge of statistics, mathematics, and computer science topics that pertain to data science work. Passing this examination at a local testing site is a requirement in order to be considered for selection into a data scientist position. Upon passing the examination, applicants will be evaluated for the minimum qualifications outlined in this ad. Transcripts will be requested prior to being invited to interview with Agency data science professionals. The qualifications listed below are the minimum acceptable to be considered for the position. Degree must be in Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science. A degree in a related field (e.g., Computer Information Systems, Engineering), a degree in the physical/hard sciences (e.g. physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, library, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics (typically 200 level or higher; such as calculus, differential equations, discrete mathematics, linear algebra, and calculus based statistics) and/or computer science (e.g., algorithms, programming, data structures, data mining, artificial intelligence). College-level Algebra or other math courses intended to meet a basic college level requirement, or upper level math courses designated as elementary or basic do not count. Note: Degrees in related fields will be considered if accompanied by a Certificate in Data Science from an accredited college/university. Relevant experience must be in one or more of the following (for Entry level) but in two or more for Full Performance, Senior, and Expert levels: designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence, computational science, software engineering, or data engineering. ENTRY/DEVELOPMENTAL Entry is with a Bachelor's degree and no experience. An Associate's degree plus 2 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. FULL PERFORMANCE Entry is with a Bachelor's degree plus 3 years of relevant experience or a Master's degree plus 1 year of relevant experience or a Doctoral degree and no experience. An Associate's degree plus 5 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. SENIOR Entry is with a Bachelor's degree plus 6 years of relevant experience or a Master's degree plus 4 years of relevant experience or a Doctoral degree plus 2 years of relevant experience. An Associate's degree plus 8 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position. EXPERT Entry is with a Bachelor's degree plus 9 years of relevant experience or a Master's degree plus 7 years of relevant experience or a Doctoral degree plus 5 years of relevant experience. An Associate's degree plus 11 years of relevant experience may be considered for individuals with in-depth experience that is clearly related to the position.


 Competencies
 The ideal candidate has a desire for continual learning along with excellent analytical, problem-solving, communication (oral and written), and interpersonal skills who is: - Accountable - Proactive - Detail oriented - Able to solve complex problems - Proficient with critical thinking and reasoning to make analytic determinations - Effective at working in a collaborative team environment - Able to bridge the gap with both technical and non-technical audiences Knowledge, skills, and relevant experience in one or more of the following is required: - Designing and implementing machine learning - Data mining - Advanced analytical algorithms - Programming - Data science - Advanced statistical analysis - Artificial Intelligence - Computational science - Software engineering - Data engineering


 Pay, Benefits, & Work Schedule
 Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position. This is a full-time position, hiring for the Maryland, Colorado & Hawaii locations. Salary ranges vary by work level. Salary range: $81,233 - $183,500 (Entry/Developmental, Full Performance, Senior, Expert) On the job training, internal NSA courses, and external training will be made available based on the need and experience of the selectee. Typical work schedule is Monday - Friday, with basic 8 hr/day requirements between 0600 to 1800 (flexible).


 How to apply
 Apply soonest, as job postings can close earlier than stated end dates due to changes in requirements. It is important to review and note the minimum qualifications, as only those applicants who meet the required qualifications will be contacted to continue the employment process. Please populate the resume tool to showcase any relevant work experience and education related to the position and answer any applicable screening questions. Information collected will be used to determine eligibility, and failure to provide accurate information may result in disqualification for this position. A confirmation email will be sent after submission of the first application and also after any future updates to submitted applications. **Due to time sensitive communications regarding applications, please ensure your spam filters are configured to accept email from noreply@intelligencecareers.gov. For job vacancies that include stated testing requirements, also include the following: @uwe.nsa.gov, @nsa.gov, and @pearson.com** U.S. Citizenship is required for all applicants. NSA is an equal opportunity employer and abides by applicable employment laws and regulations. All applicants and employees are subject to random drug testing in accordance with Executive Order 12564. Employment is contingent upon successful completion of a security background investigation and polygraph. Reasonable accommodations may be provided to applicants with disabilities during the application and hiring process where appropriate. Please visit our Diversity link for more information https://www.intelligencecareers.gov/NSA/diversity-and-inclusion.


 DCIPS Disclaimer
 The National Security Agency (NSA) is part of the DoD Intelligence Community Defense Civilian Intelligence Personnel System (DCIPS). All positions in the NSA are in the Excepted Services under 10 United States Codes (USC) 1601 appointment authority. DoD Components with DCIPS positions apply Veterans' Preference to eligible candidates as defined by Section 2108 of Title 5 USC, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 2005, DCIPS Employment and Placement. If you are a veteran claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you may be asked to submit documents verifying your eligibility.


",81233,['machine learning']
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NJ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,KS,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NY,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NY,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CT,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Data Scientist,US HQDA Field Operating Agencies and Staff Support...,VA,Full-time,"

Duties

Develop and deliver flexible ad-hoc programming or software-based tools in order to meet the vision of a data-driven organization.
Provide experience and expertise with planning, programming, training, and implementing Artificial Intelligence and Machine Learning.
Synchronize efforts to gain/maintain the leading edge in state-of-the-art technology.
Assist engineering teams to conceive, plan, and execute projects through private industry and government efforts.
Present briefings to senior leadership on complex or difficult recommendations that have DOD-wide and international impact.
Support a team whose function is to bring agile descriptive, prescriptive, and directive analytics and modeling functions to the organization.



Requirements
Conditions of Employment

Appointment may be subject to a suitability or fitness determination, as determined by a completed background investigation.
Secret security clearance required.
Business travel/Temporary Duty (TDY) may be required up to 25%.
One-year probationary period may be required.


Qualifications


Who May Apply: US Citizens

 In order to qualify, you must meet the education/experience requirements described below. Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community; student; social). You will receive credit for all qualifying experience, including volunteer experience. Your resume must clearly describe your relevant experience; if qualifying based on education, your transcripts will be required as part of your application. Additional information about transcripts is in this document.
    

Basic Education Requirement: Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position.
     OR
     Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience.
    

NOTE: YOU MUST SUBMIT A COPY OF YOUR TRANSCRIPTS WITH YOUR APPLICATION PACKAGE.


Specialized Experience: In addition to meeting the basic education requirement, applicants must meet specialized experience requirements: One year of specialized experience which includes: 1) planning, developing and implementing modeling efforts using industry-standard languages (e.g. R-Shiny or Python) and AI/ ML methods; 2) designing and delivering data flows through Oracle, AWS, or Azure services that facilitate data development and management; and 3) working with other developers to design statistical and/or mathematical computations that deliver data quality, accurate analysis, and statistically-significant results that enable leaders to make decisions. This definition of specialized experience is typical of work performed at the next lower grade/level position in the Federal service (GS-12).
    
 Some federal jobs allow you to substitute your education for the required specialized experience in order to qualify. For this job, you must meet the qualification requirement using experience alone-no substitution of education for specialized experience is permitted. 
   


Education
FOREIGN EDUCATION: If you are using education completed in foreign colleges or universities to meet the qualification requirements, you must show the education credentials have been evaluated by a private organization that specializes in interpretation of foreign education programs and such education has been deemed equivalent to that gained in an accredited U.S. education program; or full credit has been given for the courses at a U.S. accredited college or university. For further information, visit: http://www.ed.gov/about/offices/list/ous/international/usnei/us/edlite-visitus-forrecog.html 


Additional information



This announcement uses the Certain Personnel of the Department of Defense direct hire authority to recruit and appoint qualified candidates to certain positions in the competitive service.
Male applicants born after December 31, 1959, must complete a Pre-Employment Certification Statement for Selective Service Registration.
You will be required to provide proof of U.S. Citizenship.
One year trial/probationary period may be required.
Direct Deposit of Pay is required.
Selection is subject to restrictions resulting from Department of Defense referral system for displaced employees.
If you have retired from federal service and you are interested in employment as a reemployed annuitant, see the information in the Reemployed Annuitant information sheet.
This is a Science, Engineering and Analysis Career Field position.
Multiple positions may be filled from this announcement.
Salary includes applicable locality pay or Local Market Supplement.
Payment of Permanent Change of Station (PCS) costs is not authorized, based on a determination that a PCS move is not in the Government interest.
Recruitment or relocation incentive may be paid.







Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.






How You Will Be Evaluated

You will be evaluated for this job based on how well you meet the qualifications above.
As vacancies occur, the Human Resources Office will review your resume to ensure you meet the hiring eligibility and qualification requirements listed in this flyer. You will be rated based on the information provided in your resume, along with your supporting documentation.  If, after reviewing your rsum and/or supporting documentation, a determination is made that you have inflated your qualifications and/or experience, you may lose consideration for this position. Please follow all instructions carefully when applying, errors or omissions may affect your eligibility.  Veterans and Military Spouses will be considered along with all other candidates.   If selected, you may be required to provide additional supporting documentation. 




Benefits

A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits. 

Review our benefits 

Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.


Required Documents

As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
Your complete application includes your resume and other documents which prove your qualifications and eligibility to apply. If you fail to provide these documents, you will be marked as having an incomplete application package and you will not be considered any further.  1. Your resume: 

Your resume may be submitted in any format and must support the specialized experience described in this announcement.
If your resume includes a photograph or other inappropriate material or content, it will not be used to make eligibility and qualification determinations and you may not be considered for this vacancy.
For qualifications determinations your resume must contain hours worked per week and the dates of employment (i.e., HRS per week and month/year to month/year or month/year to present). If your resume does not contain this information, your application may be marked as incomplete and you may not receive consideration for this position.
For additional information see: What to include in your resume.

2. Other supporting documents:

Cover Letter, optional
This position has an individual occupational requirement (Basic Requirement) and you MUST submit a copy of your transcript with your application package or you will be rated ineligible. See: Transcripts and Licenses
NOTE: Documents submitted as part of the application package, to include supplemental documents, may be shared beyond the Human Resources Office. Some supplemental documents such as military orders and marriage certificates may contain personal information for someone other than you. You may sanitize these documents to remove another person's personal information before you submit your application. You may be asked to provide an un-sanitized version of the documents if you are selected to confirm your eligibility. 
     

If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating. 


How to Apply


Interested Applicants must submit resumes/application packages to: LTC Daniel Belzer at daniel.j.belzer.mil@army.mil  To apply for this position, you must submit the documentation specified in the Required Documents section above. Please follow all instructions carefully when applying, errors or omissions may affect your eligibility.  Alternate applications (e.g., facsimile applications) will not be accepted.  The complete application package must be submitted to the email address provided above by 11:59 PM (EST) on 11/21/2023 to receive consideration.



Agency contact information
Daniel Belzer 


Email
daniel.j.belzer.mil@army.mil 


Address


AB-APF-W2VNAA OFC OF THE CHIEF OF STAFF FOR LOGIS-AR

DO NOT MAIL

Chambersburg, PA 17201

US 




Next steps

Eligible applicants will be referred to the hiring manager. The selecting official may choose to conduct interviews.  Acknowledgement and Notice of Results letters will be sent by the hiring office.  The evaluation will be based on the information you provide. You should expect that we will verify performance, suitability, and security information and take that information into account in making employment offers. 


Fair and Transparent

The Federal hiring process is set up to be fair and transparent. Please read the following guidance. 

Equal Employment Opportunity (EEO) Policy 
Reasonable accommodation policy 
Financial suitability 
Selective Service 
New employee probationary period 
Signature and false statements 
Privacy Act 
Social security number request 





Required Documents

Your complete application includes your resume and other documents which prove your qualifications and eligibility to apply. If you fail to provide these documents, you will be marked as having an incomplete application package and you will not be considered any further.  1. Your resume: 

Your resume may be submitted in any format and must support the specialized experience described in this announcement.
If your resume includes a photograph or other inappropriate material or content, it will not be used to make eligibility and qualification determinations and you may not be considered for this vacancy.
For qualifications determinations your resume must contain hours worked per week and the dates of employment (i.e., HRS per week and month/year to month/year or month/year to present). If your resume does not contain this information, your application may be marked as incomplete and you may not receive consideration for this position.
For additional information see: What to include in your resume.

2. Other supporting documents:

Cover Letter, optional
This position has an individual occupational requirement (Basic Requirement) and you MUST submit a copy of your transcript with your application package or you will be rated ineligible. See: Transcripts and Licenses
NOTE: Documents submitted as part of the application package, to include supplemental documents, may be shared beyond the Human Resources Office. Some supplemental documents such as military orders and marriage certificates may contain personal information for someone other than you. You may sanitize these documents to remove another person's personal information before you submit your application. You may be asked to provide an un-sanitized version of the documents if you are selected to confirm your eligibility. 
   

If you are relying on your education to meet qualification requirements: 
Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education. 
Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.






 Help 
 This job is open to




The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.


",112015,"['python', 'machine learning', 'aws', 'azure']"
Senior Data Scientist,Houzz,Remote,Full-time,"

  About the Role
 

   Houzz is looking for a world-class data scientist to join our data science team. This team is focused on uncovering critical insights and delivering models to leverage those findings thus powering intelligent business decisions. As a Data Scientist here at Houzz you are on the front line of building better products for our customers.
 


 What You’ll Do
 



     Collaborate with leadership, product, marketing, engineering, operations and finance teams to identify, define and launch strategic and operational initiatives to scale our business
   


     Design, develop & deploy necessary KPIs to measure the health of the product and of the business
   


     Develop and deploy predictive models to optimize the product
   


     Partner closely with product teams to contribute to overall product strategy
   


     Identify and recommend enhancements to the data infrastructure
   


     Measure and effectively communicate results to the entire organization
   



   At a Minimum, We’d Like You to Have
 



     An M.S degree in a technical discipline such as statistics, mathematics, computer science, operations research or economics
   


     5+ years data science experience dealing with complex problems in subscription product, user retention, search & ranking and lead allocations
   


     Machine Learning experience building models with different techniques like Random Forests, GBDTs, Neural Networks etc
   


     Strong communication, presentation and interpersonal skills
   


     Be a self starter, with an ability to work independently and deliver quality results
   



   Ideally, You'll Also Have
 



     Ph.D. in a technical discipline such as statistics, mathematics, computer science
   


     Experience deploying machine learning models to production
   


     Experience with the hadoop data stack; HDFS, Presto & Hive
   


     Experience developing models using modern neural network architectures like Transformers etc.
   



   Compensation, Benefits and Perks
 

 This role has an annual starting salary range of $150,000 - $185,000. In addition to salary, you’re eligible for competitive benefits that support you and your family as part of your total rewards package at Houzz. Also, depending on the role, you could be eligible for an equity award. Actual compensation is influenced by a wide array of factors, including, but not limited to, skills, experience, and specific work location.
 


   Benefits and perks include:
 



     Flexible Paid Time Off (PTO)
   


     Home internet stipend
   


     Medical, dental, and vision benefits
   


     Maternity/paternity leave program
   


     Employee Assistance Program (EAP)
   


     Professional Development Reimbursement Program
   


     401(k) retirement savings plans (Pre-Tax and Roth)
   


     Flexible Spending Accounts (FSA) - Medical & Dependent Care
   


     Health Savings Account (HSA) with company contribution
   


     Healthy at Houzz program
   



   Houzz is an Equal Employment Opportunity employer. When applying for a role at Houzz, we guarantee your application will be considered regardless of your sex; race; color; gender; national origin; height or weight; ancestry; physical or mental disability; medical condition; genetic information; marital status; registered domestic partner status; age; sexual orientation; military and veteran status; or any other basis protected by federal, state or local law or ordinance or regulation.
 


   We embrace and celebrate the value that diversity brings to an organization. Diverse backgrounds and different points of view help Houzz provide the best experience for our community. Houzz is committed to fostering an inclusive environment through projects and initiatives, such as employee resource groups, that support Houzzers’ efforts to be themselves and share their lives at work.
 


   If you would like assistance or an accommodation due to a disability, please email us at accommodations@houzz.com. This information will be treated as confidential and used only for determining an appropriate accommodation for the interview process.
 


 Houzz is an Equal Opportunity Employer. M/F/Disability/Veterans
 


   __________________
 


   Be Who You Are and Do What You Love at Houzz
 

   About Houzz
 

   When founders Adi and Alon remodeled their home, they were frustrated by the lack of resources and inspiration to help them articulate a vision and select the right pro to make it a reality.
 


   So they built Houzz.
 


   Houzz is now the leading platform for home remodeling and design, providing an all-in-one software solution for industry professionals and tools for homeowners to update their homes from start to finish. Using Houzz, people can find ideas and inspiration, hire professionals, and shop for products. Houzz Pro (
  
   houzz.com/pro
  ) provides home industry professionals with a business management and marketing SaaS solution that helps them to win projects, collaborate with clients and teams, and run their business efficiently and profitably.
 


   Our Mission and Core Values
 

   We're proud to say there's no one quite like us. Houzz is a community-centric, innovative tech company that continues to disrupt the home renovation and design industry. Our mission-driven culture is rooted in our core values, and we’re all here for one purpose: make the home remodeling and design process more fun and productive for everyone.
 


   Our Mission
 

   To create the best experience for home renovation and design.
 


   Our Core Values
 

 We’re a Family


   At Houzz, we collaborate to accomplish our goals, always working as a team. We aim to build a culture of inclusion — celebrating and leveraging our differences for the betterment of one another, our products and our community. We take pride in making each person feel at home.
 


 We Build the Future


   Houzz is revolutionizing the home remodeling and design industry. Our global community of more than 65 million homeowners and home design enthusiasts use our platform to make their home dreams a reality, and over 3 million home professionals grow and manage their businesses with Houzz Pro. Houzz has been named one of the most innovative companies in the world by CNBC and others, and is backed by top venture capitalists. At Houzz, you can help build the future of an industry worth over $1 trillion in the U.S. and Europe alone.
 


 We Make Things Happen


   Our team members play a key role in guiding the direction of our company and work across multiple groups to implement fresh ideas that make Houzz the industry leader. If you are interested in transforming the lives of the tens of millions of people who are designing, remodeling and decorating their homes – and the millions of pros using Houzz Pro software to run more profitable, efficient businesses – you’ve found the right place!
 


 By applying for a job with us, you acknowledge and agree to the terms of our
  
    Job Applicant Privacy Notice
  .
 


Roles listing ‘Remote - US’ as a location are not currently available in the following states: Alaska, Hawaii, Louisiana and Montana.

",150000,"['machine learning', 'hadoop']"
Data Scientist I,Trusaic,CA,Full-time,"
Who we are: Trusaic is a regulatory compliance software company focused on creating better work environments, for everyone. Our mission is to help organizations create authentic change, whether that be by achieving pay equity, fostering a more diverse and inclusive workforce, increasing bottom lines, or offering more affordable healthcare.
Every day we wake up driven to make the working world a better place. If you’re interested in working in an environment where your individual contributions make a big impact, then Trusaic is the place for you.
Our culture: A culture fit is arguably one the most important aspects of a job opportunity. At Trusaic we pride ourselves in the people who make up our small, but growing team. We wear multiple hats and we help each other because the collective good of our company is made up by our individual efforts. We’re always looking to improve our processes and no workday is the same. We have a collaborative spirit, passionate hearts, and strong minds.
We celebrate each other’s company during group events, luncheons, trivia, happy hours, lunch and learns, and a whole lot more. At Trusaic, we fully subscribe to the work hard, play hard motto.
Overview of role: We are looking for an experienced Data Scientist to contribute to servicing our clients and to the continued expansion of our software offerings focused on furthering diversity, equity, and inclusion in the workplace. The successful candidate will be proficient in working on several projects simultaneously, coding and quality testing while also feeling comfortable interpreting statistical results, translating those results for non-technical audiences, and presenting those translated results to management and to our clients.
Essential Duties & Responsibilities:

Provide timely feedback to clients regarding completeness and correctness of data submissions;
Carefully review work, perform data checks, before submitting for further review;
Filter, sort, compute summary statistics, pivot tables, and merge data in spreadsheets;
Write, document, test, and debug R code and output;
Work within the git version control system;
Provide frequent, timely updates to task progress at agreed-upon times;
Interpret data, translate results for non-technical audiences, present findings.

Qualifications:

Master’s degree in quantitative subject e.g., statistics, econometrics, psychometrics, biostatistics, with 2 years post-masters work experience in a quantitative field that regularly required R coding, preferably working on multiple projects at a given time.
Successfully completed coursework in probability and statistics, including linear and logistic regression, maximum likelihood estimation, hypothesis testing, model assessment and selection, and matrix algebra.

Career advancement: Our products rely heavily on some of the most topical and challenging issues in the world. From healthcare to closing the gender/race gap, we work in a fast-paced environment where things are changing all the time. Given the nature of our products, opportunities for growth, both personally and professionally, present themselves regularly.
With the right attitude, mind-set, and work ethic, anything is possible here. If you want to make a difference in the world, are dedicated to career growth, and dream big, then Trusaic is the place for you.
Compensation & Rewards

Base Salary: $70,000 - $85,000 per year
Benefits 
   
Healthcare Plans (medical, dental, and vision)
401K Plan: Eligibility for participation in the Company's 401K plan, for which you will become eligible effective on the first day of the month after completing sixty (60) days of employment. The 401K Plan is currently funded by employee contributions only.
Paid Time Off (PTO): fifteen (15) days of PTO on an annual basis.
Group Healthcare Plan
Paid Holidays
Paid Parking or Metro Reimbursement
Monthly Luncheon
Company Events & Activities
Company Training
Career Advancement Opportunities



",70000,['git']
Global Leadership Development Program Associate – Data Engineering/Analytics Track,Advanced Sterilization Products,CA,Full-time,"The Advanced Sterilization Products (ASP) Global Leadership Development Program (GLDP) is a 2-year program, consisting of 3 cross-functional rotations designed for you to gain foundational business knowledge through hands-on, meaningful experiences. The Data Engineering/Analytics track is geared towards building leaders who are knowledgeable about data & analytics and can leverage the power of data to drive superior business results. By combining hands on learning, real-life business scenarios and various aspects of data & analytics, this program prepares early career leaders the ability to fast track their careers while delivering improved business performance for ASP. With exposure to various aspects of the data lifecycle – from creating analytical reports, machine learning, to artificial intelligence, GLDP’s quickly learn the importance of data and all aspects of the data lifecycle. 

 GLDP candidates will lead an intensive project during each rotation to make an immediate, long-lasting impact on the business. The project will allow you to build on your technical and interpersonal skills by providing you with significant responsibility as well as exposure to experienced business leaders, mentors, and subject matter experts. Following the program, you will be placed in a role within one of the many functions across ASP. 

 We recruit for the best candidates who have demonstrated leadership and have desire to grow in a high-energy, collaborative environment. You will learn how the Fortive Business System is used to shape strategy, focus execution, align our people, and create value for patients and customers around the world. Come join our winning team and support us in our mission to protect patients during their most critical moments! 
Qualifications 


GPA: 3.5 of 4.0 (preferred) 

Majors: Computer Science, Statistics, Finance/Economics, Information Systems, and other related majors (preferred) 
We value customer needs and develop solutions that matter. We seek out candidates that can deliver breakthroughs by taking risks, experimenting, and iterating quickly. 
We learn by doing – through success and fast failure. GLDP candidates thrive in our fast paced, changing environment. 
We win by getting the right things done and doing what we say we’ll do. Successful candidates set high expectations for themselves and drive results, even in the most difficult circumstances. 
We operate under a culture of continuous improvement; we expect individuals to tackle challenging problems, think strategically, and achieve results despite setbacks. 


Salary range : $56,465 - $104,765 

 Fortive Corporation Overview 

 Fortive’s essential technology makes the world stronger, safer, and smarter. We accelerate transformation across a broad range of applications including environmental, health and safety compliance, industrial condition monitoring, next-generation product design, and healthcare safety solutions. 

 We are a global industrial technology innovator with a startup spirit. Our forward-looking companies lead the way in software-powered workflow solutions, data-driven intelligence, AI-powered automation, and other disruptive technologies. We’re a force for progress, working alongside our customers and partners to solve challenges on a global scale, from workplace safety in the most demanding conditions to groundbreaking sustainability solutions. 

 We are a diverse team 18,000 strong, united by a dynamic, inclusive culture and energized by limitless learning and growth. We use the proven Fortive Business System (FBS) to accelerate our positive impact. 

 At Fortive, we believe in you. We believe in your potential—your ability to learn, grow, and make a difference. 

 At Fortive, we believe in us. We believe in the power of people working together to solve problems no one could solve alone. 

 At Fortive, we believe in growth. We’re honest about what’s working and what isn’t, and we never stop improving and innovating. 


Fortive: For you, for us, for growth. 

 Ready to move your career forward? Find out more at careers.fortive.com . Come join our team at Advanced Sterilization Products (ASP) and be part of a global leader in infection prevention solutions for the healthcare industry. With advanced products, technologies, and workflows for medical sterilization and disinfection, ASP is dedicated to defending the lives of patients, families, healthcare workers, providers, and communities. Add your talent to our extraordinary team and help us in our mission to make healthcare safer for everyone. ASP is based in Irvine, California with core sites in Everett, Washington and Schaffhausen, Switzerland plus many more offices around the world. 

 We Are an Equal Opportunity Employer 
Fortive Corporation and all Fortive Companies are proud to be equal opportunity employers. We value and encourage diversity and solicit applications from all qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity or expression, or other characteristics protected by law. Fortive and all Fortive Companies are also committed to providing reasonable accommodations for applicants with disabilities. Individuals who need a reasonable accommodation because of a disability for any part of the employment process should ask to speak with a Human Resources representative to request an accommodation.",56465,['machine learning']
Staff Data Scientist - Performance,Afresh,Remote,Full-time,"

Afresh is on a mission to eliminate food waste and make fresh food accessible to all. Our first A.I.-powered solution optimizes ordering, forecasting, and store operations for fresh food departments in brick-and-mortar grocers. With our Fresh Operating System, regional and national grocery retailers have placed $1.6 billion in produce orders across the US and we've helped our partners prevent 34 million pounds of food from going to waste. Working at Afresh represents a one-of-a-kind opportunity to have massive social impact at scale by leveraging uncommonly impactful software – we hope you'll join us!

About the role:
 You will act as the technical lead for our Data Science team. The Data Science team sits in our larger Machine Learning organization. The Afresh system comprises, among other sources of data, machine learning forecasts, inventory estimates, user-provided data, and clickstream data. You will work with product managers, go-to-market experts, applied scientists, and other stakeholders to turn this data into metrics and experiments that will guide our company towards more and more food waste reduction.
 You will also own a critical part of Afresh’s business: proving the value that we generate for our customers. To do so, you will build on our existing statistical analysis tools to ship rigorous metrics and statistical experiments that demonstrate our impact to our customers and internal teams.

In your first 3 months, you will familiarize yourself with our existing statistical toolkit and make a scoped improvement to it. You will learn about our ongoing product experiments and metric development, and work with our data scientists to spin up an experiment and/or new metric. You will attend calls with our customers and learn about the nature of data in the grocery industry.
By the end of your first 6 months, you will introduce additional metrics and ways of slicing at our data that unlock new insights for our customers. You will have onboarded onto our experimentation platform and helped guide our product team towards the right feature choice.
By the end of your first year, you will make foundational improvements to our causal inference pipelines, making them more scalable and powerful. You will introduce new norms to the team around metric creation and statistical methods.

Skills and experience:

4+ years of experience as a data scientist. 6+mo experience as a technical lead where you regularly mentored other team members.
Expert abilities in statistical analysis, especially in experimental design. Familiarity with causal inference. Extensive experience with both applied and theoretical statistics.
Expert abilities in SQL. Expert abilities in using Python for data analysis.
Familiarity with tools for Python statistical analysis (e.g., pandas, statsmodels, sklearn, dplyr).
Excellent data visualization and dashboarding skills, including familiarity with at least one major dashboarding platform (e.g. Tableau, Looker, Mode).
Excellent written and verbal visual communication skills with the proven ability to quickly deliver high-quality analyses

Base Pay: $186,300-$212,175

About Afresh  Founded in 2017, Afresh is working on the #1 solution to curb climate change: reducing food waste. By combining human insight and transformative technology, we're helping grocers provide fresher food to customers at more affordable prices.   Afresh sits at an incredible intersection of positive social impact, rocket ship financial growth, and cutting-edge technology. Our best-in-class AI research has been published in top journals including ICML, and we've raised over $148 million in funding from investors including former co-CEO of Whole Foods Market Walter Robb and Eric Schmidt's Innovation Endeavors.
 Fresh is the past, present, and future of our food system – the waste we create today will impact our planet for years to come. Join us as we continue to build a vibrant, diverse, and inclusive team that embodies our company’s values of proactivity, kindness, candor, and humility.   Afresh provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity/expression, marital status, pregnancy or related condition, or any other basis protected by law.
 Here at Afresh, many of our employees work remotely provided that they reside in one of the following states: AR, CA, CO, FL, GA, IL, KY, MA, MI, MT, MO, NV, NJ, NY, NC, OR, PA, TX, WA, WI. However, there may be key roles that will require a candidate/employee to be local to our San Francisco, CA office. In which case this requirement will be included in the job posting details under ""Skills and experience"" for reference.

",186300,"['python', 'pandas', 'machine learning', 'tableau', 'sql']"
"Data Engineer II, Machine Learning Ops - Bond & Specialty Insurance","The Travelers Companies, Inc.",CT,Full-time,"












































































































                                                                                                             Who Are We?
                                                                                                            









































































                                      Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
                                    








































































                                      Job Category
                                    


































 Data Analytics, Technology
 

   Compensation Overview
 

   The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
 


   Salary Range
  $121,000.00 - $199,600.00
 




































                                      Target Openings
                                    


































 1
 












































































































                                                                                                              What Is the Opportunity?
                                                                                                            










































































































 Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Machine Learning and business intelligence/insights.
 
   What Will You Do?
 

 Lead our ML Ops Agile teams
 Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 Design complex data solutions
 Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 Incorporate core data management competencies including data governance, data security and data quality.
 Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment.
 Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate.
 Test data movement, transformation code, and data components.
 Perform other duties as assigned.


   What Will Our Ideal Candidate Have?
 

 Bachelor’s Degree in STEM related field or equivalent
 Eight years of related experience
 Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices.
 The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs.
 Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems.
 Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues.
 Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners.
 Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts.



   What is a Must Have?
 

 Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 Four years of data engineering or equivalent experience.



   What Is in It for You?
 


 Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
 Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.






































                                      Employment Practices
                                    

                                      Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.
                                    

 If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an 
                                     
                                      email
                                      so we may assist you.
                                    

 Travelers reserves the right to fill this position at a level above or below the level included in this posting.
                                    













































                                                                                 To learn more about our comprehensive benefit programs please visit 
                                                                                
                                                                                 http://careers.travelers.com/life-at-travelers/benefits/
                                                                                .
                                                                               














































































",121000,['machine learning']
Applied Scientist,ENCHANNEL MEDICAL LTD,CA,Full-time,"
EnChannel Medical is a high-tech medical device research and development company dedicated to developing next-generation technologies and products for the treatment of atrial fibrillation, providing cardiac electrophysiologists and patients with atrial fibrillation with simpler, safer and more efficient diagnosis, treatment and management. The company has three subsidiaries, two in China and one the USA (Ladera Ranch, CA), which undertake different R&D and manufacturing tasks of the company.
 Our Algorithm team is looking for an Applied Scientist to work on developing research and product features for our mapping system. You will be responsible for designing, developing, testing, and improving machine learning (ML) algorithms for all technology subsystems. The Applied Scientist will use state-of-the-art ML to build advanced algorithmic systems such as object detection, segmentation, and classification to improve clinical workflow. This scientist will have the opportunity to design and build end-to-end solutions. The ideal candidate is detailed oriented with a desire to work in a fast-paced start-up environment while handling multiple priorities.
 Essential Functions

Investigate and implement innovative real-time applications and algorithms of computer vision, time series, and graphical data for cardiac signals.
Analyze and interpret complex cardiac signals using machine learning and statistical techniques.
Model complex problems, discover insights, and identify opportunities using statistical, algorithmic, and visualization techniques for intracardiac electrograms.
Evaluation, adoption, and refinement of prototype algorithms developed by our engineers, scientists, and consultants.
Collaborate with the software engineering team to implement algorithms into computationally efficient, “real-time” operations.
Maintain, update, and document design requirements throughout the entire system life cycle.
Collaborate with cross-functional teams to develop and implement ML solutions.
May be required to actively contribute to regulatory filings, patent applications and other industry related publications.

Requirements

Must be able to work onsite in a fast paced “start-up” culture.
Strong interest in applying ML to medical problems.
Strong programming skills in languages such as Python, C++, and MATLAB.
Experience with ML libraries such as OpenCV, TensorFlow, and PyTorch.
Broad understanding of machine learning, deep learning, and statistical techniques.
Expertise in at least one of these: computer vision, time series analysis, self-supervised learning, multi-model ML.
2+ years of practical Experience in developing ML solutions in a production environment especially in the medical domain.
A bachelor’s and/or master's degree, and/or PhD in scientific/engineering discipline; or equivalent combination of education and experience.
(preferred) Experience with use of ML in cardiac anatomy and electrophysiology, ECG, unipolar/bipolar electrogram.
(preferred) Experience in developing computer vision algorithms for CT, MRI, ultrasound images.

What you bring

Ability to communicate effectively with Scientist and Engineers.
Working with high quality standards and be pro-active in finding solutions to achieve successful outcomes.

What we offer

Amazing people and culture.
Competitive Salary.
Comprehensive benefits plan and 401K with company matching.
Casual dress and start-up work environment.
Wellness and fitness programs.

Our pay ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum new hire pay for the position located in California. Within the range, individual pay is determined by location, additional factors, including job-related skills, experience, and relevant education or training.
 EnChannel Medical is an equal opportunity employer. We believe in hiring a diverse workforce and sustaining an inclusive, people-first culture. We are committed to non-discrimination on any protected basis, such as disability and veteran status, or any basis covered under acceptable law.
",120000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Principal Data Scientist,Second Dinner,Remote,Full-time,"
Who We Are
 Second Dinner is an award-winning independent game development studio that is here to make the most fun games in the world. Not super fun games. Not SUPER DUPER fun games. We mean the MOST fun games. In fact, our game MARVEL SNAP has earned multiple Mobile Game of the Year Awards (Game Awards, DICE), Best Strategy Game (IGN), and the Apple Design Award for Innovation!

 Second Dinner is a remote-first studio, so while we are headquartered in Irvine, California, most of our team is fully remote across the United States. We want the most talented teammates wherever they call home. A diverse team with varied perspectives makes us a better company and will help us make better games. If you can bring something new to the table and expand our point of view, that's a huge upside.

 Our Data & Analytics Team
 At Second Dinner, data plays a crucial role in conveying the voices of our players and informing our decisions, which leads us to great games and player experiences. Our team informs decision-making with scientific and methodological rigor. We build data and ML-powered player experiences directly into the game. We innovate in analytics tooling and data science capabilities to redefine what is possible in game development and operations.

 Your Role
 You will report to the VP of Data and AI, and your primary responsibility is to drive the data science and experimentation initiatives in Marvel SNAP. You will help level up SNAP team’s capability in rigorous decision-making with data and experiments. You will partner with the AI team to enhance and expand the game for SNAP players. You will collaborate with Product Management (PM), Design, Marketing, and many other disciplines to help make our game wildly fun and drive growth worldwide. If you love crafting world-class game experiences, collaborating with extraordinarily talented cross-functional teams, and creating data science and analytics solutions to impact millions of players directly, then APPLY!!!

 What You’ll Do:

 Partner with PM, Design, and Marketing to identify growth opportunities and translate them into data science initiatives.
 Collaborate with PM and Design to improve our game live operations by introducing rigorous quantitative practices.
 Educate and support the SNAP team on decision science and relevant best practices.
 Partner with PM and Analytics to identify, define, compute, and validate the relevant and actionable metrics to measure the success of product features and events.
 Apply analytics, experimentation, and machine learning techniques to empower personalization in our game.
 Lead excellence in our approach to experimentation and hypothesis-driven development. Lead the design, implementation, and analysis of experiments.
 Partner with central technology teams to guide data collection and adopt new solutions that are valuable to SNAP.
 Evangelize data science, analytics, and experimentation. Level up the data literacy of the company.
 Contribute as a key member in determining the vision and strategy for data and analytics.


 What You’ll Need:

 Advanced degree in Mathematics, Statistics, Physics, Engineering, or related quantitative field.
 Expertise in Python and SQL.
 Extensive experience in data science and analytics.
 Expensive experience in predictive modeling and applied ML.
 Extensive experience in experimentation for consumer-facing products (A/B test, multivariate test, quasi-experiment, causal inference).
 Experience developing personalized recommendation systems.
 Strong ability to convey technical and statistical concepts clearly and concisely among audiences with different backgrounds.
 Strong ability to partner with stakeholders to lead product improvement and innovations.
 Fundamental understandings for ETL/ELT.
 Demonstrated success in a highly collaborative cross-functional work environment.
 Passionate player of mobile games.
 Mindset for serving a diverse and global player base.


 Nice to Have, But Not Necessary:

 Ph.D. in Engineering, Mathematics, Statistics, Physics, or related field.
 Experience with AWS, Databricks, Tableau, and Looker.
 Experience with Apache Spark.
 Experience with Unity and C#/C++.
 Experience collaborating with data engineers and ML engineers on ML/AI systems.
 Experience working in online video games, preferably free-to-play mobile games.
 Passion for making video games.


 The total compensation for this position includes a new hire offer base salary range of $190,000 - $280,000 USD + equity + comprehensive benefits + potential for discretionary performance bonuses.

 Individual pay within this salary range may span multiple levels within the discipline and is determined by assessed job-related skills, experience, relevant education or training. It also factors in market demands and business needs. The disclosed range is not adjusted based on location and may be subject to change or modification based on business needs in the future. Your recruiter can answer any questions about new hire total compensation during the hiring process.

 An overview of the benefits and perks at Second Dinner:

 Medical, Dental, and Vision insurance plans with Second Dinner paying 100% of premiums for employees and 75% for dependents for many plans
 401(k) contribution with no waiting period
 16 weeks paid parental leave with no waiting period
 Home office improvement bonus
 Paid Vacation & Sick time
 Remote-first with core overlap hours between 10AM and 4PM PT
 Company Winter Holiday shutdown (Dec 25-Jan 1)
 Company Summer Holiday shutdown (week of July 4)
 Company Events - In-person Summer all-hands gathering, in-person holiday party, annual camping event, and virtual events throughout the year


 We are an equal opportunity employer that places high value on diversity and inclusion. We do not discriminate on the basis of race, color, ancestry, national origin, religion, age, disability status, sex (including pregnancy), gender, gender identity, gender expression, sexual orientation, medical condition, genetic information, marital status, military status, or veteran status.

 You must be eligible to work in the United States to be considered for this position.

",190000,"['python', 'machine learning', 'tableau', 'aws', 'etl', 'sql', 'apache spark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Data Analyst (Hybrid) - Secret Clearance,Marathon TS,AL,Full-time,"Marathon TS is seeking a Senior Data Analyst to join a contract with a federal government client in support of an important mission.
This position requires employees to be located in the Huntsville, AL area in order to report to work on-site at Redstone Arsenal.
Responsibilities

Provide highly complex data mining, statistical analysis, trend analysis, and causal analysis.
Perform as a technical lead responsible for monitoring and providing monthly contract reports and deliverables.
Responsible for integrating multiple disciplines in an operations research team and translating applicable methods into language and application understandable by operational managers throughout the organization.
Review and provide quality control methods on products.
Prepare and update training materials to ensure newly assigned personnel gain an understanding of key analytic tools, procedures, and methodologies used.
Take structured and unstructured data and distill the information into a cohesive analytical product for a contracting functional business area audience.
Support pattern analysis methods to formulate recommendations to operational managers based upon exploiting patterns in the past, current, and anticipated operational environment.

Education and Experience

8 plus years in a technical field
BA/BS required

Required Skills

Have experience advising senior DoD decision makers on methodologies, results, and conclusions from applied operations research.
Have experience with the primary tools used for research services include, but are not limited to, Logistics Management Program, Vantage, Virtual Contracting Enterprise, General Fund Enterprise Business System (GFEBS), SAP Business Objects/Web Intelligence Reports, Microsoft SharePoint, Army-specific contract writing systems (Procurement Desktop Defense (PD2) and Procurement Automated Data and Document System (PADDS)), and various Government and Commercial business process automation systems.
Personnel should have strong data manipulation and problem-solving skills.
Must have strong technical skills in areas such as statistics, programming languages like R or Python, SQL (Structured Query Language), data visualization, and data cleaning and preparation.
Have good communication skills and problem-solving ability.

Security ClearanceActive Secret clearance is required.
Job Type: Full-time
Pay: $100,000.00 - $110,000.00 per year
Benefits:

401(k)
401(k) matching
Dental insurance
Health insurance
Paid holidays
Paid time off
Vision insurance

Experience level:

8 years

Schedule:

8 hour shift
Monday to Friday

Ability to commute/relocate:

Huntsville, AL: Reliably commute or planning to relocate before starting work (Required)

Education:

Bachelor's (Required)

Experience:

GFEBS: 1 year (Preferred)
PD2: 1 year (Preferred)
PADDS: 1 year (Preferred)

Security clearance:

Secret (Required)

Work Location: In person",100000,"['python', 'sql']"
Senior Data Analyst (Data Lead),Blue Star Partners LLC,OH,Full-time,"
Job Title: Senior Data Analyst (Data Lead) Rate: $37.40 – $48.23 per hour based on experience and qualifications Employment Type: Temporary Resource, W-2 Duration: 12/4/2023 – 12/3/24 Location: Hybrid role with requirement to be onsite Tuesdays and Wednesdays in Columbus, OH.

 Scope of Services: 
As a Senior Data Analyst with advanced problem-solving skills, this role excels in a dynamic matrix organization, collaborating seamlessly with business partners and service providers. Bringing profound technology domain awareness in Data, the Senior Analyst demonstrates superior documentation, communication, and requirements analysis skills. Operating in a metrics-driven environment, they contribute to continuous improvement with a keen understanding of business impact during IT incidents. The ability to articulate financial aspects, manage domain-specific total cost of ownership, and comprehend foundational contract principles are integral to this role. With expertise in Data Engineering and Analytics, particularly in ETL and Data ingestion within Azure Data Lake and Microsoft ADF, the Senior Analyst, with over three years of experience, is adept at translating technical complexities to stakeholders with clarity and urgency. A college degree and technology certifications further enhance their qualifications for this role. 
 Roles, Responsibilities and Deliverables: 

Superior problem-solving skills. Knowledge worker who is driven and can think and act in a fast-paced environment. 
Excels in a matrix organization by collaborating with business partners and service providers. 
Technology Domain awareness. (Data) 
Superior documentation and written and oral communication skills. 
Superior requirements elicitation and analysis skills. 
Ability to operate in a metrics-based management environment with a continuous improvement mindset. 
Ability to articulate business impact for business impacting IT incidents with a sense of urgency. 
Financial acumen in being able to put together and manage domain specific total cost of ownership. 
Foundational understanding of contracts. 
Strong communication skills and ability to communicate with stakeholders

Qualifications: 

Experience working with Data Engineering and/or Analytics with a focus on ETL and/or Data ingestion from various source systems. 
Experience working in Azure Data Lake and proficiency with Microsoft ADF preferred. 
Sr. Analyst expected to have > 3 yrs. of experience. 
College degree and certifications in the technology domain preferred.


 To apply, please submit a resume outlining your relevant experience and approach to being a Senior Data Analyst. Short-listed candidates will be expected to complete a Blue Star Partners Bio.
",74800,"['azure', 'etl']"
Machine Learning Engineer,"Optimoz, Inc",MD,Full-time,"Optimoz, Inc
Job Title: Machine Learning Engineer
Job Location: On-Site, Rockville, MD (HQ)
Employment: Full-Time/W2 w/ Benefits
Optimoz is a complete cloud engineering company that enables enterprises and federal agencies to accelerate development and delivery of applications that engage customers and drive revenue. Optimoz specializes in all aspects of Cloud Computing, DevSecOps, Continuous Integration/Continuous Delivery and Application Development leveraging on the microservices and API architecture. Our mission is simple – Empower customers to increase their delivery capabilities with the effective and efficient use of the technology.
Learn more about Optimoz and our team - https://optimoz.com/
Our team here at Optimoz is searching for a Machine Learning Engineer to join our team! As a Machine Learning Engineer you will be working on internal application development projects and assisting our clients with their AI and ML needs.
Responsibilities:

Develop and deploy machine learning models independently.
Optimize and fine-tune existing machine learning algorithms for improved performance.
Collaborate with data scientists and business analysts to understand and define project requirements.
Take a lead role in data collection, feature engineering, and data preprocessing.
Participate in code reviews, mentor entry-level engineers, and assist in their skill development.
Work on the end-to-end machine learning pipeline, including data acquisition, model training, and deployment.
Implement and fine-tune machine learning models under the guidance of senior engineers.
Participate in model evaluation, validation, and performance monitoring.
Collaborate with data scientists and engineers to understand business requirements.

Required Skills:

Bachelor's or Master's degree in Computer Science, Data Science, or related field.
2 to 5 years of professional experience.
Experience and extensive knowledge w/ Artificial Intelligence Machine Learning (AIML) and Large Language Model (LLM)
Experience/knowledge/interest in Generative AI technologies such as LangChain and Vector DBs.
Proven experience in developing and deploying machine learning models.
Proficiency in machine learning libraries (e.g., TensorFlow, PyTorch, scikit-learn).
Strong programming skills in Python and knowledge of software engineering best practices.
Experience with data engineering and data pipelines.
Good understanding of model evaluation and optimization techniques.

Preferred Skills:

Experience working in a start-up atmosphere
Experience assisting external customers and clients
Experience with deep learning and neural networks.
Knowledge of cloud platforms (e.g., AWS, Azure, GCP).
Strong communication and collaboration skills.
Research experience in machine learning.
Relevant certifications in machine learning or data science.

Optimoz, Inc provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
Job Type: Full-time
Pay: $90,000.00 - $130,000.00 per year
Benefits:

401(k)
Dental insurance
Health insurance
Professional development assistance

Ability to commute/relocate:

Rockville, MD: Reliably commute or planning to relocate before starting work (Preferred)

Experience:

Machine Learning Engineering (in a professional setting): 2 years (Required)

Work Location: In person",90000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'aws', 'azure', 'gcp']"
Sr. Data Scientist for Signal Analysis Program,DeNOVO Solutions,CO,Full-time,"





Position Name: Senior Data Scientist - Signal Analysis Project
     

Location: Aurora, CO
     

Clearance: Must have a current and active TS/SCI
     

Sign-On Bonus Eligible: Yes
     


      DeNOVO Solutions is seeking a highly skilled and innovative Senior Data Scientist with a passion for developing cutting-edge machine learning (ML) algorithms. In this role, you will have the exciting opportunity to contribute to the development of a state-of-the-art ML-based data classification system. Our system leverages a powerful combination of supervised and unsupervised ML algorithms to enhance signal geolocation identification.
     



Required Skills:


Experience and familiarity with Data Science, Machine Learning, and modeling workflows
Experience architecting and training ML models;
Experience mapping machine learning solutions to customer problem sets
Expert competency of Python
Intermediate competency of Java
Familiarity with data analysis packages/libraries (Pandas, SKLearn, R, MATLAB, SAS, MLFLOW etc.)
Experience using JIRA and Confluence
Experience working on an Agile development team
Experience and desire to work with a diverse team of developers and analyst


Desired Skills:


Experience with distributed storage and processing (Mongo, Elastic, Hadoop, Spark, etc)
Experience with cloud services (EC2, Azure, etc) and technologies and methodologies (REST, microservices, CI/CD, etc)
Experience with deeper machine learning (Torch/TensorFlow, various neural network architectures)
Experience with Random Forest and Bayesian Information Criterion (BIC) Clustering algorithms


Experience and Education Requirements: To be considered for this role you must have the following:
      

Master's or PhD in a STEM focused discipline with at least 15 years of hands-on experience in Data Science


Required Clearance


An active TS/SCI and the willingness and ability to pass a polygraph



Join Our Team! At DeNOVO Solutions, we are committed to providing exceptional technical and professional services throughout the Intelligence Community (IC). As a Minority Owned-Service Disabled Veteran Owned Small Business (MO/SDVOSB), we prioritize improving our customer's competitive position and foster a collaborative work environment. We offer an attractive benefits package to our full-time employees, which includes:
     

Competitive Wages: This position offers an annualized pay range of $175,000.00 to $225,000.00, ensuring you're rewarded for your expertise and contributions.
Comprehensive Health Benefits: Enjoy 100% employer-paid medical, dental, and vision premiums for you and your dependents.
Lifestyle Spending Account (LSA): DeNOVO Solutions cares about your well-being, providing additional support for your lifestyle needs.
Financial Security: Benefit from short-term and long-term disability coverage, along with a 401k plan featuring a 6% match.
Sign-On Bonuses: We value your skills and expertise, offering sign-on bonuses for critical positions.
Work-Life Balance: Enjoy 11 paid Federal holidays and a generous allotment of 120 hours of Paid Time Off (PTO).
Professional Development: We invest in your growth with tuition reimbursement, skillset training, and assistance in acquiring new/renewed certifications.
Company Outings and Trips: Join us for exciting company outings and trips, fostering team building and camaraderie.


About Us: DeNOVO Solutions is proud to be an Equal Opportunity/Affirmative Action Employer. We value diversity and inclusivity, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, marital status, veteran status, sexual orientation, genetic information, or any other protected characteristic under applicable law.
     




",175000,"['tensorflow', 'python', 'pandas', 'machine learning', 'azure', 'hadoop']"
(No C2C) Sr Data Engineer with Machine Learning,Kairos Technologies Inc,Remote,Full-time,"Greetings from Kairos Technologies Inc,
Role: Sr Data Engineer with Machine LearningLocation: Bethesda, MD (Remote)Duration: C2HExperience: 10+ yrs.Visa : US Citizens, GC, H4 EAD, L2...(W2 or 1099)
Data/ML Engineer is responsible for solution engineering of enterprise scale data management best practices. This includes patterns such as - modern data integration frameworks, building of scalable distributed systems using emerging cloud-based data design patterns. This role will be responsible for developing data integration tasks in data and analytics space. This position will report to director of data management group under Data Operations organization. This is an individual performer role.
Key Job Functions

Demonstrate expert ability in implementing data warehouse solutions using Snowflake.
Building data integration solutions between transaction systems and analytics platform.
Expand data integration solutions to ingest data from internal and external sources and to further transform as per the business consumption needs.
Create security policies in Snowflake to manage fine grained access control
Develop tasks for a multitude of data patterns, e.g., real-time data integration, advanced analytics, machine learning, BI and reporting.
Lead POC efforts to build foundational AI/ML services for Predictive Analytics.
Building of data products by data enrichment and ML.
Be a team player and share knowledge with the existing team members.

Education

Bachelor’s degree in computer science or a related field

Specialized Knowledge & Skills

Expertise in real-time data solutions, good to have knowledge of streams processing, Message Oriented Platforms and ETL/ELT Tools.
Strong scripting experience using Python and SQL
Working knowledge of foundational AWS compute, storage, networking and IAM.
Solid scripting experience in AWS using lambda functions. Good to have knowledge of CloudFormation template. Overall experience with AWS services should be over three years.
Hands on experience with popular cloud-based data warehouse platforms, viz. Redshift, Snowflake.
Experience with one or more data integration tools viz. Attunity (Qlik), AWS Glue ETL, Talend, Kafka etc.
Strong understanding of data security – authorization, authentication, encryption, and network security.
Experience in building data pipelines with related understanding of data ingestion, transformation of structured, semi-structured and unstructured data across cloud services
Hands on experience in using and extending machine learning framework and libraries, e.g, scikit-learn, PyTorch, TensorFlow, XGBoost etc.
Experience with AWS SageMaker family of services or similar tools to develop machine learning models
Demonstrated ability to be self-directed with excellent organization, analytical and interpersonal skills, and consistently meet or exceed deadline deliverables.
Strong communication skills to facilitate meetings and workshops to collect data, functional and technology requirements, document processes, data flows, gap analysis, and associated data to support data management/governance related efforts.
Knowledge and understanding of data standards and principles to drive best practices around data management activities and solutions.
Strong understanding of the importance and benefits of good data quality, and the ability to champion results across functions.
Ability to lead collaborative meetings which result in clearly documented outcomes, a concrete understanding of meeting attendee performance/reliability, and ongoing management & follow-up for action items.

.Acts with integrity and proactively seeks ways to ensure compliance with regulations, policies, and procedures.
Thanks& Regards,
K Hemanth Kumar | Sr IT Technical Recruiter | Kairos Technologies Inc
Job Types: Full-time, Contract
Pay: $70.00 - $75.00 per hour
Experience level:

10 years

Schedule:

8 hour shift

Experience:

Machine learning: 2 years (Preferred)
SQL: 10 years (Preferred)
Python: 5 years (Preferred)

Work Location: Remote",140000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'aws', 'etl', 'sql', 'kafka']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Data Analyst,ReadyRefresh,CT,Full-time,"*** Fully Remote Position *** 
BlueTriton is a leading provider of spring and purified water products - the name behind your favorite bottled water brands. We are proud to offer an extensive portfolio of highly recognizable, responsibly sourced, and sustainably packaged spring water in addition to other quality products and services. Get ready to quench your thirst with exciting possibilities when you join BlueTriton for a fiercely good career doing work that matters. 
ReadyRefresh brings hydration that supports a healthy lifestyle, convenience that preserves precious time and sustainability to help improve our world. Our ReadyRefresh branches and warehouses are where our iconic brands begin their journey to the customer. Job Description 

 The Senior Data Analyst role will be responsible for supporting the ReadyRefresh business, by unlocking our technology stack. They will work with functions to ensure we are maximizing our technology investment and leveraging the systems in the most efficient and effective ways. They will provide expertise on what we can do with our current technology as well as ways we can enhance or expand it. All of this to help unlock and accelerate our growth ambitions. 

 This is a Fully Remote position! 

 Key responsibilities for this position include but are not limited to: 


Perform descriptive, predictive, and prescriptive analytics in SQL, Azure, PowerBI, and MS Excel using statistical models or industry accepted tools
Provide automated data solutions, tools, and capabilities to enable self-service frameworks for data consumers
Provide expertise and translate the business needs to design; and develop tools, techniques, and metrics, and dashboards for insights and data visualization
Respond to data related inquiries in real-time to support business and technical teams
Provide analytical insights to enable growth strategies for the ReadyRefresh business
Work with business functions to understand how the business works and how data can help unlock opportunities
Responsible for establishing appreciation and adherence to the principles of data quality management, including metadata, lineage, and business definitions
Innovative thinking, ability to challenge the status quo
 Qualifications 


Key qualifications include:


Master’s degree in Analytics preferred, Bachelor's Degree required
5+ years of experience as a data analyst
Technical expertise with MS SQL, PowerBI and Excel required. Python, MS Azure a plus!
Experience with cloud warehouses and data lake platform (e.g. Synapse, Databricks)
Experience in quantitative analysis and statistical modelling
Ability to work well under pressure and achieve results on a deadline
Exceptional writing and verbal communication skills
Understanding of direct to consumer/CPG process
Strong analytical mindset
Strong accountability mindset
 Ideal candidates will benefit from possessing an analytical mindset that can see how data can answer business questions. 


Pay Range: $100,893.00 -$140,836.00. This role is eligible for a 7% annual bonus. 


Salary Range Disclaimer:
 The salary range provided for this position is an approximation based on market research, internal compensation data and the candidate’s qualifications and experience. Final salary offers are determined through a comprehensive evaluation of candidate qualifications and may vary depending on factors such as skills, experience, and geographic location of the position. Other components of the compensation package, including benefits and bonuses, will also be considered. We are committed to fair and equitable compensation practices, and we encourage open dialogue about compensation during the interview process. 

 #LI-Remote 
BlueTriton Brands is proud to be an Equal Opportunity and Affirmative Action employer, seeking to create a welcoming and diverse environment . We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state, and local law. BlueTriton Brands is committed to providing reasonable accommodation for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please contact us at BlueTritonHR@bluetriton.com 
BlueTriton Brands offers an unrivaled portfolio of water brands for healthy hydration, including Arrowhead®, Deer Park®, Ice Mountain®, Origin™, Ozarka®, Poland Spring®, Zephyrhills®, AC+ION® Alkaline Water, Splash Blast® Flavored Water Beverage, Splash Fizz® Flavored Water Beverage Saratoga® and Pure Life® Purified Water.",100893,"['python', 'azure', 'sql']"
Data Engineer,IBM,DC,Full-time,"

Introduction
 At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.
  

Your Role and Responsibilities
 Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes.
 Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region’s best places to work multiple times, Octo is an employer of choice!
 

As a Data Engineer, you will work closely with architects, engineers, and integrators to assess customer requirements and to design and support our team to unlock insights from the massive amounts of data within the Veterans Affairs ecosystem. You will be tasked with overall onboarding, operationalizing, administration, and maintenance of key big data/data science/machine learning platforms like Databricks and other cutting-edge technologies.
 Previous experience with Veterans Affairs and/or health/clinical data is a major plus.
 Us...
 We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client’s missions.
 Program Mission...
 This program supports Veterans Affairs' strategic mission of furthering efforts to modernize its data analytics platform and enhance accessibility to enterprise data and reporting tools.
 

Responsibilities...

 Serves as a technical consultant to implement Analytics solutions and produce Data Domain ETL Scripts.
 Uses PowerBI/dashboards to support problem identification and resolution.
 Develops and maintains documentation on various operational and design aspects of the Platform. Assist in troubleshooting issues and resolving them.
 Builds awareness, increases knowledge and drives adoption of modern technologies, sharing user and engineering benefits to gain buy-in.
 Effectively communicates with and influences key stakeholders across the enterprise, at all levels of the organization.
 Operates as a trusted advisor for technology, platform, or capability domain, helping to shape use cases and implementation in a unified manner.

 Years of Experience: Must have at least 5 years of experience with Microsoft database and BI technologies, including at least 2-3 years of experience with Azure Data Lake Storage, Azure Data Factory, Azure SQL DW, Azure Synapse, Databricks, Spark, and/or Python
 Education: Bachelor's degree in computer science or related area OR 8 years of additional experience will be considered in lieu of degree. 
Location: Remote within the United States.
 Clearance: Ability to obtain a Public Trust security clearance.
 Required Technical and Professional Expertise


 See below for experience and educational requirements.
 Experience defining and implementing strategies for extracting, transforming, and loading data from multiple data sources into analytic data stores.
 Knowledge of Cloud Data Analytics platforms 
Experience programming in PowerShell, Python, SQL.
 Experience with cloud data storage formats such as Parquet, Avro. 
Experience with data transformation techniques.
 Ability to test data integrity and develop tests and quality checks. 
Experience preparing data for various types of data analysis: descriptive, diagnostic, predictive, prescriptive. 
Performance analysis and tuning experience
 Experience with Data Warehouse or Big Data solutions
 Experience with ML models
 Experience with data modeling and database design
 Strong communication, interpersonal, and collaboration skills working in a team-oriented environment
 Clearance: Ability to obtain a Public Trust security clearance.


 Preferred Technical and Professional Expertise


 Experience supporting Department of Veterans Affairs (VA) and/or other federal organizations.
 Advanced SQL, NoSQL query, and scripting. Experience with Python, Java.
 Experience with Azure Data Lake Storage, Azure Data Factory, Azure SQL DW, Azure Synapse, Databricks, Spark, and/or Python
 Experience with relational database systems (i.e., DB2, SQL Server) and non-relational databases such as (Azure SQL, Amazon RDBS, MongoDB, Hadoop tools).
 Understanding of data design concepts (i.e., data modeling, data mapping, OLTP, and OLAP).
 Experience modeling data, message, and service interoperability.
 Azure PowerShell knowledge





 About Business Unit
 IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.
 



 Your Life @ IBM
 In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.
   Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.
 Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.
 Are you ready to be an IBMer?



 About IBM
 IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.
  
 Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. 
  
 At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.
 



 Location Statement
 IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:
  


Healthcare benefits including medical & prescription drug coverage, dental, vision, and mental health & well being
 - Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short & long- term disability coverage, and opportunities for performance based salary incentive programs
  

Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law
Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals
Diverse and inclusive employee resource groups, giving & volunteer opportunities, and discounts on retail products, services & experiences

 The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year. 
  
 We consider qualified applicants with criminal histories, consistent with applicable law.
  
 IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.
 



 Being You @ IBM
 IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
 
",78000,"['python', 'machine learning', 'azure', 'nosql', 'etl', 'sql', 'hadoop']"
Lead Data Science Engineer,Medidata Solutions,NY,Full-time,"



Requisition ID 
533295








Medidata: Powering Smarter Treatments and Healthier People
 Medidata, a Dassault Systèmes company, is leading the digital transformation of life sciences, creating hope for millions of people. Medidata helps generate the evidence and insights to help pharmaceutical, biotech, medical device and diagnostics companies, and academic researchers accelerate value, minimize risk, and optimize outcomes. More than one million registered users across 2,000+ customers and partners access the world's most trusted platform for clinical development, commercial, and real-world data. Known for its ground-breaking technological innovations, Medidata has supported more than 30,000 clinical trials and 9 million study participants. And Medidata’s ongoing commitment to infusing the patient voice into trial designs and solutions is helping to create a better and more inclusive experience for all participants in clinical studies. Medidata is involved in nearly 40% of company-initiated trial starts globally, with studies conducted in more than 140 countries. More than 70% of novel drugs approved by the Food and Drug Administration (FDA) in 2022 were developed with Medidata software. Medidata is headquartered in New York City and has offices around the world to meet the needs of its customers. Discover more at www.medidata.com and follow us @medidata.
 Our Team:
 Medidata is looking for individuals who will help us tackle some of the most complex questions facing the industry today using our proprietary platform and advanced analytics. At Medidata, we never work alone. This role will partner heavily with all of the key stakeholder functions including product, delivery, data science, engineering, partnerships, and biostatistics. Successful Medidata AI candidates will be skilled in analytical/quantitative thinking, structured communication, and excited about building the next horizon of Medidata’s mission to power smarter treatments and healthier people.
 Who We're Looking For:

Advanced skills in modern data architecture, data science engineering, data modeling and data quality using state-of-art cloud computing technologies (AWS).
Hands-on experience in the latest breed of data ETL, automation and
CICD technologies including Python, SQL and Git in a cloud setting.
2+ years of experience with cloud-native data warehouse technologies like Snowflake.
Skills in data analysis, insight generation and manipulation of structured and unstructured data sources. Experience with automated data quality frameworks.
Collaborate with all levels of data science engineering technology personnel and senior leadership.
Document and present work to all levels of technical and non-technical audiences.
Commitment to creating rigorous, high-quality insights from data, at scale.
You should be flexible / willing to work across matrixed delivery landscape which includes and not limited to Agile Applications
Development, Support and Deployment.
Design and implement secure data pipelines into a Snowflake data warehouse from on premise and cloud data sources.
Guide and review off-shore development team work providing coaching and coding feedback aligning to best practices set by the Data Science Engineering team.

Requirements (Education & Experience):

Undergraduate degree in a technical or scientific field, such as Statistics, Data Science, Computer Science, or similar 
8+ years professional experience as a data scientist, data engineer, data analyst, or related role 
Experience with clinical trial data is not required, but interest to learn and understand how these data improve medical research is paramount 

Medidata is making a real difference in the lives of patients everywhere by accelerating critical drug and medical device development, enabling life-saving drugs and medical devices to get to market faster. Our products sit at the convergence of the Technology and Life Sciences industries, one of most exciting areas for global innovation. Nine of the top 10 best-selling drugs in 2017 were developed on the Medidata platform.
 Medidata Solutions have powered close to 30,000 clinical trials giving us the largest collection of clinical trial data in the world. With this asset, we pioneer innovative, advanced applications and intelligent data analytics, bringing an unmatched level of quality and efficiency to clinical trials enabling treatments to reach waiting patients sooner.
 As with all roles, Medidata sets ranges based on a number of factors including function, level, candidate expertise and experience, and geographic location.
 The salary range for positions that will be physically based in the NYC Metro Area is $135,000 - $180,000
 Base pay is one part of the Total Rewards that Medidata provides to compensate and recognize employees for their work. Most sales positions are eligible for a commission on the terms of applicable plan documents, and many of Medidata’s non-sales positions are eligible for annual bonuses. Medidata believes that benefits should connect you to the support you need when it matters most and provides best-in-class benefits, including medical, dental, life and disability insurance; 401(k) matching; unlimited paid time off; and 10 paid holidays per year.
 #LI-ME1 #LI-Remote

Equal Employment Opportunity In order to provide equal employment and advancement opportunities to all individuals, employment decisions at Medidata are based on merit, qualifications and abilities. Medidata is committed to a policy of non-discrimination and equal opportunity for all employees and qualified applicants without regard to race, color, religion, gender, sex (including pregnancy, childbirth or medical or common conditions related to pregnancy or childbirth), sexual orientation, gender identity, gender expression, marital status, familial status, national origin, ancestry, age, disability, veteran status, military service, application for military service, genetic information, receipt of free medical care, or any other characteristic protected under applicable law. Medidata will make reasonable accommodations for qualified individuals with known disabilities, in accordance with applicable law.
 

",135000,"['python', 'aws', 'etl', 'sql', 'git']"
Principal Data Scientist,Remitly,WA,Full-time,"

  Job Description:
 

   Remitly is on a mission to transform the lives of immigrants and their families by providing the most trusted financial products and services on the planet. Since 2011, we have been tirelessly delivering on our promises to immigrants sending their hard earned money home. Today, we are reimagining international payments at scale and building new products to create deeper relationships with our customers and their loved ones across the globe. Join over 2,700 employees across 10 offices who are growing their careers while having a positive impact on people globally.
 

   Remitly is registered as a Money Services Business in the U.S., Canada, EU, United Kingdom, Singapore and Australia. Each of these jurisdictions require, among other items, that Remitly maintain a comprehensive Risk and Compliance Program.
 


   About the role
 

   Customer life-cycle marketing (LCM) is an important lever for Remitly to not only attract new customers but also engage and retain them. As the analytics lead for this area, you will work with the LCM team to uplevel Remitly’s LCM program by driving innovations and efficiencies. You would develop advanced analytical solutions to better understand customer behavior and lead the development of personalized solutions that will allow us to engage our customers where they are in their journey with us, ultimately improving customer acquisition and retention. You would also be responsible for the overall functional roadmap of the LCM area and guide other LCM analysts.
 


   What You'll Do
 



     Conceptualize, design, and execute strategic analytical initiatives impacting customer lifecycle (such as customer activation and churn) from start to finish, including cross-functional project leadership, data collection and manipulation, analysis and modeling, and the communication of insights and recommendations to drive desired business outcomes.
   


     Recommend, oversee and execute appropriate statistical and predictive modeling techniques to help optimize customer targeting, reduce churn, and increase customer life-time-value
   


     Build frameworks and methods that allow Remitly to personalize LCM customer interactions at scale using data products / ML tools and enable other analysts and marketers to leverage such tools
   


     Build dashboards in partnership with analysts to communicate performance metrics across markets and channels
   


     Influence strategic decisions across various functional areas, including Marketing, Finance, and Business Management via clear and effective communications
   


     Recruit, guide and coach junior and mid-level analysts and data scientists with the objective of creating a best-in-class Data Science and Analytics Function at Remitly
   



   Key Qualifications
 



     Advanced degree in Statistics, Mathematics, Applied Mathematics, Computer Science, Operations Research, Engineering, Economics, or related quantitative fields.
   


     2+ years of experience in life-cycle marketing and / or customer analytics, developing at-scale solutions to influence user behavior, and identify the next best action for various customer segments. Some experience building personalization methods at scale is highly desirable.
   


     10+ years of experience (6+ with a Ph.D.) in using data science and machine learning methods to drive business outcomes.
   


     10+ years of experience in statistical experimentation methods, such as A/B testing, causal inference, experimental design, power analysis, and non-parametric statistics.
   


     Expertise in SQL, Python and / or R
   


     Experience leading analytics projects from creation to delivery, including developing and communicating structured solutions and driving business outcomes
   


     Track record of mentorship and technical leadership
   



   Preferred Qualifications
 



     Ph.D. degree in Statistics, Mathematics, Applied Mathematics, Computer Science, Operations Research, Engineering, Economics, or related quantitative fields
   


     2+ years of experience building data products / ML tools for personalization of consumer marketing efforts
   


     Experience working with CRM tools like Braze, Iterable, etc.
   



   Our Benefits
 




      Flexible paid time off
    


      Health, dental, and vision benefits + 401k plan with company matching
    


      Company contributions to your HSA plan, if you choose one
    


      Employee Stock Purchase Plan (ESPP) available for eligible employees
    


      Continuing education and corridor travel benefits
    




   Remitly is an Equal Opportunity Employer. Equal employment opportunity has been, and will continue to be, a fundamental principle at Remitly. We are committed to nondiscrimination across our global organization and in all of our business operations. Employment is determined based on personal capabilities and qualifications without discrimination on the basis of race, creed, color, religion, sex, gender identification and expression, marital status, military status or status as an honorably discharge/veteran, pregnancy (including a woman's potential to get pregnant, pregnancy-related conditions, and childbearing), sexual orientation, age (40 and over), national origin, ancestry, citizenship or immigration status, physical, mental, or sensory disability (including the use of a trained dog guide or service animal), HIV/AIDS or hepatitis C status, genetic information, status as an actual or perceived victim of domestic violence, sexual assault, or stalking, or any other protected class as established by law.
 

   Remitly is an E-Verify Employer
 

   Compensation Details. The starting base salary range for this position is typically $168,000-210,000. In the U.S., Remitly employees are shareholders in our Company and equity is part of our total compensation plan. Your recruiter can share more information about medical benefits offered, as well as other financial benefits and total compensation components offered with this role.
 

   Your recruiter can share more information about medical benefits offered, as well as other financial benefits and total compensation components offered with this role.
 


   Remitly is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
 
",168000,"['python', 'machine learning', 'sql']"
"AI and Machine Learning Algorithms Architect / Researcher (Santa Clara, CA)",Tachyum,CA,Full-time,"
Level: Experienced, Full Time Employee
 Responsibilities

 Responsible for research and development of very high performance AI/ML algorithms
 Interface with data science, software, and hardware teams
 Analyze algorithmic and architecture options to find the optimal design points
 Work with design teams to create specifications and implementations
 Influence direction with technical proposals, analysis and recommendations
 Work with implementation to achieve your timing, area, performance and power goals
 Identify performance bottlenecks and optimize system performance

 Qualifications

 Member of our core team, responsible for optimizing hardware for AI and ML applications
 Knowledge of machine learning, deep learning and other AI algorithms
 A strong background in computer architecture is highly desirable
 Strong communication and interpersonal skills are required working with our global team
 More than 5 years of experience in high performance Verilog RTL designs
 BS or MS Degree in Electrical Engineering or Computer Science
 Ability to learn new technologies and apply the knowledge quickly
 Ability to meet project milestones and deadlines

 Benefits

 Competitive salary and benefits package.
 Opportunities for professional development and advancement.
 International environment and further career progression.
 Getting in touch with bleeding edge technology.
 Flexible working hours
 Work-life balance.
 Collaborative and supportive work environment.

 If you meet the qualifications and are interested in this opportunity, please submit your resume and cover letter. We look forward to hearing from you!
 Compensation Range
 The base salary range is $130,000 to $280,000. Your salary will be determined based on your experience and specific skillset.
 You will also be eligible for equity and benefits.
 
By sending us your application e-mail, you confirm that you have read, understand and accept the content of the Privacy Notice and consent to the processing of your data as part of this application.
",130000,"['machine learning', 'deep learning']"
Lead Data Scientist - Property & Casualty Insurance Pricing,QBE,WI,Full-time,"


  Primary Details
  Time Type: Full time
  Worker Type: Employee
 

   The Opportunity
 


   This role serves as a modelling and data science partner for assigned business areas responsible for the scientific integrity of work products, including study design, research methodology, and deployment of statistical approaches. You will model with a high degree of creativity and self-direction, mentor team members and share relevant expertise and knowledge of QBE and the data science function.
 


   Primary Responsibilities
 

Build relationship with analytics manager to size analytical opportunities and create delivery plans to ensure a positive commercial return against investments made while managing relationships with offshore analytics team
Develop analytical models to enhance risk segmentation in insurance pricing, thereby driving profitable growth
Assist in the development of commercial propositions involving the use of analytics within insurance core function through own analysis, prior experience, research and development
Work with information management specialist to identify and classify new feature sets, explore machine learning algorithms to extract new feature sets
Provide technical expertise to analytics partners to build and put models into production, quantify and analyze model performance; guide and oversee model refreshing requirements
Facilitate analytical conversations with the business around “the art of the possible using data science”, explore data from a modelling perspective, and perform initial exploratory data analysis to assess business value
Ensure model implementations conform to regulatory requirements and produce clear documentation to support
Positively promote the department, division and company as a whole, in order to maximize brand leverage and develop team profile
Manage analytical projects and coordinate activities with other shared service partners by prioritizing relevant activities and providing subject matter expertise
Undertake personal development to ensure up to date skills and knowledge
Act as a point of reference to guide and advise junior members of the team to ensure sharing of knowledge and best practice

 Required Education
  Bachelor's Degree or equivalent combination of education and work experience
 
   Property & Casualty Insurance experience
  
 Required Experience
   5 years relevant experience
  
 Preferred Competencies/Skills
 

   Strong project management, collaboration and communication skills
 

   Ability to apply logic and reasoning to identify solutions to complex business problems and implement solutions
 

   Business and financial acumen and curiosity to learn and keep up with market trends and innovations
 

   Adapt and be flexible in a complex changing environment
 

   Ability to lead, manage and motivate a team, engage and influence stakeholders at all levels
 

   Use logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems
 

   Identify problems and review related information to develop and evaluate options and implement solutions
 

   Clearly and confidently convey information to a wide audience
 

   Choose a solution to a problem even in ambiguous or difficult situations
 

   Keep an open-mind, consider unique approaches and be open to change and considerable variety in the workplace
 

   Establish a high degree of trust and credibility with others
 


 Preferred Education Specifics
 

   Bachelor's Degree or equivalent combination of education and work experience
 

 Preferred Experience
  

5+ years of relevant experience in property and casualty insurance pricing
 Experience with constructing and implementing pricing GLMs
 

   Experience with state filings for pricing models
 

 Preferred Licenses/Certifications
 

   Certified Specialist in Predictive Analytics (CAS) or other data science related certifications
  
 Preferred Knowledge
 

   Strong knowledge of statistical / data mining methods and application in a business environment
 

   Strong understanding of Data Science domain, statistical and analytical model development and implementations, proficient in machine learning techniques and related disciplines
 

   Advanced understanding of data modelling techniques, tools/language - PySpark, Python, R, Scala, SAS etc.
 

   Advanced knowledge of visualization tools like PowerBI, Tableau etc.
 

   Advanced knowledge of Property & Casualty insurance product and market trends
 


   About QBE
 


   We can never really predict what’s around the corner, but at QBE we’re asking the right questions to enable a more resilient future by helping those around us build strength and embrace change to their advantage.
 

   We’re an international insurer that’s building momentum towards realizing our vision of becoming the most consistent and innovative risk partner.
 

   And our people will be at the center of our success. We’re proud to work together, and encourage each other to enable resilience for our customers, our environment, our economies and our communities.
 

   With more than 12,000 people working across 27 countries, we’re big enough to make a real impact, but small enough to provide a friendly workplace, where people are down-to-earth, passionate, and kind.
 

   We believe this is our moment: What if it was yours too?
 

   Your career at QBE — let’s make it happen!
 


    https://www.linkedin.com/company/qbe-north-america/
  


 US Only - Travel Frequency
   Infrequent (approximately 1-4 trips annually)
  
 US Only - Physical Demands
   General office jobs: Work is generally performed in an office environment in which there is not substantial exposure to adverse environmental conditions. Must have the ability to remain in a stationary position for extended periods of time. Must be able to operate basic office equipment including telephone, headset and computer. Incumbent must be able to lift basic office equipment up to 20 lbs.
  
 US Only - Disclaimer
   To successfully perform this job, the individual must be able to perform each essential job responsibility satisfactorily. Reasonable accommodations may be made to enable an individual with disabilities to perform the essential job responsibilities.
  
 Job Type
   Individual Contributor
  
 Global Disclaimer
   The duties listed in this job description do not limit the assignment of work. They are not to be construed as a complete list of the duties normally to be performed in the position or those occasionally assigned outside an employee’s normal duties. Our Group Code of Ethics and Conduct addresses the responsibilities we all have at QBE to our company, to each other and to our customers, suppliers, communities and governments. It provides clear guidance to help us to make good judgement calls.
 


   Compensation
 

   Base pay offered will vary depending on, but not limited to education, experience, skills, geographic location and business needs
 


   Annual Salary Range: $118,000 - $178,000
 

   AL, AR, AZ, Fresno, CA, CO (Remote), DE (Remote), FL, GA, IA, ID, IL (Remote), IN, KS, KY, LA, MI, MN, MO, MS, MT, NC, ND, NE, NH, NV, OH, OK, OR, PA, SC, SD, TN, TX, UT, VA, VT, WI, WV and WY
 

   * * * * *
 

   Annual Salary Range: $130,000 - $196,000
 

   CA (Remote, Irvine and Woodland), Greenwood Village CO, CT, Chicago IL, MA, MD, NY (Remote), RI, Houston TX and WA
 

   * * * * *
 

   Annual Salary Range: $148,000 - $223,000
 

   San Francisco CA, NJ and New York City NY
 


   Benefit Highlights
 

   You are more than your work – and QBE is more than a workplace, which is why QBE provides you with the benefits, support and flexibility to help you concentrate on living your best life personally and professionally. Employees scheduled over 30 hours a week will have access to comprehensive medical, dental, vision and wellbeing benefits that enable you to take care of your health.
 


   We also offer a competitive 401(k) contribution and a paid-time off program. In addition, our paid-family and care-giver leaves are available to support our employees and their families. Regular full-time and part-time employees will also be eligible for QBE’s annual discretionary bonus plan based on business and individual performance.
 


   QBE recognizes that exemplary benefits extend beyond benefits coverage and compensation. Flexibility in your working environment is important to maintaining balance and QBE is dedicated to ensuring employees achieve personal and professional integration by providing the opportunity for hybrid work arrangements.
 


   #LI-NA
 
 Application Close Date: 13/05/2024 11:59 PM
 

   How to Apply:
 

   To submit your application, click ""Apply"" and follow the step by step process.
 


   Equal Employment Opportunity:
 

   QBE is an equal opportunity employer and is required to comply with equal employment opportunity legislation in each jurisdiction it operates.
 
",118000,"['python', 'machine learning', 'tableau', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,PA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,PA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,PA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Enterprise Data Architect/Scientist,"Prince George's County, MD",MD,Full-time,"


Nature and Variety of Work




Come join our team!


 Prince George’s County is the perfect family-friendly community. Encompassing almost 500 square miles and with over 900,000 residents, Prince George's County has an urban atmosphere that still manages to provide a scenic and peaceful place to live, work, and play.


We are Prince George’s Proud!


 About the Position:
    This is senior-level lead professional and technical software engineering work focused on data infrastructure and analytics technologies and methodologies. The incumbent will lead effort for a data management discipline inclusive of data architecture, data analytics, data science, and policy activities, and design, develop, and implement data models for enterprise and business agencies’ applications and systems.
   
 This individual will act as the primary advocate of data modeling methodologies and data science best practices, working with OIT governance, software engineering, GIS, and WEB technology practice areas, and with agencies for use and security of data assets, compliance with data use standards and agreements. Is lead for determining data tools, platforms, and solutions overseeing and evaluating vendor solutions supporting County data-driven government goals and initiatives. Work is performed under the general supervision of the Associate Director, with the strategic direction of the CIO. Work is evaluated in terms of adherence to County policies and regulations, attainment of goals, and overall contribution to departmental goals and objectives.
  


Examples of Work


What You'll Do:


 Develop data policies, strategies, and architecture with IT leaders, stakeholders, and industry defining the technologies and methodologies to be used in collecting, organizing, modeling, and reporting County information and data.
 Develop the data blueprints, framework, and data management roadmap for the enterprise and business agencies’ practice areas including reporting and compliance standards.
 Determine data reporting, analytics, and integration platforms, solutions, and tools that best fit county strategies and needs supporting data integration, statical analysis, AI, RPA, and program measurement.
 Establish processes for establishing and governing data classification, metadata structure, and context.
 Establish methods and procedures for data quality relevancy and equity.
 Assist in building a culture of data literacy, trust, and transparency, and efforts for data portal development.
 Evaluate and recommend governance, stewardship, and frameworks for managing data across the enterprise.
 Oversee the mapping of data sources, data movement, interfaces, and analytics, with the goal of safeguarding data integrity.
 Participate with agencies in developing methodologies for reports, dashboards, and analytics in their applications/systems/clouds; promote data management methodologies and standards.
 Select and recommend the appropriate tools, software, applications, and systems to support data technology goals.
 Collaborate with IT Project Architects, IT Project Managers, and Business Analysts for all data projects and efforts.
 Document the data architecture and environment to maintain a current and accurate view of the larger data picture.
 Identify and develop opportunities for data reuse, migration, or retirement.




Qualifications


What You'll Need:


 Master's degree in computer science, mathematics, business or public administration, or a closely related field,
 Plus four (4) years of experience in information technology programming, in which at least two (2) years must have involved lead/supervisory duties;
 Or an equivalent combination of education, training, and experience.

 Preferred Qualifications
:

 At least three (3) years of experience working with the following:
 o Structured and unstructured data
    o Common data science toolkits, such as R, NumPy, MatLab, etc.
    o Data visualization tools, such as Power BI, Altyrex, etc.
    o Consuming/exposing data in various ways.
   

 In-depth knowledge of a wide range of established and emerging data technologies
 Proven experience in implementation
 Solid understanding of data architecture and data modeling techniques
 Understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, Decision Forests, etc.
 Experience or working knowledge of AI, such as Salesforce Einstein, Microsoft Virtual Agent, etc.





Additional Information


CONDITIONS OF EMPLOYMENT: Upon selection, the candidate must:

 Must be willing to participate as an essential employee, when needed during emergency operations.
 Must possess and maintain a valid driver's license.

 DURATION OF ELIGIBILITY
: Candidates will be selected from a temporary register of eligible candidates, which will become effective approximately four (4) weeks after the closing date. Once a selection has been made, the register will expire.


ELIGIBILITY TO WORK:
 Under the Immigration Reform and Control Act of 1986, an employer is required to hire only U.S. citizens and lawfully authorized alien workers. Applicants who are selected for employment will be required to show and verify authorization to work in the United States.

 This employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S., only after an offer has been accepted and the Form I-9 is completed. For information on E-Verify, or if you believe the County has violated its E-Verify responsibilities, please contact the Department of Homeland Security (DHS) at 888-897-7781 or visit their website at dhs.gov/e-verify.
   

Internal Applicants:
 If you are a current Prince George's County Government employee and seeking a promotion, in accordance with Section 16-200 of the Personnel Law, you have the right to appeal a rejection rating within five (5) working days of receiving a rejection notice. Union employees should refer to their respective collective bargaining agreement and/or union representative for their grievance procedure.


 ONLY ONLINE APPLICATIONS WILL BE ACCEPTED


Prince George's County Government is an Equal Opportunity/Affirmative Action Employer Committed to Diversity in the Workplace




",119615,"['numpy', 'machine learning']"
Data Scientist - Generative AI,Cognizant Technology Solutions,NC,Full-time,"
We are Cognizant Artificial Intelligence
 Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. However, clients need new business models built from analyzing customers and business operations at every angle to really understand them.
 With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks.

 *You must be legally authorized to work in United States without the need of employer sponsorship, now or at any time in the future*

 Job Title: Data Scientist – Generative AI
 Roles & Responsibilities. Data Scientist – Generative AI Design and develop applications using Dash/Plotly tools Provide support to troubleshoot environmental and application issues for the existing Dash apps Experience in developing MLOPS process/pipelines and in ML Model deployment. Productionalize Machine learning models and monitor model performance by developing custom scripts Experience in python Data Science and ML eco system (Pandas Numpy scikit Learn Pyspark ) and proficient in SQL Tech stack: Python SQL Databricks AWS Redshift MLOPS AWS Git CI/CD Dash/Plotly .Experience 12 to15 yrs. Required Skills Technical Skills- Data Science Domain Skills- Nice to have skills Techincal Skills- Generative AI Domain Skills- Technology Analytics.

 Salary and Other Compensation:
 The annual salary for this position is $140,000.00 - $160,000.00 depending on experience and other qualifications of the successful candidate.
 This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.


 Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:

Medical/Dental/Vision/Life Insurance
Paid holidays plus Paid Time Off
401(k) plan and contributions
Long-term/Short-term Disability
Paid Parental Leave
Employee Stock Purchase Plan

Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.

 #LI-AR1 #Ind123

 Employee Status : Full Time Employee
 Shift : Day Job
 Travel : No
 Job Posting : Nov 07 2023


 About Cognizant
 Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.
 
 Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.

 Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.
 If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.

",140000,"['python', 'numpy', 'pandas', 'machine learning', 'aws', 'sql', 'git', 'pyspark']"
Senior/Lead Data Scientist - Machine Learning,Salesforce,CA,Full-time,"
To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts. 

Job Category Data 
 
Job Details 

About Salesforce 
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place. 

Each team is made up of data scientists, engineers, growth analysts, and information management experts who are dedicated to driving product strategy with data-driven insights. Teams with executives, product managers, designers, developers, user researchers, marketers, and sales strategy team members across all Cloud businesses to discover new opportunities for growth and optimization, experiment with data, drive adoption, and deliver useful insights that impact product strategy.   Your Impact:   As a Data Scientist, you will be partnering with the Product, Infrastructure, and Engineering teams embedded in the Cloud businesses, as well as functional leaders who provide data and analytical infrastructure, identify and execute initiatives that benefit the whole Di and multiple Cloud businesses. The successful candidate will need to: 

Partner with Senior Leadership (VP+) to understand their business and advise on strategic objectives, product direction, roadmaps, growth goals and retention strategies; as a Senior Analyst/ Data Scientist you will develop and own the relationships with senior stakeholders 
Produce insights (e.g. performance drivers, retention analysis, behavioral personas) to accelerate business growth; this requires acquiring and cleaning data from multiple sources, structuring and building data models, analyzing to generate insights, and distributing them 
Partner with the data engineering team and product engineering team to instrument, acquire, develop and structure data assets that are critical to measuring the success of our products 
Own the delivery by working with data engineers and business intelligence engineers to turn insights into data products (e.g. data pipelines, algorithms, self-service dashboards) 
Research, develop and implement automated algorithm deployment pipelines and processes 
Evangelize and distribute data products that drive action or product improvement 
Contribute to expanding the Salesforce data culture by growing new relationships, hosting learning sessions, integrating or designing new tools, and autonomously improving team processes 


Responsibilities 

You will be part of a team of deep learning experts working to design, train, optimize, and deploy neural networks for enterprise business applications used by millions of customers. 
Participate in the complete neural network life cycle: influence the design of new business applications, prepare datasets, develop+train NNs, optimize inference latency, work with peer product engineering teams to integrate and validate new NNs. 
Develop and maintain necessary supporting tools for: quantization & latency optimization, metrics & evaluation, visualization, and dashboards to aid in the development of NNs. 
Stay abreast of advances in machine learning, particularly in the areas of LLMs & their training, LLM inference optimization, NN quantization / distillation / pruning, and autonomous AI agents. 


Qualifications 

Strong experience with Python and software engineering best practices. 
An “under the hood” knowledge of deep learning: layer details, loss functions, optimizers, lora, etc. 
Fluency with common neural network architectures and related concepts for language, speed, computer vision, etc. 
Experience with PyTorch, or another major deep learning framework such as Jax or Tensorflow. 
Comfortable working in a Linux cluster environment. 
(bonus) Experience quantizing and optimizing the inference latency of neural networks (quantization, distillation, pruning, system-level optimizations). 


Benefits & Perks   Check out our benefits site which explains our various benefits, including wellbeing reimbursement, generous parental leave, adoption assistance, fertility benefits, and more.   Salesforce Information   Check out our Salesforce Engineering Site .   *IN SCHOOL OR GRADUATED WITHIN THE LAST 12 MONTHS? PLEASE VISIT FUTURE FORCE FOR OPPORTUNITIES *  

Accommodations 
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form . 

Posting Statement 
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com . 

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce . ﻿

Salesforce welcomes all. 

For California-based roles, the base salary hiring range for this position is $133,800 to $183,900. Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.
",133800,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
SiteOps Data Center Operations Engineer,Meta,OR,Full-time,"
 Meta is seeking an entry level engineer to apply their technical skills in a fast-paced and complex environment. Having a working knowledge of server hardware and the desire to participate in projects at a large-scale data center is central to this role. This position will work to resolve and diagnose server issues at scale, escalate issues and work with remote engineering teams. Additionally, this role will work within the rack lifecycle processes with a focus on helping build out and enable cloud scale compute and storage environments. Solid communication skills are a requirement for this role. This person should enjoy working in a fast-paced environment where adaptability and flexibility will be key to their success. The successful candidate will be able to work independently and also within groups.The candidate should also have a working knowledge and experience in at least one of the following core areas: Networking, Programming/Scripting, Hardware and OS repair.
 


SiteOps Data Center Operations Engineer Responsibilities:  

Work within Meta's ticketing system in support of the health of Meta's server fleet
 First point of contact for break fix technicians
 Accountable for assisting with projects (new capacity as well as retrofits) and repairs throughout the data center
 Understand and initial analysis to debug hardware, and Linux OS related issues
 Demonstrate personal leadership Identifying and helping to create documentation for the global data center knowledge base
 Assist with process improvements and best practices in data center operations
 Participate in on-call rotation (once a month on call for a week after hours, first point of contact)




Minimum Qualifications: 

 Bachelor's of Science degree or commensurate experience
 Knowledge of Linux and server hardware repairs
 Working conceptual knowledge of developing in Python, SQL, and/or shell scripting
 Working conceptual knowledge of technologies such as HTTP, DNS, RAID, and DHCP






About Meta:  Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.
 



  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. 
  
 Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
 
",66997,"['python', 'machine learning', 'sql']"
Data Modeler,Booz Allen Hamilton,MD,Full-time,"


Job Description










         Location: 
        

         Silver Spring,MD,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184205
        


















         Data Modeler
          The Opportunity:
 Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there’s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need an experienced data engineer like you to help our clients find answers in their big data to impact important missions—from fraud detection to cancer research to national intelligence.

 As a data modeler on our team, you’ll use your extensive technical expertise to lead the design of data architecture solutions for a system or systems architecture. You’ll resolve routine data architecture issues in collaboration with business analysts and technology teams by working with a cross-functional team to make decisions and recommendations on architecture modernization activities. In this role, you’ll your technical expertise, introduce best practices, and use tools like ERWin and MySQL Workbench. You’ll lead your team as it designs, defines, develops, and tests Cloud solution components, and you’ll serve as a liaison between clients and developers to ensure that requirements are met, and solutions are delivered.

 Work with us to use big data for good. 

Join us. The world can’t wait.

 You Have:

 3+ years of experience with data modeling, data architecture, and data analysis
 Experience with creating data models in tools, including Erwin, Embarcadero ER Studio, or Enterprise Architect
 Experience with creating conceptual, logical, and physical data models
 Experience with defining and implementing naming standards, abbreviations, guidelines, and best practices
 Knowledge of relational and dimensional models, keys and constraints, and normalization and indexes
 Ability to document source to target mappings, data dictionaries, and general modeling documentation
 Ability to obtain a security clearance
 Bachelor's degree


 Nice If You Have:

 Experience with working in diverse Agile team environments
 Experience with data querying, data mapping, and transformation analysis
 Experience with using tools, including SQL or Toad for data querying and analysis


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:
 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. 

Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['machine learning', 'mysql', 'sql']"
Applied AI/ML Data Engineer,Intuitive Surgical,CA,Full-time,"
Company Description At Intuitive, we are united behind our mission: we believe that minimally invasive care is life-enhancing care. Through ingenuity and intelligent technology, we expand the potential of physicians to heal without constraints.
 
 As a pioneer and market leader in robotic-assisted surgery, we strive to foster an inclusive and diverse team, committed to making a difference. For more than 25 years, we have worked with hospitals and care teams around the world to help solve some of healthcare's hardest challenges and advance what is possible.
 
 Intuitive has been built by the efforts of great people from diverse backgrounds. We believe great ideas can come from anywhere. We strive to foster an inclusive culture built around diversity of thought and mutual respect. We lead with inclusion and empower our team members to do their best work as their most authentic selves.
 
 Passionate people who want to make a difference drive our culture. Our team members are grounded in integrity, have a strong capacity to learn, the energy to get things done, and bring diverse, real world experiences to help us think in new ways. We actively invest in our team members to support their long-term growth so they can continue to advance our mission and achieve their highest potential.
 
 Join a team committed to taking big leaps forward for a global community of healthcare professionals and their patients. Together, let's advance the world of minimally invasive care.
  Job Description
 Primary Function:
 The Applied AI/ML Engineer plays a critical role in bringing Generative AI and Machine Learning (ML) solutions to Enterprise Analytics. These technologies offer transformative potential to optimize operations, generate valuable insights, and drive innovation, thus shaping our organization's future.
 The AI/ML Engineer will play a pivotal role in identifying, testing, and implementing scalable and cost-effective AI and ML solutions across the teams supported by Enterprise Analytics. Through maintaining, troubleshooting, and optimizing AI models, as well as developing business applications on top of them, this role will be instrumental in enhancing our organization's analytical capabilities. The role will work directly with business stakeholders, IT partners, enterprise data architects, data engineering, and external service providers to ensure that new capabilities meet the needs of the business and can support its growth.
 Roles and Responsibilities:

 Develop and maintain the infrastructure for incorporating and fine-tuning third-party AI NLP and/or Computer Vision models into the company's technology stack.
 Troubleshoot any integration issues and ensuring the seamless operation of the integrated models.
 Collaborate with stakeholders to understand the functional needs and fine-tune and/or train AI models to improve their performance on specific tasks.
 Build end-to-end ML Ops pipelines, including AI applications. Maintain, troubleshoot, and optimize ML and AI models in production environment, monitor models’ performance.
 Build business applications on top of AI models, work with a team of engineers to develop and deploy ML solutions.

 Qualifications

 Minimum Bachelor's degree or Master's degree in Computer Science, Data Science, or a related field
 A minimum 6+ years of experience in machine learning, with a strong understanding of the latest ML research and technologies
 Strong knowledge and experience with LLMs/Generative AI models
 Strong programming skills in Python (3+ years), SQL
 Experience with a variety of ML frameworks and libraries, such as PyTorch, TensorFlow, and scikit-learn
 Familiarity with open-source LLM/CV models and platforms, such as Hugging Face, LangChain, etc
 Proficiency with cloud platforms such as Microsoft Azure, Google Cloud or AWS
 Familiarity with a cloud-based data warehousing platform such as Snowflake and data analytics platforms such as Databricks
 Strong problem-solving skills
 Strong communication skills

 #LI-Hybrid
 Additional Information

 Due to the nature of our business and the role, please note that Intuitive and/or your customer(s) may require that you show current proof of vaccination against certain diseases including COVID-19. Details can vary by role.
 Intuitive is an Equal Employment Opportunity Employer. We provide equal employment opportunities to all qualified applicants and employees, and prohibit discrimination and harassment of any type, without regard to race, sex, pregnancy, sexual orientation, gender identity, national origin, color, age, religion, protected veteran or disability status, genetic information or any other status protected under federal, state, or local applicable laws.
 We will consider for employment qualified applicants with arrest and conviction records in accordance with fair chance laws.
 Preference will be given to qualified candidates who do not reside, or plan to reside, in Alabama, Arkansas, Delaware, Florida, Indiana, Iowa, Louisiana, Maryland, Mississippi, Missouri, Oklahoma, Pennsylvania, South Carolina, or Tennessee.
 We provide market-competitive compensation packages, inclusive of base pay, incentives, benefits, and equity. It would not be typical for someone to be hired at the top end of range for the role, as actual pay will be determined based on several factors, including experience, skills, and qualifications. The target salary ranges are listed.
 Base Salary Range Region 1:$167,000 - $240,200 Base Salary Range Region 2: $141,900 - $204,300 Shift: Day Travel: None Workplace Type: Purposeful Onsite - This job requires being onsite for leader-defined events and activities which could be monthly/annually. Onsite frequency may increase based on business need.
",141900,"['tensorflow', 'pytorch', 'python', 'machine learning', 'aws', 'azure', 'sql']"
Lead Data Scientist,McKesson,TX,Full-time,"
 McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve - we care. What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow's health today, we want to hear from you.
 

Position Description
:

 McKesson Technology Enterprise Analytics is seeking a Lead Data Scientist that is passionate about developing machine learning applications that ensure patients receive the medications they need, when they need them; improve quality of care for oncology patients; and exemplify operational excellence so that the business can focus on what matters most, creating value for our customers.
 

Key responsibilities: 


Develop, design, build, and oversee data science solutions to provide predictive insights that further McKesson's vision to improve care in every setting.
 Drive adoption of best-in-class capabilities, including Deep Learning, Natural Language Processing, Large Language Models and Next Best Action Recommenders.
 Direct in-house data scientists and consulting teams; Provide analytics leadership; Provide machine learning and statistical expertise. Serve as an advisor for data scientists across the Enterprise.
 Collaborate with multi-disciplinary team members (data scientists, data engineers and business analysts); Manage business stakeholder relationships to drive action and value from data science insights.
 Collaborate with multi-disciplinary team members; Manage business stakeholder relationships to drive action and value from data science insights;
 Recruit top talent data scientists to join our team.
 Communicate strategy and results to technical and non-technical audiences; Develop and maintain strong relationships with key stakeholders, partners, and internal clients.
 Solve problems from the business point of view, define KPIs, build and execute solid analytics work plans, gather and organize large and complex data assets, perform relevant analyses (data exploration and statistical modeling), automate work streams, foster teamwork in interactions, develop client relationships with business stakeholders, and communicate hypotheses and findings in a structured way.


 Minimum Requirements
:


 Master's degree +6 years of work experience or PhD +3 years, with relevant experience providing advanced analytics solutions The degree should be in computer science, applied mathematics, statistics, machine learning, or a related data centric-technical field.


 Critical Skills
:


 Mentorship experience with machine learning engineers/data scientists in business or scientific research settings.
 Industry experience using TensorFlow, Pytorch and open source software libraries to develop Representation Machine Learning Systems; e.g. Next-Best-Action, Recommendation systems; Deep Learning Neural Networks; Image understanding; Document classification and keyword extraction.
 Experience in core data science and predictive analytics methods: Statistics (t-tests, Poisson process), Segmentation and clustering techniques, predictive modeling: e.g. regression, classification, Time Series analysis: e.g. ARIMA, Traditional machine learning methods: e.g. Random Forest, ensemble model techniques, Optimization: e.g. linear programming.
 Experience in SQL, relational databases: e.g. Snowflake, HANA, Microsoft SQL.
 Expert level skill in a programming language: Python + additional languages (e.g. Java, C/C++).
 Experience with Linux, Shell scripting: e.g. Bash.
 Familiarity with a data visualization tool: e.g. Tableau, Power BI, R.
 Ability to process and synthesize complex data.
 Ability to communicate effectively and professionally, delivering impactful solutions and presenting work in a concise and thoughtful manner.


 Desired Skills
:


 Experience with cloud computing data platforms: e.g. Azure, GCP.
 Experience with distributed computing: e.g. Hadoop, Spark.
 Experience developing open-source machine learning libraries.
 Desire to work in a project-based environment to address business .issues and implement business solutions..
 Driven by making impact with technical and data science expertise, acute strategic and analytical skills; Highly organized with the ability to multitask and prioritize workload.
 Self-motivated, demonstrated ability to manage engagements, serve as a champion of Data Science and able to act as a full member of project team.
 Experience in applied analytics for business problem solving, demand forecasting, analytics solution for pricing, loyalty program effectiveness, customer segmentation, customer LTV maximization, cost and profit analysis, CRM management etc.

 At McKesson, we care about the well-being of the patients and communities we serve, and that starts with caring for our people. That's why we have a Total Rewards package that includes comprehensive benefits to support physical, mental, and financial well-being. Our Total Rewards offerings serve the different needs of our diverse employee population and ensure they are the healthiest versions of themselves. For more information regarding benefits at McKesson, please click here.
 
 As part of Total Rewards, we are proud to offer a competitive compensation package at McKesson. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered.
 

Our Base Pay Range for this position

 $147,500 - $245,800
 

McKesson is an Equal Opportunity/Affirmative Action employer. 

 All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.Qualified applicants will not be disqualified from consideration for employment based upon criminal history.
 
 McKesson is committed to being an Equal Employment Opportunity Employer and offers opportunities to all job seekers including job seekers with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to Disability_Accommodation@McKesson.com. Resumes or CVs submitted to this email box will not be accepted.
 
 Current employees must apply through the internal career site.
 

Join us at McKesson!
",147500,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'tableau', 'azure', 'gcp', 'sql', 'hadoop']"
"Manager, Drug Discovery AI",NVIDIA,CA,Full-time,"

  NVIDIA is using the power of high performance computing and AI to accelerate digital biology. We are seeking passionate and hardworking individuals to help us realize our mission. As a Manager, you will lead a team focused on deep learning development for cheminformatics, virtual screening, and protein modeling. This position provides the opportunity to develop, productize, and deliver drug discovery AI technologies across Nvidia's BioNeMo platform.
 


   What You’ll Be Doing:
 



     Define the roadmap for the future internal and public releases of the BioNeMo projects: define deliveries and work packages, help synchronize the dependencies across the other teams, formulate benchmarks and key performance indicators.
   


     Drive the technical choices to build the new features of the drug discovery AI technology stack: leverage existing deep learning technologies, provide feedback on performance and compute requirements, design new integrated deep learning models adapted to the problems of drug discovery.
   


     Mentor and supervise a team of experts in deep learning applications in small molecule generation, protein sequence and structure models
   


     Collaborate with multiple other teams, including Drug Discovery AI teams, AI infrastructure teams, product management, and Nvidia Research.
   


     Help bring up end-to-end drug discovery AI solutions based on the Nvidia BioNeMo platform.
   



   What We Need To See:
 



     Excellent interpersonal and 5+ years of leadership experience.
   


     PhD in Computer Science, Computational Chemistry, Computational Biology, or relevant field for Drug Discovery AI, or equivalent experience
   


     10+ overall years of relevant industry experience
   


     Participated in designing and implementing modern deep learning algorithms in cheminformatics, virtual screening, and/or protein design
   


     Excellent communication, analysis and problem solving skills
   



   Ways To Stand Out From The Crowd:
 



     Have significant deep learning experience, especially with LLMs, graph-based and geometric deep learning for drug discovery use cases.
   


     Have published in major journals or conferences in a field relevant to deep learning and drug discovery.
   



   With competitive salaries and a generous benefits package, we are widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us and, due to unprecedented growth, our exclusive engineering teams are rapidly growing. If you're a creative and autonomous engineer with a real passion for technology, we want to hear from you.
 
 The base salary range is 216,000 USD - 414,000 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
 







          You will also be eligible for equity and 
         
          benefits
         . 
         NVIDIA accepts applications on an ongoing basis.








 NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

",216000,['deep learning']
AI Engineer,Thunkable,NY,Full-time,"

  Role Overview
 


 Thunkable is on the lookout for a highly skilled software engineer with a passion for machine learning and a special focus on deep learning and generative AI. Our ideal candidate will be adept in working with Large Language Models (LLMs), and possess a strong foundation in programming languages such as Python and JavaScript/TypeScript. Experience with technologies like Langchain, Autogen, AutoGPT, and tools for code generation and completion will be highly valued.
 


 What you'll do
 


 Participate in the design, development, and integration of cutting-edge machine learning techniques within the Thunkable platform, in partnership with product management, full-stack engineering, and design teams.
Establish use cases and devise evaluation methods & benchmarks for various approaches to support and enhance Thunkable’s products and user experiences.
Actively monitor and refine the performance and efficiency of live ML systems.
Keep abreast of the latest trends and breakthroughs in machine learning, NLP, and adjacent domains to maintain our edge in innovation.
Mentor team members, fostering AI literacy and thought leadership within the company.
Research developments in LLMs and generative AI to identify opportunities for leveraging them to boost Thunkable’s capabilities.



 What you'll need
 


 A minimum of 5 years of experience as a Software Engineer or equivalent research experience.
Strong grasp of core web technologies.
Proven ability to dissect and resolve complex software development issues across diverse components.
Excellent problem-solving acumen with the capability to articulate intricate ideas to both technical and non-technical audiences.
A history, if brief, of working with large language models and generative AI and associated techniques such as RAG, prompt management or fine tuning.
A strong advocate for ethical AI, prioritizing transparency and user-centric approaches
Advanced degree (Master’s or Ph.D.) in Computer Science, Engineering, Statistics, Mathematics, or a related field, or industry experience to match.
Proficiency in SQL, familiarity with large datasets, and experience with cloud platforms like AWS or GCP.



 Bonus Points
 

Deep understanding of deep learning, reinforcement learning, and NLP.
Experience in handling and analyzing large datasets with statistical and machine learning techniques.
Knowledge in the design of experiments, survey design, and large-scale AB testing.
Technical knowledge in Deep Learning, particularly in Generative AI (e.g., GANs, GPT models).Familiarity with Multi-modal ML, Graph ML, and/or Reinforcement Learning.
Contributions to technical articles and presentations at Engineering/ML conferences are advantageous.
Experience developing and training models in PyTorch is ideal.



 Life at Thunkable
 


 Thunkable is on a mission to democratize app development and empower everyone to build without writing a single line of code. Our platform enables anyone to build and publish their iOS and Android apps for free. Today, non-engineers use Thunkable to prototype and share new ideas, develop proofs-of-concept for their own digital business, and design and ship their own ad-supported and premium apps. Thunkable was incubated at Google Research and MIT.
 


 We are backed by Lightspeed, NEA, Owl Ventures, SV Angel, Zhenfund, and Y-Combinator. Our founders are MIT engineers who want to extend the power and fun of creation to people who don’t code.
 

   Joining Thunkable means joining a team of passionate, entrepreneurial and friendly people with different backgrounds, shared ideas, and similar goals.
 


 What will you get when joining our team?
 


 Get compensated: We offer competitive pay, equity and benefits to our employees based on their location. You’ll get access to unlimited PTO regardless of your location.
Wellness and Training Budget: We value your well-being and want to invest in it.
Work Where You Want: The company is based in San Francisco (with an office), but operates globally, with team members working across a number of cities, countries, and time zones (to facilitate async work we prioritize countries and locations in a max 2h time zone difference from those hubs: San Francisco, New York and Dublin)
Shared values: Creativity, Openness, Transparency, Persistence, and Entrepreneurialism.
Challenge yourself by acquiring new abilities, interacting with clients, enhancing products, or learning design. We will encourage you to reach your full potential.



 We believe that a diverse and inclusive workplace helps ensure we learn from each other’s different backgrounds, experiences, and perspectives and is critical for building a product that supports the wide range of our users’ needs. Thunkable is an equal opportunity employer and a pleasant and supportive place to work. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply.



 This position offers a competitive salary that is based on a combination of factors including location. The salary range for this role in San Francisco is between $160,000 and $190,000 per year and will be based on qualifications and skills. If the successful candidate is located in a different location or country, the salary may vary based on the cost of living, currency and other local factors. We are open to discussing salary with candidates who are interested in the role and may be willing to negotiate based on the candidate's experience and qualifications. We are committed to paying our employees fairly and providing opportunities for professional growth and development.

",160000,"['pytorch', 'python', 'machine learning', 'deep learning', 'aws', 'gcp', 'sql']"
"GenAI Machine Learning Engineer, Performance Optimization",Databricks,CA,Full-time,"
P-984
 Founded in late 2020 by a small group of machine learning engineers and researchers, MosaicML enables companies to securely fine-tune, train and deploy custom AI models on their own data, for maximum security and control. Compatible with all major cloud providers, the MosaicML platform provides maximum flexibility for AI development. Introduced in 2023, MosaicML’s pretrained transformer models have established a new standard for open source, commercially usable LLMs and have been downloaded over 3 million times. MosaicML is committed to the belief that a company’s AI models are just as valuable as any other core IP, and that high-quality AI models should be available to all.
 Now part of Databricks since July 2023, we are passionate about enabling our customers to solve the world's toughest problems — from making the next mode of transportation a reality to accelerating the development of medical breakthroughs. We do this by building and running the world's best data and AI platform so our customers can use deep data insights to improve their business. We leap at every opportunity to solve technical challenges, striving to empower our customers with the best data and AI capabilities.
 You will:

Explore and analyze performance bottlenecks in ML training and inference
Design, implement and benchmark libraries and methods to overcome aforementioned bottlenecks
Build tools for performance profiling, analysis, and estimation for ML training and inference
Balance the tradeoff between performance and usability for our customers
Facilitate our community through documentation, talks, tutorials, and collaborations
Collaborate with external researchers and leading AI companies on various efficiency methods

We look for:

Hands on experience the internals of deep learning frameworks (e.g. PyTorch, TensorFlow) and deep learning models
Experience with high-performance linear algebra libraries such as cuDNN, CUTLASS, Eigen, MKL, etc.
General experience with the training and deployment of ML models
Experience with compiler technologies relevant to machine learning
Experience with distributed systems development or distributed ML workloads
Hands on experience with writing CUDA code and knowledge of GPU internals (Preferred)
Publications in top tier ML or System Conferences such as MLSys, ICML, ICLR, KDD, NeurIPS (Preferred)

We value candidates who are curious about all parts of the company's success and are willing to learn new technologies along the way.



 Pay Range Transparency

      Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.
    



     Local Pay Range
   

     $150,000—$190,000 USD
   



 About Databricks
 Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
 Our Commitment to Diversity and Inclusion
 At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance

    If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.
  

",150000,"['tensorflow', 'pytorch', 'machine learning', 'deep learning', 'apache spark']"
Data Scientist,KBR,MD,Full-time,"
Title: Data Scientist
 
 KBR is looking to add a Data Scientist with Natural Language Processing (NLP) & BI tools experience to our team. Due to contract requirements, candidates must be US Citizens and hold an active/current D.O.D Secret clearance. 

In this role, you will...

 Discover NLP approaches to deliver insights and develop predictive models to meet customer needs.
 Utilize standard data science approaches such as data ingest, ETL, preprocessing, model building, model deploying, and monitoring models once deployed.
 Demonstrate experience working with raw data by processing and ingesting it into a database, cleaning it to be fed into a model, deploying it for some application, and explaining findings clearly to a general audience.
 Troubleshoot problems with data ingesting and processing
 Contribute to research and identification of the most accurate model architecture for current problems.
 Collaborate in data science meetings by presenting on theoretical or applied data science topics.
 Demonstrate the ability to troubleshoot in cloud environments such as AWS, Azure, and Google Cloud.
 Familiarity with machine learning platforms, such as CDSW
 Develop visualizations to convey meaningful insights.
 Present insights from models to a non-technical crowd to convey findings
 Suggest meaningful approaches, models, and services to address problems.
 Stay informed about trends and recent capabilities within data science.


 Required Education, Skills, & Experience
 Education: A bachelor's degree in data science, statistics, computer science, or a related quantitative field.
 Clearance: Active/Current D.O.D Secret Clearance
 Experience: 2 years of relevant work experience

 Proficient in Python; other equivalent languages are considered.
 Experience with BI tools such as QlikSense, Tableau, PowerBI, Zoomdata, etc.
 Experience in NLP approaches, machine learning techniques, and neural networks
 Competent in using SQL and other relational database query languages


 Highly Desired Education, Skills, & Experience
 Education: Masters in data science, statistics, computer science, or a related quantitative field.
 Experience/Skills:

 Excellent communication skills
 Exposure to one more neural network framework – Tensorflow, Torch/ PyTorch, ONNX, etc
 Previously worked with distributed computing environments such as Hadoop.


 Contract Requirements Regarding Education And Experience Will Prevail.
 Salary range: $86K-$110K  When you become part of the KBR team, your career opportunities are endless. Our people are the heart of everything we do here at KBR. We Value our People!  KBR offers a selection of competitive lifestyle benefits, which could include a 401K plan with company match, medical, dental, vision, life insurance, AD&D, flexible spending account, disability, paid time off, or flexible work schedule. We support career advancement through professional training and development.  At KBR, we are passionate about our people, sustainability, and Zero Harm culture. These ideals form all that we do and are at the heart of our commitment to, and ongoing journey toward, being a more inclusive and diverse company. That commitment is central to our team of team’s philosophy and fosters an environment of real collaboration across cultures and locations. Our individual differences and perspectives enhance our teams' value and help us develop solutions for the most challenging problems. We understand that embracing those differences and working together makes us more innovative, resilient, and safer. We Deliver — Together.

 KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.

",86000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'tableau', 'aws', 'azure', 'etl', 'sql', 'hadoop']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
AI Engineer,Thunkable,NY,Full-time,"

  Role Overview
 


 Thunkable is on the lookout for a highly skilled software engineer with a passion for machine learning and a special focus on deep learning and generative AI. Our ideal candidate will be adept in working with Large Language Models (LLMs), and possess a strong foundation in programming languages such as Python and JavaScript/TypeScript. Experience with technologies like Langchain, Autogen, AutoGPT, and tools for code generation and completion will be highly valued.
 


 What you'll do
 


 Participate in the design, development, and integration of cutting-edge machine learning techniques within the Thunkable platform, in partnership with product management, full-stack engineering, and design teams.
Establish use cases and devise evaluation methods & benchmarks for various approaches to support and enhance Thunkable’s products and user experiences.
Actively monitor and refine the performance and efficiency of live ML systems.
Keep abreast of the latest trends and breakthroughs in machine learning, NLP, and adjacent domains to maintain our edge in innovation.
Mentor team members, fostering AI literacy and thought leadership within the company.
Research developments in LLMs and generative AI to identify opportunities for leveraging them to boost Thunkable’s capabilities.



 What you'll need
 


 A minimum of 5 years of experience as a Software Engineer or equivalent research experience.
Strong grasp of core web technologies.
Proven ability to dissect and resolve complex software development issues across diverse components.
Excellent problem-solving acumen with the capability to articulate intricate ideas to both technical and non-technical audiences.
A history, if brief, of working with large language models and generative AI and associated techniques such as RAG, prompt management or fine tuning.
A strong advocate for ethical AI, prioritizing transparency and user-centric approaches
Advanced degree (Master’s or Ph.D.) in Computer Science, Engineering, Statistics, Mathematics, or a related field, or industry experience to match.
Proficiency in SQL, familiarity with large datasets, and experience with cloud platforms like AWS or GCP.



 Bonus Points
 

Deep understanding of deep learning, reinforcement learning, and NLP.
Experience in handling and analyzing large datasets with statistical and machine learning techniques.
Knowledge in the design of experiments, survey design, and large-scale AB testing.
Technical knowledge in Deep Learning, particularly in Generative AI (e.g., GANs, GPT models).Familiarity with Multi-modal ML, Graph ML, and/or Reinforcement Learning.
Contributions to technical articles and presentations at Engineering/ML conferences are advantageous.
Experience developing and training models in PyTorch is ideal.



 Life at Thunkable
 


 Thunkable is on a mission to democratize app development and empower everyone to build without writing a single line of code. Our platform enables anyone to build and publish their iOS and Android apps for free. Today, non-engineers use Thunkable to prototype and share new ideas, develop proofs-of-concept for their own digital business, and design and ship their own ad-supported and premium apps. Thunkable was incubated at Google Research and MIT.
 


 We are backed by Lightspeed, NEA, Owl Ventures, SV Angel, Zhenfund, and Y-Combinator. Our founders are MIT engineers who want to extend the power and fun of creation to people who don’t code.
 

   Joining Thunkable means joining a team of passionate, entrepreneurial and friendly people with different backgrounds, shared ideas, and similar goals.
 


 What will you get when joining our team?
 


 Get compensated: We offer competitive pay, equity and benefits to our employees based on their location. You’ll get access to unlimited PTO regardless of your location.
Wellness and Training Budget: We value your well-being and want to invest in it.
Work Where You Want: The company is based in San Francisco (with an office), but operates globally, with team members working across a number of cities, countries, and time zones (to facilitate async work we prioritize countries and locations in a max 2h time zone difference from those hubs: San Francisco, New York and Dublin)
Shared values: Creativity, Openness, Transparency, Persistence, and Entrepreneurialism.
Challenge yourself by acquiring new abilities, interacting with clients, enhancing products, or learning design. We will encourage you to reach your full potential.



 We believe that a diverse and inclusive workplace helps ensure we learn from each other’s different backgrounds, experiences, and perspectives and is critical for building a product that supports the wide range of our users’ needs. Thunkable is an equal opportunity employer and a pleasant and supportive place to work. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply.



 This position offers a competitive salary that is based on a combination of factors including location. The salary range for this role in San Francisco is between $160,000 and $190,000 per year and will be based on qualifications and skills. If the successful candidate is located in a different location or country, the salary may vary based on the cost of living, currency and other local factors. We are open to discussing salary with candidates who are interested in the role and may be willing to negotiate based on the candidate's experience and qualifications. We are committed to paying our employees fairly and providing opportunities for professional growth and development.

",160000,"['pytorch', 'python', 'machine learning', 'deep learning', 'aws', 'gcp', 'sql']"
Data Scientist,KBR,MD,Full-time,"
Title: Data Scientist
 
 KBR is looking to add a Data Scientist with Natural Language Processing (NLP) & BI tools experience to our team. Due to contract requirements, candidates must be US Citizens and hold an active/current D.O.D Secret clearance. 

In this role, you will...

 Discover NLP approaches to deliver insights and develop predictive models to meet customer needs.
 Utilize standard data science approaches such as data ingest, ETL, preprocessing, model building, model deploying, and monitoring models once deployed.
 Demonstrate experience working with raw data by processing and ingesting it into a database, cleaning it to be fed into a model, deploying it for some application, and explaining findings clearly to a general audience.
 Troubleshoot problems with data ingesting and processing
 Contribute to research and identification of the most accurate model architecture for current problems.
 Collaborate in data science meetings by presenting on theoretical or applied data science topics.
 Demonstrate the ability to troubleshoot in cloud environments such as AWS, Azure, and Google Cloud.
 Familiarity with machine learning platforms, such as CDSW
 Develop visualizations to convey meaningful insights.
 Present insights from models to a non-technical crowd to convey findings
 Suggest meaningful approaches, models, and services to address problems.
 Stay informed about trends and recent capabilities within data science.


 Required Education, Skills, & Experience
 Education: A bachelor's degree in data science, statistics, computer science, or a related quantitative field.
 Clearance: Active/Current D.O.D Secret Clearance
 Experience: 2 years of relevant work experience

 Proficient in Python; other equivalent languages are considered.
 Experience with BI tools such as QlikSense, Tableau, PowerBI, Zoomdata, etc.
 Experience in NLP approaches, machine learning techniques, and neural networks
 Competent in using SQL and other relational database query languages


 Highly Desired Education, Skills, & Experience
 Education: Masters in data science, statistics, computer science, or a related quantitative field.
 Experience/Skills:

 Excellent communication skills
 Exposure to one more neural network framework – Tensorflow, Torch/ PyTorch, ONNX, etc
 Previously worked with distributed computing environments such as Hadoop.


 Contract Requirements Regarding Education And Experience Will Prevail.
 Salary range: $86K-$110K  When you become part of the KBR team, your career opportunities are endless. Our people are the heart of everything we do here at KBR. We Value our People!  KBR offers a selection of competitive lifestyle benefits, which could include a 401K plan with company match, medical, dental, vision, life insurance, AD&D, flexible spending account, disability, paid time off, or flexible work schedule. We support career advancement through professional training and development.  At KBR, we are passionate about our people, sustainability, and Zero Harm culture. These ideals form all that we do and are at the heart of our commitment to, and ongoing journey toward, being a more inclusive and diverse company. That commitment is central to our team of team’s philosophy and fosters an environment of real collaboration across cultures and locations. Our individual differences and perspectives enhance our teams' value and help us develop solutions for the most challenging problems. We understand that embracing those differences and working together makes us more innovative, resilient, and safer. We Deliver — Together.

 KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.

",86000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'tableau', 'aws', 'azure', 'etl', 'sql', 'hadoop']"
"GenAI Machine Learning Engineer, Performance Optimization",Databricks,CA,Full-time,"
P-984
 Founded in late 2020 by a small group of machine learning engineers and researchers, MosaicML enables companies to securely fine-tune, train and deploy custom AI models on their own data, for maximum security and control. Compatible with all major cloud providers, the MosaicML platform provides maximum flexibility for AI development. Introduced in 2023, MosaicML’s pretrained transformer models have established a new standard for open source, commercially usable LLMs and have been downloaded over 3 million times. MosaicML is committed to the belief that a company’s AI models are just as valuable as any other core IP, and that high-quality AI models should be available to all.
 Now part of Databricks since July 2023, we are passionate about enabling our customers to solve the world's toughest problems — from making the next mode of transportation a reality to accelerating the development of medical breakthroughs. We do this by building and running the world's best data and AI platform so our customers can use deep data insights to improve their business. We leap at every opportunity to solve technical challenges, striving to empower our customers with the best data and AI capabilities.
 You will:

Explore and analyze performance bottlenecks in ML training and inference
Design, implement and benchmark libraries and methods to overcome aforementioned bottlenecks
Build tools for performance profiling, analysis, and estimation for ML training and inference
Balance the tradeoff between performance and usability for our customers
Facilitate our community through documentation, talks, tutorials, and collaborations
Collaborate with external researchers and leading AI companies on various efficiency methods

We look for:

Hands on experience the internals of deep learning frameworks (e.g. PyTorch, TensorFlow) and deep learning models
Experience with high-performance linear algebra libraries such as cuDNN, CUTLASS, Eigen, MKL, etc.
General experience with the training and deployment of ML models
Experience with compiler technologies relevant to machine learning
Experience with distributed systems development or distributed ML workloads
Hands on experience with writing CUDA code and knowledge of GPU internals (Preferred)
Publications in top tier ML or System Conferences such as MLSys, ICML, ICLR, KDD, NeurIPS (Preferred)

We value candidates who are curious about all parts of the company's success and are willing to learn new technologies along the way.



 Pay Range Transparency

      Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.
    



     Local Pay Range
   

     $150,000—$190,000 USD
   



 About Databricks
 Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
 Our Commitment to Diversity and Inclusion
 At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance

    If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.
  

",150000,"['tensorflow', 'pytorch', 'machine learning', 'deep learning', 'apache spark']"
Sr. Data Engineer,"The Travelers Companies, Inc.",CT,Full-time,"












































































































                                                                                                             Who Are We?
                                                                                                            









































































                                      Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
                                    








































































                                      Job Category
                                    


































 Technology
 

   Compensation Overview
 

   The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
 


   Salary Range
  $138,100.00 - $227,800.00
 




































                                      Target Openings
                                    


































 1
 












































































































                                                                                                              What Is the Opportunity?
                                                                                                            










































































































 Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
 
   What Will You Do?
 

 Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.
 Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 Incorporate core data management competencies including data governance, data security and data quality.
 Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment.
 Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate.
 Collaborate across team to support delivery and educate end users on complex data products/analytic environment.
 Perform other duties as assigned.


   What Will Our Ideal Candidate Have?
 

 Bachelor’s Degree in STEM related field or equivalent
 Ten years of related experience
 Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices.
 Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems.
 Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers.
 Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize.
 Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas.
 Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members.
 Experience with some of the following tools & platforms (or similar): AWS (s3, Lambda, Kinesis, API Gateway, IAM, Glue, SNS, SQS, EventBridge, EKS, VPC, Step Functions, ECS/EKS, DynamoDB, etc.), Databricks, Python, JavaScript, Kafka, dbt, Terraform, Snowflake, SQL, Jenkins, Github, Airflow, OpenSearch (Elasticsearch & Kibana), Talend, Alation, Neo4j, Hashicorp Vault / AWS Secrets Manager, Docker / OpenShift / Open Cloud Foundry, MongoDB, Docker, BlackDuck, SonarQube.
 Knowledge and experience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Datalakes, Data Security, Networking, Serverless, Testing/Test Automation (Unit, Integration, Performance, etc.), WebServices, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization.



   What is a Must Have?
 

 Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 Five years of data engineering or equivalent experience.



   What Is in It for You?
 

 Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
 Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.






































                                      Employment Practices
                                    

                                      Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.
                                    

 If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an 
                                     
                                      email
                                      so we may assist you.
                                    

 Travelers reserves the right to fill this position at a level above or below the level included in this posting.
                                    













































                                                                                 To learn more about our comprehensive benefit programs please visit 
                                                                                
                                                                                 http://careers.travelers.com/life-at-travelers/benefits/
                                                                                .
                                                                               














































































",138100,"['python', 'machine learning', 'aws', 'docker', 'sql', 'airflow', 'kafka']"
"Solutions Engineer, Machine Learning",Coactive AI,CA,Full-time,"

Coactive makes it easy to search, filter, and analyze visual content. Increasingly image and video data captures the content we watch, the products we buy, and the work we do, and already represents 80% of internet traffic. But rather than being an asset, visual content is often a tax or even a liability because it is so hard to work with and understand. Coactive solves this by bringing structure to unstructured data. Rather than spending months (or years) building complex infrastructure, data teams can unlock the value of their visual data in minutes to power use cases such as content understanding and moderation, search, and analytics.
 Coactive was founded by experts who shaped the fields of high-performance deep learning and data-centric AI. We have the scars from building and working with the first generation of modern machine learning systems at Google, Meta (formerly Facebook), Pinterest, eBay, Lyft, and other leading organizations. Through our decades of experience, we have developed a playbook to democratize the toughest parts of machine learning systems; no PhD required.

 As a solutions engineer, you will work at the intersection of sales, customer success, and machine learning to help us solve customers' most pressing problems with unstructured image and video data. In this role you will work coactively across the engineering (specifically, machine learning), sales, and customer success teams to build repeatable processes, as well as guide the sale and adoption of Coactive's products. You will leverage your understanding and empathy to support the strategic and technical needs of customers across the customer lifecycle.


 What you'll do:



Provide technical support for sales and customer success, and implement a system for communicating product feedback.
Create and deliver enterprise-grade technical materials to support sales (e.g., video tutorials, documentation, vertical-specific demos, etc.)
Lead and execute successful customer Proof-of-Value engagements.
Design and lead technical workshops for existing customers (as well as potentially new customers, as needed).
Support internal teams (e.g., product, engineering, marketing, customer success, sales) by serving as an advocate for prospects and provide feedback from field engagements.
Maintain clear documentation and processes to facilitate repeatable and effective collaboration.
Occasional travel to customer on-sites and conferences.



 What we look for:

BS (or higher) in Computer Science or related fields, or equivalent professional experience
2+ years of production-level experience in one of: Python, Java, C++, or similar language
Experience with data infrastructure and ML tools is required, such as PyTorch, TensorFlow, scikit-learn, MLflow, Spark and Ray
Experience providing technical guidance/support during customer calls and sales discussions, and as needed for addressing product usage needs and issues
Experience developing pre and post sales materials and enthusiasm for operating as a mentor/educator for other Solutions Engineers and/or Account Executives
Knowledge of and experience with leading customers to solutions that provide value and grow usage of enterprise products
Ability to create tooling to enable non-technical teams
Ability to adapt to change in a fast-paced startup environment, especially with regard to designing and implementing valuable solutions
2+ years of customer-facing enterprise sales experience preferred
Previous experience as a machine learning engineer is a plus



 What you can expect from us:
 This is a hybrid position based in San Jose, California.
 The estimated annual base salary for this position is between $125,000-$156,000.*
 At Coactive, cash salary is only one part of our total compensation package. Other benefits for this position include, but are not limited to:

Market leading equity grants
100% medical, dental, & vision coverage for you
Medical, dental, & vision partially covered for your dependents
Unlimited PTO
A workspace allowance
Social events ranging from book clubs, happy hours, and hiking to board game nights and games of Mario Kart.

Further, you can expect a supportive work environment from us. We build products, but we develop people.



Actual pay is dependent on an individual candidate's professional background, experience, skills and qualifications, as well as market demand and business demands. This pay range is subject to change and may be modified in the future. The salary, other compensation, and benefits information is accurate as of the date of this posting.


 We embrace and celebrate the diversity of our employees. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.
 We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

",125000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Sr. Data Engineer,"The Travelers Companies, Inc.",CT,Full-time,"












































































































                                                                                                             Who Are We?
                                                                                                            









































































                                      Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
                                    








































































                                      Job Category
                                    


































 Technology
 

   Compensation Overview
 

   The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
 


   Salary Range
  $138,100.00 - $227,800.00
 




































                                      Target Openings
                                    


































 1
 












































































































                                                                                                              What Is the Opportunity?
                                                                                                            










































































































 Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
 
   What Will You Do?
 

 Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.
 Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 Incorporate core data management competencies including data governance, data security and data quality.
 Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment.
 Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate.
 Collaborate across team to support delivery and educate end users on complex data products/analytic environment.
 Perform other duties as assigned.


   What Will Our Ideal Candidate Have?
 

 Bachelor’s Degree in STEM related field or equivalent
 Ten years of related experience
 Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices.
 Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems.
 Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers.
 Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize.
 Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas.
 Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members.
 Experience with some of the following tools & platforms (or similar): AWS (s3, Lambda, Kinesis, API Gateway, IAM, Glue, SNS, SQS, EventBridge, EKS, VPC, Step Functions, ECS/EKS, DynamoDB, etc.), Databricks, Python, JavaScript, Kafka, dbt, Terraform, Snowflake, SQL, Jenkins, Github, Airflow, OpenSearch (Elasticsearch & Kibana), Talend, Alation, Neo4j, Hashicorp Vault / AWS Secrets Manager, Docker / OpenShift / Open Cloud Foundry, MongoDB, Docker, BlackDuck, SonarQube.
 Knowledge and experience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Datalakes, Data Security, Networking, Serverless, Testing/Test Automation (Unit, Integration, Performance, etc.), WebServices, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization.



   What is a Must Have?
 

 Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 Five years of data engineering or equivalent experience.



   What Is in It for You?
 

 Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
 Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.






































                                      Employment Practices
                                    

                                      Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.
                                    

 If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an 
                                     
                                      email
                                      so we may assist you.
                                    

 Travelers reserves the right to fill this position at a level above or below the level included in this posting.
                                    













































                                                                                 To learn more about our comprehensive benefit programs please visit 
                                                                                
                                                                                 http://careers.travelers.com/life-at-travelers/benefits/
                                                                                .
                                                                               














































































",138100,"['python', 'machine learning', 'aws', 'docker', 'sql', 'airflow', 'kafka']"
Hewlett Packard Labs - Machine Learning Research Scientist,Hewlett-Packard CDS GmbH,CA,Full-time,"













This role has been designated as ‘’Onsite’ with an expectation that you will primarily work from an HPE office.






















 Who We Are:




























 Hewlett Packard Enterprise is the global edge-to-cloud company advancing the way people live and work. We help companies connect, protect, analyze, and act on their data and applications wherever they live, from edge to cloud, so they can turn insights into outcomes at the speed required to thrive in today’s complex world. Our culture thrives on finding new and better ways to accelerate what’s next. We know diverse backgrounds are valued and succeed here. We have the flexibility to manage our work and personal needs. We make bold moves, together, and are a force for good. If you are looking to stretch and grow your career our culture will embrace you. Open up opportunities with HPE.















 Job Description:

 The AI research team at Hewlett Packard Labs seeks highly qualified, self-motivated researchers to accelerate research toward Reinforcement Learning and Machine Learning applications in the area of sustainability, digital twins, LLMs, the trustworthiness of AI, complex scientific applications like nuclear fusion, sports analytics, and other domains. This position is for the core AI research team at Hewlett Packard Labs.

 Hewlett Packard Labs is an internationally renowned research organization with its headquarters and largest facility in Milpitas, California, in the San Francisco Bay area. As the central research organization for Hewlett Packard Enterprise (HPE), Hewlett Packard Labs' purpose is to deliver breakthrough technologies and technology advancements that provide a competitive advantage for the company, by investing in fundamental science and technology in areas of interest to HPE and getting the resulting technologies ready for adoption into new and existing markets.

 The Artificial Intelligence Research Lab focuses on researching and developing technologies, architectures, and software to develop cutting-edge solutions in key areas of Deep Learning and Machine Learning, including Reinforcement Learning. This team focuses on complex multi-objective and multi-agent Reinforcement Learning with innovative applications to sustainability at scale, complex clean energy generation, nuclear fusion, and similar complex problems. The team also works on the robustness and explainability of models, 2D and 3D computer vision, and NLP / LLMs. There is work related to the use of reinforcement and transformers for model free optimizations. The team also works on fine tuning and self-correction of LLMs and all aspect of trust of LLMs. This is a unique opportunity to work at a start-up pace within a big company. We are looking for an entrepreneurial mind-set, and a deep passion to take a ML problem and conduct research and come up with a solution with a fast turnaround time. You will have an opportunity to work with Machine Learning experts who have made multiple successful products and get guidance and coaching in different areas including software engineering, hardware optimizations, data pipelining, and innovations from the latest AI research to bring hardened Deep Learning solutions to the real world. 

This is a new and growing team at HPE in which you will be building the software and applications for Neural Network and Machine Learning. It will also involve working with system programming, Deep Learning frameworks and models, GPU acceleration, Model optimization, real-time streaming data, distributed computing, and deployment.

 We are seeking highly qualified candidates to come join one of our research teams as an intern or a post-doc, with the possibility of longer-term co-innovation and collaboration. We are particularly interested in individuals with a background in computer systems, machine learning, deep learning, and statistics, with a good understanding of the current state of the art, major trends and opportunities, and a demonstrated track record in making things real in innovative ways. The ideal candidate combines this interest with a broad, entrepreneurial interest in creating the next generation of HPE’s products and technologies.

 We expect all our researchers including interns and post-docs to provide thought leadership and technical influence both internally and externally to HPE, as well as take innovative ideas and make them real – contributing along the full range from initial novel ideas to design, development, implementation, evaluation, and technology transfer. The ideal candidate can thrive in an applied research environment, balancing significant technical and scientific contributions with the ability to bring such contributions to practice through innovative solutions that address the needs of our customers and partners. We expect the successful candidate to collaborate with Hewlett Packard Labs research teams as well as with external partners, and to work in alignment with HPE's broader innovation community. Excellent software systems building skills are a significant plus.

 Education and Experience 

PhD degree (with significant research and innovation experience) in a relevant discipline (e.g. machine learning, computer science, statistics, etc.)
 Track record of world-class innovative contributions and ideas in machine learning.


 Technical Skills: 

Experience in emerging ML areas, including reinforcement learning and generative AI research
 Experience in developing ML software with high proficiency in data structures and algorithms.
 Experience in Machine Learning frameworks like PyTorch - required
 Strong programming skills and experience with Python
 Software development experience in Deep Learning, GPU acceleration, and Model Optimization.
 Demonstrated ability to generate, frame, and carry out leadership research as shown, for example, by papers published in top-tier ML conferences or journals.









 Additional Skills:






 Accountability, Accountability, Action Planning, Active Learning, Active Listening, Bias, Business, Calendar Management, Coaching, Computer Literacy, Creativity, Critical Thinking, Design Thinking, Empathy, Follow-Through, Growth Mindset, Intellectual Curiosity, Long Term Planning, Managing Ambiguity, Office Administration, Policy and procedures, Problem Solving, Project Management, Recordkeeping, Risk Assessment {+ 5 more}
      







 What We Can Offer You:







 Health & Wellbeing
 We strive to provide our team members and their loved ones with a comprehensive suite of benefits that supports their physical, financial and emotional wellbeing.

 Personal & Professional Development
 We also invest in your career because the better you are, the better we all are. We have specific programs catered to helping you reach any career goals you have — whether you want to become a knowledge expert in your field or apply your skills to another division.

 Diversity, Inclusion & Belonging
 We are unconditionally inclusive in the way we work and celebrate individual uniqueness. We know diverse backgrounds are valued and succeed here. We have the flexibility to manage our work and personal needs. We make bold moves, together, and are a force for good.








 Let's Stay Connected:





















 Follow @HPECareers on Instagram to see the latest on people, culture and tech at HPE. 















Job: Administration
       Job Level: N/A
      
 States with Pay Range Requirement

 The expected salary/wage range for a U.S.-based hire filling this position is provided below. Actual offer may vary from this range based upon geographic location, work experience, education/training, and/or skill level. If this is a sales role, then the listed salary range reflects combined base salary and target-level sales compensation pay. If this is a non-sales role, then the listed salary range reflects base salary only. Variable incentives may also be offered. Information about employee benefits offered can be found at https://myhperewards.com/main/new-hire-enrollment.html.
 Hourly: $53.00 - $64.25
      







 HPE is an Equal Employment Opportunity/ Veterans/Disabled/LGBT and Affirmative Action employer. We are committed to diversity and building a team that represents a variety of backgrounds, perspectives, and skills. We do not discriminate and all decisions we make are made on the basis of qualifications, merit, and business need. Our goal is to be one global diverse team that is representative of our customers, in an inclusive environment where we can continue to innovate and grow together. Please click here: Equal Employment Opportunity.







 Hewlett Packard Enterprise is EEO F/M/Protected Veteran/ Individual with Disabilities.

 HPE will comply with all applicable laws related to employer use of arrest and conviction records, including laws requiring employers to consider for employment qualified applicants with criminal histories. .






",106000,"['pytorch', 'python', 'machine learning', 'deep learning']"
"Solutions Engineer, Machine Learning",Coactive AI,CA,Full-time,"

Coactive makes it easy to search, filter, and analyze visual content. Increasingly image and video data captures the content we watch, the products we buy, and the work we do, and already represents 80% of internet traffic. But rather than being an asset, visual content is often a tax or even a liability because it is so hard to work with and understand. Coactive solves this by bringing structure to unstructured data. Rather than spending months (or years) building complex infrastructure, data teams can unlock the value of their visual data in minutes to power use cases such as content understanding and moderation, search, and analytics.
 Coactive was founded by experts who shaped the fields of high-performance deep learning and data-centric AI. We have the scars from building and working with the first generation of modern machine learning systems at Google, Meta (formerly Facebook), Pinterest, eBay, Lyft, and other leading organizations. Through our decades of experience, we have developed a playbook to democratize the toughest parts of machine learning systems; no PhD required.

 As a solutions engineer, you will work at the intersection of sales, customer success, and machine learning to help us solve customers' most pressing problems with unstructured image and video data. In this role you will work coactively across the engineering (specifically, machine learning), sales, and customer success teams to build repeatable processes, as well as guide the sale and adoption of Coactive's products. You will leverage your understanding and empathy to support the strategic and technical needs of customers across the customer lifecycle.


 What you'll do:



Provide technical support for sales and customer success, and implement a system for communicating product feedback.
Create and deliver enterprise-grade technical materials to support sales (e.g., video tutorials, documentation, vertical-specific demos, etc.)
Lead and execute successful customer Proof-of-Value engagements.
Design and lead technical workshops for existing customers (as well as potentially new customers, as needed).
Support internal teams (e.g., product, engineering, marketing, customer success, sales) by serving as an advocate for prospects and provide feedback from field engagements.
Maintain clear documentation and processes to facilitate repeatable and effective collaboration.
Occasional travel to customer on-sites and conferences.



 What we look for:

BS (or higher) in Computer Science or related fields, or equivalent professional experience
2+ years of production-level experience in one of: Python, Java, C++, or similar language
Experience with data infrastructure and ML tools is required, such as PyTorch, TensorFlow, scikit-learn, MLflow, Spark and Ray
Experience providing technical guidance/support during customer calls and sales discussions, and as needed for addressing product usage needs and issues
Experience developing pre and post sales materials and enthusiasm for operating as a mentor/educator for other Solutions Engineers and/or Account Executives
Knowledge of and experience with leading customers to solutions that provide value and grow usage of enterprise products
Ability to create tooling to enable non-technical teams
Ability to adapt to change in a fast-paced startup environment, especially with regard to designing and implementing valuable solutions
2+ years of customer-facing enterprise sales experience preferred
Previous experience as a machine learning engineer is a plus



 What you can expect from us:
 This is a hybrid position based in San Jose, California.
 The estimated annual base salary for this position is between $125,000-$156,000.*
 At Coactive, cash salary is only one part of our total compensation package. Other benefits for this position include, but are not limited to:

Market leading equity grants
100% medical, dental, & vision coverage for you
Medical, dental, & vision partially covered for your dependents
Unlimited PTO
A workspace allowance
Social events ranging from book clubs, happy hours, and hiking to board game nights and games of Mario Kart.

Further, you can expect a supportive work environment from us. We build products, but we develop people.



Actual pay is dependent on an individual candidate's professional background, experience, skills and qualifications, as well as market demand and business demands. This pay range is subject to change and may be modified in the future. The salary, other compensation, and benefits information is accurate as of the date of this posting.


 We embrace and celebrate the diversity of our employees. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.
 We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

",125000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Statistical Clerk,SIU Medicine,IL,Full-time,"Department: Center for Clinical Research-SMS 

Division: NA 

Location: .Springfield 

Job Category: Business 


Overview:
 The primary function of the position is to provide statistical support, and other related duties, to achieve success in research projects for the Center of Clinical Research (CCR). The appointee will be responsible for compiling statistical data and interpreting quantitative information by application of statistical methods related to studies being supported by the CCR. 


Salary: $17.56/hour 
SOUTHERN ILLINOIS UNIVERSITY SCHOOL OF MEDICINE 
CIVIL SERVICE POSITION DESCRIPTION 

 INCUMBENT CSN FLSA STATUS non-exempt 

 PRESENT CLASSIFICATION Statistical Clerk DATE 

 DEPARTMENT/DIVISION Center for Clinical Research 

 FUNCTION 

 The primary function of the position is to provide statistical support, and other related duties, to 
achieve success in research projects for the Center of Clinical Research (CCR). The appointee 
will be responsible for compiling statistical data and interpreting quantitative information by 
application of statistical methods related to studies being supported by the CCR. 

 ORGANIZATIONAL RELATIONSHIP 

 This position reports to the Director of the Statistics and Informatics Division, who reports to the 
Director, Center for Clinical Research. 

 DUTIES AND RESPONSIBILITIES 

 The following information is intended to be representative of the work performed by incumbent 
in this position and is not all-inclusive. The omission of a specific duty or responsibility will not 
preclude it from the position if the work is similar, related, or a logical extension of position 
responsibilities. 

 Demonstrates, by actions, commitment to the mission and the behavioral standards of SIU 
School of Medicine. Provides excellent service to both internal and external customers through 
collaboration and partnership; compassion and respect; integrity and accountability; diversity and 
inclusion; as well as continuous learning and improvement. 

 TIME COMMITMENT 

 I. Research 100% 

 a. Prepares data for analysis by organizing information, checking for any inaccuracies such 
as out of range values/outliers. 

 b. Checks information and data for accuracy and makes corrections. 
c. Prepares data for computer input; analyzes, compiles and interprets results. 
d. Prepares tables, graphs, and reports on numeric or quantitative results using software 

 packages; compiles and provides requested data by using statistical, graphical, 
spreadsheet and database software packages. 

 e. Recommends ways to improve the collection and tabulation of data. 
f. Participates in the analyses of quantitative statistical data. 
g. Reports results of descriptive and inferential statistical analyses, including information in 

 the form of graphs, charts, and tables. 
h. Works with others in the Statistics and Informatics Division to determine project plans 

 and ensure goals are met. 

 i. Performs other related duties as assigned. 

 SKILLS AND ABILITIES NEEDED FOR THE POSITION 



Sensitive to the needs of underrepresented minority populations
Working knowledge of at least one statistical software package such as SAS, SPSS, R, or
 Stata 


Ability to learn databases systems such Access, SQL, and REDCap
Knowledge of statistical procedures
Knowledge of data management tools and Microsoft Office Programs
Skills in operation of office equipment
Ability to work with numerical data
Arithmetical accuracy
 RESPONSIBILITY 

 A. Supervisory Controls - After initial training of job responsibilities, employee will be 
expected to perform duties with minimal supervision. Employee must to be able to determine 
priorities and work independently in order to complete duties in an efficient and effective 
manner. Supervisor will function more in the capacity of a consultant instead of actually 
supervising each work assignment. Deadline and general instructions must be established for 
certain projects, however, it will be the employee’s responsibility to organize and complete 
the projects by utilizing his or her own initiative, creativity and judgment. 

 B. Guidelines – The incumbent will be required to abide by the rules, regulations, and policies 

 outlined by SIU School of Medicine, the Center for Clinical Research, and the State of 
Illinois. Describe the extent to which this employee is restricted by or free from the use of 
guidelines in performing work. 

 DIFFICULTY 

 A. Complexity – The incumbent must be able perform a variety of statistical related tasks to 
assist in the support of research projects as outlined by the supervisor. Timely response to 
requests is required. Standard office equipment, personal computers, statistical software 
packages, and database systems will be used to perform duties. Attention to details and the 
use of sound judgement are imperative. 

 B. Scope and Effect – The incumbent is to provide daily statistical assistance and support to 
various research projects being supported by the CCR. This will require flexibility and the 
ability to meet strict deadlines. The ability to learn and work with various statistical software 
and database systems is critical. 

 PERSONAL CONTACTS 

 The incumbent will have contact with a variety of SIU staff and faculty in multiple departments 
via face-to-face meetings, phone calls, and email communications in order to complete statistical 
support on various research projects. 

 ENVIRONMENTAL, HEALTH AND SAFETY RESPONSIBILITIES 

 Participates in meetings, trainings and other environmental, health and safety activities as 
required by SIU School of Medicine. 

 WORKING CONDITIONS 

 See attached form outlining the physical and environmental requirements of the position. 

 ____________________________________ ________________________________ 
Incumbent Date Albert Botchway, Ph.D. Date 
Statistical Clerk Supervisor 
Center for Clinical Research Director, Statistics and Informatics Division 
Center for Clinical Research 

 _____________________________________ 
Joseph C. Milbrandt, Ph.D. Date 
Director, Center for Clinical Research 

 PHYSICAL AND ENVIRONMENTAL REQUIREMENTS 
SIU SCHOOL OF MEDICINE 


Incumbent: Classification: Statistical Clerk 


-

Position No. (If applicable): Department: Center for Clinical Research-SMS 


WORK ENVIRONMENT: (Check all applicable environments) 

 Office Hospital 

 Clinic Warehouse 

 Research Laboratory Outdoors 


Other (Be Specific):

PHYSICAL DEMANDS: Seldom Occasionally Frequently Constantly N/A 

 (Indicate frequency of activity during (Performed rarely less (Performed less than (Performed 26% to 50% of the time) (Performed 51 % or most of the time) 
performance of position duties) than 2% of the time) 25% of the time) 

 (Click on the Physical Demands Definitions button at the bottom of the form for a list of physical demands definitions) 

 Bm!ing 0 0 0 @ 0 

 Writing 0 0 @ 0 0 

 0 0 @ 0 0 

 Close visual acui 0 0 0 @ 0 

 To!'le! @ 0 0 0 0 

 Hearing - Qgnve!11atign 0 0 @ 0 0 

 Hearing - Qther Sounds 0 0 @ 0 0 

 filQQping_ @ 0 0 0 0 

 @ 0 0 0 0 

 Gross hand manipulation 0 @ 0 0 0 

 Fine hand manipulation 0 0 0 @ 0 

 Working in dust fumes gases gr irritants 0 0 0 0 @ 

 Working at heights 0 0 0 0 @ 

 Working in extreme @Id heat and/gr humidi 0 0 0 0 @ 

 Working in close Quarte!11 0 0 0 0 @ 

 C!i.m.bing 0 0 0 0 @ 

 Qperating mgtgr vehicles @ 0 0 0 0 

 Sitting 0 0 0 @ 0 

 filaru!ing_ 0 @ 0 0 0 

 wa!king_ 0 @ 0 0 0 

 Working above shoulder level @ 0 0 0 0 

 Twisting @ 0 0 0 0 

 Kneeling @ 0 0 0 0 

 Pushing or pulling @ 

 Carrml Less than 5 lbs. 0 

 Lifting Less than 5 lbs. 0 


Other (Please list): 0 0 0 0 0 
I affirm the environmental and physical demands hsted on this form are an accurate reflection of the I have read, understand and am capable of meeting the physical and 
requirements of this position to the best of my knowledge and belief. environmental demands of this position. 

 __________________ Albert Botchway, PhD 

 Supervisor Signature Date Supervisor Name Employee Signature Date 

 HR-0195S Page 1 of 1 
01/10",35120,['sql']
"Scientist I, Computational Biology & Machine Learning",Arsenal Biosciences,CA,Full-time,"








        ArsenalBio, a privately held, clinical-stage programmable cell therapy company engineering advanced CAR T therapies for solid tumors, is seeking a talented Scientist I, Computational Biology & Machine Learning to work hybrid based in our South San Francisco office.
       


 ArsenalBio’s mission is to develop efficacious and safe cellular therapies for patients with chronic diseases, initially cancer. With our programmable and computationally driven approach, our team is engineering living medicines to attack cancer’s inherent multi-faceted nature and overcome the challenges of addressing solid tumors with cell therapy.
       


 Driven by a collective of diverse experts across immunology, synthetic biology, molecular biology, automation and computational biology, we are united in purpose to deliver radical breakthroughs for people with cancer, and prioritize the team’s outcomes over individual goals to achieve our company mission – together.
       


 ArsenalBio is looking for a highly motivated Scientist-I to join the Computational Biology and Machine Learning group. You will work closely with an interdisciplinary team of scientists and engineers to develop algorithms, models, and computational workflows to analyze large amounts of data from a variety of technologies. By addressing challenging problems in synthetic and molecular biology, immunology, and high throughput assays, you will meaningfully contribute to accelerating the development of curative cell therapies against cancer and will have a direct impact on patients' lives.
       

 What You Will Do:

 Analyze data from next generation sequencing assays (eg. RNA-seq, single-cell RNA-seq, ATAC-seq), flow cytometry, or other related technologies.
 Develop machine learning or statistical methods to extract insights from large screening experiments.
 Work closely with ArsenalBio scientists across different functions and disciplines to rapidly iterate through the cycle of experimental design, hypothesis testing, data collection, and interpretation.
 Assist with experimental design, for example through modeling or simulations.
 Help productionize computational workflows so that they can be executed in a robust and reproducible manner.
 Develop visualization tools.


 What Will You Bring:

 Ph.D. in Bioinformatics, Computer Science, Electrical Engineering, Statistics, Biomedical Engineering, Biology, or a related field with 0-2 years of industry experience


OR Masters with 5+ years of industry experience
OR Bachelors with 7+ years of industry experience
 Demonstrated ability to
       
 data analysis and engineering skills to answer biological questions.
 Hands-on experience analyzing next generation sequencing data and/or flow cytometry data.
 Ability to work collaboratively and communicate effectively in an interdisciplinary environment.
 Proficiency in Python or R.
 Experience working in Linux environments.


 Additional Desired Skills:

 Familiarity with cloud computing environments and version control systems (eg. git).
 Familiarity with cell therapy or immunotherapy will be appreciated, but not required.



 What We Will Offer You:


         An opportunity to work with the best talent in the field of cell therapy, and be part of ONE TEAM to advance therapies to patients who need it most.
       


 ArsenalBio has a generous and comprehensive benefits package that includes but is not limited to medical, dental, and vision as well as mental health resources, virtual and telehealth options, coaching, infertility treatment, parental leave and health savings accounts. We also offer flexible work schedules and flexible time off, which includes two extra “Arsenal Days of Rest” every quarter for employees to recharge.
       


 We have a robust mentorship program, and comprehensive development tools to help employees take control of their career paths and grow into their best selves. ArsenalBio believes in investing in the well-being of our employees - both at work and at home, as they are our greatest asset. They bring scientific talents in molecular biology, immunology, pharmacology, protein chemistry, computational biology, automation, genome engineering, software and other fields to make the future happen now.
       


 We are committed to hiring the best talent from diverse backgrounds. A diverse workforce engenders richness of thought, creativity and discovery. We invite individuals who embrace intellectual achievement to bring their unique personal and professional journeys and together we will build transformative cell therapies for cancer patients.
       


 We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
       


 The estimated base salary offer for the preferred primary location of San Francisco Bay area ranges from $126,100–$154,500.
       

         Salary ranges for other locations may vary from this range. Base pay offered may vary depending on job related knowledge, experience, education, and location. In addition to these factors, we believe in the importance of pay equity and consider internal equity of our current employees as part of any final offer.
       


 To all recruitment agencies: ArsenalBio does not accept agency resumes. Please do not forward resumes to our jobs alias, or ArsenalBio employees. ArsenalBio is not responsible for any fees related to unsolicited resumes.
       




 








Bold ideas. Reliable data. World-Class Science.
Designing therapies to cure our most important health challenges requires the audacity to advance a bold idea and explore new biologies with world-class science. 

            By pushing at the frontiers of science, challenging what we think we know, and holding ourselves to the highest standards of irrefutable proof, we are reshaping the future of curative cellular therapies. 
           














Benefits

                ArsenalBio is powered by people.
               





                And we believe that people work best when given freedom and flexibility in a supportive environment that allows us all to show up as our true selves. We respect that your life extends beyond the work we’ll do here together, and we continually strive to provide you with what you need to care for yourself and your family.
               









               Health & Wellness
              
 




               Financial Well-Being
              
 




               Time Off
              
 




               Mindful Workspace
              
 














ArsenalBio was formed by its investors and scientific founders to discover, develop and commercialize curative and safe cellular therapies for patients with life threatening diseases, initially cancer. 
We believe the most productive and secure route to achieving this goal is to build scaled platforms of technologies challenged with scientific questions to yield informative data from hypothesis driven, well controlled experiments. These data will inform the design of ambitious, best-in-class, lead compositions. Our leads will be rigorously evaluated and honed until we are convinced our matured leads, called development candidates, can be prepared for testing in needy, and vulnerable patients. 
Our products will be designed to speed the transition of cell therapy from hospital-based to outpatient treatments, increasing access to more patients at lower cost to patients, health systems, and insurers. 
To achieve this mission, we are building diverse teams of talented, curious, and caring individuals who believe in our mission and our vision to be sustainable in our business plan, our work habits, and our personal lives. 
Our values create: a foundation for mutual respect, an engaging harmony from many voices, and unselfish behavior to aid our colleagues. 

            This is ArsenalBio.
             This is our Company.
           










",126100,"['python', 'machine learning', 'git']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
"Manager, Drug Discovery AI",NVIDIA,CA,Full-time,"

  NVIDIA is using the power of high performance computing and AI to accelerate digital biology. We are seeking passionate and hardworking individuals to help us realize our mission. As a Manager, you will lead a team focused on deep learning development for cheminformatics, virtual screening, and protein modeling. This position provides the opportunity to develop, productize, and deliver drug discovery AI technologies across Nvidia's BioNeMo platform.
 


   What You’ll Be Doing:
 



     Define the roadmap for the future internal and public releases of the BioNeMo projects: define deliveries and work packages, help synchronize the dependencies across the other teams, formulate benchmarks and key performance indicators.
   


     Drive the technical choices to build the new features of the drug discovery AI technology stack: leverage existing deep learning technologies, provide feedback on performance and compute requirements, design new integrated deep learning models adapted to the problems of drug discovery.
   


     Mentor and supervise a team of experts in deep learning applications in small molecule generation, protein sequence and structure models
   


     Collaborate with multiple other teams, including Drug Discovery AI teams, AI infrastructure teams, product management, and Nvidia Research.
   


     Help bring up end-to-end drug discovery AI solutions based on the Nvidia BioNeMo platform.
   



   What We Need To See:
 



     Excellent interpersonal and 5+ years of leadership experience.
   


     PhD in Computer Science, Computational Chemistry, Computational Biology, or relevant field for Drug Discovery AI, or equivalent experience
   


     10+ overall years of relevant industry experience
   


     Participated in designing and implementing modern deep learning algorithms in cheminformatics, virtual screening, and/or protein design
   


     Excellent communication, analysis and problem solving skills
   



   Ways To Stand Out From The Crowd:
 



     Have significant deep learning experience, especially with LLMs, graph-based and geometric deep learning for drug discovery use cases.
   


     Have published in major journals or conferences in a field relevant to deep learning and drug discovery.
   



   With competitive salaries and a generous benefits package, we are widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us and, due to unprecedented growth, our exclusive engineering teams are rapidly growing. If you're a creative and autonomous engineer with a real passion for technology, we want to hear from you.
 
 The base salary range is 216,000 USD - 414,000 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
 







          You will also be eligible for equity and 
         
          benefits
         . 
         NVIDIA accepts applications on an ongoing basis.








 NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

",216000,['deep learning']
AI Engineer,Thunkable,NY,Full-time,"

  Role Overview
 


 Thunkable is on the lookout for a highly skilled software engineer with a passion for machine learning and a special focus on deep learning and generative AI. Our ideal candidate will be adept in working with Large Language Models (LLMs), and possess a strong foundation in programming languages such as Python and JavaScript/TypeScript. Experience with technologies like Langchain, Autogen, AutoGPT, and tools for code generation and completion will be highly valued.
 


 What you'll do
 


 Participate in the design, development, and integration of cutting-edge machine learning techniques within the Thunkable platform, in partnership with product management, full-stack engineering, and design teams.
Establish use cases and devise evaluation methods & benchmarks for various approaches to support and enhance Thunkable’s products and user experiences.
Actively monitor and refine the performance and efficiency of live ML systems.
Keep abreast of the latest trends and breakthroughs in machine learning, NLP, and adjacent domains to maintain our edge in innovation.
Mentor team members, fostering AI literacy and thought leadership within the company.
Research developments in LLMs and generative AI to identify opportunities for leveraging them to boost Thunkable’s capabilities.



 What you'll need
 


 A minimum of 5 years of experience as a Software Engineer or equivalent research experience.
Strong grasp of core web technologies.
Proven ability to dissect and resolve complex software development issues across diverse components.
Excellent problem-solving acumen with the capability to articulate intricate ideas to both technical and non-technical audiences.
A history, if brief, of working with large language models and generative AI and associated techniques such as RAG, prompt management or fine tuning.
A strong advocate for ethical AI, prioritizing transparency and user-centric approaches
Advanced degree (Master’s or Ph.D.) in Computer Science, Engineering, Statistics, Mathematics, or a related field, or industry experience to match.
Proficiency in SQL, familiarity with large datasets, and experience with cloud platforms like AWS or GCP.



 Bonus Points
 

Deep understanding of deep learning, reinforcement learning, and NLP.
Experience in handling and analyzing large datasets with statistical and machine learning techniques.
Knowledge in the design of experiments, survey design, and large-scale AB testing.
Technical knowledge in Deep Learning, particularly in Generative AI (e.g., GANs, GPT models).Familiarity with Multi-modal ML, Graph ML, and/or Reinforcement Learning.
Contributions to technical articles and presentations at Engineering/ML conferences are advantageous.
Experience developing and training models in PyTorch is ideal.



 Life at Thunkable
 


 Thunkable is on a mission to democratize app development and empower everyone to build without writing a single line of code. Our platform enables anyone to build and publish their iOS and Android apps for free. Today, non-engineers use Thunkable to prototype and share new ideas, develop proofs-of-concept for their own digital business, and design and ship their own ad-supported and premium apps. Thunkable was incubated at Google Research and MIT.
 


 We are backed by Lightspeed, NEA, Owl Ventures, SV Angel, Zhenfund, and Y-Combinator. Our founders are MIT engineers who want to extend the power and fun of creation to people who don’t code.
 

   Joining Thunkable means joining a team of passionate, entrepreneurial and friendly people with different backgrounds, shared ideas, and similar goals.
 


 What will you get when joining our team?
 


 Get compensated: We offer competitive pay, equity and benefits to our employees based on their location. You’ll get access to unlimited PTO regardless of your location.
Wellness and Training Budget: We value your well-being and want to invest in it.
Work Where You Want: The company is based in San Francisco (with an office), but operates globally, with team members working across a number of cities, countries, and time zones (to facilitate async work we prioritize countries and locations in a max 2h time zone difference from those hubs: San Francisco, New York and Dublin)
Shared values: Creativity, Openness, Transparency, Persistence, and Entrepreneurialism.
Challenge yourself by acquiring new abilities, interacting with clients, enhancing products, or learning design. We will encourage you to reach your full potential.



 We believe that a diverse and inclusive workplace helps ensure we learn from each other’s different backgrounds, experiences, and perspectives and is critical for building a product that supports the wide range of our users’ needs. Thunkable is an equal opportunity employer and a pleasant and supportive place to work. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply.



 This position offers a competitive salary that is based on a combination of factors including location. The salary range for this role in San Francisco is between $160,000 and $190,000 per year and will be based on qualifications and skills. If the successful candidate is located in a different location or country, the salary may vary based on the cost of living, currency and other local factors. We are open to discussing salary with candidates who are interested in the role and may be willing to negotiate based on the candidate's experience and qualifications. We are committed to paying our employees fairly and providing opportunities for professional growth and development.

",160000,"['pytorch', 'python', 'machine learning', 'deep learning', 'aws', 'gcp', 'sql']"
Data Scientist,KBR,MD,Full-time,"
Title: Data Scientist
 
 KBR is looking to add a Data Scientist with Natural Language Processing (NLP) & BI tools experience to our team. Due to contract requirements, candidates must be US Citizens and hold an active/current D.O.D Secret clearance. 

In this role, you will...

 Discover NLP approaches to deliver insights and develop predictive models to meet customer needs.
 Utilize standard data science approaches such as data ingest, ETL, preprocessing, model building, model deploying, and monitoring models once deployed.
 Demonstrate experience working with raw data by processing and ingesting it into a database, cleaning it to be fed into a model, deploying it for some application, and explaining findings clearly to a general audience.
 Troubleshoot problems with data ingesting and processing
 Contribute to research and identification of the most accurate model architecture for current problems.
 Collaborate in data science meetings by presenting on theoretical or applied data science topics.
 Demonstrate the ability to troubleshoot in cloud environments such as AWS, Azure, and Google Cloud.
 Familiarity with machine learning platforms, such as CDSW
 Develop visualizations to convey meaningful insights.
 Present insights from models to a non-technical crowd to convey findings
 Suggest meaningful approaches, models, and services to address problems.
 Stay informed about trends and recent capabilities within data science.


 Required Education, Skills, & Experience
 Education: A bachelor's degree in data science, statistics, computer science, or a related quantitative field.
 Clearance: Active/Current D.O.D Secret Clearance
 Experience: 2 years of relevant work experience

 Proficient in Python; other equivalent languages are considered.
 Experience with BI tools such as QlikSense, Tableau, PowerBI, Zoomdata, etc.
 Experience in NLP approaches, machine learning techniques, and neural networks
 Competent in using SQL and other relational database query languages


 Highly Desired Education, Skills, & Experience
 Education: Masters in data science, statistics, computer science, or a related quantitative field.
 Experience/Skills:

 Excellent communication skills
 Exposure to one more neural network framework – Tensorflow, Torch/ PyTorch, ONNX, etc
 Previously worked with distributed computing environments such as Hadoop.


 Contract Requirements Regarding Education And Experience Will Prevail.
 Salary range: $86K-$110K  When you become part of the KBR team, your career opportunities are endless. Our people are the heart of everything we do here at KBR. We Value our People!  KBR offers a selection of competitive lifestyle benefits, which could include a 401K plan with company match, medical, dental, vision, life insurance, AD&D, flexible spending account, disability, paid time off, or flexible work schedule. We support career advancement through professional training and development.  At KBR, we are passionate about our people, sustainability, and Zero Harm culture. These ideals form all that we do and are at the heart of our commitment to, and ongoing journey toward, being a more inclusive and diverse company. That commitment is central to our team of team’s philosophy and fosters an environment of real collaboration across cultures and locations. Our individual differences and perspectives enhance our teams' value and help us develop solutions for the most challenging problems. We understand that embracing those differences and working together makes us more innovative, resilient, and safer. We Deliver — Together.

 KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.

",86000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'tableau', 'aws', 'azure', 'etl', 'sql', 'hadoop']"
"GenAI Machine Learning Engineer, Performance Optimization",Databricks,CA,Full-time,"
P-984
 Founded in late 2020 by a small group of machine learning engineers and researchers, MosaicML enables companies to securely fine-tune, train and deploy custom AI models on their own data, for maximum security and control. Compatible with all major cloud providers, the MosaicML platform provides maximum flexibility for AI development. Introduced in 2023, MosaicML’s pretrained transformer models have established a new standard for open source, commercially usable LLMs and have been downloaded over 3 million times. MosaicML is committed to the belief that a company’s AI models are just as valuable as any other core IP, and that high-quality AI models should be available to all.
 Now part of Databricks since July 2023, we are passionate about enabling our customers to solve the world's toughest problems — from making the next mode of transportation a reality to accelerating the development of medical breakthroughs. We do this by building and running the world's best data and AI platform so our customers can use deep data insights to improve their business. We leap at every opportunity to solve technical challenges, striving to empower our customers with the best data and AI capabilities.
 You will:

Explore and analyze performance bottlenecks in ML training and inference
Design, implement and benchmark libraries and methods to overcome aforementioned bottlenecks
Build tools for performance profiling, analysis, and estimation for ML training and inference
Balance the tradeoff between performance and usability for our customers
Facilitate our community through documentation, talks, tutorials, and collaborations
Collaborate with external researchers and leading AI companies on various efficiency methods

We look for:

Hands on experience the internals of deep learning frameworks (e.g. PyTorch, TensorFlow) and deep learning models
Experience with high-performance linear algebra libraries such as cuDNN, CUTLASS, Eigen, MKL, etc.
General experience with the training and deployment of ML models
Experience with compiler technologies relevant to machine learning
Experience with distributed systems development or distributed ML workloads
Hands on experience with writing CUDA code and knowledge of GPU internals (Preferred)
Publications in top tier ML or System Conferences such as MLSys, ICML, ICLR, KDD, NeurIPS (Preferred)

We value candidates who are curious about all parts of the company's success and are willing to learn new technologies along the way.



 Pay Range Transparency

      Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.
    



     Local Pay Range
   

     $150,000—$190,000 USD
   



 About Databricks
 Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
 Our Commitment to Diversity and Inclusion
 At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance

    If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.
  

",150000,"['tensorflow', 'pytorch', 'machine learning', 'deep learning', 'apache spark']"
Sr. Data Engineer,"The Travelers Companies, Inc.",CT,Full-time,"












































































































                                                                                                             Who Are We?
                                                                                                            









































































                                      Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
                                    








































































                                      Job Category
                                    


































 Technology
 

   Compensation Overview
 

   The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
 


   Salary Range
  $138,100.00 - $227,800.00
 




































                                      Target Openings
                                    


































 1
 












































































































                                                                                                              What Is the Opportunity?
                                                                                                            










































































































 Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
 
   What Will You Do?
 

 Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.
 Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 Incorporate core data management competencies including data governance, data security and data quality.
 Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment.
 Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate.
 Collaborate across team to support delivery and educate end users on complex data products/analytic environment.
 Perform other duties as assigned.


   What Will Our Ideal Candidate Have?
 

 Bachelor’s Degree in STEM related field or equivalent
 Ten years of related experience
 Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices.
 Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems.
 Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers.
 Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize.
 Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas.
 Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members.
 Experience with some of the following tools & platforms (or similar): AWS (s3, Lambda, Kinesis, API Gateway, IAM, Glue, SNS, SQS, EventBridge, EKS, VPC, Step Functions, ECS/EKS, DynamoDB, etc.), Databricks, Python, JavaScript, Kafka, dbt, Terraform, Snowflake, SQL, Jenkins, Github, Airflow, OpenSearch (Elasticsearch & Kibana), Talend, Alation, Neo4j, Hashicorp Vault / AWS Secrets Manager, Docker / OpenShift / Open Cloud Foundry, MongoDB, Docker, BlackDuck, SonarQube.
 Knowledge and experience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Datalakes, Data Security, Networking, Serverless, Testing/Test Automation (Unit, Integration, Performance, etc.), WebServices, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization.



   What is a Must Have?
 

 Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 Five years of data engineering or equivalent experience.



   What Is in It for You?
 

 Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
 Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.






































                                      Employment Practices
                                    

                                      Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.
                                    

 If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an 
                                     
                                      email
                                      so we may assist you.
                                    

 Travelers reserves the right to fill this position at a level above or below the level included in this posting.
                                    













































                                                                                 To learn more about our comprehensive benefit programs please visit 
                                                                                
                                                                                 http://careers.travelers.com/life-at-travelers/benefits/
                                                                                .
                                                                               














































































",138100,"['python', 'machine learning', 'aws', 'docker', 'sql', 'airflow', 'kafka']"
"Solutions Engineer, Machine Learning",Coactive AI,CA,Full-time,"

Coactive makes it easy to search, filter, and analyze visual content. Increasingly image and video data captures the content we watch, the products we buy, and the work we do, and already represents 80% of internet traffic. But rather than being an asset, visual content is often a tax or even a liability because it is so hard to work with and understand. Coactive solves this by bringing structure to unstructured data. Rather than spending months (or years) building complex infrastructure, data teams can unlock the value of their visual data in minutes to power use cases such as content understanding and moderation, search, and analytics.
 Coactive was founded by experts who shaped the fields of high-performance deep learning and data-centric AI. We have the scars from building and working with the first generation of modern machine learning systems at Google, Meta (formerly Facebook), Pinterest, eBay, Lyft, and other leading organizations. Through our decades of experience, we have developed a playbook to democratize the toughest parts of machine learning systems; no PhD required.

 As a solutions engineer, you will work at the intersection of sales, customer success, and machine learning to help us solve customers' most pressing problems with unstructured image and video data. In this role you will work coactively across the engineering (specifically, machine learning), sales, and customer success teams to build repeatable processes, as well as guide the sale and adoption of Coactive's products. You will leverage your understanding and empathy to support the strategic and technical needs of customers across the customer lifecycle.


 What you'll do:



Provide technical support for sales and customer success, and implement a system for communicating product feedback.
Create and deliver enterprise-grade technical materials to support sales (e.g., video tutorials, documentation, vertical-specific demos, etc.)
Lead and execute successful customer Proof-of-Value engagements.
Design and lead technical workshops for existing customers (as well as potentially new customers, as needed).
Support internal teams (e.g., product, engineering, marketing, customer success, sales) by serving as an advocate for prospects and provide feedback from field engagements.
Maintain clear documentation and processes to facilitate repeatable and effective collaboration.
Occasional travel to customer on-sites and conferences.



 What we look for:

BS (or higher) in Computer Science or related fields, or equivalent professional experience
2+ years of production-level experience in one of: Python, Java, C++, or similar language
Experience with data infrastructure and ML tools is required, such as PyTorch, TensorFlow, scikit-learn, MLflow, Spark and Ray
Experience providing technical guidance/support during customer calls and sales discussions, and as needed for addressing product usage needs and issues
Experience developing pre and post sales materials and enthusiasm for operating as a mentor/educator for other Solutions Engineers and/or Account Executives
Knowledge of and experience with leading customers to solutions that provide value and grow usage of enterprise products
Ability to create tooling to enable non-technical teams
Ability to adapt to change in a fast-paced startup environment, especially with regard to designing and implementing valuable solutions
2+ years of customer-facing enterprise sales experience preferred
Previous experience as a machine learning engineer is a plus



 What you can expect from us:
 This is a hybrid position based in San Jose, California.
 The estimated annual base salary for this position is between $125,000-$156,000.*
 At Coactive, cash salary is only one part of our total compensation package. Other benefits for this position include, but are not limited to:

Market leading equity grants
100% medical, dental, & vision coverage for you
Medical, dental, & vision partially covered for your dependents
Unlimited PTO
A workspace allowance
Social events ranging from book clubs, happy hours, and hiking to board game nights and games of Mario Kart.

Further, you can expect a supportive work environment from us. We build products, but we develop people.



Actual pay is dependent on an individual candidate's professional background, experience, skills and qualifications, as well as market demand and business demands. This pay range is subject to change and may be modified in the future. The salary, other compensation, and benefits information is accurate as of the date of this posting.


 We embrace and celebrate the diversity of our employees. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.
 We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

",125000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Data Scientist,KBR,MD,Full-time,"
Title: Data Scientist
 
 KBR is looking to add a Data Scientist with Natural Language Processing (NLP) & BI tools experience to our team. Due to contract requirements, candidates must be US Citizens and hold an active/current D.O.D Secret clearance. 

In this role, you will...

 Discover NLP approaches to deliver insights and develop predictive models to meet customer needs.
 Utilize standard data science approaches such as data ingest, ETL, preprocessing, model building, model deploying, and monitoring models once deployed.
 Demonstrate experience working with raw data by processing and ingesting it into a database, cleaning it to be fed into a model, deploying it for some application, and explaining findings clearly to a general audience.
 Troubleshoot problems with data ingesting and processing
 Contribute to research and identification of the most accurate model architecture for current problems.
 Collaborate in data science meetings by presenting on theoretical or applied data science topics.
 Demonstrate the ability to troubleshoot in cloud environments such as AWS, Azure, and Google Cloud.
 Familiarity with machine learning platforms, such as CDSW
 Develop visualizations to convey meaningful insights.
 Present insights from models to a non-technical crowd to convey findings
 Suggest meaningful approaches, models, and services to address problems.
 Stay informed about trends and recent capabilities within data science.


 Required Education, Skills, & Experience
 Education: A bachelor's degree in data science, statistics, computer science, or a related quantitative field.
 Clearance: Active/Current D.O.D Secret Clearance
 Experience: 2 years of relevant work experience

 Proficient in Python; other equivalent languages are considered.
 Experience with BI tools such as QlikSense, Tableau, PowerBI, Zoomdata, etc.
 Experience in NLP approaches, machine learning techniques, and neural networks
 Competent in using SQL and other relational database query languages


 Highly Desired Education, Skills, & Experience
 Education: Masters in data science, statistics, computer science, or a related quantitative field.
 Experience/Skills:

 Excellent communication skills
 Exposure to one more neural network framework – Tensorflow, Torch/ PyTorch, ONNX, etc
 Previously worked with distributed computing environments such as Hadoop.


 Contract Requirements Regarding Education And Experience Will Prevail.
 Salary range: $86K-$110K  When you become part of the KBR team, your career opportunities are endless. Our people are the heart of everything we do here at KBR. We Value our People!  KBR offers a selection of competitive lifestyle benefits, which could include a 401K plan with company match, medical, dental, vision, life insurance, AD&D, flexible spending account, disability, paid time off, or flexible work schedule. We support career advancement through professional training and development.  At KBR, we are passionate about our people, sustainability, and Zero Harm culture. These ideals form all that we do and are at the heart of our commitment to, and ongoing journey toward, being a more inclusive and diverse company. That commitment is central to our team of team’s philosophy and fosters an environment of real collaboration across cultures and locations. Our individual differences and perspectives enhance our teams' value and help us develop solutions for the most challenging problems. We understand that embracing those differences and working together makes us more innovative, resilient, and safer. We Deliver — Together.

 KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.

",86000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'tableau', 'aws', 'azure', 'etl', 'sql', 'hadoop']"
"GenAI Machine Learning Engineer, Performance Optimization",Databricks,CA,Full-time,"
P-984
 Founded in late 2020 by a small group of machine learning engineers and researchers, MosaicML enables companies to securely fine-tune, train and deploy custom AI models on their own data, for maximum security and control. Compatible with all major cloud providers, the MosaicML platform provides maximum flexibility for AI development. Introduced in 2023, MosaicML’s pretrained transformer models have established a new standard for open source, commercially usable LLMs and have been downloaded over 3 million times. MosaicML is committed to the belief that a company’s AI models are just as valuable as any other core IP, and that high-quality AI models should be available to all.
 Now part of Databricks since July 2023, we are passionate about enabling our customers to solve the world's toughest problems — from making the next mode of transportation a reality to accelerating the development of medical breakthroughs. We do this by building and running the world's best data and AI platform so our customers can use deep data insights to improve their business. We leap at every opportunity to solve technical challenges, striving to empower our customers with the best data and AI capabilities.
 You will:

Explore and analyze performance bottlenecks in ML training and inference
Design, implement and benchmark libraries and methods to overcome aforementioned bottlenecks
Build tools for performance profiling, analysis, and estimation for ML training and inference
Balance the tradeoff between performance and usability for our customers
Facilitate our community through documentation, talks, tutorials, and collaborations
Collaborate with external researchers and leading AI companies on various efficiency methods

We look for:

Hands on experience the internals of deep learning frameworks (e.g. PyTorch, TensorFlow) and deep learning models
Experience with high-performance linear algebra libraries such as cuDNN, CUTLASS, Eigen, MKL, etc.
General experience with the training and deployment of ML models
Experience with compiler technologies relevant to machine learning
Experience with distributed systems development or distributed ML workloads
Hands on experience with writing CUDA code and knowledge of GPU internals (Preferred)
Publications in top tier ML or System Conferences such as MLSys, ICML, ICLR, KDD, NeurIPS (Preferred)

We value candidates who are curious about all parts of the company's success and are willing to learn new technologies along the way.



 Pay Range Transparency

      Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.
    



     Local Pay Range
   

     $150,000—$190,000 USD
   



 About Databricks
 Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
 Our Commitment to Diversity and Inclusion
 At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance

    If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.
  

",150000,"['tensorflow', 'pytorch', 'machine learning', 'deep learning', 'apache spark']"
"Solutions Engineer, Machine Learning",Coactive AI,CA,Full-time,"

Coactive makes it easy to search, filter, and analyze visual content. Increasingly image and video data captures the content we watch, the products we buy, and the work we do, and already represents 80% of internet traffic. But rather than being an asset, visual content is often a tax or even a liability because it is so hard to work with and understand. Coactive solves this by bringing structure to unstructured data. Rather than spending months (or years) building complex infrastructure, data teams can unlock the value of their visual data in minutes to power use cases such as content understanding and moderation, search, and analytics.
 Coactive was founded by experts who shaped the fields of high-performance deep learning and data-centric AI. We have the scars from building and working with the first generation of modern machine learning systems at Google, Meta (formerly Facebook), Pinterest, eBay, Lyft, and other leading organizations. Through our decades of experience, we have developed a playbook to democratize the toughest parts of machine learning systems; no PhD required.

 As a solutions engineer, you will work at the intersection of sales, customer success, and machine learning to help us solve customers' most pressing problems with unstructured image and video data. In this role you will work coactively across the engineering (specifically, machine learning), sales, and customer success teams to build repeatable processes, as well as guide the sale and adoption of Coactive's products. You will leverage your understanding and empathy to support the strategic and technical needs of customers across the customer lifecycle.


 What you'll do:



Provide technical support for sales and customer success, and implement a system for communicating product feedback.
Create and deliver enterprise-grade technical materials to support sales (e.g., video tutorials, documentation, vertical-specific demos, etc.)
Lead and execute successful customer Proof-of-Value engagements.
Design and lead technical workshops for existing customers (as well as potentially new customers, as needed).
Support internal teams (e.g., product, engineering, marketing, customer success, sales) by serving as an advocate for prospects and provide feedback from field engagements.
Maintain clear documentation and processes to facilitate repeatable and effective collaboration.
Occasional travel to customer on-sites and conferences.



 What we look for:

BS (or higher) in Computer Science or related fields, or equivalent professional experience
2+ years of production-level experience in one of: Python, Java, C++, or similar language
Experience with data infrastructure and ML tools is required, such as PyTorch, TensorFlow, scikit-learn, MLflow, Spark and Ray
Experience providing technical guidance/support during customer calls and sales discussions, and as needed for addressing product usage needs and issues
Experience developing pre and post sales materials and enthusiasm for operating as a mentor/educator for other Solutions Engineers and/or Account Executives
Knowledge of and experience with leading customers to solutions that provide value and grow usage of enterprise products
Ability to create tooling to enable non-technical teams
Ability to adapt to change in a fast-paced startup environment, especially with regard to designing and implementing valuable solutions
2+ years of customer-facing enterprise sales experience preferred
Previous experience as a machine learning engineer is a plus



 What you can expect from us:
 This is a hybrid position based in San Jose, California.
 The estimated annual base salary for this position is between $125,000-$156,000.*
 At Coactive, cash salary is only one part of our total compensation package. Other benefits for this position include, but are not limited to:

Market leading equity grants
100% medical, dental, & vision coverage for you
Medical, dental, & vision partially covered for your dependents
Unlimited PTO
A workspace allowance
Social events ranging from book clubs, happy hours, and hiking to board game nights and games of Mario Kart.

Further, you can expect a supportive work environment from us. We build products, but we develop people.



Actual pay is dependent on an individual candidate's professional background, experience, skills and qualifications, as well as market demand and business demands. This pay range is subject to change and may be modified in the future. The salary, other compensation, and benefits information is accurate as of the date of this posting.


 We embrace and celebrate the diversity of our employees. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.
 We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

",125000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Statistical Clerk,SIU Medicine,IL,Full-time,"Department: Center for Clinical Research-SMS 

Division: NA 

Location: .Springfield 

Job Category: Business 


Overview:
 The primary function of the position is to provide statistical support, and other related duties, to achieve success in research projects for the Center of Clinical Research (CCR). The appointee will be responsible for compiling statistical data and interpreting quantitative information by application of statistical methods related to studies being supported by the CCR. 


Salary: $17.56/hour 
SOUTHERN ILLINOIS UNIVERSITY SCHOOL OF MEDICINE 
CIVIL SERVICE POSITION DESCRIPTION 

 INCUMBENT CSN FLSA STATUS non-exempt 

 PRESENT CLASSIFICATION Statistical Clerk DATE 

 DEPARTMENT/DIVISION Center for Clinical Research 

 FUNCTION 

 The primary function of the position is to provide statistical support, and other related duties, to 
achieve success in research projects for the Center of Clinical Research (CCR). The appointee 
will be responsible for compiling statistical data and interpreting quantitative information by 
application of statistical methods related to studies being supported by the CCR. 

 ORGANIZATIONAL RELATIONSHIP 

 This position reports to the Director of the Statistics and Informatics Division, who reports to the 
Director, Center for Clinical Research. 

 DUTIES AND RESPONSIBILITIES 

 The following information is intended to be representative of the work performed by incumbent 
in this position and is not all-inclusive. The omission of a specific duty or responsibility will not 
preclude it from the position if the work is similar, related, or a logical extension of position 
responsibilities. 

 Demonstrates, by actions, commitment to the mission and the behavioral standards of SIU 
School of Medicine. Provides excellent service to both internal and external customers through 
collaboration and partnership; compassion and respect; integrity and accountability; diversity and 
inclusion; as well as continuous learning and improvement. 

 TIME COMMITMENT 

 I. Research 100% 

 a. Prepares data for analysis by organizing information, checking for any inaccuracies such 
as out of range values/outliers. 

 b. Checks information and data for accuracy and makes corrections. 
c. Prepares data for computer input; analyzes, compiles and interprets results. 
d. Prepares tables, graphs, and reports on numeric or quantitative results using software 

 packages; compiles and provides requested data by using statistical, graphical, 
spreadsheet and database software packages. 

 e. Recommends ways to improve the collection and tabulation of data. 
f. Participates in the analyses of quantitative statistical data. 
g. Reports results of descriptive and inferential statistical analyses, including information in 

 the form of graphs, charts, and tables. 
h. Works with others in the Statistics and Informatics Division to determine project plans 

 and ensure goals are met. 

 i. Performs other related duties as assigned. 

 SKILLS AND ABILITIES NEEDED FOR THE POSITION 



Sensitive to the needs of underrepresented minority populations
Working knowledge of at least one statistical software package such as SAS, SPSS, R, or
 Stata 


Ability to learn databases systems such Access, SQL, and REDCap
Knowledge of statistical procedures
Knowledge of data management tools and Microsoft Office Programs
Skills in operation of office equipment
Ability to work with numerical data
Arithmetical accuracy
 RESPONSIBILITY 

 A. Supervisory Controls - After initial training of job responsibilities, employee will be 
expected to perform duties with minimal supervision. Employee must to be able to determine 
priorities and work independently in order to complete duties in an efficient and effective 
manner. Supervisor will function more in the capacity of a consultant instead of actually 
supervising each work assignment. Deadline and general instructions must be established for 
certain projects, however, it will be the employee’s responsibility to organize and complete 
the projects by utilizing his or her own initiative, creativity and judgment. 

 B. Guidelines – The incumbent will be required to abide by the rules, regulations, and policies 

 outlined by SIU School of Medicine, the Center for Clinical Research, and the State of 
Illinois. Describe the extent to which this employee is restricted by or free from the use of 
guidelines in performing work. 

 DIFFICULTY 

 A. Complexity – The incumbent must be able perform a variety of statistical related tasks to 
assist in the support of research projects as outlined by the supervisor. Timely response to 
requests is required. Standard office equipment, personal computers, statistical software 
packages, and database systems will be used to perform duties. Attention to details and the 
use of sound judgement are imperative. 

 B. Scope and Effect – The incumbent is to provide daily statistical assistance and support to 
various research projects being supported by the CCR. This will require flexibility and the 
ability to meet strict deadlines. The ability to learn and work with various statistical software 
and database systems is critical. 

 PERSONAL CONTACTS 

 The incumbent will have contact with a variety of SIU staff and faculty in multiple departments 
via face-to-face meetings, phone calls, and email communications in order to complete statistical 
support on various research projects. 

 ENVIRONMENTAL, HEALTH AND SAFETY RESPONSIBILITIES 

 Participates in meetings, trainings and other environmental, health and safety activities as 
required by SIU School of Medicine. 

 WORKING CONDITIONS 

 See attached form outlining the physical and environmental requirements of the position. 

 ____________________________________ ________________________________ 
Incumbent Date Albert Botchway, Ph.D. Date 
Statistical Clerk Supervisor 
Center for Clinical Research Director, Statistics and Informatics Division 
Center for Clinical Research 

 _____________________________________ 
Joseph C. Milbrandt, Ph.D. Date 
Director, Center for Clinical Research 

 PHYSICAL AND ENVIRONMENTAL REQUIREMENTS 
SIU SCHOOL OF MEDICINE 


Incumbent: Classification: Statistical Clerk 


-

Position No. (If applicable): Department: Center for Clinical Research-SMS 


WORK ENVIRONMENT: (Check all applicable environments) 

 Office Hospital 

 Clinic Warehouse 

 Research Laboratory Outdoors 


Other (Be Specific):

PHYSICAL DEMANDS: Seldom Occasionally Frequently Constantly N/A 

 (Indicate frequency of activity during (Performed rarely less (Performed less than (Performed 26% to 50% of the time) (Performed 51 % or most of the time) 
performance of position duties) than 2% of the time) 25% of the time) 

 (Click on the Physical Demands Definitions button at the bottom of the form for a list of physical demands definitions) 

 Bm!ing 0 0 0 @ 0 

 Writing 0 0 @ 0 0 

 0 0 @ 0 0 

 Close visual acui 0 0 0 @ 0 

 To!'le! @ 0 0 0 0 

 Hearing - Qgnve!11atign 0 0 @ 0 0 

 Hearing - Qther Sounds 0 0 @ 0 0 

 filQQping_ @ 0 0 0 0 

 @ 0 0 0 0 

 Gross hand manipulation 0 @ 0 0 0 

 Fine hand manipulation 0 0 0 @ 0 

 Working in dust fumes gases gr irritants 0 0 0 0 @ 

 Working at heights 0 0 0 0 @ 

 Working in extreme @Id heat and/gr humidi 0 0 0 0 @ 

 Working in close Quarte!11 0 0 0 0 @ 

 C!i.m.bing 0 0 0 0 @ 

 Qperating mgtgr vehicles @ 0 0 0 0 

 Sitting 0 0 0 @ 0 

 filaru!ing_ 0 @ 0 0 0 

 wa!king_ 0 @ 0 0 0 

 Working above shoulder level @ 0 0 0 0 

 Twisting @ 0 0 0 0 

 Kneeling @ 0 0 0 0 

 Pushing or pulling @ 

 Carrml Less than 5 lbs. 0 

 Lifting Less than 5 lbs. 0 


Other (Please list): 0 0 0 0 0 
I affirm the environmental and physical demands hsted on this form are an accurate reflection of the I have read, understand and am capable of meeting the physical and 
requirements of this position to the best of my knowledge and belief. environmental demands of this position. 

 __________________ Albert Botchway, PhD 

 Supervisor Signature Date Supervisor Name Employee Signature Date 

 HR-0195S Page 1 of 1 
01/10",35120,['sql']
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Sr. Data Engineer,"The Travelers Companies, Inc.",CT,Full-time,"












































































































                                                                                                             Who Are We?
                                                                                                            









































































                                      Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
                                    








































































                                      Job Category
                                    


































 Technology
 

   Compensation Overview
 

   The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
 


   Salary Range
  $138,100.00 - $227,800.00
 




































                                      Target Openings
                                    


































 1
 












































































































                                                                                                              What Is the Opportunity?
                                                                                                            










































































































 Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
 
   What Will You Do?
 

 Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.
 Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 Incorporate core data management competencies including data governance, data security and data quality.
 Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment.
 Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate.
 Collaborate across team to support delivery and educate end users on complex data products/analytic environment.
 Perform other duties as assigned.


   What Will Our Ideal Candidate Have?
 

 Bachelor’s Degree in STEM related field or equivalent
 Ten years of related experience
 Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices.
 Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems.
 Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers.
 Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize.
 Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas.
 Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members.
 Experience with some of the following tools & platforms (or similar): AWS (s3, Lambda, Kinesis, API Gateway, IAM, Glue, SNS, SQS, EventBridge, EKS, VPC, Step Functions, ECS/EKS, DynamoDB, etc.), Databricks, Python, JavaScript, Kafka, dbt, Terraform, Snowflake, SQL, Jenkins, Github, Airflow, OpenSearch (Elasticsearch & Kibana), Talend, Alation, Neo4j, Hashicorp Vault / AWS Secrets Manager, Docker / OpenShift / Open Cloud Foundry, MongoDB, Docker, BlackDuck, SonarQube.
 Knowledge and experience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Datalakes, Data Security, Networking, Serverless, Testing/Test Automation (Unit, Integration, Performance, etc.), WebServices, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization.



   What is a Must Have?
 

 Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 Five years of data engineering or equivalent experience.



   What Is in It for You?
 

 Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
 Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.






































                                      Employment Practices
                                    

                                      Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.
                                    

 If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an 
                                     
                                      email
                                      so we may assist you.
                                    

 Travelers reserves the right to fill this position at a level above or below the level included in this posting.
                                    













































                                                                                 To learn more about our comprehensive benefit programs please visit 
                                                                                
                                                                                 http://careers.travelers.com/life-at-travelers/benefits/
                                                                                .
                                                                               














































































",138100,"['python', 'machine learning', 'aws', 'docker', 'sql', 'airflow', 'kafka']"
Hewlett Packard Labs - Machine Learning Research Scientist,Hewlett-Packard CDS GmbH,CA,Full-time,"













This role has been designated as ‘’Onsite’ with an expectation that you will primarily work from an HPE office.






















 Who We Are:




























 Hewlett Packard Enterprise is the global edge-to-cloud company advancing the way people live and work. We help companies connect, protect, analyze, and act on their data and applications wherever they live, from edge to cloud, so they can turn insights into outcomes at the speed required to thrive in today’s complex world. Our culture thrives on finding new and better ways to accelerate what’s next. We know diverse backgrounds are valued and succeed here. We have the flexibility to manage our work and personal needs. We make bold moves, together, and are a force for good. If you are looking to stretch and grow your career our culture will embrace you. Open up opportunities with HPE.















 Job Description:

 The AI research team at Hewlett Packard Labs seeks highly qualified, self-motivated researchers to accelerate research toward Reinforcement Learning and Machine Learning applications in the area of sustainability, digital twins, LLMs, the trustworthiness of AI, complex scientific applications like nuclear fusion, sports analytics, and other domains. This position is for the core AI research team at Hewlett Packard Labs.

 Hewlett Packard Labs is an internationally renowned research organization with its headquarters and largest facility in Milpitas, California, in the San Francisco Bay area. As the central research organization for Hewlett Packard Enterprise (HPE), Hewlett Packard Labs' purpose is to deliver breakthrough technologies and technology advancements that provide a competitive advantage for the company, by investing in fundamental science and technology in areas of interest to HPE and getting the resulting technologies ready for adoption into new and existing markets.

 The Artificial Intelligence Research Lab focuses on researching and developing technologies, architectures, and software to develop cutting-edge solutions in key areas of Deep Learning and Machine Learning, including Reinforcement Learning. This team focuses on complex multi-objective and multi-agent Reinforcement Learning with innovative applications to sustainability at scale, complex clean energy generation, nuclear fusion, and similar complex problems. The team also works on the robustness and explainability of models, 2D and 3D computer vision, and NLP / LLMs. There is work related to the use of reinforcement and transformers for model free optimizations. The team also works on fine tuning and self-correction of LLMs and all aspect of trust of LLMs. This is a unique opportunity to work at a start-up pace within a big company. We are looking for an entrepreneurial mind-set, and a deep passion to take a ML problem and conduct research and come up with a solution with a fast turnaround time. You will have an opportunity to work with Machine Learning experts who have made multiple successful products and get guidance and coaching in different areas including software engineering, hardware optimizations, data pipelining, and innovations from the latest AI research to bring hardened Deep Learning solutions to the real world. 

This is a new and growing team at HPE in which you will be building the software and applications for Neural Network and Machine Learning. It will also involve working with system programming, Deep Learning frameworks and models, GPU acceleration, Model optimization, real-time streaming data, distributed computing, and deployment.

 We are seeking highly qualified candidates to come join one of our research teams as an intern or a post-doc, with the possibility of longer-term co-innovation and collaboration. We are particularly interested in individuals with a background in computer systems, machine learning, deep learning, and statistics, with a good understanding of the current state of the art, major trends and opportunities, and a demonstrated track record in making things real in innovative ways. The ideal candidate combines this interest with a broad, entrepreneurial interest in creating the next generation of HPE’s products and technologies.

 We expect all our researchers including interns and post-docs to provide thought leadership and technical influence both internally and externally to HPE, as well as take innovative ideas and make them real – contributing along the full range from initial novel ideas to design, development, implementation, evaluation, and technology transfer. The ideal candidate can thrive in an applied research environment, balancing significant technical and scientific contributions with the ability to bring such contributions to practice through innovative solutions that address the needs of our customers and partners. We expect the successful candidate to collaborate with Hewlett Packard Labs research teams as well as with external partners, and to work in alignment with HPE's broader innovation community. Excellent software systems building skills are a significant plus.

 Education and Experience 

PhD degree (with significant research and innovation experience) in a relevant discipline (e.g. machine learning, computer science, statistics, etc.)
 Track record of world-class innovative contributions and ideas in machine learning.


 Technical Skills: 

Experience in emerging ML areas, including reinforcement learning and generative AI research
 Experience in developing ML software with high proficiency in data structures and algorithms.
 Experience in Machine Learning frameworks like PyTorch - required
 Strong programming skills and experience with Python
 Software development experience in Deep Learning, GPU acceleration, and Model Optimization.
 Demonstrated ability to generate, frame, and carry out leadership research as shown, for example, by papers published in top-tier ML conferences or journals.









 Additional Skills:






 Accountability, Accountability, Action Planning, Active Learning, Active Listening, Bias, Business, Calendar Management, Coaching, Computer Literacy, Creativity, Critical Thinking, Design Thinking, Empathy, Follow-Through, Growth Mindset, Intellectual Curiosity, Long Term Planning, Managing Ambiguity, Office Administration, Policy and procedures, Problem Solving, Project Management, Recordkeeping, Risk Assessment {+ 5 more}
      







 What We Can Offer You:







 Health & Wellbeing
 We strive to provide our team members and their loved ones with a comprehensive suite of benefits that supports their physical, financial and emotional wellbeing.

 Personal & Professional Development
 We also invest in your career because the better you are, the better we all are. We have specific programs catered to helping you reach any career goals you have — whether you want to become a knowledge expert in your field or apply your skills to another division.

 Diversity, Inclusion & Belonging
 We are unconditionally inclusive in the way we work and celebrate individual uniqueness. We know diverse backgrounds are valued and succeed here. We have the flexibility to manage our work and personal needs. We make bold moves, together, and are a force for good.








 Let's Stay Connected:





















 Follow @HPECareers on Instagram to see the latest on people, culture and tech at HPE. 















Job: Administration
       Job Level: N/A
      
 States with Pay Range Requirement

 The expected salary/wage range for a U.S.-based hire filling this position is provided below. Actual offer may vary from this range based upon geographic location, work experience, education/training, and/or skill level. If this is a sales role, then the listed salary range reflects combined base salary and target-level sales compensation pay. If this is a non-sales role, then the listed salary range reflects base salary only. Variable incentives may also be offered. Information about employee benefits offered can be found at https://myhperewards.com/main/new-hire-enrollment.html.
 Hourly: $53.00 - $64.25
      







 HPE is an Equal Employment Opportunity/ Veterans/Disabled/LGBT and Affirmative Action employer. We are committed to diversity and building a team that represents a variety of backgrounds, perspectives, and skills. We do not discriminate and all decisions we make are made on the basis of qualifications, merit, and business need. Our goal is to be one global diverse team that is representative of our customers, in an inclusive environment where we can continue to innovate and grow together. Please click here: Equal Employment Opportunity.







 Hewlett Packard Enterprise is EEO F/M/Protected Veteran/ Individual with Disabilities.

 HPE will comply with all applicable laws related to employer use of arrest and conviction records, including laws requiring employers to consider for employment qualified applicants with criminal histories. .






",106000,"['pytorch', 'python', 'machine learning', 'deep learning']"
"Solutions Engineer, Machine Learning",Coactive AI,CA,Full-time,"

Coactive makes it easy to search, filter, and analyze visual content. Increasingly image and video data captures the content we watch, the products we buy, and the work we do, and already represents 80% of internet traffic. But rather than being an asset, visual content is often a tax or even a liability because it is so hard to work with and understand. Coactive solves this by bringing structure to unstructured data. Rather than spending months (or years) building complex infrastructure, data teams can unlock the value of their visual data in minutes to power use cases such as content understanding and moderation, search, and analytics.
 Coactive was founded by experts who shaped the fields of high-performance deep learning and data-centric AI. We have the scars from building and working with the first generation of modern machine learning systems at Google, Meta (formerly Facebook), Pinterest, eBay, Lyft, and other leading organizations. Through our decades of experience, we have developed a playbook to democratize the toughest parts of machine learning systems; no PhD required.

 As a solutions engineer, you will work at the intersection of sales, customer success, and machine learning to help us solve customers' most pressing problems with unstructured image and video data. In this role you will work coactively across the engineering (specifically, machine learning), sales, and customer success teams to build repeatable processes, as well as guide the sale and adoption of Coactive's products. You will leverage your understanding and empathy to support the strategic and technical needs of customers across the customer lifecycle.


 What you'll do:



Provide technical support for sales and customer success, and implement a system for communicating product feedback.
Create and deliver enterprise-grade technical materials to support sales (e.g., video tutorials, documentation, vertical-specific demos, etc.)
Lead and execute successful customer Proof-of-Value engagements.
Design and lead technical workshops for existing customers (as well as potentially new customers, as needed).
Support internal teams (e.g., product, engineering, marketing, customer success, sales) by serving as an advocate for prospects and provide feedback from field engagements.
Maintain clear documentation and processes to facilitate repeatable and effective collaboration.
Occasional travel to customer on-sites and conferences.



 What we look for:

BS (or higher) in Computer Science or related fields, or equivalent professional experience
2+ years of production-level experience in one of: Python, Java, C++, or similar language
Experience with data infrastructure and ML tools is required, such as PyTorch, TensorFlow, scikit-learn, MLflow, Spark and Ray
Experience providing technical guidance/support during customer calls and sales discussions, and as needed for addressing product usage needs and issues
Experience developing pre and post sales materials and enthusiasm for operating as a mentor/educator for other Solutions Engineers and/or Account Executives
Knowledge of and experience with leading customers to solutions that provide value and grow usage of enterprise products
Ability to create tooling to enable non-technical teams
Ability to adapt to change in a fast-paced startup environment, especially with regard to designing and implementing valuable solutions
2+ years of customer-facing enterprise sales experience preferred
Previous experience as a machine learning engineer is a plus



 What you can expect from us:
 This is a hybrid position based in San Jose, California.
 The estimated annual base salary for this position is between $125,000-$156,000.*
 At Coactive, cash salary is only one part of our total compensation package. Other benefits for this position include, but are not limited to:

Market leading equity grants
100% medical, dental, & vision coverage for you
Medical, dental, & vision partially covered for your dependents
Unlimited PTO
A workspace allowance
Social events ranging from book clubs, happy hours, and hiking to board game nights and games of Mario Kart.

Further, you can expect a supportive work environment from us. We build products, but we develop people.



Actual pay is dependent on an individual candidate's professional background, experience, skills and qualifications, as well as market demand and business demands. This pay range is subject to change and may be modified in the future. The salary, other compensation, and benefits information is accurate as of the date of this posting.


 We embrace and celebrate the diversity of our employees. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.
 We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

",125000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Statistical Clerk,SIU Medicine,IL,Full-time,"Department: Center for Clinical Research-SMS 

Division: NA 

Location: .Springfield 

Job Category: Business 


Overview:
 The primary function of the position is to provide statistical support, and other related duties, to achieve success in research projects for the Center of Clinical Research (CCR). The appointee will be responsible for compiling statistical data and interpreting quantitative information by application of statistical methods related to studies being supported by the CCR. 


Salary: $17.56/hour 
SOUTHERN ILLINOIS UNIVERSITY SCHOOL OF MEDICINE 
CIVIL SERVICE POSITION DESCRIPTION 

 INCUMBENT CSN FLSA STATUS non-exempt 

 PRESENT CLASSIFICATION Statistical Clerk DATE 

 DEPARTMENT/DIVISION Center for Clinical Research 

 FUNCTION 

 The primary function of the position is to provide statistical support, and other related duties, to 
achieve success in research projects for the Center of Clinical Research (CCR). The appointee 
will be responsible for compiling statistical data and interpreting quantitative information by 
application of statistical methods related to studies being supported by the CCR. 

 ORGANIZATIONAL RELATIONSHIP 

 This position reports to the Director of the Statistics and Informatics Division, who reports to the 
Director, Center for Clinical Research. 

 DUTIES AND RESPONSIBILITIES 

 The following information is intended to be representative of the work performed by incumbent 
in this position and is not all-inclusive. The omission of a specific duty or responsibility will not 
preclude it from the position if the work is similar, related, or a logical extension of position 
responsibilities. 

 Demonstrates, by actions, commitment to the mission and the behavioral standards of SIU 
School of Medicine. Provides excellent service to both internal and external customers through 
collaboration and partnership; compassion and respect; integrity and accountability; diversity and 
inclusion; as well as continuous learning and improvement. 

 TIME COMMITMENT 

 I. Research 100% 

 a. Prepares data for analysis by organizing information, checking for any inaccuracies such 
as out of range values/outliers. 

 b. Checks information and data for accuracy and makes corrections. 
c. Prepares data for computer input; analyzes, compiles and interprets results. 
d. Prepares tables, graphs, and reports on numeric or quantitative results using software 

 packages; compiles and provides requested data by using statistical, graphical, 
spreadsheet and database software packages. 

 e. Recommends ways to improve the collection and tabulation of data. 
f. Participates in the analyses of quantitative statistical data. 
g. Reports results of descriptive and inferential statistical analyses, including information in 

 the form of graphs, charts, and tables. 
h. Works with others in the Statistics and Informatics Division to determine project plans 

 and ensure goals are met. 

 i. Performs other related duties as assigned. 

 SKILLS AND ABILITIES NEEDED FOR THE POSITION 



Sensitive to the needs of underrepresented minority populations
Working knowledge of at least one statistical software package such as SAS, SPSS, R, or
 Stata 


Ability to learn databases systems such Access, SQL, and REDCap
Knowledge of statistical procedures
Knowledge of data management tools and Microsoft Office Programs
Skills in operation of office equipment
Ability to work with numerical data
Arithmetical accuracy
 RESPONSIBILITY 

 A. Supervisory Controls - After initial training of job responsibilities, employee will be 
expected to perform duties with minimal supervision. Employee must to be able to determine 
priorities and work independently in order to complete duties in an efficient and effective 
manner. Supervisor will function more in the capacity of a consultant instead of actually 
supervising each work assignment. Deadline and general instructions must be established for 
certain projects, however, it will be the employee’s responsibility to organize and complete 
the projects by utilizing his or her own initiative, creativity and judgment. 

 B. Guidelines – The incumbent will be required to abide by the rules, regulations, and policies 

 outlined by SIU School of Medicine, the Center for Clinical Research, and the State of 
Illinois. Describe the extent to which this employee is restricted by or free from the use of 
guidelines in performing work. 

 DIFFICULTY 

 A. Complexity – The incumbent must be able perform a variety of statistical related tasks to 
assist in the support of research projects as outlined by the supervisor. Timely response to 
requests is required. Standard office equipment, personal computers, statistical software 
packages, and database systems will be used to perform duties. Attention to details and the 
use of sound judgement are imperative. 

 B. Scope and Effect – The incumbent is to provide daily statistical assistance and support to 
various research projects being supported by the CCR. This will require flexibility and the 
ability to meet strict deadlines. The ability to learn and work with various statistical software 
and database systems is critical. 

 PERSONAL CONTACTS 

 The incumbent will have contact with a variety of SIU staff and faculty in multiple departments 
via face-to-face meetings, phone calls, and email communications in order to complete statistical 
support on various research projects. 

 ENVIRONMENTAL, HEALTH AND SAFETY RESPONSIBILITIES 

 Participates in meetings, trainings and other environmental, health and safety activities as 
required by SIU School of Medicine. 

 WORKING CONDITIONS 

 See attached form outlining the physical and environmental requirements of the position. 

 ____________________________________ ________________________________ 
Incumbent Date Albert Botchway, Ph.D. Date 
Statistical Clerk Supervisor 
Center for Clinical Research Director, Statistics and Informatics Division 
Center for Clinical Research 

 _____________________________________ 
Joseph C. Milbrandt, Ph.D. Date 
Director, Center for Clinical Research 

 PHYSICAL AND ENVIRONMENTAL REQUIREMENTS 
SIU SCHOOL OF MEDICINE 


Incumbent: Classification: Statistical Clerk 


-

Position No. (If applicable): Department: Center for Clinical Research-SMS 


WORK ENVIRONMENT: (Check all applicable environments) 

 Office Hospital 

 Clinic Warehouse 

 Research Laboratory Outdoors 


Other (Be Specific):

PHYSICAL DEMANDS: Seldom Occasionally Frequently Constantly N/A 

 (Indicate frequency of activity during (Performed rarely less (Performed less than (Performed 26% to 50% of the time) (Performed 51 % or most of the time) 
performance of position duties) than 2% of the time) 25% of the time) 

 (Click on the Physical Demands Definitions button at the bottom of the form for a list of physical demands definitions) 

 Bm!ing 0 0 0 @ 0 

 Writing 0 0 @ 0 0 

 0 0 @ 0 0 

 Close visual acui 0 0 0 @ 0 

 To!'le! @ 0 0 0 0 

 Hearing - Qgnve!11atign 0 0 @ 0 0 

 Hearing - Qther Sounds 0 0 @ 0 0 

 filQQping_ @ 0 0 0 0 

 @ 0 0 0 0 

 Gross hand manipulation 0 @ 0 0 0 

 Fine hand manipulation 0 0 0 @ 0 

 Working in dust fumes gases gr irritants 0 0 0 0 @ 

 Working at heights 0 0 0 0 @ 

 Working in extreme @Id heat and/gr humidi 0 0 0 0 @ 

 Working in close Quarte!11 0 0 0 0 @ 

 C!i.m.bing 0 0 0 0 @ 

 Qperating mgtgr vehicles @ 0 0 0 0 

 Sitting 0 0 0 @ 0 

 filaru!ing_ 0 @ 0 0 0 

 wa!king_ 0 @ 0 0 0 

 Working above shoulder level @ 0 0 0 0 

 Twisting @ 0 0 0 0 

 Kneeling @ 0 0 0 0 

 Pushing or pulling @ 

 Carrml Less than 5 lbs. 0 

 Lifting Less than 5 lbs. 0 


Other (Please list): 0 0 0 0 0 
I affirm the environmental and physical demands hsted on this form are an accurate reflection of the I have read, understand and am capable of meeting the physical and 
requirements of this position to the best of my knowledge and belief. environmental demands of this position. 

 __________________ Albert Botchway, PhD 

 Supervisor Signature Date Supervisor Name Employee Signature Date 

 HR-0195S Page 1 of 1 
01/10",35120,['sql']
"Scientist I, Computational Biology & Machine Learning",Arsenal Biosciences,CA,Full-time,"








        ArsenalBio, a privately held, clinical-stage programmable cell therapy company engineering advanced CAR T therapies for solid tumors, is seeking a talented Scientist I, Computational Biology & Machine Learning to work hybrid based in our South San Francisco office.
       


 ArsenalBio’s mission is to develop efficacious and safe cellular therapies for patients with chronic diseases, initially cancer. With our programmable and computationally driven approach, our team is engineering living medicines to attack cancer’s inherent multi-faceted nature and overcome the challenges of addressing solid tumors with cell therapy.
       


 Driven by a collective of diverse experts across immunology, synthetic biology, molecular biology, automation and computational biology, we are united in purpose to deliver radical breakthroughs for people with cancer, and prioritize the team’s outcomes over individual goals to achieve our company mission – together.
       


 ArsenalBio is looking for a highly motivated Scientist-I to join the Computational Biology and Machine Learning group. You will work closely with an interdisciplinary team of scientists and engineers to develop algorithms, models, and computational workflows to analyze large amounts of data from a variety of technologies. By addressing challenging problems in synthetic and molecular biology, immunology, and high throughput assays, you will meaningfully contribute to accelerating the development of curative cell therapies against cancer and will have a direct impact on patients' lives.
       

 What You Will Do:

 Analyze data from next generation sequencing assays (eg. RNA-seq, single-cell RNA-seq, ATAC-seq), flow cytometry, or other related technologies.
 Develop machine learning or statistical methods to extract insights from large screening experiments.
 Work closely with ArsenalBio scientists across different functions and disciplines to rapidly iterate through the cycle of experimental design, hypothesis testing, data collection, and interpretation.
 Assist with experimental design, for example through modeling or simulations.
 Help productionize computational workflows so that they can be executed in a robust and reproducible manner.
 Develop visualization tools.


 What Will You Bring:

 Ph.D. in Bioinformatics, Computer Science, Electrical Engineering, Statistics, Biomedical Engineering, Biology, or a related field with 0-2 years of industry experience


OR Masters with 5+ years of industry experience
OR Bachelors with 7+ years of industry experience
 Demonstrated ability to
       
 data analysis and engineering skills to answer biological questions.
 Hands-on experience analyzing next generation sequencing data and/or flow cytometry data.
 Ability to work collaboratively and communicate effectively in an interdisciplinary environment.
 Proficiency in Python or R.
 Experience working in Linux environments.


 Additional Desired Skills:

 Familiarity with cloud computing environments and version control systems (eg. git).
 Familiarity with cell therapy or immunotherapy will be appreciated, but not required.



 What We Will Offer You:


         An opportunity to work with the best talent in the field of cell therapy, and be part of ONE TEAM to advance therapies to patients who need it most.
       


 ArsenalBio has a generous and comprehensive benefits package that includes but is not limited to medical, dental, and vision as well as mental health resources, virtual and telehealth options, coaching, infertility treatment, parental leave and health savings accounts. We also offer flexible work schedules and flexible time off, which includes two extra “Arsenal Days of Rest” every quarter for employees to recharge.
       


 We have a robust mentorship program, and comprehensive development tools to help employees take control of their career paths and grow into their best selves. ArsenalBio believes in investing in the well-being of our employees - both at work and at home, as they are our greatest asset. They bring scientific talents in molecular biology, immunology, pharmacology, protein chemistry, computational biology, automation, genome engineering, software and other fields to make the future happen now.
       


 We are committed to hiring the best talent from diverse backgrounds. A diverse workforce engenders richness of thought, creativity and discovery. We invite individuals who embrace intellectual achievement to bring their unique personal and professional journeys and together we will build transformative cell therapies for cancer patients.
       


 We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
       


 The estimated base salary offer for the preferred primary location of San Francisco Bay area ranges from $126,100–$154,500.
       

         Salary ranges for other locations may vary from this range. Base pay offered may vary depending on job related knowledge, experience, education, and location. In addition to these factors, we believe in the importance of pay equity and consider internal equity of our current employees as part of any final offer.
       


 To all recruitment agencies: ArsenalBio does not accept agency resumes. Please do not forward resumes to our jobs alias, or ArsenalBio employees. ArsenalBio is not responsible for any fees related to unsolicited resumes.
       




 








Bold ideas. Reliable data. World-Class Science.
Designing therapies to cure our most important health challenges requires the audacity to advance a bold idea and explore new biologies with world-class science. 

            By pushing at the frontiers of science, challenging what we think we know, and holding ourselves to the highest standards of irrefutable proof, we are reshaping the future of curative cellular therapies. 
           














Benefits

                ArsenalBio is powered by people.
               





                And we believe that people work best when given freedom and flexibility in a supportive environment that allows us all to show up as our true selves. We respect that your life extends beyond the work we’ll do here together, and we continually strive to provide you with what you need to care for yourself and your family.
               









               Health & Wellness
              
 




               Financial Well-Being
              
 




               Time Off
              
 




               Mindful Workspace
              
 














ArsenalBio was formed by its investors and scientific founders to discover, develop and commercialize curative and safe cellular therapies for patients with life threatening diseases, initially cancer. 
We believe the most productive and secure route to achieving this goal is to build scaled platforms of technologies challenged with scientific questions to yield informative data from hypothesis driven, well controlled experiments. These data will inform the design of ambitious, best-in-class, lead compositions. Our leads will be rigorously evaluated and honed until we are convinced our matured leads, called development candidates, can be prepared for testing in needy, and vulnerable patients. 
Our products will be designed to speed the transition of cell therapy from hospital-based to outpatient treatments, increasing access to more patients at lower cost to patients, health systems, and insurers. 
To achieve this mission, we are building diverse teams of talented, curious, and caring individuals who believe in our mission and our vision to be sustainable in our business plan, our work habits, and our personal lives. 
Our values create: a foundation for mutual respect, an engaging harmony from many voices, and unselfish behavior to aid our colleagues. 

            This is ArsenalBio.
             This is our Company.
           










",126100,"['python', 'machine learning', 'git']"
Lead Data Scientist,McKesson,TX,Full-time,"
 McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve - we care. What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow's health today, we want to hear from you.
 

Position Description
:

 McKesson Technology Enterprise Analytics is seeking a Lead Data Scientist that is passionate about developing machine learning applications that ensure patients receive the medications they need, when they need them; improve quality of care for oncology patients; and exemplify operational excellence so that the business can focus on what matters most, creating value for our customers.
 

Key responsibilities: 


Develop, design, build, and oversee data science solutions to provide predictive insights that further McKesson's vision to improve care in every setting.
 Drive adoption of best-in-class capabilities, including Deep Learning, Natural Language Processing, Large Language Models and Next Best Action Recommenders.
 Direct in-house data scientists and consulting teams; Provide analytics leadership; Provide machine learning and statistical expertise. Serve as an advisor for data scientists across the Enterprise.
 Collaborate with multi-disciplinary team members (data scientists, data engineers and business analysts); Manage business stakeholder relationships to drive action and value from data science insights.
 Collaborate with multi-disciplinary team members; Manage business stakeholder relationships to drive action and value from data science insights;
 Recruit top talent data scientists to join our team.
 Communicate strategy and results to technical and non-technical audiences; Develop and maintain strong relationships with key stakeholders, partners, and internal clients.
 Solve problems from the business point of view, define KPIs, build and execute solid analytics work plans, gather and organize large and complex data assets, perform relevant analyses (data exploration and statistical modeling), automate work streams, foster teamwork in interactions, develop client relationships with business stakeholders, and communicate hypotheses and findings in a structured way.


 Minimum Requirements
:


 Master's degree +6 years of work experience or PhD +3 years, with relevant experience providing advanced analytics solutions The degree should be in computer science, applied mathematics, statistics, machine learning, or a related data centric-technical field.


 Critical Skills
:


 Mentorship experience with machine learning engineers/data scientists in business or scientific research settings.
 Industry experience using TensorFlow, Pytorch and open source software libraries to develop Representation Machine Learning Systems; e.g. Next-Best-Action, Recommendation systems; Deep Learning Neural Networks; Image understanding; Document classification and keyword extraction.
 Experience in core data science and predictive analytics methods: Statistics (t-tests, Poisson process), Segmentation and clustering techniques, predictive modeling: e.g. regression, classification, Time Series analysis: e.g. ARIMA, Traditional machine learning methods: e.g. Random Forest, ensemble model techniques, Optimization: e.g. linear programming.
 Experience in SQL, relational databases: e.g. Snowflake, HANA, Microsoft SQL.
 Expert level skill in a programming language: Python + additional languages (e.g. Java, C/C++).
 Experience with Linux, Shell scripting: e.g. Bash.
 Familiarity with a data visualization tool: e.g. Tableau, Power BI, R.
 Ability to process and synthesize complex data.
 Ability to communicate effectively and professionally, delivering impactful solutions and presenting work in a concise and thoughtful manner.


 Desired Skills
:


 Experience with cloud computing data platforms: e.g. Azure, GCP.
 Experience with distributed computing: e.g. Hadoop, Spark.
 Experience developing open-source machine learning libraries.
 Desire to work in a project-based environment to address business .issues and implement business solutions..
 Driven by making impact with technical and data science expertise, acute strategic and analytical skills; Highly organized with the ability to multitask and prioritize workload.
 Self-motivated, demonstrated ability to manage engagements, serve as a champion of Data Science and able to act as a full member of project team.
 Experience in applied analytics for business problem solving, demand forecasting, analytics solution for pricing, loyalty program effectiveness, customer segmentation, customer LTV maximization, cost and profit analysis, CRM management etc.

 At McKesson, we care about the well-being of the patients and communities we serve, and that starts with caring for our people. That's why we have a Total Rewards package that includes comprehensive benefits to support physical, mental, and financial well-being. Our Total Rewards offerings serve the different needs of our diverse employee population and ensure they are the healthiest versions of themselves. For more information regarding benefits at McKesson, please click here.
 
 As part of Total Rewards, we are proud to offer a competitive compensation package at McKesson. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered.
 

Our Base Pay Range for this position

 $147,500 - $245,800
 

McKesson is an Equal Opportunity/Affirmative Action employer. 

 All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.Qualified applicants will not be disqualified from consideration for employment based upon criminal history.
 
 McKesson is committed to being an Equal Employment Opportunity Employer and offers opportunities to all job seekers including job seekers with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to Disability_Accommodation@McKesson.com. Resumes or CVs submitted to this email box will not be accepted.
 
 Current employees must apply through the internal career site.
 

Join us at McKesson!
",147500,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'tableau', 'azure', 'gcp', 'sql', 'hadoop']"
Data Scientist,KBR,MD,Full-time,"
Title: Data Scientist
 
 KBR is looking to add a Data Scientist with Natural Language Processing (NLP) & BI tools experience to our team. Due to contract requirements, candidates must be US Citizens and hold an active/current D.O.D Secret clearance. 

In this role, you will...

 Discover NLP approaches to deliver insights and develop predictive models to meet customer needs.
 Utilize standard data science approaches such as data ingest, ETL, preprocessing, model building, model deploying, and monitoring models once deployed.
 Demonstrate experience working with raw data by processing and ingesting it into a database, cleaning it to be fed into a model, deploying it for some application, and explaining findings clearly to a general audience.
 Troubleshoot problems with data ingesting and processing
 Contribute to research and identification of the most accurate model architecture for current problems.
 Collaborate in data science meetings by presenting on theoretical or applied data science topics.
 Demonstrate the ability to troubleshoot in cloud environments such as AWS, Azure, and Google Cloud.
 Familiarity with machine learning platforms, such as CDSW
 Develop visualizations to convey meaningful insights.
 Present insights from models to a non-technical crowd to convey findings
 Suggest meaningful approaches, models, and services to address problems.
 Stay informed about trends and recent capabilities within data science.


 Required Education, Skills, & Experience
 Education: A bachelor's degree in data science, statistics, computer science, or a related quantitative field.
 Clearance: Active/Current D.O.D Secret Clearance
 Experience: 2 years of relevant work experience

 Proficient in Python; other equivalent languages are considered.
 Experience with BI tools such as QlikSense, Tableau, PowerBI, Zoomdata, etc.
 Experience in NLP approaches, machine learning techniques, and neural networks
 Competent in using SQL and other relational database query languages


 Highly Desired Education, Skills, & Experience
 Education: Masters in data science, statistics, computer science, or a related quantitative field.
 Experience/Skills:

 Excellent communication skills
 Exposure to one more neural network framework – Tensorflow, Torch/ PyTorch, ONNX, etc
 Previously worked with distributed computing environments such as Hadoop.


 Contract Requirements Regarding Education And Experience Will Prevail.
 Salary range: $86K-$110K  When you become part of the KBR team, your career opportunities are endless. Our people are the heart of everything we do here at KBR. We Value our People!  KBR offers a selection of competitive lifestyle benefits, which could include a 401K plan with company match, medical, dental, vision, life insurance, AD&D, flexible spending account, disability, paid time off, or flexible work schedule. We support career advancement through professional training and development.  At KBR, we are passionate about our people, sustainability, and Zero Harm culture. These ideals form all that we do and are at the heart of our commitment to, and ongoing journey toward, being a more inclusive and diverse company. That commitment is central to our team of team’s philosophy and fosters an environment of real collaboration across cultures and locations. Our individual differences and perspectives enhance our teams' value and help us develop solutions for the most challenging problems. We understand that embracing those differences and working together makes us more innovative, resilient, and safer. We Deliver — Together.

 KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.

",86000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'tableau', 'aws', 'azure', 'etl', 'sql', 'hadoop']"
"GenAI Machine Learning Engineer, Performance Optimization",Databricks,CA,Full-time,"
P-984
 Founded in late 2020 by a small group of machine learning engineers and researchers, MosaicML enables companies to securely fine-tune, train and deploy custom AI models on their own data, for maximum security and control. Compatible with all major cloud providers, the MosaicML platform provides maximum flexibility for AI development. Introduced in 2023, MosaicML’s pretrained transformer models have established a new standard for open source, commercially usable LLMs and have been downloaded over 3 million times. MosaicML is committed to the belief that a company’s AI models are just as valuable as any other core IP, and that high-quality AI models should be available to all.
 Now part of Databricks since July 2023, we are passionate about enabling our customers to solve the world's toughest problems — from making the next mode of transportation a reality to accelerating the development of medical breakthroughs. We do this by building and running the world's best data and AI platform so our customers can use deep data insights to improve their business. We leap at every opportunity to solve technical challenges, striving to empower our customers with the best data and AI capabilities.
 You will:

Explore and analyze performance bottlenecks in ML training and inference
Design, implement and benchmark libraries and methods to overcome aforementioned bottlenecks
Build tools for performance profiling, analysis, and estimation for ML training and inference
Balance the tradeoff between performance and usability for our customers
Facilitate our community through documentation, talks, tutorials, and collaborations
Collaborate with external researchers and leading AI companies on various efficiency methods

We look for:

Hands on experience the internals of deep learning frameworks (e.g. PyTorch, TensorFlow) and deep learning models
Experience with high-performance linear algebra libraries such as cuDNN, CUTLASS, Eigen, MKL, etc.
General experience with the training and deployment of ML models
Experience with compiler technologies relevant to machine learning
Experience with distributed systems development or distributed ML workloads
Hands on experience with writing CUDA code and knowledge of GPU internals (Preferred)
Publications in top tier ML or System Conferences such as MLSys, ICML, ICLR, KDD, NeurIPS (Preferred)

We value candidates who are curious about all parts of the company's success and are willing to learn new technologies along the way.



 Pay Range Transparency

      Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.
    



     Local Pay Range
   

     $150,000—$190,000 USD
   



 About Databricks
 Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
 Our Commitment to Diversity and Inclusion
 At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance

    If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.
  

",150000,"['tensorflow', 'pytorch', 'machine learning', 'deep learning', 'apache spark']"
"Solutions Engineer, Machine Learning",Coactive AI,CA,Full-time,"

Coactive makes it easy to search, filter, and analyze visual content. Increasingly image and video data captures the content we watch, the products we buy, and the work we do, and already represents 80% of internet traffic. But rather than being an asset, visual content is often a tax or even a liability because it is so hard to work with and understand. Coactive solves this by bringing structure to unstructured data. Rather than spending months (or years) building complex infrastructure, data teams can unlock the value of their visual data in minutes to power use cases such as content understanding and moderation, search, and analytics.
 Coactive was founded by experts who shaped the fields of high-performance deep learning and data-centric AI. We have the scars from building and working with the first generation of modern machine learning systems at Google, Meta (formerly Facebook), Pinterest, eBay, Lyft, and other leading organizations. Through our decades of experience, we have developed a playbook to democratize the toughest parts of machine learning systems; no PhD required.

 As a solutions engineer, you will work at the intersection of sales, customer success, and machine learning to help us solve customers' most pressing problems with unstructured image and video data. In this role you will work coactively across the engineering (specifically, machine learning), sales, and customer success teams to build repeatable processes, as well as guide the sale and adoption of Coactive's products. You will leverage your understanding and empathy to support the strategic and technical needs of customers across the customer lifecycle.


 What you'll do:



Provide technical support for sales and customer success, and implement a system for communicating product feedback.
Create and deliver enterprise-grade technical materials to support sales (e.g., video tutorials, documentation, vertical-specific demos, etc.)
Lead and execute successful customer Proof-of-Value engagements.
Design and lead technical workshops for existing customers (as well as potentially new customers, as needed).
Support internal teams (e.g., product, engineering, marketing, customer success, sales) by serving as an advocate for prospects and provide feedback from field engagements.
Maintain clear documentation and processes to facilitate repeatable and effective collaboration.
Occasional travel to customer on-sites and conferences.



 What we look for:

BS (or higher) in Computer Science or related fields, or equivalent professional experience
2+ years of production-level experience in one of: Python, Java, C++, or similar language
Experience with data infrastructure and ML tools is required, such as PyTorch, TensorFlow, scikit-learn, MLflow, Spark and Ray
Experience providing technical guidance/support during customer calls and sales discussions, and as needed for addressing product usage needs and issues
Experience developing pre and post sales materials and enthusiasm for operating as a mentor/educator for other Solutions Engineers and/or Account Executives
Knowledge of and experience with leading customers to solutions that provide value and grow usage of enterprise products
Ability to create tooling to enable non-technical teams
Ability to adapt to change in a fast-paced startup environment, especially with regard to designing and implementing valuable solutions
2+ years of customer-facing enterprise sales experience preferred
Previous experience as a machine learning engineer is a plus



 What you can expect from us:
 This is a hybrid position based in San Jose, California.
 The estimated annual base salary for this position is between $125,000-$156,000.*
 At Coactive, cash salary is only one part of our total compensation package. Other benefits for this position include, but are not limited to:

Market leading equity grants
100% medical, dental, & vision coverage for you
Medical, dental, & vision partially covered for your dependents
Unlimited PTO
A workspace allowance
Social events ranging from book clubs, happy hours, and hiking to board game nights and games of Mario Kart.

Further, you can expect a supportive work environment from us. We build products, but we develop people.



Actual pay is dependent on an individual candidate's professional background, experience, skills and qualifications, as well as market demand and business demands. This pay range is subject to change and may be modified in the future. The salary, other compensation, and benefits information is accurate as of the date of this posting.


 We embrace and celebrate the diversity of our employees. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.
 We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

",125000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,PA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,PA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,PA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,PA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Data Modeler,Booz Allen Hamilton,MD,Full-time,"


Job Description










         Location: 
        

         Silver Spring,MD,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184205
        


















         Data Modeler
          The Opportunity:
 Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there’s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need an experienced data engineer like you to help our clients find answers in their big data to impact important missions—from fraud detection to cancer research to national intelligence.

 As a data modeler on our team, you’ll use your extensive technical expertise to lead the design of data architecture solutions for a system or systems architecture. You’ll resolve routine data architecture issues in collaboration with business analysts and technology teams by working with a cross-functional team to make decisions and recommendations on architecture modernization activities. In this role, you’ll your technical expertise, introduce best practices, and use tools like ERWin and MySQL Workbench. You’ll lead your team as it designs, defines, develops, and tests Cloud solution components, and you’ll serve as a liaison between clients and developers to ensure that requirements are met, and solutions are delivered.

 Work with us to use big data for good. 

Join us. The world can’t wait.

 You Have:

 3+ years of experience with data modeling, data architecture, and data analysis
 Experience with creating data models in tools, including Erwin, Embarcadero ER Studio, or Enterprise Architect
 Experience with creating conceptual, logical, and physical data models
 Experience with defining and implementing naming standards, abbreviations, guidelines, and best practices
 Knowledge of relational and dimensional models, keys and constraints, and normalization and indexes
 Ability to document source to target mappings, data dictionaries, and general modeling documentation
 Ability to obtain a security clearance
 Bachelor's degree


 Nice If You Have:

 Experience with working in diverse Agile team environments
 Experience with data querying, data mapping, and transformation analysis
 Experience with using tools, including SQL or Toad for data querying and analysis


 Clearance:
 Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

 Create Your Career:
 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. 

Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",73100,"['machine learning', 'mysql', 'sql']"
Applied AI/ML Data Engineer,Intuitive Surgical,CA,Full-time,"
Company Description At Intuitive, we are united behind our mission: we believe that minimally invasive care is life-enhancing care. Through ingenuity and intelligent technology, we expand the potential of physicians to heal without constraints.
 
 As a pioneer and market leader in robotic-assisted surgery, we strive to foster an inclusive and diverse team, committed to making a difference. For more than 25 years, we have worked with hospitals and care teams around the world to help solve some of healthcare's hardest challenges and advance what is possible.
 
 Intuitive has been built by the efforts of great people from diverse backgrounds. We believe great ideas can come from anywhere. We strive to foster an inclusive culture built around diversity of thought and mutual respect. We lead with inclusion and empower our team members to do their best work as their most authentic selves.
 
 Passionate people who want to make a difference drive our culture. Our team members are grounded in integrity, have a strong capacity to learn, the energy to get things done, and bring diverse, real world experiences to help us think in new ways. We actively invest in our team members to support their long-term growth so they can continue to advance our mission and achieve their highest potential.
 
 Join a team committed to taking big leaps forward for a global community of healthcare professionals and their patients. Together, let's advance the world of minimally invasive care.
  Job Description
 Primary Function:
 The Applied AI/ML Engineer plays a critical role in bringing Generative AI and Machine Learning (ML) solutions to Enterprise Analytics. These technologies offer transformative potential to optimize operations, generate valuable insights, and drive innovation, thus shaping our organization's future.
 The AI/ML Engineer will play a pivotal role in identifying, testing, and implementing scalable and cost-effective AI and ML solutions across the teams supported by Enterprise Analytics. Through maintaining, troubleshooting, and optimizing AI models, as well as developing business applications on top of them, this role will be instrumental in enhancing our organization's analytical capabilities. The role will work directly with business stakeholders, IT partners, enterprise data architects, data engineering, and external service providers to ensure that new capabilities meet the needs of the business and can support its growth.
 Roles and Responsibilities:

 Develop and maintain the infrastructure for incorporating and fine-tuning third-party AI NLP and/or Computer Vision models into the company's technology stack.
 Troubleshoot any integration issues and ensuring the seamless operation of the integrated models.
 Collaborate with stakeholders to understand the functional needs and fine-tune and/or train AI models to improve their performance on specific tasks.
 Build end-to-end ML Ops pipelines, including AI applications. Maintain, troubleshoot, and optimize ML and AI models in production environment, monitor models’ performance.
 Build business applications on top of AI models, work with a team of engineers to develop and deploy ML solutions.

 Qualifications

 Minimum Bachelor's degree or Master's degree in Computer Science, Data Science, or a related field
 A minimum 6+ years of experience in machine learning, with a strong understanding of the latest ML research and technologies
 Strong knowledge and experience with LLMs/Generative AI models
 Strong programming skills in Python (3+ years), SQL
 Experience with a variety of ML frameworks and libraries, such as PyTorch, TensorFlow, and scikit-learn
 Familiarity with open-source LLM/CV models and platforms, such as Hugging Face, LangChain, etc
 Proficiency with cloud platforms such as Microsoft Azure, Google Cloud or AWS
 Familiarity with a cloud-based data warehousing platform such as Snowflake and data analytics platforms such as Databricks
 Strong problem-solving skills
 Strong communication skills

 #LI-Hybrid
 Additional Information

 Due to the nature of our business and the role, please note that Intuitive and/or your customer(s) may require that you show current proof of vaccination against certain diseases including COVID-19. Details can vary by role.
 Intuitive is an Equal Employment Opportunity Employer. We provide equal employment opportunities to all qualified applicants and employees, and prohibit discrimination and harassment of any type, without regard to race, sex, pregnancy, sexual orientation, gender identity, national origin, color, age, religion, protected veteran or disability status, genetic information or any other status protected under federal, state, or local applicable laws.
 We will consider for employment qualified applicants with arrest and conviction records in accordance with fair chance laws.
 Preference will be given to qualified candidates who do not reside, or plan to reside, in Alabama, Arkansas, Delaware, Florida, Indiana, Iowa, Louisiana, Maryland, Mississippi, Missouri, Oklahoma, Pennsylvania, South Carolina, or Tennessee.
 We provide market-competitive compensation packages, inclusive of base pay, incentives, benefits, and equity. It would not be typical for someone to be hired at the top end of range for the role, as actual pay will be determined based on several factors, including experience, skills, and qualifications. The target salary ranges are listed.
 Base Salary Range Region 1:$167,000 - $240,200 Base Salary Range Region 2: $141,900 - $204,300 Shift: Day Travel: None Workplace Type: Purposeful Onsite - This job requires being onsite for leader-defined events and activities which could be monthly/annually. Onsite frequency may increase based on business need.
",141900,"['tensorflow', 'pytorch', 'python', 'machine learning', 'aws', 'azure', 'sql']"
Lead Data Scientist,McKesson,TX,Full-time,"
 McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve - we care. What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow's health today, we want to hear from you.
 

Position Description
:

 McKesson Technology Enterprise Analytics is seeking a Lead Data Scientist that is passionate about developing machine learning applications that ensure patients receive the medications they need, when they need them; improve quality of care for oncology patients; and exemplify operational excellence so that the business can focus on what matters most, creating value for our customers.
 

Key responsibilities: 


Develop, design, build, and oversee data science solutions to provide predictive insights that further McKesson's vision to improve care in every setting.
 Drive adoption of best-in-class capabilities, including Deep Learning, Natural Language Processing, Large Language Models and Next Best Action Recommenders.
 Direct in-house data scientists and consulting teams; Provide analytics leadership; Provide machine learning and statistical expertise. Serve as an advisor for data scientists across the Enterprise.
 Collaborate with multi-disciplinary team members (data scientists, data engineers and business analysts); Manage business stakeholder relationships to drive action and value from data science insights.
 Collaborate with multi-disciplinary team members; Manage business stakeholder relationships to drive action and value from data science insights;
 Recruit top talent data scientists to join our team.
 Communicate strategy and results to technical and non-technical audiences; Develop and maintain strong relationships with key stakeholders, partners, and internal clients.
 Solve problems from the business point of view, define KPIs, build and execute solid analytics work plans, gather and organize large and complex data assets, perform relevant analyses (data exploration and statistical modeling), automate work streams, foster teamwork in interactions, develop client relationships with business stakeholders, and communicate hypotheses and findings in a structured way.


 Minimum Requirements
:


 Master's degree +6 years of work experience or PhD +3 years, with relevant experience providing advanced analytics solutions The degree should be in computer science, applied mathematics, statistics, machine learning, or a related data centric-technical field.


 Critical Skills
:


 Mentorship experience with machine learning engineers/data scientists in business or scientific research settings.
 Industry experience using TensorFlow, Pytorch and open source software libraries to develop Representation Machine Learning Systems; e.g. Next-Best-Action, Recommendation systems; Deep Learning Neural Networks; Image understanding; Document classification and keyword extraction.
 Experience in core data science and predictive analytics methods: Statistics (t-tests, Poisson process), Segmentation and clustering techniques, predictive modeling: e.g. regression, classification, Time Series analysis: e.g. ARIMA, Traditional machine learning methods: e.g. Random Forest, ensemble model techniques, Optimization: e.g. linear programming.
 Experience in SQL, relational databases: e.g. Snowflake, HANA, Microsoft SQL.
 Expert level skill in a programming language: Python + additional languages (e.g. Java, C/C++).
 Experience with Linux, Shell scripting: e.g. Bash.
 Familiarity with a data visualization tool: e.g. Tableau, Power BI, R.
 Ability to process and synthesize complex data.
 Ability to communicate effectively and professionally, delivering impactful solutions and presenting work in a concise and thoughtful manner.


 Desired Skills
:


 Experience with cloud computing data platforms: e.g. Azure, GCP.
 Experience with distributed computing: e.g. Hadoop, Spark.
 Experience developing open-source machine learning libraries.
 Desire to work in a project-based environment to address business .issues and implement business solutions..
 Driven by making impact with technical and data science expertise, acute strategic and analytical skills; Highly organized with the ability to multitask and prioritize workload.
 Self-motivated, demonstrated ability to manage engagements, serve as a champion of Data Science and able to act as a full member of project team.
 Experience in applied analytics for business problem solving, demand forecasting, analytics solution for pricing, loyalty program effectiveness, customer segmentation, customer LTV maximization, cost and profit analysis, CRM management etc.

 At McKesson, we care about the well-being of the patients and communities we serve, and that starts with caring for our people. That's why we have a Total Rewards package that includes comprehensive benefits to support physical, mental, and financial well-being. Our Total Rewards offerings serve the different needs of our diverse employee population and ensure they are the healthiest versions of themselves. For more information regarding benefits at McKesson, please click here.
 
 As part of Total Rewards, we are proud to offer a competitive compensation package at McKesson. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered.
 

Our Base Pay Range for this position

 $147,500 - $245,800
 

McKesson is an Equal Opportunity/Affirmative Action employer. 

 All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.Qualified applicants will not be disqualified from consideration for employment based upon criminal history.
 
 McKesson is committed to being an Equal Employment Opportunity Employer and offers opportunities to all job seekers including job seekers with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to Disability_Accommodation@McKesson.com. Resumes or CVs submitted to this email box will not be accepted.
 
 Current employees must apply through the internal career site.
 

Join us at McKesson!
",147500,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'tableau', 'azure', 'gcp', 'sql', 'hadoop']"
"Manager, Drug Discovery AI",NVIDIA,CA,Full-time,"

  NVIDIA is using the power of high performance computing and AI to accelerate digital biology. We are seeking passionate and hardworking individuals to help us realize our mission. As a Manager, you will lead a team focused on deep learning development for cheminformatics, virtual screening, and protein modeling. This position provides the opportunity to develop, productize, and deliver drug discovery AI technologies across Nvidia's BioNeMo platform.
 


   What You’ll Be Doing:
 



     Define the roadmap for the future internal and public releases of the BioNeMo projects: define deliveries and work packages, help synchronize the dependencies across the other teams, formulate benchmarks and key performance indicators.
   


     Drive the technical choices to build the new features of the drug discovery AI technology stack: leverage existing deep learning technologies, provide feedback on performance and compute requirements, design new integrated deep learning models adapted to the problems of drug discovery.
   


     Mentor and supervise a team of experts in deep learning applications in small molecule generation, protein sequence and structure models
   


     Collaborate with multiple other teams, including Drug Discovery AI teams, AI infrastructure teams, product management, and Nvidia Research.
   


     Help bring up end-to-end drug discovery AI solutions based on the Nvidia BioNeMo platform.
   



   What We Need To See:
 



     Excellent interpersonal and 5+ years of leadership experience.
   


     PhD in Computer Science, Computational Chemistry, Computational Biology, or relevant field for Drug Discovery AI, or equivalent experience
   


     10+ overall years of relevant industry experience
   


     Participated in designing and implementing modern deep learning algorithms in cheminformatics, virtual screening, and/or protein design
   


     Excellent communication, analysis and problem solving skills
   



   Ways To Stand Out From The Crowd:
 



     Have significant deep learning experience, especially with LLMs, graph-based and geometric deep learning for drug discovery use cases.
   


     Have published in major journals or conferences in a field relevant to deep learning and drug discovery.
   



   With competitive salaries and a generous benefits package, we are widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people in the world working for us and, due to unprecedented growth, our exclusive engineering teams are rapidly growing. If you're a creative and autonomous engineer with a real passion for technology, we want to hear from you.
 
 The base salary range is 216,000 USD - 414,000 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
 







          You will also be eligible for equity and 
         
          benefits
         . 
         NVIDIA accepts applications on an ongoing basis.








 NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.

",216000,['deep learning']
AI Engineer,Thunkable,NY,Full-time,"

  Role Overview
 


 Thunkable is on the lookout for a highly skilled software engineer with a passion for machine learning and a special focus on deep learning and generative AI. Our ideal candidate will be adept in working with Large Language Models (LLMs), and possess a strong foundation in programming languages such as Python and JavaScript/TypeScript. Experience with technologies like Langchain, Autogen, AutoGPT, and tools for code generation and completion will be highly valued.
 


 What you'll do
 


 Participate in the design, development, and integration of cutting-edge machine learning techniques within the Thunkable platform, in partnership with product management, full-stack engineering, and design teams.
Establish use cases and devise evaluation methods & benchmarks for various approaches to support and enhance Thunkable’s products and user experiences.
Actively monitor and refine the performance and efficiency of live ML systems.
Keep abreast of the latest trends and breakthroughs in machine learning, NLP, and adjacent domains to maintain our edge in innovation.
Mentor team members, fostering AI literacy and thought leadership within the company.
Research developments in LLMs and generative AI to identify opportunities for leveraging them to boost Thunkable’s capabilities.



 What you'll need
 


 A minimum of 5 years of experience as a Software Engineer or equivalent research experience.
Strong grasp of core web technologies.
Proven ability to dissect and resolve complex software development issues across diverse components.
Excellent problem-solving acumen with the capability to articulate intricate ideas to both technical and non-technical audiences.
A history, if brief, of working with large language models and generative AI and associated techniques such as RAG, prompt management or fine tuning.
A strong advocate for ethical AI, prioritizing transparency and user-centric approaches
Advanced degree (Master’s or Ph.D.) in Computer Science, Engineering, Statistics, Mathematics, or a related field, or industry experience to match.
Proficiency in SQL, familiarity with large datasets, and experience with cloud platforms like AWS or GCP.



 Bonus Points
 

Deep understanding of deep learning, reinforcement learning, and NLP.
Experience in handling and analyzing large datasets with statistical and machine learning techniques.
Knowledge in the design of experiments, survey design, and large-scale AB testing.
Technical knowledge in Deep Learning, particularly in Generative AI (e.g., GANs, GPT models).Familiarity with Multi-modal ML, Graph ML, and/or Reinforcement Learning.
Contributions to technical articles and presentations at Engineering/ML conferences are advantageous.
Experience developing and training models in PyTorch is ideal.



 Life at Thunkable
 


 Thunkable is on a mission to democratize app development and empower everyone to build without writing a single line of code. Our platform enables anyone to build and publish their iOS and Android apps for free. Today, non-engineers use Thunkable to prototype and share new ideas, develop proofs-of-concept for their own digital business, and design and ship their own ad-supported and premium apps. Thunkable was incubated at Google Research and MIT.
 


 We are backed by Lightspeed, NEA, Owl Ventures, SV Angel, Zhenfund, and Y-Combinator. Our founders are MIT engineers who want to extend the power and fun of creation to people who don’t code.
 

   Joining Thunkable means joining a team of passionate, entrepreneurial and friendly people with different backgrounds, shared ideas, and similar goals.
 


 What will you get when joining our team?
 


 Get compensated: We offer competitive pay, equity and benefits to our employees based on their location. You’ll get access to unlimited PTO regardless of your location.
Wellness and Training Budget: We value your well-being and want to invest in it.
Work Where You Want: The company is based in San Francisco (with an office), but operates globally, with team members working across a number of cities, countries, and time zones (to facilitate async work we prioritize countries and locations in a max 2h time zone difference from those hubs: San Francisco, New York and Dublin)
Shared values: Creativity, Openness, Transparency, Persistence, and Entrepreneurialism.
Challenge yourself by acquiring new abilities, interacting with clients, enhancing products, or learning design. We will encourage you to reach your full potential.



 We believe that a diverse and inclusive workplace helps ensure we learn from each other’s different backgrounds, experiences, and perspectives and is critical for building a product that supports the wide range of our users’ needs. Thunkable is an equal opportunity employer and a pleasant and supportive place to work. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply.



 This position offers a competitive salary that is based on a combination of factors including location. The salary range for this role in San Francisco is between $160,000 and $190,000 per year and will be based on qualifications and skills. If the successful candidate is located in a different location or country, the salary may vary based on the cost of living, currency and other local factors. We are open to discussing salary with candidates who are interested in the role and may be willing to negotiate based on the candidate's experience and qualifications. We are committed to paying our employees fairly and providing opportunities for professional growth and development.

",160000,"['pytorch', 'python', 'machine learning', 'deep learning', 'aws', 'gcp', 'sql']"
Data Scientist,KBR,MD,Full-time,"
Title: Data Scientist
 
 KBR is looking to add a Data Scientist with Natural Language Processing (NLP) & BI tools experience to our team. Due to contract requirements, candidates must be US Citizens and hold an active/current D.O.D Secret clearance. 

In this role, you will...

 Discover NLP approaches to deliver insights and develop predictive models to meet customer needs.
 Utilize standard data science approaches such as data ingest, ETL, preprocessing, model building, model deploying, and monitoring models once deployed.
 Demonstrate experience working with raw data by processing and ingesting it into a database, cleaning it to be fed into a model, deploying it for some application, and explaining findings clearly to a general audience.
 Troubleshoot problems with data ingesting and processing
 Contribute to research and identification of the most accurate model architecture for current problems.
 Collaborate in data science meetings by presenting on theoretical or applied data science topics.
 Demonstrate the ability to troubleshoot in cloud environments such as AWS, Azure, and Google Cloud.
 Familiarity with machine learning platforms, such as CDSW
 Develop visualizations to convey meaningful insights.
 Present insights from models to a non-technical crowd to convey findings
 Suggest meaningful approaches, models, and services to address problems.
 Stay informed about trends and recent capabilities within data science.


 Required Education, Skills, & Experience
 Education: A bachelor's degree in data science, statistics, computer science, or a related quantitative field.
 Clearance: Active/Current D.O.D Secret Clearance
 Experience: 2 years of relevant work experience

 Proficient in Python; other equivalent languages are considered.
 Experience with BI tools such as QlikSense, Tableau, PowerBI, Zoomdata, etc.
 Experience in NLP approaches, machine learning techniques, and neural networks
 Competent in using SQL and other relational database query languages


 Highly Desired Education, Skills, & Experience
 Education: Masters in data science, statistics, computer science, or a related quantitative field.
 Experience/Skills:

 Excellent communication skills
 Exposure to one more neural network framework – Tensorflow, Torch/ PyTorch, ONNX, etc
 Previously worked with distributed computing environments such as Hadoop.


 Contract Requirements Regarding Education And Experience Will Prevail.
 Salary range: $86K-$110K  When you become part of the KBR team, your career opportunities are endless. Our people are the heart of everything we do here at KBR. We Value our People!  KBR offers a selection of competitive lifestyle benefits, which could include a 401K plan with company match, medical, dental, vision, life insurance, AD&D, flexible spending account, disability, paid time off, or flexible work schedule. We support career advancement through professional training and development.  At KBR, we are passionate about our people, sustainability, and Zero Harm culture. These ideals form all that we do and are at the heart of our commitment to, and ongoing journey toward, being a more inclusive and diverse company. That commitment is central to our team of team’s philosophy and fosters an environment of real collaboration across cultures and locations. Our individual differences and perspectives enhance our teams' value and help us develop solutions for the most challenging problems. We understand that embracing those differences and working together makes us more innovative, resilient, and safer. We Deliver — Together.

 KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.

",86000,"['tensorflow', 'pytorch', 'python', 'machine learning', 'tableau', 'aws', 'azure', 'etl', 'sql', 'hadoop']"
"GenAI Machine Learning Engineer, Performance Optimization",Databricks,CA,Full-time,"
P-984
 Founded in late 2020 by a small group of machine learning engineers and researchers, MosaicML enables companies to securely fine-tune, train and deploy custom AI models on their own data, for maximum security and control. Compatible with all major cloud providers, the MosaicML platform provides maximum flexibility for AI development. Introduced in 2023, MosaicML’s pretrained transformer models have established a new standard for open source, commercially usable LLMs and have been downloaded over 3 million times. MosaicML is committed to the belief that a company’s AI models are just as valuable as any other core IP, and that high-quality AI models should be available to all.
 Now part of Databricks since July 2023, we are passionate about enabling our customers to solve the world's toughest problems — from making the next mode of transportation a reality to accelerating the development of medical breakthroughs. We do this by building and running the world's best data and AI platform so our customers can use deep data insights to improve their business. We leap at every opportunity to solve technical challenges, striving to empower our customers with the best data and AI capabilities.
 You will:

Explore and analyze performance bottlenecks in ML training and inference
Design, implement and benchmark libraries and methods to overcome aforementioned bottlenecks
Build tools for performance profiling, analysis, and estimation for ML training and inference
Balance the tradeoff between performance and usability for our customers
Facilitate our community through documentation, talks, tutorials, and collaborations
Collaborate with external researchers and leading AI companies on various efficiency methods

We look for:

Hands on experience the internals of deep learning frameworks (e.g. PyTorch, TensorFlow) and deep learning models
Experience with high-performance linear algebra libraries such as cuDNN, CUTLASS, Eigen, MKL, etc.
General experience with the training and deployment of ML models
Experience with compiler technologies relevant to machine learning
Experience with distributed systems development or distributed ML workloads
Hands on experience with writing CUDA code and knowledge of GPU internals (Preferred)
Publications in top tier ML or System Conferences such as MLSys, ICML, ICLR, KDD, NeurIPS (Preferred)

We value candidates who are curious about all parts of the company's success and are willing to learn new technologies along the way.



 Pay Range Transparency

      Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.
    



     Local Pay Range
   

     $150,000—$190,000 USD
   



 About Databricks
 Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.
 Our Commitment to Diversity and Inclusion
 At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.
Compliance

    If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.
  

",150000,"['tensorflow', 'pytorch', 'machine learning', 'deep learning', 'apache spark']"
Sr. Data Engineer,"The Travelers Companies, Inc.",CT,Full-time,"












































































































                                                                                                             Who Are We?
                                                                                                            









































































                                      Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
                                    








































































                                      Job Category
                                    


































 Technology
 

   Compensation Overview
 

   The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
 


   Salary Range
  $138,100.00 - $227,800.00
 




































                                      Target Openings
                                    


































 1
 












































































































                                                                                                              What Is the Opportunity?
                                                                                                            










































































































 Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Senior Data Engineer you will accelerate growth and transformation of our analytics landscape. You will bring a strong desire to guide team members' growth and develop data solutions that translate complex data into user-friendly terminology. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights.
 
   What Will You Do?
 

 Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions.
 Design complex data solutions, including incorporating new data sources and ensuring designs are consistent across projects and aligned to data strategies.
 Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
 Incorporate core data management competencies including data governance, data security and data quality.
 Act as a data and technology subject matter expert within lines of business to support delivery and educate end users on data products/analytic environment.
 Perform data and system analysis, assessment and resolution for defects and incidents of high complexity and correct as appropriate.
 Collaborate across team to support delivery and educate end users on complex data products/analytic environment.
 Perform other duties as assigned.


   What Will Our Ideal Candidate Have?
 

 Bachelor’s Degree in STEM related field or equivalent
 Ten years of related experience
 Advanced knowledge of tools, techniques, and manipulation including cloud platforms, programming languages, and modern software engineering practices.
 Strong delivery skills including the ability to determine the software design strategy and methodology to be used for efforts, use automated tests, analysis, and informed feedback loops to ensure the quality and production readiness of work before release, monitor the health of work efforts and that of adjacent systems.
 Demonstrated track record of domain expertise including the ability to develop business partnerships and influence priorities by identifying solutions that are aligned with current business objective and closely follow industry trends relevant to domain, understanding how to apply them, and sharing knowledge with coworkers.
 Strong problem solver who utilizes data and proofs of concepts to find creative solutions to difficult problems involving a significant number of factors with broad implications, reflects on solutions, measures impact, and uses that information to ideate and optimize.
 Excellent communication skills with the ability to develop business partnerships, describe technology concepts in ways the business can understand, document initiatives in a concise and clear manner, and empathetically and attentively listen to others thoughts and ideas.
 Ability to lead and take action even when there is no clear owner, inspire and motivate others, and be effective at influencing team members.
 Experience with some of the following tools & platforms (or similar): AWS (s3, Lambda, Kinesis, API Gateway, IAM, Glue, SNS, SQS, EventBridge, EKS, VPC, Step Functions, ECS/EKS, DynamoDB, etc.), Databricks, Python, JavaScript, Kafka, dbt, Terraform, Snowflake, SQL, Jenkins, Github, Airflow, OpenSearch (Elasticsearch & Kibana), Talend, Alation, Neo4j, Hashicorp Vault / AWS Secrets Manager, Docker / OpenShift / Open Cloud Foundry, MongoDB, Docker, BlackDuck, SonarQube.
 Knowledge and experience with the some of the following concepts: Real-time & Batch Data Processing, Workload Orchestration, Cloud, Datalakes, Data Security, Networking, Serverless, Testing/Test Automation (Unit, Integration, Performance, etc.), WebServices, DevOps, Logging, Monitoring, and Alerting, Containerization, Encryption / Decryption, Data Masking, Cost & Performance Optimization.



   What is a Must Have?
 

 Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
 Five years of data engineering or equivalent experience.



   What Is in It for You?
 

 Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
 Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
 Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
 Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
 Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.






































                                      Employment Practices
                                    

                                      Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.
                                    

 If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an 
                                     
                                      email
                                      so we may assist you.
                                    

 Travelers reserves the right to fill this position at a level above or below the level included in this posting.
                                    













































                                                                                 To learn more about our comprehensive benefit programs please visit 
                                                                                
                                                                                 http://careers.travelers.com/life-at-travelers/benefits/
                                                                                .
                                                                               














































































",138100,"['python', 'machine learning', 'aws', 'docker', 'sql', 'airflow', 'kafka']"
Hewlett Packard Labs - Machine Learning Research Scientist,Hewlett-Packard CDS GmbH,CA,Full-time,"













This role has been designated as ‘’Onsite’ with an expectation that you will primarily work from an HPE office.






















 Who We Are:




























 Hewlett Packard Enterprise is the global edge-to-cloud company advancing the way people live and work. We help companies connect, protect, analyze, and act on their data and applications wherever they live, from edge to cloud, so they can turn insights into outcomes at the speed required to thrive in today’s complex world. Our culture thrives on finding new and better ways to accelerate what’s next. We know diverse backgrounds are valued and succeed here. We have the flexibility to manage our work and personal needs. We make bold moves, together, and are a force for good. If you are looking to stretch and grow your career our culture will embrace you. Open up opportunities with HPE.















 Job Description:

 The AI research team at Hewlett Packard Labs seeks highly qualified, self-motivated researchers to accelerate research toward Reinforcement Learning and Machine Learning applications in the area of sustainability, digital twins, LLMs, the trustworthiness of AI, complex scientific applications like nuclear fusion, sports analytics, and other domains. This position is for the core AI research team at Hewlett Packard Labs.

 Hewlett Packard Labs is an internationally renowned research organization with its headquarters and largest facility in Milpitas, California, in the San Francisco Bay area. As the central research organization for Hewlett Packard Enterprise (HPE), Hewlett Packard Labs' purpose is to deliver breakthrough technologies and technology advancements that provide a competitive advantage for the company, by investing in fundamental science and technology in areas of interest to HPE and getting the resulting technologies ready for adoption into new and existing markets.

 The Artificial Intelligence Research Lab focuses on researching and developing technologies, architectures, and software to develop cutting-edge solutions in key areas of Deep Learning and Machine Learning, including Reinforcement Learning. This team focuses on complex multi-objective and multi-agent Reinforcement Learning with innovative applications to sustainability at scale, complex clean energy generation, nuclear fusion, and similar complex problems. The team also works on the robustness and explainability of models, 2D and 3D computer vision, and NLP / LLMs. There is work related to the use of reinforcement and transformers for model free optimizations. The team also works on fine tuning and self-correction of LLMs and all aspect of trust of LLMs. This is a unique opportunity to work at a start-up pace within a big company. We are looking for an entrepreneurial mind-set, and a deep passion to take a ML problem and conduct research and come up with a solution with a fast turnaround time. You will have an opportunity to work with Machine Learning experts who have made multiple successful products and get guidance and coaching in different areas including software engineering, hardware optimizations, data pipelining, and innovations from the latest AI research to bring hardened Deep Learning solutions to the real world. 

This is a new and growing team at HPE in which you will be building the software and applications for Neural Network and Machine Learning. It will also involve working with system programming, Deep Learning frameworks and models, GPU acceleration, Model optimization, real-time streaming data, distributed computing, and deployment.

 We are seeking highly qualified candidates to come join one of our research teams as an intern or a post-doc, with the possibility of longer-term co-innovation and collaboration. We are particularly interested in individuals with a background in computer systems, machine learning, deep learning, and statistics, with a good understanding of the current state of the art, major trends and opportunities, and a demonstrated track record in making things real in innovative ways. The ideal candidate combines this interest with a broad, entrepreneurial interest in creating the next generation of HPE’s products and technologies.

 We expect all our researchers including interns and post-docs to provide thought leadership and technical influence both internally and externally to HPE, as well as take innovative ideas and make them real – contributing along the full range from initial novel ideas to design, development, implementation, evaluation, and technology transfer. The ideal candidate can thrive in an applied research environment, balancing significant technical and scientific contributions with the ability to bring such contributions to practice through innovative solutions that address the needs of our customers and partners. We expect the successful candidate to collaborate with Hewlett Packard Labs research teams as well as with external partners, and to work in alignment with HPE's broader innovation community. Excellent software systems building skills are a significant plus.

 Education and Experience 

PhD degree (with significant research and innovation experience) in a relevant discipline (e.g. machine learning, computer science, statistics, etc.)
 Track record of world-class innovative contributions and ideas in machine learning.


 Technical Skills: 

Experience in emerging ML areas, including reinforcement learning and generative AI research
 Experience in developing ML software with high proficiency in data structures and algorithms.
 Experience in Machine Learning frameworks like PyTorch - required
 Strong programming skills and experience with Python
 Software development experience in Deep Learning, GPU acceleration, and Model Optimization.
 Demonstrated ability to generate, frame, and carry out leadership research as shown, for example, by papers published in top-tier ML conferences or journals.









 Additional Skills:






 Accountability, Accountability, Action Planning, Active Learning, Active Listening, Bias, Business, Calendar Management, Coaching, Computer Literacy, Creativity, Critical Thinking, Design Thinking, Empathy, Follow-Through, Growth Mindset, Intellectual Curiosity, Long Term Planning, Managing Ambiguity, Office Administration, Policy and procedures, Problem Solving, Project Management, Recordkeeping, Risk Assessment {+ 5 more}
      







 What We Can Offer You:







 Health & Wellbeing
 We strive to provide our team members and their loved ones with a comprehensive suite of benefits that supports their physical, financial and emotional wellbeing.

 Personal & Professional Development
 We also invest in your career because the better you are, the better we all are. We have specific programs catered to helping you reach any career goals you have — whether you want to become a knowledge expert in your field or apply your skills to another division.

 Diversity, Inclusion & Belonging
 We are unconditionally inclusive in the way we work and celebrate individual uniqueness. We know diverse backgrounds are valued and succeed here. We have the flexibility to manage our work and personal needs. We make bold moves, together, and are a force for good.








 Let's Stay Connected:





















 Follow @HPECareers on Instagram to see the latest on people, culture and tech at HPE. 















Job: Administration
       Job Level: N/A
      
 States with Pay Range Requirement

 The expected salary/wage range for a U.S.-based hire filling this position is provided below. Actual offer may vary from this range based upon geographic location, work experience, education/training, and/or skill level. If this is a sales role, then the listed salary range reflects combined base salary and target-level sales compensation pay. If this is a non-sales role, then the listed salary range reflects base salary only. Variable incentives may also be offered. Information about employee benefits offered can be found at https://myhperewards.com/main/new-hire-enrollment.html.
 Hourly: $53.00 - $64.25
      







 HPE is an Equal Employment Opportunity/ Veterans/Disabled/LGBT and Affirmative Action employer. We are committed to diversity and building a team that represents a variety of backgrounds, perspectives, and skills. We do not discriminate and all decisions we make are made on the basis of qualifications, merit, and business need. Our goal is to be one global diverse team that is representative of our customers, in an inclusive environment where we can continue to innovate and grow together. Please click here: Equal Employment Opportunity.







 Hewlett Packard Enterprise is EEO F/M/Protected Veteran/ Individual with Disabilities.

 HPE will comply with all applicable laws related to employer use of arrest and conviction records, including laws requiring employers to consider for employment qualified applicants with criminal histories. .






",106000,"['pytorch', 'python', 'machine learning', 'deep learning']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
USGS Data Integration Fellowship at the Alaska Climate Adaptation Science Center,U.S. Department of the Interior (DOI),AK,Full-time,"




Organization


     U.S. Department of the Interior (DOI) 
    



Reference Code


     DOI-USGS-2023-15 
    



How to Apply


Connect with ORISE...on the GO! Download the new ORISE GO mobile app in the Apple App Store or Google Play Store to help you stay engaged, connected, and informed during your ORISE experience and beyond!
A complete application package consists of:

An application
Transcript(s) – For this opportunity, an unofficial transcript or copy of the student academic records printed by the applicant or by academic advisors from internal institution systems may be submitted.
A current resume/CV
Two educational or professional recommendations.

All documents must be in English or include an official English translation.




Application Deadline


     1/5/2024 3:00:00 PM Eastern Time Zone 
    



Description



Applications will be reviewed on a rolling-basis.

USGS Office/Lab and Location: A research opportunity is currently available with the U.S. Geological Survey (USGS) at the Alaska Climate Adaptation Science Center (AKCASC) located in Anchorage or Fairbanks, Alaska. Remote participation is a possibility.
The USGS mission is to monitor, analyze, and predict current and evolving dynamics of complex human and natural Earth-system interactions and to deliver actionable intelligence at scales and timeframes relevant to decision makers. As the Nation's largest water, earth, and biological science and civilian mapping agency, USGS collects, monitors, analyzes, and provides science about natural resource conditions, issues, and problems.
The Alaska Climate Adaptation Science Center (AKCASC) is a federal-university partnership between the USGS and the University of Alaska system. Research and administration is located at University of Alaska Fairbanks (Fairbanks, AK), University of Alaska Southeast (Juneau, AK), and USGS (Anchorage, AK). Established in 2010, the Alaska CASC is Congressionally mandated to meet state and federal needs around climate impacts, adaptation, and resilience. Hosted by UAF's International Arctic Research Center with a USGS-hosted office in Anchorage, the Alaska CASC provides scientific information, tools, and techniques that managers and others interested in land, water, wildlife, and cultural resources can use to adapt to climate change. https://akcasc.org/
Research Project: Our research directions are determined by representatives of federal, state, tribal, and regional organizations. We aim to meet high-level climate science priorities while ensuring this science also is pertinent to and addresses management needs. We create and use high-resolution climate models and derivative products to help project ecological and population responses at national, regional, and local scales. We integrate physical climate models with ecological, habitat, and population response models. We develop methods to assess vulnerability of species, habitats, and human communities. We develop standardized approaches to modeling, monitoring, data management and decision support.
The selected participant will assist in the development of quantitative climate and ecological scenarios, including climate impacts modeling and summary products, derived from existing high-resolution climate data and projections. Participant will leverage existing capacity that develops climate impacts information on climate-driven environmental changes in Alaska, northwest Canada, and the Arctic. Results of this research will fill important gaps in understanding of climate-driven impacts in Alaska and be used to support adaptation planning and dialogue with natural and cultural resource managers. Project funding for two years is available.
Learning Objectives: The objective is to help the AKCASC provide climate information to collaborators and managers and refine that information to meet agency management and decision-making needs. Through this fellowship, the participant will have the opportunity to: co-develop foundational data sets and derived information to support and communicate research on regional climate impacts in Alaska and the Arctic; gain experience developing actionable science tailored to the needs of federal and non-federal decision makers and researchers; and gain valuable experience being a part of a partnership-driven program within a federal science agency.
Mentor: The mentor for this opportunity is Jeremy Littel (jlittell@usgs.gov). If you have questions about the nature of the research please contact the mentor.
Anticipated Appointment Start Date: January 2024. Start date is flexible and will depend on a variety of factors.
Appointment Length: The appointment will initially be for one year but may be extended upon recommendation of USGS and is contingent on the availability of funds.
Level of Participation: The appointment is full-time.
Participant Stipend: The participant will receive a monthly stipend based on education and experience. The current stipend range for this opportunity is $51,332 - $77,898 per year plus an additional travel and supplies allowance.
Citizenship Requirements: This opportunity is available to U.S. citizens and Lawful Permanent Residents.
ORISE Information: This program, administered by ORAU through its contract with the U.S. Department of Energy (DOE) to manage the Oak Ridge Institute for Science and Education (ORISE), was established through an interagency agreement between DOE and USGS. Participants do not become employees of USGS, DOE or the program administrator, and there are no employment-related benefits. Proof of health insurance is required for participation in this program. Health insurance can be obtained through ORISE.
Questions: If you have questions about the application process please email USGS@orau.org and include the reference code for this opportunity.




Qualifications


The qualified candidate should have received a master's or doctoral degree in one of the relevant fields listed in the eligibility requirements section, or be currently pursuing one of the degrees with completion before January 1, 2024. Degree must have been received within the last five years.
Preferred Skills:

Background and capability in data science and statistical computing, scripting, including capability with multiple geospatial data production and analysis languages, frameworks, and technologies - such as R, Python, QGIS, GDAL, Julia, Pandas, Google Earth Engine, or similar - especially ability to process and analyze raster and NetCDF datasets
Expert analytical, troubleshooting, and critical thinking skills
Knowledge of, and ability to implement, scientific metadata standards and protocols
Knowledge of Quality Assurance / Quality control as it applies to geospatial scientific datasets and analysis
Knowledge of Linux filesystems (or similar, as appropriate) able to manage data and execute processing code on clusters/processing node desired but not required
Experience analyzing climate data / projections and quantifying/modeling impacts responses desired but not required
Ability to work effectively and productively in digital collaboration and communication environments with teams of diverse professionals, possibly remotely
Expertise with time series analysis, spatial statistics, or hydrologic modeling desired but not required





Eligibility Requirements



Citizenship: LPR or U.S. Citizen
Degree: Master's Degree or Doctoral Degree received within the last 60 months or anticipated to be received by 1/1/2024 12:00:00 AM. 
Overall GPA: 3.50 
Discipline(s): 

Computer, Information, and Data Sciences
Earth and Geosciences
Environmental and Marine Sciences
Life Health and Medical Sciences
Social and Behavioral Sciences






",51332,"['python', 'pandas']"
"Staff Full Stack Software Engineer, Machine Learning Group",Qualcomm,CA,Full-time,"
Company: Qualcomm Technologies, Inc.
 
 Job Area: Engineering Group, Engineering Group > Machine Learning Engineering
 
 General Summary:
 In this position you will be responsible for assisting with the software design and development of the next generation Qualcomm Neural Processing SDK and associated tools. You will have the opportunity to show your passion for software design and development with your analytical, design, programming, and debugging skills.

 Responsibilities

 Design and develop intuitive, performant and rich user interfaces (IDE) for Qualcomm AI SW toolchains and applications.
 Interact with cross functional technology teams, understand requirements, and propose solutions.
 Take ownership in design and follow product lifecycle approaches to deliver features.
 Troubleshoot applications, fix bugs, and make enhancements for existing IDE / UI components.
 Participate in code and design reviews.


 Minimum Qualifications:

Bachelor's degree in Computer Science, Engineering, Information Systems, or related field and 4+ years of Hardware Engineering, Software Engineering, Systems Engineering, or related work experience. 
OR
  Master's degree in Computer Science, Engineering, Information Systems, or related field and 3+ years of Hardware Engineering, Software Engineering, Systems Engineering, or related work experience.
  OR
  PhD in Computer Science, Engineering, Information Systems, or related field and 2+ years of Hardware Engineering, Software Engineering, Systems Engineering, or related work experience.
 
 Preferred Qualifications:


 3+ years industry experience in building modern web based or desktop applications (ElectronJS or similar)
 Experience building various JavaScript graphs, plots, responsive and Realtime UI components.
 Experience with Bootstrap libraries, Javascript/Jquery, D3(or similar data visualization library), Angular (or comparable JavaScript framework) and Python
 Experience with web technologies/platforms like NodeJS, TypeScript, Ajax.
 Experience working with SASS (or comparable CSS extensions)
 Some experience with plugin development in IDEs such as Visual Studio Code, WebStorm, Eclipse, etc
 Good knowledge on various UI frameworks and design patterns.
 Ability to make complex technical and design decisions for building scalable UI applications.
 Some understanding of database application designs and implementation using MySQL/ MongoDB / Sqlite.
 Familiarity working with and writing REST API web services.
 Familiarity with web UI testing frameworks like Spectron, Jasmine, Selenium, Karma etc., and an overall emphasis on writing and maintaining unit and integration tests
 Programming/debugging skills in more than one programming languages (C/C++, Java, Python, JavaScript)
 Experience working with containerization technologies such as Docker
 Some experience working with deep learning models training / inference pipelines.
 Experience with one or more ML / AI frameworks (Tensorflow, Pytorch, OnnxRuntime, etc).
 Linux software development
 Experience with Android or other embedded systems and developing tools for embedded platforms.
 Ability to collaborate across a globally diverse team and multiple interests










 Although this role has some expected minor physical activity, this should not deter otherwise qualified applicants from applying. If you are an individual with a physical or mental disability and need an accommodation during the application/hiring process, please call Qualcomm’s toll-free number found here for assistance. Qualcomm will provide reasonable accommodations, upon request, to support individuals with disabilities as part of our ongoing efforts to create an accessible workplace.

 Qualcomm is an equal opportunity employer and supports workforce diversity.








 To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.
 EEO Employer: Qualcomm is an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or any other protected classification.

 Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law.

 Pay range: $148,500.00 - $222,500.00
 
 The above pay scale reflects the broad, minimum to maximum, pay scale for this job code for the location for which it has been posted. Even more importantly, please note that salary is only one component of total compensation at Qualcomm. We also offer a competitive annual discretionary bonus program and opportunity for annual RSU grants (employees on sales-incentive plans are not eligible for our annual bonus). In addition, our highly competitive benefits package is designed to support your success at work, at home, and at play. Your recruiter will be happy to discuss all that Qualcomm has to offer!

 If you would like more information about this role, please contact Qualcomm Careers.
",148500,"['tensorflow', 'pytorch', 'python', 'machine learning', 'deep learning', 'docker', 'mysql']"
"Generative Machine Learning Engineer, Senior",Booz Allen Hamilton,MD,Full-time,"


Job Description










         Location: 
        

         Bethesda,MD,US 
        



         Remote Work: 
        

         Hybrid 
        



         Job Number: 
        

         R0184200
        


















         Generative Machine Learning Engineer, Senior
          The Opportunity:
 As an experienced software engineer or data scientist, you know that Artificial Intelligence (AI), Machine Learning (ML), and Natural Language Processing (NLP), including Large Language Models (LLMs), are critical to understanding and processing massive datasets and informing humans on decision options at machine speed. We need your technical knowledge and problem-solving abilities to identify and develop opportunities for the use of AI, ML, and LLMs to solve real-world business and operational problems that help our clients meet their needs.

 In this role, you’ll help develop core technical capabilities that can lead to large impact across strategic clients and their customers, ultimately driving the adoption of GenAI solutions that address various mission needs. You’ll your knowledge with a large community of ML engineers across the firm and collaborate with data engineers, data scientists, solutions architects, systems engineers, and product owners to deliver world-class solutions. Your advanced consulting skills and extensive technical expertise will guide internal strategy and clients as they navigate the landscape of GenAI models, tools, and frameworks.

 Work with us to solve real-world challenges and define ML strategies for our federal clients.

 Join us. The world can’t wait.

 You Have:

 5+ years of experience with python development geared toward cloud solutions
 3+ years of experience operationalizing machine learning applications (MLOps)
 2+ years of experience applying LLMs and generative AI models, including transformers and GPT models
 Ability to become competent in branches of ML
 Ability to distill complex technical concepts into easily understood summaries consumable by business leaders with a non-technical background
 Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements
 Bachelor’s degree in CS, Mathematics, or Engineering


 Nice If You Have:

 Experience with finetuning LLMs
 Experience with API design, Containerization, or DevOps
 Experience managing or leading high-performing Agile teams
 Experience with methods for testing, evaluating, and governing ML models
 Experience with Human In The Loop (HITL) systems
 Experience with ML explainability metrics and responsible AI
 Experience with ML model life cycle processes and tools
 Knowledge of the considerations necessary for deploying ML models to compute-constrained hardware
 Master’s degree in CS, Mathematics, or Engineering


 Vetting:
 Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client.

 Create Your Career:

 Grow With Us
 Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

 A Place Where You Belong
 Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

 Support Your Well-Being
 Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

 Your Candidate Journey
 At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

 Compensation
 At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
 Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
         
 Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

 If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
 If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.


 EEO Commitment
 We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.









",93300,"['python', 'machine learning']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NM,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,OH,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Sr. Data Analyst,accelerate360,NY,Full-time,"
Sr. Data Analyst
A360 Media is looking for a Senior Data Analyst to join our team. We’re looking for a team member with experience to own our data analytics process. The ideal candidate will possess the consistent ability to derive insights for the business and successfully communicate these insights to all stakeholders through email, virtual and in person presentations 

Responsibilities:

Partner with editorial and audience development teams to build and maintain custom dashboards, reports, and data analysis decks and fulfill ad-hoc data requests through data visualization platforms (Looker Studio, Tableau, etc.) 
Build insights to inform audience development driving site session, engagement, audience growth and revenue 
Monitor and provide real-time tech and tag support of traffic fluctuations to the audience development team 
Create audience identity cohorts that segment users of digital content for sales, edit and marketing needs 
Merge multiple datasets, including (but not limited to) website data and social platforms 
Lead management of our javascript analytics tags, ensuring quality data collection across website interactions, including across distributed content sites 
Collaborate with internal teams from edit to social media managers to develop large-scale projects and performance reporting 
Lead initiatives focused on analytics implementation, customization, and automation of data collection processes. The ideal candidate will have solid analytics implementation experience across the life cycle and digital platforms (including web, responsive, and native apps) using Google Analytics and/or other partners 
Ensure that all analytical tracking tags are correctly configured to provide robust metrics and insights 
Train incoming employees on in-house analytics tools 
Independently prioritize analytical needs of team and business based on complexity, timing, and visibility 


Qualifications:

Minimum 3-5 years experience in analytics; media experience preferred 
BS, MBA, or Masters in statistics, mathematics, tech, engineering, analytics, or comparable areas preferred 
A solid understanding of the behavior of online visitors with experience in improving user experience and increasing page views and/or user engagement 


Experience in leading projects that include data wrangling and exploration 
Analytics tools: Big Query or similar SQL databases (a must), Google Analytics or Adobe Analytics (a must), Parse.ly or Chartbeat a plus, social analytics tools a plus 
Portfolio of data visualization work in Excel, Tableau, Plotly, Google Data Studio, Looker, or similar 
Extensive experience in Microsoft Excel (formulas, pivot tables, charts) 
SQL for relational databases and Javascript tag creation. Knowledge of graph databases and identity management of anonymous datasets is a plus 
Experience joining and analyzing multiple datasets 
Extensive data validation experience 
Great written and verbal communication skills, especially when presenting ideas to senior management 
Eagerness to present findings to multiple audiences 
Salary Range: $120k - $125k

",120000,"['tableau', 'sql']"
Applied AI/ML Data Engineer,Intuitive Surgical,CA,Full-time,"
Company Description At Intuitive, we are united behind our mission: we believe that minimally invasive care is life-enhancing care. Through ingenuity and intelligent technology, we expand the potential of physicians to heal without constraints.
 
 As a pioneer and market leader in robotic-assisted surgery, we strive to foster an inclusive and diverse team, committed to making a difference. For more than 25 years, we have worked with hospitals and care teams around the world to help solve some of healthcare's hardest challenges and advance what is possible.
 
 Intuitive has been built by the efforts of great people from diverse backgrounds. We believe great ideas can come from anywhere. We strive to foster an inclusive culture built around diversity of thought and mutual respect. We lead with inclusion and empower our team members to do their best work as their most authentic selves.
 
 Passionate people who want to make a difference drive our culture. Our team members are grounded in integrity, have a strong capacity to learn, the energy to get things done, and bring diverse, real world experiences to help us think in new ways. We actively invest in our team members to support their long-term growth so they can continue to advance our mission and achieve their highest potential.
 
 Join a team committed to taking big leaps forward for a global community of healthcare professionals and their patients. Together, let's advance the world of minimally invasive care.
  Job Description
 Primary Function:
 The Applied AI/ML Engineer plays a critical role in bringing Generative AI and Machine Learning (ML) solutions to Enterprise Analytics. These technologies offer transformative potential to optimize operations, generate valuable insights, and drive innovation, thus shaping our organization's future.
 The AI/ML Engineer will play a pivotal role in identifying, testing, and implementing scalable and cost-effective AI and ML solutions across the teams supported by Enterprise Analytics. Through maintaining, troubleshooting, and optimizing AI models, as well as developing business applications on top of them, this role will be instrumental in enhancing our organization's analytical capabilities. The role will work directly with business stakeholders, IT partners, enterprise data architects, data engineering, and external service providers to ensure that new capabilities meet the needs of the business and can support its growth.
 Roles and Responsibilities:

 Develop and maintain the infrastructure for incorporating and fine-tuning third-party AI NLP and/or Computer Vision models into the company's technology stack.
 Troubleshoot any integration issues and ensuring the seamless operation of the integrated models.
 Collaborate with stakeholders to understand the functional needs and fine-tune and/or train AI models to improve their performance on specific tasks.
 Build end-to-end ML Ops pipelines, including AI applications. Maintain, troubleshoot, and optimize ML and AI models in production environment, monitor models’ performance.
 Build business applications on top of AI models, work with a team of engineers to develop and deploy ML solutions.

 Qualifications

 Minimum Bachelor's degree or Master's degree in Computer Science, Data Science, or a related field
 A minimum 6+ years of experience in machine learning, with a strong understanding of the latest ML research and technologies
 Strong knowledge and experience with LLMs/Generative AI models
 Strong programming skills in Python (3+ years), SQL
 Experience with a variety of ML frameworks and libraries, such as PyTorch, TensorFlow, and scikit-learn
 Familiarity with open-source LLM/CV models and platforms, such as Hugging Face, LangChain, etc
 Proficiency with cloud platforms such as Microsoft Azure, Google Cloud or AWS
 Familiarity with a cloud-based data warehousing platform such as Snowflake and data analytics platforms such as Databricks
 Strong problem-solving skills
 Strong communication skills

 #LI-Hybrid
 Additional Information

 Due to the nature of our business and the role, please note that Intuitive and/or your customer(s) may require that you show current proof of vaccination against certain diseases including COVID-19. Details can vary by role.
 Intuitive is an Equal Employment Opportunity Employer. We provide equal employment opportunities to all qualified applicants and employees, and prohibit discrimination and harassment of any type, without regard to race, sex, pregnancy, sexual orientation, gender identity, national origin, color, age, religion, protected veteran or disability status, genetic information or any other status protected under federal, state, or local applicable laws.
 We will consider for employment qualified applicants with arrest and conviction records in accordance with fair chance laws.
 Preference will be given to qualified candidates who do not reside, or plan to reside, in Alabama, Arkansas, Delaware, Florida, Indiana, Iowa, Louisiana, Maryland, Mississippi, Missouri, Oklahoma, Pennsylvania, South Carolina, or Tennessee.
 We provide market-competitive compensation packages, inclusive of base pay, incentives, benefits, and equity. It would not be typical for someone to be hired at the top end of range for the role, as actual pay will be determined based on several factors, including experience, skills, and qualifications. The target salary ranges are listed.
 Base Salary Range Region 1:$167,000 - $240,200 Base Salary Range Region 2: $141,900 - $204,300 Shift: Day Travel: None Workplace Type: Purposeful Onsite - This job requires being onsite for leader-defined events and activities which could be monthly/annually. Onsite frequency may increase based on business need.
",141900,"['tensorflow', 'pytorch', 'python', 'machine learning', 'aws', 'azure', 'sql']"
Enterprise Data Architect/Scientist,"Prince George's County, MD",MD,Full-time,"


Nature and Variety of Work




Come join our team!


 Prince George’s County is the perfect family-friendly community. Encompassing almost 500 square miles and with over 900,000 residents, Prince George's County has an urban atmosphere that still manages to provide a scenic and peaceful place to live, work, and play.


We are Prince George’s Proud!


 About the Position:
    This is senior-level lead professional and technical software engineering work focused on data infrastructure and analytics technologies and methodologies. The incumbent will lead effort for a data management discipline inclusive of data architecture, data analytics, data science, and policy activities, and design, develop, and implement data models for enterprise and business agencies’ applications and systems.
   
 This individual will act as the primary advocate of data modeling methodologies and data science best practices, working with OIT governance, software engineering, GIS, and WEB technology practice areas, and with agencies for use and security of data assets, compliance with data use standards and agreements. Is lead for determining data tools, platforms, and solutions overseeing and evaluating vendor solutions supporting County data-driven government goals and initiatives. Work is performed under the general supervision of the Associate Director, with the strategic direction of the CIO. Work is evaluated in terms of adherence to County policies and regulations, attainment of goals, and overall contribution to departmental goals and objectives.
  


Examples of Work


What You'll Do:


 Develop data policies, strategies, and architecture with IT leaders, stakeholders, and industry defining the technologies and methodologies to be used in collecting, organizing, modeling, and reporting County information and data.
 Develop the data blueprints, framework, and data management roadmap for the enterprise and business agencies’ practice areas including reporting and compliance standards.
 Determine data reporting, analytics, and integration platforms, solutions, and tools that best fit county strategies and needs supporting data integration, statical analysis, AI, RPA, and program measurement.
 Establish processes for establishing and governing data classification, metadata structure, and context.
 Establish methods and procedures for data quality relevancy and equity.
 Assist in building a culture of data literacy, trust, and transparency, and efforts for data portal development.
 Evaluate and recommend governance, stewardship, and frameworks for managing data across the enterprise.
 Oversee the mapping of data sources, data movement, interfaces, and analytics, with the goal of safeguarding data integrity.
 Participate with agencies in developing methodologies for reports, dashboards, and analytics in their applications/systems/clouds; promote data management methodologies and standards.
 Select and recommend the appropriate tools, software, applications, and systems to support data technology goals.
 Collaborate with IT Project Architects, IT Project Managers, and Business Analysts for all data projects and efforts.
 Document the data architecture and environment to maintain a current and accurate view of the larger data picture.
 Identify and develop opportunities for data reuse, migration, or retirement.




Qualifications


What You'll Need:


 Master's degree in computer science, mathematics, business or public administration, or a closely related field,
 Plus four (4) years of experience in information technology programming, in which at least two (2) years must have involved lead/supervisory duties;
 Or an equivalent combination of education, training, and experience.

 Preferred Qualifications
:

 At least three (3) years of experience working with the following:
 o Structured and unstructured data
    o Common data science toolkits, such as R, NumPy, MatLab, etc.
    o Data visualization tools, such as Power BI, Altyrex, etc.
    o Consuming/exposing data in various ways.
   

 In-depth knowledge of a wide range of established and emerging data technologies
 Proven experience in implementation
 Solid understanding of data architecture and data modeling techniques
 Understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, Decision Forests, etc.
 Experience or working knowledge of AI, such as Salesforce Einstein, Microsoft Virtual Agent, etc.





Additional Information


CONDITIONS OF EMPLOYMENT: Upon selection, the candidate must:

 Must be willing to participate as an essential employee, when needed during emergency operations.
 Must possess and maintain a valid driver's license.

 DURATION OF ELIGIBILITY
: Candidates will be selected from a temporary register of eligible candidates, which will become effective approximately four (4) weeks after the closing date. Once a selection has been made, the register will expire.


ELIGIBILITY TO WORK:
 Under the Immigration Reform and Control Act of 1986, an employer is required to hire only U.S. citizens and lawfully authorized alien workers. Applicants who are selected for employment will be required to show and verify authorization to work in the United States.

 This employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S., only after an offer has been accepted and the Form I-9 is completed. For information on E-Verify, or if you believe the County has violated its E-Verify responsibilities, please contact the Department of Homeland Security (DHS) at 888-897-7781 or visit their website at dhs.gov/e-verify.
   

Internal Applicants:
 If you are a current Prince George's County Government employee and seeking a promotion, in accordance with Section 16-200 of the Personnel Law, you have the right to appeal a rejection rating within five (5) working days of receiving a rejection notice. Union employees should refer to their respective collective bargaining agreement and/or union representative for their grievance procedure.


 ONLY ONLINE APPLICATIONS WILL BE ACCEPTED


Prince George's County Government is an Equal Opportunity/Affirmative Action Employer Committed to Diversity in the Workplace




",119615,"['numpy', 'machine learning']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,AZ,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,NC,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,MO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,TX,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CO,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,HI,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
Senior Staff AI Data Engineer,Recruiting From Scratch,CA,Full-time,"


Who is 
Recruiting from Scratch 
: 


   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. 
  


   https://www.recruitingfromscratch.com/ 
  


This is a hybrid role based in our Palo Alto or San Francisco offices and will require you to be in office Tuesdays and Thursdays. 
What’s so interesting about this role? 
We believe that AI can revolutionize the dating industry. Our Data Engineer lead is responsible for building high quality ML datasets at scale, used to train ML models that power AI-centric features. In this pivotal role, you will have the opportunity to build foundational tools and data pipelines to ingest, normalize and clean the valuable data that would be fundamental for our ML engineers to build AI tools including recommendations, LLMs, ads, visual search, growth/notifications, trust and safety. 
What’s the job? 
We’re looking for an exceptional data engineer who is passionate about data for AI and values it can bring to our company, Who loves working with data ops at scale; and who is committed to the hard work necessary to continuously improve our ML data pipelines. 
In this position, you will be responsible for establishing and executing the strategy for our organization’s ML Data Engine, with an initial focus on agile ML Data OPs. This includes identification of infrastructure components and data stack to be used, design and implementation of pipelines between data systems and teams, automation workflows, data enrichment and monitoring tools all for AI models. As a tech lead specialized in data engineering, you are expected to code and contribute to the stack. 
Responsibilities: 

Dive into our dataset and design, implement and scale data pre/post processing pipelines of ML models 
Work on applied ML solutions in the areas of data mining, cleaning, normalizing and modeling 
Be self-motivated in seeking solutions when the correct path isn’t always known 
Collaborate with engineers in conceptualizing, planning and implementing data engineering initiatives working with different stakeholders 
Design and build data platforms & frameworks for processing high volumes of data, in real time as well as batch, that will be used across engineering teams 
Build data processing streams for cleaning and modeling text data for LLMs 
Research and evaluate new technologies in the big data space to guide our continuous improvement 
Collaborate with multi-functional teams to help tune the performance of large data applications 
Work with Privacy and Security team on data governance, risk and compliance initiatives 
Work on initiatives to ensure stability, performance and reliability of our data infrastructure 

What we’ll love about you 

Bachelors in Computer Science, Mathematics, Physics, or a related fields 
5+ years of experience as a data engineer building production-level pre/post-processing data pipelines for ML/DL models, including 2+ years of technical leadership experience 
Experience in statistical analysis & visualization on datasets using Pandas or R 
Experience designing and building highly available, distributed systems of data extraction, ingestion, normalization and processing of large data sets in real time as well as batch, that will be used across engineering teams using orchestration frameworks like Airflow, KubeFlow or other pipeline tools 
Demonstrated prior experience in creating data pipelines for text data sets NLP/ large language models 
Ability to produce well-engineered software, including appropriate automated test suites, technical documentation, and operational strategy 
Excellent coding skills in Python, Java, bash, SQL, and expertise with Git version control 
Experience using big data technologies (Snowflake, Airflow, Kubernetes, Docker, Helm, Spark, pySpark) 
Experience with any public cloud environment - AWS, GCP or Azure 
Significant experience with relational databases and query authoring (SQL) as well as NoSQL databases like DynamoDB etc 
Experience building and maintaining ETL (managing high-quality reliable ETL pipelines) 

We’ll really swoon if you have 

2+ years of experience of technical leadership in building data engineering pipelines for AI 
Previous experience in building data pipeline for conversational AI APIs and recommender systems 
Experience with distributed systems and microservices 
Experience with Kubernetes and building Docker images 


Experience with building stream-processing systems, using solutions such as Kafka, Storm or Spark-Streaming 
Strong understanding of applied machine learning topics 
Be familiar with legal compliance (with data management tools) data classification, and retention 
Consistent track record of managing and implementing complex data projects 


What you'll love about us 

Mission and Impact: We are the world-leading LGBTQ social networking service. Your role will impact the lives of millions of LGBTQ people around the world 
Multiple Locations: We are hiring someone for this role to be based ideally in San Francisco or Palo Alto 
Family Insurance: Insurance premium coverage for health, dental, and vision for you and partial coverage for your dependents 
Retirement Savings: Generous 401K plan with 6% match and immediate vest in the US 
Compensation: Industry-competitive compensation and eligibility for company bonus and equity programs 
Queer-Inclusive Benefits: Industry-leading gender-affirming offerings with up to 90% cost coverage, access to Included Health, monthly stipends for HRT, and more 
Additional Benefits: Flexible vacation policy, monthly stipends for cell phone, internet, wellness, and food, one-time home-office setup stipend, and company-sponsored events 


Base Pay Range 


     $160,000—$280,000 USD 
    




   https://www.recruitingfromscratch.com/
  

",160000,"['python', 'pandas', 'machine learning', 'aws', 'azure', 'docker', 'gcp', 'nosql', 'etl', 'sql', 'airflow', 'git', 'kafka', 'pyspark']"
